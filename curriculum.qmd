---
title: "ğŸ“Š Curriculum Complet"
subtitle: "Vue d'ensemble du programme Data Engineering"
---

## ğŸ¯ Parcours PÃ©dagogique

Ce bootcamp est structurÃ© en **3 niveaux progressifs**, conÃ§us pour vous emmener de zÃ©ro Ã  un niveau Senior Data Engineer.

```
DurÃ©e totale estimÃ©e : 
â”œâ”€â”€ ğŸŸ¦ Niveau 1 (DÃ©butant)      
â”œâ”€â”€ ğŸŸ© Niveau 2 (IntermÃ©diaire) 
â””â”€â”€ ğŸŸ¥ Niveau 3 (AvancÃ©)        
```

---

## ğŸŸ¦ Niveau 1 : DÃ©butant â€” Fondations

**Objectif** : Construire des bases solides en Python, SQL, et systÃ¨mes distribuÃ©s.

| # | Module | DurÃ©e | CompÃ©tences |
|:--|:-------|:-----:|:------------|
| 01 | Introduction au Data Engineering | 2h | RÃ´le du DE, Ã©cosystÃ¨me, architectures |
| 02 | Linux & Bash | 4h | Commandes, scripting, cron |
| 03 | Git & Versioning | 3h | Branches, merge, workflows |
| 04 | Python Fondamental | 6h | Syntaxe, structures, fichiers |
| 05 | Python Data Processing | 6h | POO, dÃ©corateurs, gÃ©nÃ©rateurs |
| 06 | Introduction BDD Relationnelles | 3h | Concepts, modÃ©lisation |
| 07 | SQL pour Data Engineers | 8h | RequÃªtes, jointures, optimisation |
| 08 | Introduction Big Data | 4h | Hadoop, HDFS, MapReduce |
| 09 | MongoDB | 4h | NoSQL, CRUD, agrÃ©gations |
| 10 | Elasticsearch | 4h | Recherche, indexation |
| 11 | Introduction PySpark | 6h | RDD, DataFrame, transformations |
| 12 | Orchestration de Pipelines | 4h | Concepts, scheduling |
| 13 | **Bonus** : FastAPI | 4h | API REST pour Data Engineers |

**ğŸ“¦ Projet DÃ©butant** : Pipeline CSV â†’ Nettoyage â†’ AgrÃ©gation â†’ Export

---

## ğŸŸ© Niveau 2 : IntermÃ©diaire â€” Industrialisation

**Objectif** : MaÃ®triser les technologies d'entreprise : Docker, Kubernetes, Lakehouse, Streaming.

| # | Module | DurÃ©e | CompÃ©tences |
|:--|:-------|:-----:|:------------|
| 14 | Docker pour Data Engineers | 6h | Images, containers, Compose |
| 15 | Kubernetes Fondamentaux | 6h | Pods, Deployments, Services |
| 16 | K8s pour Data Workloads | 4h | StatefulSets, volumes |
| 17 | Cloud Object Storage | 4h | S3, GCS, MinIO, IAM |
| 18 | Polars | 4h | High-performance DataFrames |
| 19 | High Performance Python | 4h | Profiling, optimisation |
| 20 | PySpark AvancÃ© | 8h | Partitioning, broadcast, UDF |
| 21 | Spark SQL Deep Dive | 6h | Catalyst, plans d'exÃ©cution |
| 22 | Spark on Kubernetes | 6h | Spark Operator, scaling |
| 23 | Table Formats (Delta, Iceberg) | 8h | ACID, Time Travel, MERGE |
| 24 | Kafka & Streaming | 6h | Producers, Consumers, Topics |
| 25 | Spark Structured Streaming | 6h | Watermarks, Windows |
| 26 | Orchestration Airflow | 6h | DAGs, Operators, XCom |
| 27 | dbt & Data Quality | 6h | Models, Tests, Great Expectations |
| 28 | CI/CD pour Data Pipelines | 4h | GitHub Actions, dÃ©ploiement |

**ğŸ“¦ Projet IntermÃ©diaire** : Pipeline E-commerce Olist (Kafka â†’ Spark â†’ Delta â†’ dbt)

---

## ğŸŸ¥ Niveau 3 : AvancÃ© â€” Architecture & Leadership

**Objectif** : Atteindre le niveau Senior Data Engineer / Architecte Data.

| # | Module | DurÃ©e | CompÃ©tences |
|:--|:-------|:-----:|:------------|
| 31 | Kubernetes Deep Dive | 8h | Prometheus, Grafana, Helm, ArgoCD |
| 32 | Messaging Systems | 6h | Kafka avancÃ©, RabbitMQ, Pulsar, Debezium |
| 33 | Spark & Scala Internals | 8h | Catalyst, Tungsten, AQE, optimisation |
| 34 | Apache Flink | 8h | Exactly-once, State, Flink SQL |
| 35 | MLOps pour Data Engineers | 6h | Feature Stores, MLflow |
| 36 | Data Governance & Security | 6h | IAM, RLS, Data Contracts, GDPR |
| 37 | Architectural Trade-Offs | 4h | FinOps, ADR, Capacity Planning |
| 38 | Technical Leadership | 4h | RFC, Design Reviews, Mentoring |
| 39 | Data Platform Design | 6h | Data Mesh, Lakehouse patterns |

**ğŸ“¦ Projet AvancÃ©** : Plateforme Data Multi-Tenant (K8s + Kafka + Flink + MLOps + Governance)

---

## ğŸ† CompÃ©tences par Niveau

```
                    DÃ©butant    IntermÃ©diaire    AvancÃ©
                    â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”€â”€â”€â”€â”€â”€
Python & SQL           â–ˆâ–ˆâ–‘â–‘â–‘        â–ˆâ–ˆâ–ˆâ–ˆâ–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
PySpark                â–ˆâ–‘â–‘â–‘â–‘        â–ˆâ–ˆâ–ˆâ–ˆâ–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Docker & K8s           â–‘â–‘â–‘â–‘â–‘        â–ˆâ–ˆâ–ˆâ–ˆâ–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Lakehouse              â–‘â–‘â–‘â–‘â–‘        â–ˆâ–ˆâ–ˆâ–ˆâ–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Streaming              â–‘â–‘â–‘â–‘â–‘        â–ˆâ–ˆâ–ˆâ–‘â–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Architecture           â–‘â–‘â–‘â–‘â–‘        â–ˆâ–ˆâ–‘â–‘â–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
Leadership             â–‘â–‘â–‘â–‘â–‘        â–‘â–‘â–‘â–‘â–‘           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
```

---

## ğŸ“ˆ Progression RecommandÃ©e

1. **Suivez l'ordre** des modules â€” ils sont conÃ§us pour Ãªtre sÃ©quentiels
2. **Faites tous les exercices** â€” la pratique est essentielle
3. **ComplÃ©tez les projets intÃ©grateurs** â€” ils valident vos compÃ©tences
4. **Prenez des notes** â€” crÃ©ez votre propre documentation
5. **ExpÃ©rimentez** â€” modifiez le code, cassez des choses, apprenez

---

## ğŸ“ Certification

Ã€ la fin de chaque niveau, vous serez capable de :

| Niveau | Vous pouvez... |
|--------|----------------|
| ğŸŸ¦ DÃ©butant | CrÃ©er des pipelines batch simples, manipuler des donnÃ©es avec Python/SQL/Spark |
| ğŸŸ© IntermÃ©diaire | DÃ©ployer des jobs Spark sur K8s, construire un Lakehouse, orchestrer avec Airflow |
| ğŸŸ¥ AvancÃ© | Architecturer une plateforme Data complÃ¨te, optimiser les performances, lead une Ã©quipe |

---

[ğŸš€ Commencer le Bootcamp](notebooks/beginner/01_intro_data_engineering.ipynb){.btn .btn-primary}
