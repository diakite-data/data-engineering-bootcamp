---
title: "Bootcamp Data Engineering â€“ From Zero to Hero"
format:
  html:
    toc: false
---

<div class="hero">

# ğŸš€ Bootcamp Data Engineering : From Zero to Hero  
### Devenez un Data Engineer opÃ©rationnel, Senior-Ready.

</div>

---

## ğŸ¯ Pourquoi choisir ce Bootcamp ?

Ce programme a Ã©tÃ© conÃ§u par et pour des Data Engineers, en se concentrant sur les **exigences rÃ©elles** du marchÃ© du travail. Nous transformons votre ambition en expertise pratique.

* âœ” **Expertise Industrielle :** MaÃ®trisez les outils modernes utilisÃ©s par les gÃ©ants de la Tech (Spark 3.x, Kafka, Docker, Kubernetes, dbt, Cloud multi-plateforme).
* âœ” **Architectures AvancÃ©es :** Devenez architecte de vos propres pipelines en comprenant les modÃ¨les Lakehouse (Delta/Iceberg), Medaillon, et les architectures Kappa/Lambda modernes. 
* âœ” **Focus Production :** DÃ©ployez des pipelines batch et streaming de bout en bout, de l'ingestion brute Ã  la table Gold optimisÃ©e.
* âœ” **Progression MesurÃ©e :** Le parcours est divisÃ© en trois niveaux clairs : **DÃ©butant â†’ IntermÃ©diaire â†’ AvancÃ©**, pour une montÃ©e en compÃ©tence garantie.

### ğŸ‘¥ Ã€ qui sâ€™adresse ce Bootcamp ?

* **Ã‰tudiants & DÃ©veloppeurs :** Vous voulez une porte d'entrÃ©e structurÃ©e dans le domaine de la Data Engineering.
* **Analystes BI :** Vous souhaitez migrer vers le Big Data, le Cloud et l'industrialisation des pipelines.
* **Professionnels :** Vous cherchez Ã  structurer, optimiser et gouverner une plateforme Data moderne en entreprise.

---

### ğŸ› ï¸ RÃ©sumÃ© des Technologies (Votre BoÃ®te Ã  Outils)

| Domaine | Outils & Technologies |
| :--- | :--- |
| **Big Data Processing** | Spark (PySpark), Spark SQL, Polars, Dask, Vaex |
| **Data Lakehouse** | **Delta Lake, Apache Iceberg**, Hudi |
| **Streaming** | Apache Kafka, Spark Structured Streaming, Flink |
| **DevOps / Infra** | Docker, **Kubernetes (K8s), Spark Operator**, Helm |
| **Cloud Computing** | AWS S3, GCP GCS, Azure Blob, IAM, MinIO |
| **Data Quality & ETL** | **dbt (Data Build Tool)**, Great Expectations |
| **MLOps & Architecture** | MLflow, Feature Store, Data Mesh, Observability |

---

## ğŸ“˜ La Structure ComplÃ¨te du Programme

La progression est claire : **Fondations â†’ Industrialisation â†’ Architecture.**

---

# ğŸŸ¦ Niveau 1 : DÃ©butant â€“ Fondations & Premiers Pipelines

**Objectif :** Poser les bases solides pour lire, comprendre et manipuler la donnÃ©e dans un contexte d'entreprise.

### ğŸ”¹ Bloc 1 : Python & IngÃ©nierie des Fondations
* Python pour Data Engineering, Bash & Shell.
* Git & Flux de versionning.
* Environnements, Packaging & DÃ©pendances.

### ğŸ”¹ Bloc 2 : DonnÃ©es Relationnelles & ModÃ©lisation
* Bases de donnÃ©es relationnelles & SQL avancÃ©.
* ModÃ©lisation (Star Schema, Datamarts).
* Architecture Data Classique (DW vs DL).

### ğŸ”¹ Bloc 3 : Big Data & Architectures Fondamentales
* Introduction au Big Data & Distributed Computing.
* Architectures : **Lambda, Kappa, Lakehouse, Medaillon**.
* PySpark pour dÃ©butants (RDD â†’ DataFrames).
* MongoDB & SystÃ¨mes NoSQL.

### ğŸ”¹ Bloc 4 : Orchestration & Premiers Pas
* Elasticsearch et NoSQL.
* Orchestration : Introduction (Airflow, Nifi â€“ AperÃ§u).
* Projet : Pipeline PySpark simple sur fichiers locaux.

> **â¡ï¸ RÃ©sultat Concret :** Vous Ãªtes capable d'ingÃ©rer un dataset brut, de le nettoyer et de le transformer en **couche Silver puis Gold** via un pipeline PySpark.

---

# ğŸŸ© Niveau 2 : IntermÃ©diaire â€“ Industrialisation & Lakehouse

**Objectif :** MaÃ®triser le cÅ“ur du mÃ©tier : l'optimisation, le Cloud, les formats transactionnels et le dÃ©ploiement sur K8s.

### ğŸ”¹ Bloc 5 : Containerisation & Orchestration (DÃ©ploiement)
* Docker pour la Data.
* Kubernetes (bases et concepts clÃ©s).
* Kubernetes pour Workloads Data.

### ğŸ”¹ Bloc 6 : Traitement DistribuÃ© AvancÃ© & Cloud
* Polars & High Performance Python (Multiprocessing, Dask).
* PySpark avancÃ© & Spark SQL Deep Dive (Window Functions, Optimisations).
* Spark sur Kubernetes (**Spark Operator, Autoscaling**).
* Cloud & Object Storage (S3, GCS, Azure Blob, MinIO).

### ğŸ”¹ Bloc 7 : Data Lakehouse Transactionnel
* Table Formats modernes : **Delta Lake, Iceberg, Hudi** (ACID).
* Time Travel, Schema Evolution, OpÃ©rations `MERGE INTO`, Compaction.
* Gouvernance & Catalogue (Glue, Purview).

### ğŸ”¹ Bloc 8 : Streaming & QualitÃ© Industrielle
* Kafka & Architectures Streaming.
* **Spark Structured Streaming** (Exactly-once, Watermarks).
* Data Quality & Tests : **dbt + Great Expectations**.
* CI/CD pour Pipelines Data.

> **â¡ï¸ RÃ©sultat Concret :** Vous Ãªtes capable de dÃ©ployer un job Spark sur Kubernetes avec un **Operator**, en accÃ©dant Ã  un storage Cloud sÃ©curisÃ© et en gÃ©rant les transactions (ACID).

---

# ğŸŸ¥ Niveau 3 : AvancÃ© â€“ Architecture & Seniority

**Objectif :** Concevoir, optimiser et gouverner des systÃ¨mes rÃ©silients Ã  grande Ã©chelle.

### ğŸ”¹ Bloc 9 : Optimisation ExtrÃªme & Internals
* Internals Spark : Le Shuffle, Catalyst, Memory Management.
* Optimisation avancÃ©e (**AQE, Skew Join Handling**).
* HPC & ParallÃ©lisme Python (mÃ©canismes avancÃ©s).

### ğŸ”¹ Bloc 10 : SystÃ¨mes Temps RÃ©el AvancÃ©s
* Apache Flink (traitement d'Ã©vÃ©nements Ã  faible latence).
* Exactly-once processing, Watermarks et gestion du "late data".
* Unified Batch-Streaming (Architecture Kappa Moderne).

### ğŸ”¹ Bloc 11 : Architecture & StratÃ©gie d'Entreprise
* Architecture Cloud Ã  Grande Ã‰chelle (Serverless, multi-rÃ©gion).
* **Data Mesh** & Domain Ownership.
* MLOps pour Data Engineers (Feature Store, MLflow).
* Observability : Logs, Metrics (Prometheus/Grafana).
* **FinOps** pour Data Engineering (optimisation des coÃ»ts Cloud et Spark).

> **â¡ï¸ RÃ©sultat Concret :** Vous Ãªtes capable d'architecturer une plateforme Data multi-cloud scalable, optimisÃ©e pour la performance et les coÃ»ts, en intÃ©grant les principes de Data Mesh et d'Observability.

---

## ğŸ“Œ Comment utiliser ce Bootcamp ?

Le Bootcamp est organisÃ© dans lâ€™ordre pÃ©dagogique exact nÃ©cessaire pour devenir Data Engineer :

1. Ouvrez le **menu latÃ©ral gauche**.  
2. Cliquez sur le premier module : **01 â€“ Introduction au Data Engineering**.  
3. Progressez ensuite dans lâ€™ordre recommandÃ© (DÃ©butant â†’ IntermÃ©diaire â†’ AvancÃ©).

ğŸ‘‰ Pour commencer tout de suite :  
[ğŸš€ **DÃ©marrer le Module 01**](notebooks/beginner/01_intro_data_engineering.ipynb)

---

## ğŸš€ Ready to Start?

Ce bootcamp est conÃ§u pour vous emmener de la thÃ©orie Ã  la pratique industrielle.

ğŸ‘‰ **Commencez aujourd'hui** pour dÃ©marrer votre transition.  
ğŸ‘‰ Le programme est 100% pratique, progressif et centrÃ© sur le monde professionnel.

**Bonne montÃ©e en compÃ©tence ! ğŸ’ª**
