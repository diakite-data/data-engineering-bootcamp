---
title: "Bootcamp Data Engineering â€“ From Zero to Hero"
format:
  html:
    toc: false
---

<div class="hero" style="padding: 40px 0; text-align:center;">
  <h1>ğŸš€ Bootcamp Data Engineering : From Zero to Hero</h1>
  <h3>Devenez un Data Engineer opÃ©rationnel, prÃªt pour l'entreprise.</h3>
</div>

---

## ğŸ¯ Pourquoi choisir ce Bootcamp ?

Ce programme a Ã©tÃ© conÃ§u par des Data Engineers expÃ©rimentÃ©s, en se concentrant sur les **exigences rÃ©elles du marchÃ©**.  
Il vous accompagne de maniÃ¨re progressive vers un niveau **professionnel â€“ Senior Ready**.

### âœ” Ce que vous allez maÃ®triser

- **Outils industriels** : Spark 3.x, Kafka, Flink, Docker, Kubernetes, dbt, Lakehouse (Delta/Iceberg).
- **Architectures modernes** : MÃ©daillon (Bronze/Silver/Gold), Kappa, Lambda, Data Lakehouse, Data Mesh.
- **CompÃ©tences d'ingÃ©nierie** : optimisation, gouvernance, orchestration, CI/CD, cloud.
- **Industrialisation** : crÃ©ation de pipelines batch et streaming totalement opÃ©rationnels.
- **Leadership technique** : RFC, Design Reviews, ADR, pensÃ©e architecturale.

---

## ğŸ‘¥ Ã€ qui s'adresse ce Bootcamp ?

- **Ã‰tudiants / DÃ©veloppeurs** voulant entrer dans le monde du Big Data.
- **Analystes BI** souhaitant Ã©voluer vers le Data Engineering moderne.
- **Professionnels expÃ©rimentÃ©s** voulant structurer une plateforme Data complÃ¨te.
- **Architectes & Managers** cherchant Ã  comprendre les technos Data modernes.

---

## ğŸ› ï¸ Votre BoÃ®te Ã  Outils Data Engineering

| Domaine | Outils & Technologies |
| :--- | :--- |
| **Big Data Processing** | PySpark, Spark SQL, Scala, Polars, Dask |
| **Lakehouse** | Delta Lake, Apache Iceberg, Hudi |
| **Streaming** | Kafka, Spark Streaming, Flink, Debezium CDC |
| **DevOps / Infra** | Docker, Kubernetes, Helm, ArgoCD, Spark Operator |
| **Monitoring** | Prometheus, Grafana, Alertmanager |
| **Cloud** | AWS S3, GCP GCS, Azure Blob, IAM, MinIO |
| **QualitÃ© & ETL** | dbt, Great Expectations, Data Contracts |
| **MLOps** | MLflow, Feast (Feature Store), Model Monitoring |
| **Governance** | DataHub, Unity Catalog, RLS/CLS, GDPR |

---

# ğŸ“˜ Structure ComplÃ¨te du Programme (3 Niveaux)

La progression est organisÃ©e selon un parcours **pÃ©dagogique optimal** :

---

# ğŸŸ¦ Niveau 1 : DÃ©butant â€“ Fondations & Premiers Pipelines

### ğŸ¯ Objectif  
Construire des bases solides en Python, SQL, systÃ¨mes distribuÃ©s, modÃ©lisation et premiers pipelines.

### ğŸ“š Modules

| # | Module | ThÃ¨mes ClÃ©s |
|:--|:-------|:------------|
| 01 | Introduction au Data Engineering | RÃ´le du DE, Ã©cosystÃ¨me, architectures (Lambda, Kappa, Lakehouse) |
| 02 | Fondamentaux Linux & Bash | Commandes essentielles, scripting, cron, permissions |
| 03 | Git & Versioning | Branches, merge, rebase, workflows collaboratifs |
| 04 | Python pour Data Engineering | Syntaxe, structures, fichiers, exceptions |
| 05 | Python AvancÃ© | POO, dÃ©corateurs, gÃ©nÃ©rateurs, context managers |
| 06 | Packaging & Environnements | venv, pip, pyproject.toml, structure projet |
| 07 | SQL Fondamental | SELECT, JOIN, agrÃ©gations, sous-requÃªtes |
| 08 | SQL AvancÃ© | Window functions, CTE, optimisation, indexation |
| 09 | ModÃ©lisation de DonnÃ©es | Normalisation, Star Schema, Data Vault, SCD |
| 10 | Introduction Big Data | Hadoop, HDFS, MapReduce, Ã©cosystÃ¨me |
| 11 | Introduction PySpark | RDD, DataFrame, transformations, actions |
| 12 | MongoDB pour Data Engineers | NoSQL, CRUD, agrÃ©gations, indexation |
| 13 | Projet IntÃ©grateur DÃ©butant | Pipeline CSV â†’ Nettoyage â†’ AgrÃ©gation â†’ Export |

> **ğŸ¯ RÃ©sultat :** Capable d'ingÃ©rer, transformer et produire un dataset Gold simple.

---

# ğŸŸ© Niveau 2 : IntermÃ©diaire â€“ Industrialisation & Lakehouse

### ğŸ¯ Objectif  
MaÃ®triser les technologies indispensables en entreprise : Docker, Kubernetes, Spark avancÃ©, Lakehouse, streaming, orchestration.

### ğŸ“š Modules

| # | Module | ThÃ¨mes ClÃ©s |
|:--|:-------|:------------|
| 14 | Docker pour Data Engineering | Images, containers, volumes, Dockerfile, Compose |
| 15 | Kubernetes Fondamentaux | Pods, Deployments, Services, ConfigMaps, Secrets |
| 16 | Cloud Object Storage | S3, GCS, Azure Blob, MinIO, IAM, performances |
| 17 | PySpark AvancÃ© | Partitioning, caching, broadcast, UDF, optimisation |
| 18 | Spark SQL Deep Dive | Catalyst, plans d'exÃ©cution, tuning, adaptive query |
| 19 | Spark on Kubernetes | Spark Operator, SparkApplication, scaling, monitoring |
| 20 | Polars & High Performance Python | API Polars, lazy evaluation, vs Pandas/Spark |
| 21 | Formats de Fichiers | Parquet, Avro, ORC, compression, partitioning |
| 22 | Table Formats (Delta, Iceberg, Hudi) | ACID, Time Travel, Schema Evolution, MERGE INTO |
| 23 | Apache Kafka & Streaming | Producers, Consumers, Topics, Partitions, Consumer Groups |
| 24 | Spark Structured Streaming | Watermarks, Windows, foreachBatch, checkpointing |
| 25 | Orchestration avec Airflow | DAGs, Operators, XCom, Connections, bonnes pratiques |
| 26 | dbt & Data Quality | Models, Tests, Documentation, Great Expectations |
| 27 | CI/CD pour Data Pipelines | GitHub Actions, tests, dÃ©ploiement automatisÃ© |
| 28 | Projet IntÃ©grateur IntermÃ©diaire | Pipeline Kafka â†’ Spark â†’ Delta Lake â†’ dbt (Dataset Olist) |

> **ğŸ¯ RÃ©sultat :** DÃ©ployer un job Spark sur Kubernetes, stocker en Delta, orchestrer & monitorer.

---

# ğŸŸ¥ Niveau 3 : AvancÃ© â€“ Architecture, Optimisation & Seniority

### ğŸ¯ Objectif  
Atteindre le niveau "Senior Data Engineer / Architecte Data".

### ğŸ“š Modules

| # | Module | ThÃ¨mes ClÃ©s |
|:--|:-------|:------------|
| 31 | Kubernetes Deep Dive | StatefulSets, Operators, CNI/CSI, Prometheus/Grafana, Helm, ArgoCD |
| 32 | Distributed Messaging Systems | Kafka avancÃ©, RabbitMQ, Pulsar, Debezium CDC, choix d'architecture |
| 33 | Spark & Scala Internals | Scala essentials, Catalyst, Tungsten, AQE, shuffling, joins optimisÃ©s |
| 34 | Apache Flink | Exactly-once, State Management, Watermarks, Flink SQL, vs Kafka Streams |
| 35 | MLOps for Data Engineers | Feature Stores (Feast), MLflow, Pipelines ML, Model Monitoring |
| 36 | Data Governance & Security | IAM, RLS/CLS, chiffrement, Data Contracts, DataHub, GDPR, Audit |
| 37 | Architectural Trade-Offs | FinOps, ADR, Latence vs CoÃ»t, Capacity Planning, justification technique |
| 38 | Technical Leadership | RFC, Design Reviews, Incidents/Postmortems, Mentoring, Communication |
| 39 | Data Platform Design | Data Mesh, Multi-Format Strategy (Delta/Iceberg/Hudi), Platform Patterns |
| 40 | Projet IntÃ©grateur AvancÃ© | Plateforme Data Multi-Tenant : K8s + Kafka + Flink + Lakehouse + MLOps + Governance |

> **ğŸ¯ RÃ©sultat :** Architecturer une plateforme Data complÃ¨te, scalable, sÃ©curisÃ©e et optimisÃ©e.

---

# ğŸ“Š Vue d'Ensemble du Parcours

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PARCOURS COMPLET                                  â”‚
â”‚                                                                             â”‚
â”‚   ğŸŸ¦ NIVEAU 1 : DÃ‰BUTANT                    DurÃ©e estimÃ©e : 6-8 semaines   â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚   Modules 01-13                                                             â”‚
â”‚   Python â†’ SQL â†’ Big Data â†’ PySpark â†’ MongoDB                               â”‚
â”‚   ğŸ“¦ Projet : Pipeline simple                                               â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚   ğŸŸ© NIVEAU 2 : INTERMÃ‰DIAIRE               DurÃ©e estimÃ©e : 8-10 semaines  â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                              â”‚
â”‚   Modules 14-28                                                             â”‚
â”‚   Docker â†’ K8s â†’ Spark avancÃ© â†’ Lakehouse â†’ Streaming â†’ dbt                â”‚
â”‚   ğŸ“¦ Projet : Pipeline E-commerce (Olist)                                   â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚   ğŸŸ¥ NIVEAU 3 : AVANCÃ‰                      DurÃ©e estimÃ©e : 8-10 semaines  â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                     â”‚
â”‚   Modules 31-40                                                             â”‚
â”‚   K8s Deep Dive â†’ Flink â†’ MLOps â†’ Governance â†’ Architecture â†’ Leadership   â”‚
â”‚   ğŸ“¦ Projet : Plateforme Data Multi-Tenant                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ† CompÃ©tences Acquises par Niveau

| CompÃ©tence | DÃ©butant | IntermÃ©diaire | AvancÃ© |
|:-----------|:--------:|:-------------:|:------:|
| Python & SQL | âœ… | âœ…âœ… | âœ…âœ…âœ… |
| PySpark | âœ… | âœ…âœ… | âœ…âœ…âœ… |
| Docker & Kubernetes | - | âœ…âœ… | âœ…âœ…âœ… |
| Lakehouse (Delta/Iceberg) | - | âœ…âœ… | âœ…âœ…âœ… |
| Streaming (Kafka) | - | âœ…âœ… | âœ…âœ…âœ… |
| Flink | - | - | âœ…âœ… |
| dbt & Data Quality | - | âœ…âœ… | âœ…âœ… |
| MLOps | - | - | âœ…âœ… |
| Governance & Security | - | âœ… | âœ…âœ…âœ… |
| Architecture & Design | - | âœ… | âœ…âœ…âœ… |
| Leadership technique | - | - | âœ…âœ…âœ… |

---

# ğŸš€ DÃ©marrer le Bootcamp

ğŸ‘‰ Cliquez dans le menu de gauche pour ouvrir le premier module, ou dÃ©marrez ici :

<div style="text-align: center; margin: 30px 0;">
  <a href="notebooks/beginner/01_intro_data_engineering.ipynb" style="background-color: #4CAF50; color: white; padding: 15px 30px; text-decoration: none; font-size: 18px; border-radius: 5px;">
    ğŸ“˜ Commencer le Module 01
  </a>
</div>

---

## ğŸ’¡ Conseils pour RÃ©ussir

1. **Suivez l'ordre** : Les modules sont conÃ§us pour Ãªtre suivis sÃ©quentiellement.
2. **Pratiquez** : Faites tous les exercices et projets intÃ©grateurs.
3. **ExpÃ©rimentez** : Modifiez le code, cassez des choses, apprenez des erreurs.
4. **Documentez** : Prenez des notes, crÃ©ez votre propre documentation.
5. **Construisez votre portfolio** : Les projets intÃ©grateurs sont prÃ©sentables en entretien.

---

## ğŸ‰ Bonne montÃ©e en compÃ©tence !  

Vous Ãªtes maintenant prÃªt Ã  progresser Ã©tape par Ã©tape jusqu'au niveau **Senior Data Engineer**.
