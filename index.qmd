---
title: "Bootcamp Data Engineering â€“ From Zero to Hero"
format:
  html:
    toc: false
---

<div class="hero" style="padding: 40px 0; text-align:center;">
  <h2>ğŸš€ Bootcamp Data Engineering </h2>
  <h1>From Zero to Hero</h1>
  <h3>Devenez un Data Engineer opÃ©rationnel, prÃªt pour l'entreprise.</h3>
</div>

---

## ğŸ¯ Pourquoi choisir ce Bootcamp ?

Ce programme a Ã©tÃ© conÃ§u par des Data Engineers expÃ©rimentÃ©s, en se concentrant sur les **exigences rÃ©elles du marchÃ©**.  
Il vous accompagne de maniÃ¨re progressive vers un niveau **professionnel â€“ Senior Ready**.

### âœ” Ce que vous allez maÃ®triser

- **Outils industriels** : Spark 3.x, Kafka, Flink, Docker, Kubernetes, dbt, Lakehouse (Delta/Iceberg).
- **Architectures modernes** : MÃ©daillon (Bronze/Silver/Gold), Kappa, Lambda, Data Lakehouse, Data Mesh.
- **CompÃ©tences d'ingÃ©nierie** : optimisation, gouvernance, orchestration, CI/CD, cloud.
- **Industrialisation** : crÃ©ation de pipelines batch et streaming totalement opÃ©rationnels.
- **Leadership technique** : RFC, Design Reviews, ADR, pensÃ©e architecturale.

---

## ğŸ‘¥ Ã€ qui s'adresse ce Bootcamp ?

- **Ã‰tudiants / DÃ©veloppeurs** voulant entrer dans le monde du Big Data.
- **Analystes BI** souhaitant Ã©voluer vers le Data Engineering moderne.
- **Professionnels expÃ©rimentÃ©s** voulant structurer une plateforme Data complÃ¨te.
- **Architectes & Managers** cherchant Ã  comprendre les technos Data modernes.

---

## ğŸ› ï¸ Votre BoÃ®te Ã  Outils Data Engineering

| Domaine | Outils & Technologies |
| :--- | :--- |
| **Big Data Processing** | PySpark, Spark SQL, Scala, Polars, Pandas |
| **Lakehouse** | Delta Lake, Apache Iceberg, Hudi |
| **Streaming** | Kafka, Spark Streaming, Flink, Debezium CDC |
| **DevOps / Infra** | Docker, Kubernetes, Helm, ArgoCD, Spark Operator |
| **Monitoring** | Prometheus, Grafana, Alertmanager |
| **Cloud** | AWS S3, GCP GCS, Azure Blob, IAM, MinIO |
| **QualitÃ© & ETL** | dbt, Great Expectations, Data Contracts |
| **MLOps** | MLflow, Feast (Feature Store), Model Monitoring |
| **Governance** | DataHub, Unity Catalog, RLS/CLS, GDPR |

---

# ğŸ“˜ Structure ComplÃ¨te du Programme (3 Niveaux)

La progression est organisÃ©e selon un parcours **pÃ©dagogique optimal** :

---

# ğŸŸ¦ Niveau 1 : DÃ©butant â€“ Fondations & Premiers Pipelines

### ğŸ¯ Objectif  
Construire des bases solides en Python, SQL, systÃ¨mes distribuÃ©s et premiers pipelines.

### ğŸ“š Modules

| # | Module | ThÃ¨mes ClÃ©s |
|:--|:-------|:------------|
| 01 | Introduction au Data Engineering | RÃ´le du DE, Ã©cosystÃ¨me, architectures (Lambda, Kappa, Lakehouse) |
| 02 | Fondamentaux Linux & Bash | Commandes essentielles, scripting, cron, permissions |
| 03 | Git & Versioning | Branches, merge, rebase, workflows collaboratifs |
| 04 | Python Fondamental | Syntaxe, structures, fichiers, exceptions |
| 05 | Python Data Processing | POO, dÃ©corateurs, gÃ©nÃ©rateurs, context managers |
| 06 | Introduction BDD Relationnelles | Concepts SGBD, modÃ©lisation, normalisation |
| 07 | SQL pour Data Engineers | RequÃªtes, jointures, window functions, optimisation |
| 08 | Introduction Big Data | Hadoop, HDFS, MapReduce, Ã©cosystÃ¨me distribuÃ© |
| 09 | MongoDB pour Data Engineers | NoSQL, CRUD, agrÃ©gations, indexation |
| 10 | Elasticsearch | Recherche full-text, indexation, requÃªtes DSL |
| 11 | Introduction PySpark | RDD, DataFrame, transformations, actions |
| 12 | Orchestration de Pipelines | Concepts, scheduling, dÃ©pendances |
| 13 | **Bonus** : FastAPI | API REST pour exposer vos donnÃ©es |

### ğŸ® Projet IntÃ©grateur : Video Games Analytics Platform

> **Pipeline complet** : Kaggle CSV â†’ Web Scraping â†’ DuckDB + Elasticsearch â†’ PySpark â†’ FastAPI â†’ Streamlit Dashboard
>
> [ğŸš€ AccÃ©der au projet](notebooks/beginner/projet_debutant.ipynb)

> **ğŸ¯ RÃ©sultat :** Capable de construire un pipeline data de bout en bout, de l'ingestion au dashboard.

---

# ğŸŸ© Niveau 2 : IntermÃ©diaire â€“ Industrialisation & Lakehouse

### ğŸ¯ Objectif  
MaÃ®triser les technologies indispensables en entreprise : Docker, Kubernetes, Spark avancÃ©, Lakehouse, streaming, orchestration.

### ğŸ“š Modules

| # | Module | ThÃ¨mes ClÃ©s |
|:--|:-------|:------------|
| 14 | Docker pour Data Engineers | Images, containers, volumes, Dockerfile, Compose |
| 15 | Kubernetes Fondamentaux | Pods, Deployments, Services, ConfigMaps, Secrets |
| 16 | K8s pour Data Workloads | StatefulSets, Jobs, CronJobs, volumes persistants |
| 17 | Polars pour Data Engineering | API Polars, lazy evaluation, vs Pandas/Spark |
| 18 | High Performance Python | Profiling, optimisation, multiprocessing, async |
| 19 | PySpark AvancÃ© | Partitioning, caching, broadcast, UDF, optimisation |
| 20 | Spark SQL Deep Dive | Catalyst, plans d'exÃ©cution, tuning, adaptive query |
| 21 | Spark on Kubernetes | Spark Operator, SparkApplication, scaling, monitoring |
| 22 | Cloud Object Storage | S3, GCS, Azure Blob, MinIO, IAM, performances |
| 23 | Table Formats (Delta, Iceberg) | ACID, Time Travel, Schema Evolution, MERGE INTO |
| 24 | Kafka & Streaming | Producers, Consumers, Topics, Partitions, Consumer Groups |
| 25 | dbt & Data Quality | Models, Tests, Documentation, Great Expectations |

### ğŸ“¦ Projet IntÃ©grateur : Pipeline E-commerce Olist

> **Pipeline Lakehouse** : Kafka â†’ Spark Streaming â†’ Delta Lake â†’ dbt â†’ Dashboard
>
> [ğŸš€ AccÃ©der au projet](notebooks/intermediate/26_projet_integrateur.ipynb)

> **ğŸ¯ RÃ©sultat :** DÃ©ployer un job Spark sur Kubernetes, stocker en Delta, orchestrer & monitorer.

---

# ğŸŸ¥ Niveau 3 : AvancÃ© â€“ Architecture, Optimisation & Seniority

### ğŸ¯ Objectif  
Atteindre le niveau "Senior Data Engineer / Architecte Data" avec une maÃ®trise des systÃ¨mes distribuÃ©s, de l'architecture et du leadership technique.

### ğŸ“š Modules

| # | Module | ThÃ¨mes ClÃ©s |
|:--|:-------|:------------|
| 27 | Kubernetes Deep Dive | Operators, CRDs, Helm avancÃ©, GitOps, troubleshooting |
| 28 | Orchestration AvancÃ©e | Airflow 2.x, DAGs dynamiques, KubernetesPodOperator, Dagster |
| 29 | Messaging DistribuÃ© | Kafka internals, Pulsar, RabbitMQ, patterns de messaging |
| 30 | Spark & Scala Deep Dive | Internals Spark, Catalyst, Tungsten, optimisation bas niveau |
| 31 | Data Engineering pour le ML | Feature Stores, pipelines ML, MLflow, model serving |
| 32 | Data Mesh & Contracts | Data Products, Domain Ownership, Data Contracts, APIs |
| 33 | Realtime OLAP & Dashboards | ClickHouse, Apache Druid, Pinot, dashboards temps rÃ©el |
| 34 | Patterns & DÃ©cisions d'Architecture | ADR, RFC, trade-offs, design reviews, documentation |
| 35 | Leadership & Trade-offs | Communication technique, mentoring, gestion de projet tech |

> **ğŸ¯ RÃ©sultat :** Capable de concevoir et dÃ©fendre une architecture Data complÃ¨te, mener des design reviews, et guider une Ã©quipe technique.

---

# ğŸ“Š Vue d'Ensemble du Parcours

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PARCOURS COMPLET                                  â”‚
â”‚                                                                             â”‚
â”‚   ğŸŸ¦ NIVEAU 1 : DÃ‰BUTANT                                                    â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚   Modules 01-13                                                             â”‚
â”‚   Python â†’ SQL â†’ Big Data â†’ PySpark â†’ MongoDB â†’ Elasticsearch              â”‚
â”‚   ğŸ® Projet : Video Games Analytics Platform                                â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚   ğŸŸ© NIVEAU 2 : INTERMÃ‰DIAIRE                                               â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                              â”‚
â”‚   Modules 14-25                                                             â”‚
â”‚   Docker â†’ K8s â†’ Spark avancÃ© â†’ Lakehouse â†’ Streaming â†’ dbt                 â”‚
â”‚   ğŸ“¦ Projet : Pipeline E-commerce Olist                                     â”‚
â”‚                          â”‚                                                  â”‚
â”‚                          â–¼                                                  â”‚
â”‚   ğŸŸ¥ NIVEAU 3 : AVANCÃ‰                                                      â”‚
â”‚   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                     â”‚
â”‚   Modules 27-35                                                             â”‚
â”‚   K8s Deep Dive â†’ Orchestration â†’ Messaging â†’ Spark/Scala â†’ ML             â”‚
â”‚   Architecture â†’ Data Mesh â†’ OLAP â†’ Leadership                              â”‚
â”‚                                                                             â”‚
â”‚                          â–¼                                                  â”‚
â”‚                    ğŸ† SENIOR READY                                          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ† CompÃ©tences Acquises par Niveau

| CompÃ©tence | DÃ©butant | IntermÃ©diaire | AvancÃ© |
|:-----------|:--------:|:-------------:|:------:|
| Python & SQL | âœ… | âœ…âœ… | âœ…âœ…âœ… |
| PySpark | âœ… | âœ…âœ… | âœ…âœ…âœ… |
| Spark Scala | - | - | âœ…âœ… |
| Docker & Kubernetes | - | âœ…âœ… | âœ…âœ…âœ… |
| Lakehouse (Delta/Iceberg) | - | âœ…âœ… | âœ…âœ…âœ… |
| Streaming (Kafka) | - | âœ…âœ… | âœ…âœ…âœ… |
| Orchestration (Airflow) | - | âœ… | âœ…âœ…âœ… |
| dbt & Data Quality | - | âœ…âœ… | âœ…âœ… |
| OLAP & Realtime Analytics | - | - | âœ…âœ… |
| MLOps & Feature Stores | - | - | âœ…âœ… |
| Data Mesh & Contracts | - | - | âœ…âœ…âœ… |
| Governance & Security | - | âœ… | âœ…âœ…âœ… |
| Architecture & Design | - | âœ… | âœ…âœ…âœ… |
| Leadership technique | - | - | âœ…âœ…âœ… |

---

# ğŸš€ DÃ©marrer le Bootcamp

ğŸ‘‰ Cliquez dans le menu de gauche pour ouvrir le premier module, ou choisissez votre point d'entrÃ©e :

<div style="text-align: center; margin: 30px 0; display: flex; flex-wrap: wrap; justify-content: center; gap: 15px;">
  <a href="notebooks/beginner/01_intro_data_engineering.ipynb" style="background: linear-gradient(135deg, #3b82f6, #1d4ed8); color: white; padding: 15px 30px; text-decoration: none; font-size: 16px; border-radius: 10px; font-weight: 600; box-shadow: 0 4px 15px rgba(59, 130, 246, 0.3);">
    ğŸŸ¦ Niveau DÃ©butant
  </a>
  <a href="notebooks/intermediate/14_docker_for_data_engineers.ipynb" style="background: linear-gradient(135deg, #22c55e, #16a34a); color: white; padding: 15px 30px; text-decoration: none; font-size: 16px; border-radius: 10px; font-weight: 600; box-shadow: 0 4px 15px rgba(34, 197, 94, 0.3);">
    ğŸŸ© Niveau IntermÃ©diaire
  </a>
  <a href="notebooks/advanced/27_kubernetes_deep_dive.ipynb" style="background: linear-gradient(135deg, #ef4444, #dc2626); color: white; padding: 15px 30px; text-decoration: none; font-size: 16px; border-radius: 10px; font-weight: 600; box-shadow: 0 4px 15px rgba(239, 68, 68, 0.3);">
    ğŸŸ¥ Niveau AvancÃ©
  </a>
</div>

---

## ğŸ’¡ Conseils pour RÃ©ussir

1. **Suivez l'ordre** : Les modules sont conÃ§us pour Ãªtre suivis sÃ©quentiellement.
2. **Pratiquez** : Faites tous les exercices et projets intÃ©grateurs.
3. **ExpÃ©rimentez** : Modifiez le code, cassez des choses, apprenez des erreurs.
4. **Documentez** : Prenez des notes, crÃ©ez votre propre documentation.
5. **Construisez votre portfolio** : Les projets intÃ©grateurs sont prÃ©sentables en entretien.

---

## ğŸ‰ Bonne montÃ©e en compÃ©tence !  

Vous Ãªtes maintenant prÃªt Ã  progresser Ã©tape par Ã©tape jusqu'au niveau **Senior Data Engineer**.
