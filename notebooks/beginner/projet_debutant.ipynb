{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Projet IntÃ©grateur : Video Games Analytics Platform\n",
    "\n",
    "## Du CSV au Dashboard â€” Ton Premier Pipeline Data Complet\n",
    "\n",
    "---\n",
    "\n",
    "Bienvenue dans ce **projet intÃ©grateur** ! Tu vas construire une plateforme d'analyse de jeux vidÃ©o **de A Ã  Z**, en mobilisant toutes les compÃ©tences acquises dans les modules prÃ©cÃ©dents.\n",
    "\n",
    "### Approche PÃ©dagogique\n",
    "\n",
    "Ce projet est structurÃ© en **dÃ©fis**. Pour chaque Ã©tape :\n",
    "\n",
    "1. **Lis le dÃ©fi** et les consignes\n",
    "2. **RÃ©flÃ©chis** et essaie de coder toi-mÃªme\n",
    "3. **Consulte les indices** si tu bloques\n",
    "4. **VÃ©rifie** ta solution en dÃ©roulant les rÃ©ponses\n",
    "\n",
    "> âš ï¸ **Important** : Ne regarde pas les solutions avant d'avoir essayÃ© ! C'est en pratiquant qu'on apprend.\n",
    "\n",
    "---\n",
    "\n",
    "## Ce que tu vas construire\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        VIDEO GAMES ANALYTICS PLATFORM                           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚  ğŸ“¥ SOURCES  â”‚      â”‚ âš™ï¸ PROCESSING â”‚      â”‚ ğŸ’¾ STOCKAGE  â”‚      â”‚ğŸ“Š EXPOSITION â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                     â”‚                     â”‚                     â”‚\n",
    "         â–¼                     â–¼                     â–¼                     â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚    Kaggle    â”‚â”€â”€â”€â”€â”€â–¶â”‚    Pandas    â”‚â”€â”€â”€â”€â”€â–¶â”‚   DuckDB     â”‚â”€â”€â”€â”€â”€â–¶â”‚   FastAPI    â”‚\n",
    "  â”‚  Video Games â”‚      â”‚  Nettoyage   â”‚      â”‚ SQL Analyticsâ”‚      â”‚   REST API   â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                     â”‚                     â”‚                     â”‚\n",
    "         â–¼                     â–¼                     â–¼                     â–¼\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚ Web Scraping â”‚â”€â”€â”€â”€â”€â–¶â”‚   PySpark    â”‚â”€â”€â”€â”€â”€â–¶â”‚Elasticsearch â”‚â”€â”€â”€â”€â”€â–¶â”‚  Streamlit   â”‚\n",
    "  â”‚   RAWG API   â”‚      â”‚ AgrÃ©gations  â”‚      â”‚  Recherche   â”‚      â”‚  Dashboard   â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competences",
   "metadata": {},
   "source": [
    "## CompÃ©tences MobilisÃ©es\n",
    "\n",
    "| Module | CompÃ©tence | Application dans le projet |\n",
    "|--------|------------|---------------------------|\n",
    "| M01 | Concepts Data Engineering | Architecture du pipeline |\n",
    "| M02 | Bash & Linux | Scripts d'automatisation |\n",
    "| M03 | Git | Versioning du projet |\n",
    "| M04-05 | Python & Pandas | Traitement de donnÃ©es |\n",
    "| M06-07 | SQL & Databases | RequÃªtes analytiques avec DuckDB |\n",
    "| M08 | Big Data Concepts | PensÃ©e distribuÃ©e |\n",
    "| M10 | Elasticsearch | Recherche full-text |\n",
    "| M11 | PySpark | Traitement Ã  l'Ã©chelle |\n",
    "| M12 | Orchestration | Pipeline automatisÃ© |\n",
    "| M13 | FastAPI | API REST |\n",
    "| **NEW** | **Web Scraping** | BeautifulSoup, Requests |\n",
    "| **NEW** | **Streamlit** | Dashboard interactif |\n",
    "\n",
    "---\n",
    "\n",
    "## Le Dataset\n",
    "\n",
    "**Kaggle - Video Game Sales with Ratings**\n",
    "\n",
    "ğŸ”— https://www.kaggle.com/datasets/rush4ratio/video-game-sales-with-ratings\n",
    "\n",
    "| Colonne | Description |\n",
    "|---------|-------------|\n",
    "| `Name` | Nom du jeu |\n",
    "| `Platform` | Console (PS4, Xbox, PC...) |\n",
    "| `Year_of_Release` | AnnÃ©e de sortie |\n",
    "| `Genre` | Genre (Action, Sports, RPG...) |\n",
    "| `Publisher` | Ã‰diteur |\n",
    "| `NA_Sales`, `EU_Sales`, `JP_Sales`, `Other_Sales` | Ventes par rÃ©gion (millions) |\n",
    "| `Global_Sales` | Ventes mondiales |\n",
    "| `Critic_Score` | Note Metacritic (0-100) |\n",
    "| `User_Score` | Note utilisateurs (0-10) |\n",
    "| `Rating` | Classification ESRB (E, T, M...) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase0_title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 0 : Setup du Projet\n",
    "\n",
    "Avant de coder, il faut prÃ©parer l'environnement de travail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi0_1",
   "metadata": {},
   "source": [
    "## DÃ©fi 0.1 : CrÃ©er la structure du projet\n",
    "\n",
    "### Consigne\n",
    "\n",
    "CrÃ©e une structure de dossiers pour le projet `videogames-analytics` avec :\n",
    "- Un dossier `data/` avec des sous-dossiers `raw/`, `processed/`, `enriched/`\n",
    "- Un dossier `scripts/` pour les scripts Python\n",
    "- Un dossier `api/` pour FastAPI\n",
    "- Un dossier `dashboard/` pour Streamlit\n",
    "- Un dossier `notebooks/` pour l'exploration\n",
    "- Les fichiers `requirements.txt`, `.gitignore`, `README.md`\n",
    "\n",
    "Structure attendue :\n",
    "```\n",
    "videogames-analytics/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/           # DonnÃ©es brutes (CSV Kaggle)\n",
    "â”‚   â”œâ”€â”€ processed/     # DonnÃ©es nettoyÃ©es (Parquet)\n",
    "â”‚   â””â”€â”€ enriched/      # DonnÃ©es enrichies (scraping)\n",
    "â”œâ”€â”€ scripts/           # Scripts Python du pipeline\n",
    "â”œâ”€â”€ api/               # API FastAPI\n",
    "â”œâ”€â”€ dashboard/         # Dashboard Streamlit\n",
    "â”œâ”€â”€ notebooks/         # Notebooks d'exploration\n",
    "â”œâ”€â”€ tests/             # Tests unitaires\n",
    "â”œâ”€â”€ requirements.txt   # DÃ©pendances Python\n",
    "â”œâ”€â”€ .gitignore         # Fichiers Ã  ignorer\n",
    "â””â”€â”€ README.md          # Documentation\n",
    "```\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "1. Quelle commande Bash permet de crÃ©er plusieurs dossiers en une seule ligne ?\n",
    "2. Comment crÃ©er des sous-dossiers imbriquÃ©s qui n'existent pas encore ?\n",
    "3. Quels fichiers/dossiers doit-on ignorer dans Git pour un projet Python data ?\n",
    "\n",
    "---\n",
    "\n",
    "*Prends le temps de rÃ©flÃ©chir et d'essayer avant de regarder les indices ou la solution* â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code0_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# TON CODE ICI\n",
    "# CrÃ©e la structure du projet videogames-analytics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution0_1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "- Utilise `mkdir -p` pour crÃ©er des dossiers imbriquÃ©s (l'option `-p` crÃ©e les parents si nÃ©cessaire)\n",
    "- Tu peux utiliser les accolades `{}` pour crÃ©er plusieurs dossiers : `mkdir -p projet/{dossier1,dossier2}`\n",
    "- Pour le `.gitignore`, pense Ã  : `__pycache__/`, `.env`, `data/raw/*`, `*.pyc`, `.venv/`, `*.db`\n",
    "- Utilise `cat << 'EOF' > fichier` pour crÃ©er un fichier multi-lignes\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution complÃ¨te</b></summary>\n",
    "\n",
    "```bash\n",
    "# CrÃ©ation de la structure en une commande\n",
    "mkdir -p videogames-analytics/{data/{raw,processed,enriched},scripts,api,dashboard,notebooks,tests}\n",
    "\n",
    "cd videogames-analytics\n",
    "\n",
    "# CrÃ©er requirements.txt\n",
    "cat << 'EOF' > requirements.txt\n",
    "# Data Processing\n",
    "pandas>=2.0.0\n",
    "numpy>=1.24.0\n",
    "pyarrow>=12.0.0\n",
    "\n",
    "# Web Scraping\n",
    "requests>=2.31.0\n",
    "beautifulsoup4>=4.12.0\n",
    "lxml>=4.9.0\n",
    "\n",
    "# Databases\n",
    "duckdb>=0.9.0\n",
    "elasticsearch>=8.0.0\n",
    "\n",
    "# Big Data\n",
    "pyspark>=3.5.0\n",
    "\n",
    "# API\n",
    "fastapi>=0.104.0\n",
    "uvicorn>=0.24.0\n",
    "\n",
    "# Dashboard\n",
    "streamlit>=1.28.0\n",
    "plotly>=5.18.0\n",
    "\n",
    "# Utilities\n",
    "python-dotenv>=1.0.0\n",
    "tqdm>=4.66.0\n",
    "EOF\n",
    "\n",
    "# CrÃ©er .gitignore\n",
    "cat << 'EOF' > .gitignore\n",
    "# Data (on ne versionne pas les donnÃ©es)\n",
    "data/raw/*\n",
    "data/processed/*\n",
    "data/enriched/*\n",
    "!data/*/.gitkeep\n",
    "*.db\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    ".venv/\n",
    "venv/\n",
    "\n",
    "# Environment\n",
    ".env\n",
    "*.log\n",
    "\n",
    "# IDE\n",
    ".idea/\n",
    ".vscode/\n",
    "\n",
    "# Jupyter\n",
    ".ipynb_checkpoints/\n",
    "EOF\n",
    "\n",
    "# CrÃ©er les .gitkeep pour garder les dossiers vides dans Git\n",
    "touch data/raw/.gitkeep data/processed/.gitkeep data/enriched/.gitkeep\n",
    "\n",
    "echo \"âœ… Structure crÃ©Ã©e !\"\n",
    "```\n",
    "\n",
    "**Explications :**\n",
    "- `mkdir -p` crÃ©e tous les dossiers parents manquants\n",
    "- Les accolades `{a,b,c}` crÃ©ent plusieurs dossiers en une commande\n",
    "- `cat << 'EOF' > fichier` permet d'Ã©crire plusieurs lignes dans un fichier\n",
    "- `.gitkeep` est une convention pour garder les dossiers vides dans Git\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi0_2",
   "metadata": {},
   "source": [
    "## DÃ©fi 0.2 : Initialiser Git\n",
    "\n",
    "### Consigne\n",
    "\n",
    "1. Initialise un dÃ©pÃ´t Git dans le dossier `videogames-analytics`\n",
    "2. Ajoute tous les fichiers\n",
    "3. Fais un premier commit avec le message : `\"ğŸ® Initial commit: project structure\"`\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "1. Quelle commande initialise un nouveau dÃ©pÃ´t Git ?\n",
    "2. Comment ajouter tous les fichiers d'un coup au staging ?\n",
    "3. Quelle est la syntaxe pour crÃ©er un commit avec un message ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code0_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# TON CODE ICI\n",
    "# Initialise Git et fais le premier commit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution0_2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "Les 3 commandes Git essentielles :\n",
    "- `git init` : initialise un nouveau dÃ©pÃ´t\n",
    "- `git add .` : ajoute tous les fichiers au staging\n",
    "- `git commit -m \"message\"` : crÃ©e un commit\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```bash\n",
    "cd videogames-analytics\n",
    "\n",
    "# Initialiser le dÃ©pÃ´t Git\n",
    "git init\n",
    "\n",
    "# Ajouter tous les fichiers au staging\n",
    "git add .\n",
    "\n",
    "# CrÃ©er le premier commit\n",
    "git commit -m \"ğŸ® Initial commit: project structure\"\n",
    "\n",
    "# VÃ©rifier l'historique\n",
    "git log --oneline\n",
    "```\n",
    "\n",
    "**RÃ©sultat attendu :**\n",
    "```\n",
    "abc1234 ğŸ® Initial commit: project structure\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase1_title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 1 : Ingestion des DonnÃ©es\n",
    "\n",
    "## TÃ©lÃ©chargement du Dataset\n",
    "\n",
    "TÃ©lÃ©charge le dataset depuis Kaggle :\n",
    "1. Va sur https://www.kaggle.com/datasets/rush4ratio/video-game-sales-with-ratings\n",
    "2. TÃ©lÃ©charge le ZIP\n",
    "3. Extrait le CSV dans `data/raw/`\n",
    "\n",
    "> ğŸ’¡ Si tu n'as pas de compte Kaggle, utilise le code ci-dessous pour gÃ©nÃ©rer des donnÃ©es d'exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GÃ©nÃ©ration de donnÃ©es d'exemple (exÃ©cute cette cellule si tu n'as pas Kaggle)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"videogames-analytics\")\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_games = 5000\n",
    "\n",
    "platforms = ['PS4', 'XOne', 'PC', 'WiiU', 'PS3', 'X360', 'Wii', 'PSV', '3DS', 'PS2']\n",
    "genres = ['Action', 'Sports', 'Shooter', 'Role-Playing', 'Racing', 'Platform', \n",
    "          'Fighting', 'Simulation', 'Adventure', 'Strategy', 'Puzzle', 'Misc']\n",
    "publishers = ['Electronic Arts', 'Activision', 'Ubisoft', 'Nintendo', 'Sony', \n",
    "              'Take-Two', 'Sega', 'Capcom', 'Konami', 'Bandai Namco', 'Square Enix']\n",
    "ratings = ['E', 'E10+', 'T', 'M', 'RP', None]\n",
    "\n",
    "game_prefixes = ['Super', 'Ultimate', 'Call of', 'Legend of', 'Final', 'Grand', 'Dark']\n",
    "game_suffixes = ['Warriors', 'Quest', 'Adventure', 'Legends', 'Chronicles', 'Heroes']\n",
    "game_names = [f\"{np.random.choice(game_prefixes)} {np.random.choice(game_suffixes)} {i}\" \n",
    "              for i in range(n_games)]\n",
    "\n",
    "games_df = pd.DataFrame({\n",
    "    'Name': game_names,\n",
    "    'Platform': np.random.choice(platforms, n_games),\n",
    "    'Year_of_Release': np.random.choice(range(2000, 2024), n_games),\n",
    "    'Genre': np.random.choice(genres, n_games),\n",
    "    'Publisher': np.random.choice(publishers, n_games),\n",
    "    'NA_Sales': np.round(np.random.exponential(0.5, n_games), 2),\n",
    "    'EU_Sales': np.round(np.random.exponential(0.3, n_games), 2),\n",
    "    'JP_Sales': np.round(np.random.exponential(0.2, n_games), 2),\n",
    "    'Other_Sales': np.round(np.random.exponential(0.1, n_games), 2),\n",
    "    'Critic_Score': np.where(np.random.random(n_games) > 0.2, \n",
    "                             np.random.randint(40, 100, n_games), np.nan),\n",
    "    'User_Score': np.where(np.random.random(n_games) > 0.3,\n",
    "                           np.round(np.random.uniform(3, 10, n_games), 1), np.nan),\n",
    "    'Rating': np.random.choice(ratings, n_games)\n",
    "})\n",
    "\n",
    "games_df['Global_Sales'] = (games_df['NA_Sales'] + games_df['EU_Sales'] + \n",
    "                            games_df['JP_Sales'] + games_df['Other_Sales']).round(2)\n",
    "\n",
    "games_df.to_csv(RAW_DIR / 'Video_Games_Sales.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Dataset crÃ©Ã© : {len(games_df):,} jeux\")\n",
    "print(f\"ğŸ“ Fichier : {RAW_DIR / 'Video_Games_Sales.csv'}\")\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi1_1",
   "metadata": {},
   "source": [
    "## DÃ©fi 1.1 : Explorer les donnÃ©es\n",
    "\n",
    "### Consigne\n",
    "\n",
    "Charge le CSV et rÃ©ponds Ã  ces questions :\n",
    "\n",
    "1. **Combien** de jeux contient le dataset ?\n",
    "2. **Quelles colonnes** ont des valeurs manquantes ? Quel pourcentage ?\n",
    "3. **Quel est le jeu** le plus vendu ?\n",
    "4. **Quels sont les 5 genres** les plus reprÃ©sentÃ©s ?\n",
    "5. **Quelle est la plage d'annÃ©es** couverte par le dataset ?\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "- Quelle mÃ©thode Pandas donne les dimensions d'un DataFrame ?\n",
    "- Comment compter les valeurs manquantes par colonne ?\n",
    "- Comment trouver la ligne avec la valeur maximale d'une colonne ?\n",
    "- Comment compter les occurrences de chaque valeur d'une colonne ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code1_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TON CODE ICI\n",
    "# Explore les donnÃ©es et rÃ©ponds aux 5 questions\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Charge le CSV\n",
    "df = pd.read_csv('videogames-analytics/data/raw/Video_Games_Sales.csv')\n",
    "\n",
    "# Question 1 : Combien de jeux ?\n",
    "\n",
    "\n",
    "# Question 2 : Valeurs manquantes ?\n",
    "\n",
    "\n",
    "# Question 3 : Jeu le plus vendu ?\n",
    "\n",
    "\n",
    "# Question 4 : Top 5 genres ?\n",
    "\n",
    "\n",
    "# Question 5 : Plage d'annÃ©es ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution1_1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "- Nombre de lignes : `len(df)` ou `df.shape[0]`\n",
    "- Valeurs manquantes : `df.isnull().sum()`\n",
    "- Pourcentage : `df.isnull().sum() / len(df) * 100`\n",
    "- Ligne avec max : `df.loc[df['colonne'].idxmax()]`\n",
    "- Compter par catÃ©gorie : `df['colonne'].value_counts()`\n",
    "- Min/Max : `df['colonne'].min()`, `df['colonne'].max()`\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "df = pd.read_csv('videogames-analytics/data/raw/Video_Games_Sales.csv')\n",
    "\n",
    "# 1. Nombre de jeux\n",
    "print(f\"ğŸ“Š Nombre de jeux : {len(df):,}\")\n",
    "print(f\"   (ou avec shape : {df.shape[0]:,} lignes, {df.shape[1]} colonnes)\")\n",
    "\n",
    "# 2. Valeurs manquantes\n",
    "print(\"\\nâ“ Valeurs manquantes :\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "missing_df = pd.DataFrame({'Manquantes': missing, '%': missing_pct})\n",
    "print(missing_df[missing_df['Manquantes'] > 0])\n",
    "\n",
    "# 3. Jeu le plus vendu\n",
    "top_game = df.loc[df['Global_Sales'].idxmax()]\n",
    "print(f\"\\nğŸ† Jeu le plus vendu : {top_game['Name']}\")\n",
    "print(f\"   Ventes : {top_game['Global_Sales']}M$ | Plateforme : {top_game['Platform']}\")\n",
    "\n",
    "# 4. Top 5 genres\n",
    "print(\"\\nğŸ¯ Top 5 genres :\")\n",
    "print(df['Genre'].value_counts().head())\n",
    "\n",
    "# 5. Plage d'annÃ©es\n",
    "min_year = df['Year_of_Release'].min()\n",
    "max_year = df['Year_of_Release'].max()\n",
    "print(f\"\\nğŸ“… AnnÃ©es : {min_year:.0f} - {max_year:.0f}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi1_2",
   "metadata": {},
   "source": [
    "## DÃ©fi 1.2 : Nettoyer les donnÃ©es\n",
    "\n",
    "### Consigne\n",
    "\n",
    "CrÃ©e une fonction `clean_videogames_data(input_path, output_path)` qui :\n",
    "\n",
    "1. **Supprime les doublons** sur les colonnes (Name, Platform, Year_of_Release)\n",
    "2. **Convertit `Year_of_Release`** en entier (en gÃ©rant les NaN)\n",
    "3. **Remplit les ventes manquantes** par 0\n",
    "4. **CrÃ©e une colonne `Decade`** : la dÃ©cennie (ex: 2010 pour l'annÃ©e 2015)\n",
    "5. **CrÃ©e une colonne `Sales_Category`** basÃ©e sur Global_Sales :\n",
    "   - `< 0.1` â†’ \"Flop\"\n",
    "   - `0.1 - 1` â†’ \"Niche\"\n",
    "   - `1 - 5` â†’ \"Hit\"\n",
    "   - `> 5` â†’ \"Blockbuster\"\n",
    "6. **Sauvegarde le rÃ©sultat en Parquet** dans `data/processed/`\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "- Comment supprimer les doublons sur certaines colonnes seulement ?\n",
    "- Comment crÃ©er une colonne basÃ©e sur des conditions multiples (bins) ?\n",
    "- Pourquoi choisir Parquet plutÃ´t que CSV pour les donnÃ©es nettoyÃ©es ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code1_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TON CODE ICI\n",
    "# CrÃ©e la fonction de nettoyage\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_videogames_data(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Nettoie le dataset de jeux vidÃ©o.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Chemin vers le CSV brut\n",
    "        output_path: Chemin pour sauvegarder le Parquet nettoyÃ©\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame nettoyÃ©\n",
    "    \"\"\"\n",
    "    # TON CODE ICI\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test ta fonction\n",
    "# PROJECT_ROOT = Path('videogames-analytics')\n",
    "# cleaned_df = clean_videogames_data(\n",
    "#     input_path=PROJECT_ROOT / 'data' / 'raw' / 'Video_Games_Sales.csv',\n",
    "#     output_path=PROJECT_ROOT / 'data' / 'processed' / 'games_cleaned.parquet'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution1_2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "- Doublons sur colonnes spÃ©cifiques : `df.drop_duplicates(subset=['col1', 'col2'])`\n",
    "- Conversion avec NaN : `pd.to_numeric(df['col'], errors='coerce')` puis `.astype('Int64')` (nullable integer)\n",
    "- DÃ©cennie : `df['Year'] // 10 * 10` (division entiÃ¨re puis multiplication)\n",
    "- CatÃ©gories avec bins : `pd.cut(df['col'], bins=[...], labels=[...])`\n",
    "- Parquet : `df.to_parquet('fichier.parquet', index=False)`\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_videogames_data(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Nettoie le dataset de jeux vidÃ©o.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ§¹ Nettoyage des donnÃ©es...\")\n",
    "    \n",
    "    # Charger\n",
    "    df = pd.read_csv(input_path)\n",
    "    initial_count = len(df)\n",
    "    print(f\"   Lignes initiales : {initial_count:,}\")\n",
    "    \n",
    "    # 1. Supprimer les doublons\n",
    "    df = df.drop_duplicates(subset=['Name', 'Platform', 'Year_of_Release'])\n",
    "    print(f\"   AprÃ¨s dÃ©duplication : {len(df):,} (-{initial_count - len(df)})\")\n",
    "    \n",
    "    # 2. Convertir Year_of_Release en entier nullable\n",
    "    df['Year_of_Release'] = pd.to_numeric(df['Year_of_Release'], errors='coerce')\n",
    "    df['Year_of_Release'] = df['Year_of_Release'].astype('Int64')\n",
    "    \n",
    "    # 3. Remplir les ventes manquantes par 0\n",
    "    sales_cols = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n",
    "    df[sales_cols] = df[sales_cols].fillna(0)\n",
    "    \n",
    "    # 4. CrÃ©er la dÃ©cennie\n",
    "    df['Decade'] = (df['Year_of_Release'] // 10 * 10).astype('Int64')\n",
    "    \n",
    "    # 5. CrÃ©er la catÃ©gorie de ventes\n",
    "    df['Sales_Category'] = pd.cut(\n",
    "        df['Global_Sales'],\n",
    "        bins=[-np.inf, 0.1, 1, 5, np.inf],\n",
    "        labels=['Flop', 'Niche', 'Hit', 'Blockbuster']\n",
    "    )\n",
    "    \n",
    "    # 6. Sauvegarder en Parquet\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_parquet(output_path, index=False)\n",
    "    \n",
    "    print(f\"   âœ… SauvegardÃ© : {output_path}\")\n",
    "    print(f\"   Lignes finales : {len(df):,}\")\n",
    "    print(f\"   Nouvelles colonnes : Decade, Sales_Category\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ExÃ©cution\n",
    "PROJECT_ROOT = Path('videogames-analytics')\n",
    "cleaned_df = clean_videogames_data(\n",
    "    input_path=PROJECT_ROOT / 'data' / 'raw' / 'Video_Games_Sales.csv',\n",
    "    output_path=PROJECT_ROOT / 'data' / 'processed' / 'games_cleaned.parquet'\n",
    ")\n",
    "\n",
    "# VÃ©rification\n",
    "print(\"\\nğŸ“Š AperÃ§u :\")\n",
    "print(cleaned_df[['Name', 'Year_of_Release', 'Decade', 'Global_Sales', 'Sales_Category']].head())\n",
    "```\n",
    "\n",
    "**Pourquoi Parquet ?**\n",
    "- **Compression** : fichier 5-10x plus petit que CSV\n",
    "- **Types prÃ©servÃ©s** : pas de perte des types (dates, entiers, catÃ©gories)\n",
    "- **Lecture rapide** : format colonne optimisÃ© pour l'analytique\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase2_title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 2 : Web Scraping\n",
    "\n",
    "Le **Web Scraping** consiste Ã  extraire des donnÃ©es depuis des pages web automatiquement.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      WEB SCRAPING PIPELINE                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚   URL    â”‚â”€â”€â”€â”€â–¶â”‚ requests â”‚â”€â”€â”€â”€â–¶â”‚   HTML   â”‚â”€â”€â”€â”€â–¶â”‚   BS4    â”‚â”€â”€â”€â”€â–¶ DataFrame\n",
    "   â”‚          â”‚     â”‚  GET     â”‚     â”‚  brut    â”‚     â”‚  parse   â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Outils Python\n",
    "\n",
    "| Outil | Usage |\n",
    "|-------|-------|\n",
    "| `requests` | Envoyer des requÃªtes HTTP et rÃ©cupÃ©rer le HTML |\n",
    "| `BeautifulSoup` | Parser le HTML et extraire les Ã©lÃ©ments |\n",
    "| `lxml` | Parser HTML/XML (plus rapide) |\n",
    "\n",
    "### RÃ¨gles d'Ã‰thique du Scraping\n",
    "\n",
    "1. **Respecter le `robots.txt`** â€” vÃ©rifie ce que le site autorise\n",
    "2. **Ajouter des dÃ©lais** â€” `time.sleep()` entre les requÃªtes\n",
    "3. **S'identifier** â€” utilise un User-Agent descriptif\n",
    "4. **Ne pas surcharger** â€” limite le nombre de requÃªtes\n",
    "5. **VÃ©rifier les CGU** â€” certains sites interdisent le scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi2_1",
   "metadata": {},
   "source": [
    "## DÃ©fi 2.1 : Scraper Wikipedia\n",
    "\n",
    "### Consigne\n",
    "\n",
    "Ã‰cris une fonction `scrape_bestselling_games()` qui :\n",
    "\n",
    "1. RÃ©cupÃ¨re la page : https://en.wikipedia.org/wiki/List_of_best-selling_video_games\n",
    "2. Trouve le premier tableau avec la classe `wikitable`\n",
    "3. Extrait les **10 premiers jeux** avec : Nom, Ventes, Plateforme(s)\n",
    "4. Retourne un DataFrame pandas\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "- Comment envoyer une requÃªte HTTP GET en Python ?\n",
    "- Pourquoi faut-il spÃ©cifier un User-Agent ?\n",
    "- Comment trouver un Ã©lÃ©ment HTML par sa classe avec BeautifulSoup ?\n",
    "- Comment extraire le texte d'une balise HTML ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code2_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TON CODE ICI\n",
    "# CrÃ©e la fonction de scraping Wikipedia\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_bestselling_games() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrape la liste des jeux les plus vendus depuis Wikipedia.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec colonnes: name, sales, platform\n",
    "    \"\"\"\n",
    "    # TON CODE ICI\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test ta fonction\n",
    "# df_wiki = scrape_bestselling_games()\n",
    "# print(df_wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution2_1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. RequÃªte HTTP avec User-Agent\n",
    "headers = {'User-Agent': 'MonBot/1.0 (contact@example.com)'}\n",
    "response = requests.get(url, headers=headers, timeout=10)\n",
    "response.raise_for_status()  # LÃ¨ve une exception si erreur HTTP\n",
    "\n",
    "# 2. Parser le HTML\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# 3. Trouver un Ã©lÃ©ment par classe\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# 4. Trouver toutes les lignes\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# 5. Extraire le texte d'une cellule\n",
    "cell.get_text(strip=True)  # strip=True enlÃ¨ve les espaces\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_bestselling_games() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrape la liste des jeux les plus vendus depuis Wikipedia.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_best-selling_video_games\"\n",
    "    \n",
    "    # Headers pour s'identifier (bonne pratique)\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Educational Bot - Data Engineering Bootcamp)'\n",
    "    }\n",
    "    \n",
    "    # RequÃªte HTTP\n",
    "    print(f\"ğŸŒ RÃ©cupÃ©ration de {url}...\")\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    response.raise_for_status()  # Erreur si status != 200\n",
    "    \n",
    "    # Parser le HTML\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    # Trouver le premier tableau wikitable\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    \n",
    "    if not table:\n",
    "        raise ValueError(\"âŒ Tableau non trouvÃ© sur la page\")\n",
    "    \n",
    "    # Extraire les donnÃ©es\n",
    "    games = []\n",
    "    rows = table.find_all('tr')[1:11]  # Skip header, prendre 10 lignes\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all(['td', 'th'])\n",
    "        if len(cells) >= 3:\n",
    "            games.append({\n",
    "                'name': cells[0].get_text(strip=True),\n",
    "                'sales': cells[1].get_text(strip=True),\n",
    "                'platform': cells[2].get_text(strip=True) if len(cells) > 2 else 'N/A'\n",
    "            })\n",
    "    \n",
    "    print(f\"âœ… {len(games)} jeux extraits\")\n",
    "    return pd.DataFrame(games)\n",
    "\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    df_wiki = scrape_bestselling_games()\n",
    "    print(\"\\nğŸ® Top 10 jeux les plus vendus (Wikipedia) :\")\n",
    "    print(df_wiki.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur : {e}\")\n",
    "```\n",
    "\n",
    "**Explications :**\n",
    "- `raise_for_status()` lÃ¨ve une exception si le serveur retourne une erreur (404, 500, etc.)\n",
    "- `find_all('tr')[1:11]` : on ignore la premiÃ¨re ligne (header) et on prend les 10 suivantes\n",
    "- `get_text(strip=True)` extrait le texte en enlevant les espaces superflus\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase3_title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 3 : Stockage des DonnÃ©es\n",
    "\n",
    "On va stocker nos donnÃ©es dans deux systÃ¨mes complÃ©mentaires :\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     ARCHITECTURE STOCKAGE                       â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                        â”‚  games_cleaned  â”‚\n",
    "                        â”‚    .parquet     â”‚\n",
    "                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                 â”‚\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚                         â”‚\n",
    "                    â–¼                         â–¼\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚     DuckDB      â”‚       â”‚  Elasticsearch  â”‚\n",
    "          â”‚                 â”‚       â”‚                 â”‚\n",
    "          â”‚  â€¢ SQL queries  â”‚       â”‚  â€¢ Full-text    â”‚\n",
    "          â”‚  â€¢ Analytics    â”‚       â”‚  â€¢ Fuzzy search â”‚\n",
    "          â”‚  â€¢ Aggregations â”‚       â”‚  â€¢ Suggestions  â”‚\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "| SystÃ¨me | Usage | Avantage |\n",
    "|---------|-------|----------|\n",
    "| **DuckDB** | RequÃªtes SQL analytiques | Ultra-rapide, zero config |\n",
    "| **Elasticsearch** | Recherche full-text | Recherche fuzzy, suggestions |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi3_1",
   "metadata": {},
   "source": [
    "## DÃ©fi 3.1 : Charger dans DuckDB\n",
    "\n",
    "### Consigne\n",
    "\n",
    "1. CrÃ©e une base DuckDB `data/videogames.db`\n",
    "2. Charge le fichier Parquet nettoyÃ© dans une table `games`\n",
    "3. Ã‰cris et exÃ©cute les requÃªtes SQL suivantes :\n",
    "   - **Top 10 jeux** les plus vendus\n",
    "   - **Ventes totales par genre** (triÃ©es par ventes dÃ©croissantes)\n",
    "   - **Top 3 jeux par genre** (utilise une Window Function)\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "- Comment DuckDB peut lire directement un fichier Parquet sans le charger en mÃ©moire ?\n",
    "- Quelle est la diffÃ©rence entre `GROUP BY` et `PARTITION BY` ?\n",
    "- Quelle fonction SQL permet de numÃ©roter les lignes dans chaque groupe ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code3_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TON CODE ICI\n",
    "# Charge les donnÃ©es dans DuckDB et exÃ©cute les requÃªtes\n",
    "\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('videogames-analytics')\n",
    "DB_PATH = PROJECT_ROOT / 'data' / 'videogames.db'\n",
    "\n",
    "# 1. Connexion et crÃ©ation de la table\n",
    "\n",
    "\n",
    "# 2. Top 10 jeux les plus vendus\n",
    "\n",
    "\n",
    "# 3. Ventes totales par genre\n",
    "\n",
    "\n",
    "# 4. Top 3 jeux par genre (Window Function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution3_1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "```python\n",
    "# Connexion DuckDB\n",
    "conn = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "# CrÃ©er une table depuis un Parquet\n",
    "conn.execute(\"\"\"\n",
    "    CREATE OR REPLACE TABLE games AS \n",
    "    SELECT * FROM read_parquet('chemin/fichier.parquet')\n",
    "\"\"\")\n",
    "\n",
    "# Window Function pour classement par groupe\n",
    "ROW_NUMBER() OVER (PARTITION BY genre ORDER BY sales DESC) as rank\n",
    "\n",
    "# Puis filtrer avec WHERE rank <= 3\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```python\n",
    "import duckdb\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('videogames-analytics')\n",
    "DB_PATH = PROJECT_ROOT / 'data' / 'videogames.db'\n",
    "PARQUET_PATH = PROJECT_ROOT / 'data' / 'processed' / 'games_cleaned.parquet'\n",
    "\n",
    "# Connexion\n",
    "conn = duckdb.connect(str(DB_PATH))\n",
    "\n",
    "# 1. CrÃ©er la table depuis le Parquet\n",
    "conn.execute(f\"\"\"\n",
    "    CREATE OR REPLACE TABLE games AS \n",
    "    SELECT * FROM read_parquet('{PARQUET_PATH}')\n",
    "\"\"\")\n",
    "print(f\"âœ… Table 'games' crÃ©Ã©e avec {conn.execute('SELECT COUNT(*) FROM games').fetchone()[0]:,} lignes\")\n",
    "\n",
    "# 2. Top 10 jeux les plus vendus\n",
    "print(\"\\nğŸ† Top 10 jeux les plus vendus :\")\n",
    "print(conn.execute(\"\"\"\n",
    "    SELECT Name, Platform, Genre, Global_Sales\n",
    "    FROM games\n",
    "    ORDER BY Global_Sales DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf())\n",
    "\n",
    "# 3. Ventes totales par genre\n",
    "print(\"\\nğŸ“Š Ventes par genre :\")\n",
    "print(conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        Genre,\n",
    "        COUNT(*) as nb_games,\n",
    "        ROUND(SUM(Global_Sales), 2) as total_sales,\n",
    "        ROUND(AVG(Global_Sales), 2) as avg_sales\n",
    "    FROM games\n",
    "    GROUP BY Genre\n",
    "    ORDER BY total_sales DESC\n",
    "\"\"\").fetchdf())\n",
    "\n",
    "# 4. Top 3 jeux par genre (Window Function)\n",
    "print(\"\\nğŸ¯ Top 3 par genre :\")\n",
    "print(conn.execute(\"\"\"\n",
    "    WITH ranked AS (\n",
    "        SELECT \n",
    "            Genre,\n",
    "            Name,\n",
    "            Global_Sales,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY Genre \n",
    "                ORDER BY Global_Sales DESC\n",
    "            ) as rank\n",
    "        FROM games\n",
    "    )\n",
    "    SELECT Genre, rank, Name, Global_Sales\n",
    "    FROM ranked\n",
    "    WHERE rank <= 3\n",
    "    ORDER BY Genre, rank\n",
    "\"\"\").fetchdf().head(20))\n",
    "\n",
    "conn.close()\n",
    "print(f\"\\nâœ… Base sauvegardÃ©e : {DB_PATH}\")\n",
    "```\n",
    "\n",
    "**Explication Window Function :**\n",
    "- `PARTITION BY Genre` : crÃ©e des \"fenÃªtres\" par genre\n",
    "- `ORDER BY Global_Sales DESC` : ordonne dans chaque fenÃªtre\n",
    "- `ROW_NUMBER()` : numÃ©rote de 1 Ã  N dans chaque fenÃªtre\n",
    "- On filtre ensuite `WHERE rank <= 3` pour garder le top 3\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi3_2",
   "metadata": {},
   "source": [
    "## DÃ©fi 3.2 : Indexer dans Elasticsearch\n",
    "\n",
    "### PrÃ©requis\n",
    "\n",
    "Lance Elasticsearch en local (comme vu dans le M10) :\n",
    "```bash\n",
    "cd elasticsearch-8.x.x\n",
    "./bin/elasticsearch\n",
    "```\n",
    "\n",
    "### Consigne\n",
    "\n",
    "1. CrÃ©e une fonction `index_games_to_es(df, index_name)` qui :\n",
    "   - Se connecte Ã  Elasticsearch local (http://localhost:9200)\n",
    "   - Supprime l'index s'il existe dÃ©jÃ \n",
    "   - CrÃ©e un index `videogames` avec un mapping appropriÃ©\n",
    "   - Indexe tous les jeux en utilisant le bulk API\n",
    "\n",
    "2. CrÃ©e une fonction `search_games(query)` qui :\n",
    "   - Fait une recherche fuzzy sur le champ `Name`\n",
    "   - Retourne les 10 meilleurs rÃ©sultats\n",
    "\n",
    "## Questions pour rÃ©flÃ©chir\n",
    "\n",
    "- Pourquoi utiliser le bulk API plutÃ´t que des insertions une par une ?\n",
    "- Quelle est la diffÃ©rence entre les types `text` et `keyword` dans ES ?\n",
    "- Comment fonctionne la recherche fuzzy ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code3_2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TON CODE ICI\n",
    "# Indexe les jeux dans Elasticsearch\n",
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def index_games_to_es(df: pd.DataFrame, index_name: str = \"videogames\") -> int:\n",
    "    \"\"\"\n",
    "    Indexe les jeux dans Elasticsearch.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame des jeux\n",
    "        index_name: Nom de l'index ES\n",
    "    \n",
    "    Returns:\n",
    "        Nombre de documents indexÃ©s\n",
    "    \"\"\"\n",
    "    # TON CODE ICI\n",
    "    pass\n",
    "\n",
    "\n",
    "def search_games(query: str, index_name: str = \"videogames\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Recherche des jeux par nom (fuzzy search).\n",
    "    \n",
    "    Args:\n",
    "        query: Terme de recherche\n",
    "        index_name: Nom de l'index ES\n",
    "    \n",
    "    Returns:\n",
    "        Liste des rÃ©sultats\n",
    "    \"\"\"\n",
    "    # TON CODE ICI\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution3_2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "```python\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "# Connexion\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "es.ping()  # VÃ©rifie la connexion\n",
    "\n",
    "# Supprimer un index\n",
    "es.indices.delete(index=\"videogames\", ignore=[404])\n",
    "\n",
    "# CrÃ©er avec mapping\n",
    "es.indices.create(index=\"videogames\", body={\"mappings\": {...}})\n",
    "\n",
    "# Bulk indexation\n",
    "actions = [{\"_index\": \"videogames\", \"_source\": doc} for doc in docs]\n",
    "helpers.bulk(es, actions)\n",
    "\n",
    "# Recherche fuzzy\n",
    "es.search(index=\"videogames\", query={\n",
    "    \"match\": {\"Name\": {\"query\": \"...\", \"fuzziness\": \"AUTO\"}}\n",
    "})\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```python\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def index_games_to_es(df: pd.DataFrame, index_name: str = \"videogames\") -> int:\n",
    "    \"\"\"\n",
    "    Indexe les jeux dans Elasticsearch.\n",
    "    \"\"\"\n",
    "    # Connexion\n",
    "    es = Elasticsearch(\"http://localhost:9200\")\n",
    "    \n",
    "    if not es.ping():\n",
    "        raise ConnectionError(\"âŒ Elasticsearch non disponible sur localhost:9200\")\n",
    "    \n",
    "    print(f\"âœ… ConnectÃ© Ã  Elasticsearch\")\n",
    "    \n",
    "    # Supprimer l'index s'il existe\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"   Index '{index_name}' supprimÃ©\")\n",
    "    \n",
    "    # CrÃ©er l'index avec mapping\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"Name\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "                \"Platform\": {\"type\": \"keyword\"},\n",
    "                \"Genre\": {\"type\": \"keyword\"},\n",
    "                \"Publisher\": {\"type\": \"keyword\"},\n",
    "                \"Year_of_Release\": {\"type\": \"integer\"},\n",
    "                \"Global_Sales\": {\"type\": \"float\"},\n",
    "                \"Critic_Score\": {\"type\": \"float\"},\n",
    "                \"Sales_Category\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"   Index '{index_name}' crÃ©Ã©\")\n",
    "    \n",
    "    # PrÃ©parer les documents (remplacer NaN par None)\n",
    "    records = df.where(pd.notnull(df), None).to_dict('records')\n",
    "    \n",
    "    # Bulk indexation\n",
    "    actions = [\n",
    "        {\"_index\": index_name, \"_source\": record}\n",
    "        for record in records\n",
    "    ]\n",
    "    \n",
    "    success, errors = helpers.bulk(es, actions, raise_on_error=False)\n",
    "    \n",
    "    print(f\"âœ… {success} documents indexÃ©s\")\n",
    "    if errors:\n",
    "        print(f\"âš ï¸ {len(errors)} erreurs\")\n",
    "    \n",
    "    return success\n",
    "\n",
    "\n",
    "def search_games(query: str, index_name: str = \"videogames\") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Recherche des jeux par nom (fuzzy search).\n",
    "    \"\"\"\n",
    "    es = Elasticsearch(\"http://localhost:9200\")\n",
    "    \n",
    "    response = es.search(\n",
    "        index=index_name,\n",
    "        query={\n",
    "            \"match\": {\n",
    "                \"Name\": {\n",
    "                    \"query\": query,\n",
    "                    \"fuzziness\": \"AUTO\"  # TolÃ¨re les fautes de frappe\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        size=10\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        results.append({\n",
    "            'score': hit['_score'],\n",
    "            **hit['_source']\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Test\n",
    "try:\n",
    "    # Charger et indexer\n",
    "    df = pd.read_parquet('videogames-analytics/data/processed/games_cleaned.parquet')\n",
    "    index_games_to_es(df)\n",
    "    \n",
    "    # Rechercher\n",
    "    print(\"\\nğŸ” Recherche 'Final Fantasi' (avec faute) :\")\n",
    "    results = search_games(\"Final Fantasi\")\n",
    "    for r in results[:5]:\n",
    "        print(f\"   {r['Name']} ({r['Platform']}) - Score: {r['score']:.2f}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Erreur : {e}\")\n",
    "    print(\"   Assure-toi qu'Elasticsearch est lancÃ© sur localhost:9200\")\n",
    "```\n",
    "\n",
    "**Explications :**\n",
    "- `text` : le champ est analysÃ© (tokenisÃ©, stemming) â†’ pour la recherche full-text\n",
    "- `keyword` : valeur exacte â†’ pour les filtres et agrÃ©gations\n",
    "- `fuzziness: AUTO` : tolÃ¨re 1-2 caractÃ¨res d'erreur selon la longueur du mot\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phase4_title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âš¡ Phase 4 : Traitement PySpark\n",
    "\n",
    "Utilisons PySpark pour des analyses Ã  grande Ã©chelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defi4_1",
   "metadata": {},
   "source": [
    "## DÃ©fi 4.1 : Analyses avec Window Functions\n",
    "\n",
    "### Consigne\n",
    "\n",
    "Utilise PySpark pour :\n",
    "\n",
    "1. Charger le fichier Parquet\n",
    "2. Calculer les **statistiques par Publisher** :\n",
    "   - Nombre de jeux\n",
    "   - Ventes totales\n",
    "   - Score critique moyen\n",
    "   - Nombre de genres diffÃ©rents\n",
    "3. Utiliser `ROW_NUMBER()` pour classer les jeux **par ventes dans chaque genre**\n",
    "4. Sauvegarder les rÃ©sultats en Parquet\n",
    "\n",
    "### Questions pour rÃ©flÃ©chir\n",
    "\n",
    "- Quelle est la diffÃ©rence entre `groupBy().agg()` et les Window Functions ?\n",
    "- Comment crÃ©er une fenÃªtre partitionnÃ©e en PySpark ?\n",
    "- Quelle fonction Spark donne le rang dans une fenÃªtre ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code4_1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TON CODE ICI\n",
    "# Analyses PySpark avec Window Functions\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# CrÃ©er la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VideoGamesAnalytics\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 1. Charger les donnÃ©es\n",
    "\n",
    "\n",
    "# 2. Stats par Publisher\n",
    "\n",
    "\n",
    "# 3. Classement par genre avec Window\n",
    "\n",
    "\n",
    "# 4. Sauvegarder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solution4_1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>ğŸ’¡ <b>Cliquer pour voir les indices</b></summary>\n",
    "\n",
    "```python\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# AgrÃ©gation par groupe\n",
    "df.groupBy(\"Publisher\").agg(\n",
    "    F.count(\"*\").alias(\"nb_games\"),\n",
    "    F.sum(\"Global_Sales\").alias(\"total_sales\")\n",
    ")\n",
    "\n",
    "# Window Function\n",
    "window = Window.partitionBy(\"Genre\").orderBy(F.desc(\"Global_Sales\"))\n",
    "df.withColumn(\"rank\", F.row_number().over(window))\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "<summary>âœ… <b>Cliquer pour voir la solution</b></summary>\n",
    "\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('videogames-analytics')\n",
    "\n",
    "# CrÃ©er la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VideoGamesAnalytics\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(f\"âœ… Spark {spark.version} initialisÃ©\")\n",
    "\n",
    "# 1. Charger les donnÃ©es\n",
    "games_sdf = spark.read.parquet(str(PROJECT_ROOT / 'data' / 'processed' / 'games_cleaned.parquet'))\n",
    "print(f\"ğŸ“Š {games_sdf.count():,} jeux chargÃ©s\")\n",
    "\n",
    "# 2. Stats par Publisher\n",
    "print(\"\\nğŸ¢ Statistiques par Publisher :\")\n",
    "publisher_stats = games_sdf.groupBy(\"Publisher\").agg(\n",
    "    F.count(\"*\").alias(\"nb_games\"),\n",
    "    F.round(F.sum(\"Global_Sales\"), 2).alias(\"total_sales\"),\n",
    "    F.round(F.avg(\"Critic_Score\"), 1).alias(\"avg_critic\"),\n",
    "    F.countDistinct(\"Genre\").alias(\"nb_genres\")\n",
    ").orderBy(F.desc(\"total_sales\"))\n",
    "\n",
    "publisher_stats.show(10)\n",
    "\n",
    "# 3. Classement par genre avec Window\n",
    "print(\"\\nğŸ† Top 3 jeux par genre :\")\n",
    "window_genre = Window.partitionBy(\"Genre\").orderBy(F.desc(\"Global_Sales\"))\n",
    "\n",
    "ranked_games = games_sdf.withColumn(\n",
    "    \"rank_in_genre\", F.row_number().over(window_genre)\n",
    ").filter(\n",
    "    F.col(\"rank_in_genre\") <= 3\n",
    ").select(\n",
    "    \"Genre\", \"rank_in_genre\", \"Name\", \"Platform\", \"Global_Sales\"\n",
    ").orderBy(\"Genre\", \"rank_in_genre\")\n",
    "\n",
    "ranked_games.show(20)\n",
    "\n",
    "# 4. Sauvegarder\n",
    "output_path = PROJECT_ROOT / 'data' / 'processed' / 'publisher_stats'\n",
    "publisher_stats.write.mode(\"overwrite\").parquet(str(output_path))\n",
    "print(f\"âœ… RÃ©sultats sauvegardÃ©s : {output_path}\")\n",
    "\n",
    "spark.stop()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remaining_phases",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Phase 5 : API REST avec FastAPI\n",
    "\n",
    "## DÃ©fi 5.1 : CrÃ©er les endpoints\n",
    "\n",
    "### Consigne\n",
    "\n",
    "CrÃ©e `api/main.py` avec les endpoints suivants :\n",
    "\n",
    "| Endpoint | MÃ©thode | Description |\n",
    "|----------|---------|-------------|\n",
    "| `/` | GET | Message de bienvenue |\n",
    "| `/games` | GET | Liste avec filtres (genre, platform, min_sales) |\n",
    "| `/games/{name}` | GET | DÃ©tails d'un jeu |\n",
    "| `/stats/genres` | GET | Stats par genre |\n",
    "| `/stats/publishers` | GET | Top publishers |\n",
    "| `/search?q=...` | GET | Recherche Elasticsearch |\n",
    "\n",
    "**Lancer l'API** : `uvicorn api.main:app --reload`\n",
    "\n",
    "---\n",
    "\n",
    "# Phase 6 : Dashboard Streamlit\n",
    "\n",
    "## DÃ©fi 6.1 : Dashboard interactif\n",
    "\n",
    "### Consigne\n",
    "\n",
    "CrÃ©e `dashboard/app.py` avec :\n",
    "\n",
    "- **Sidebar** : filtres (genre, plateforme, annÃ©es)\n",
    "- **KPIs** : nombre de jeux, ventes totales, score moyen\n",
    "- **Graphiques** : bar chart par genre, line chart Ã©volution, pie chart rÃ©gions\n",
    "- **Tableau** : top 10 jeux\n",
    "\n",
    "**Lancer le dashboard** : `streamlit run dashboard/app.py`\n",
    "\n",
    "---\n",
    "\n",
    "# Phase 7 : Automatisation\n",
    "\n",
    "## DÃ©fi 7.1 : Script de pipeline\n",
    "\n",
    "### Consigne\n",
    "\n",
    "CrÃ©e `scripts/run_pipeline.sh` qui :\n",
    "\n",
    "1. Affiche la date/heure de dÃ©marrage\n",
    "2. Installe les dÃ©pendances\n",
    "3. ExÃ©cute chaque Ã©tape du pipeline\n",
    "4. Log tout dans `pipeline.log`\n",
    "5. Affiche un rÃ©sumÃ© Ã  la fin\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ’¡ **Note** : Les solutions complÃ¨tes pour les phases 4-7 suivent le mÃªme format que les phases prÃ©cÃ©dentes. Essaie d'abord par toi-mÃªme !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_recap",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ‰ FÃ©licitations !\n",
    "\n",
    "Tu as terminÃ© le **Projet IntÃ©grateur DÃ©butant** !\n",
    "\n",
    "## âœ… Ce que tu as construit\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    VIDEO GAMES ANALYTICS - COMPÃ‰TENCES                      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                              â”‚  Video Games    â”‚\n",
    "                              â”‚   Analytics     â”‚\n",
    "                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                       â”‚\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚                            â”‚                            â”‚\n",
    "          â–¼                            â–¼                            â–¼\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚  INGESTION  â”‚              â”‚  PROCESSING â”‚              â”‚   STORAGE   â”‚\n",
    "   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "   â”‚ â€¢ Kaggle    â”‚              â”‚ â€¢ Pandas    â”‚              â”‚ â€¢ DuckDB    â”‚\n",
    "   â”‚ â€¢ Scraping  â”‚              â”‚ â€¢ PySpark   â”‚              â”‚ â€¢ ES        â”‚\n",
    "   â”‚ â€¢ BS4       â”‚              â”‚ â€¢ Window    â”‚              â”‚ â€¢ Parquet   â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "          â”‚                            â”‚                            â”‚\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                       â”‚\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚                            â”‚                            â”‚\n",
    "          â–¼                            â–¼                            â–¼\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚   SERVING   â”‚              â”‚   DEVOPS    â”‚              â”‚  DASHBOARD  â”‚\n",
    "   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "   â”‚ â€¢ FastAPI   â”‚              â”‚ â€¢ Git       â”‚              â”‚ â€¢ Streamlit â”‚\n",
    "   â”‚ â€¢ REST API  â”‚              â”‚ â€¢ Bash      â”‚              â”‚ â€¢ Plotly    â”‚\n",
    "   â”‚ â€¢ Pydantic  â”‚              â”‚ â€¢ Automationâ”‚              â”‚ â€¢ Filters   â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## ğŸ“š CompÃ©tences ValidÃ©es\n",
    "\n",
    "| Domaine | CompÃ©tences |\n",
    "|---------|-------------|\n",
    "| **Ingestion** | CSV, Web Scraping, APIs |\n",
    "| **Processing** | Pandas, PySpark, SQL |\n",
    "| **Storage** | DuckDB, Elasticsearch, Parquet |\n",
    "| **Serving** | FastAPI, Streamlit |\n",
    "| **DevOps** | Git, Bash, Automation |\n",
    "\n",
    "## ğŸš€ Prochaine Ã©tape\n",
    "\n",
    "ğŸ‘‰ **Niveau IntermÃ©diaire** : Docker, Kubernetes, Kafka, Delta Lake, dbt, Airflow...\n",
    "\n",
    "---\n",
    "\n",
    "*ğŸ® Video Games Analytics Platform â€” Data Engineering Bootcamp*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
