{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üêª‚Äç‚ùÑÔ∏è Polars pour Data Engineers\n",
    "\n",
    "Bienvenue dans ce module o√π tu vas d√©couvrir **Polars**, la biblioth√®que DataFrame ultra-rapide qui r√©volutionne le traitement de donn√©es en Python. Tu apprendras pourquoi Polars surpasse Pandas, comment exploiter son moteur d'ex√©cution lazy, et comment construire des pipelines ETL performants !\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Pr√©requis\n",
    "\n",
    "| Niveau | Comp√©tence |\n",
    "|--------|------------|\n",
    "| ‚úÖ Requis | Connaissances de base en Python |\n",
    "| ‚úÖ Requis | Avoir utilis√© Pandas (m√™me basiquement) |\n",
    "| üí° Recommand√© | Avoir suivi les modules pr√©c√©dents du bootcamp |\n",
    "\n",
    "## üéØ Objectifs du module\n",
    "\n",
    "√Ä la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Comprendre pourquoi Polars est **5-100x plus rapide** que Pandas\n",
    "- Ma√Ætriser l'architecture **columnar** et le format **Apache Arrow**\n",
    "- Utiliser les **expressions Polars** pour des transformations efficaces\n",
    "- Exploiter l'ex√©cution **Lazy** pour des pipelines optimis√©s\n",
    "- Migrer du code Pandas vers Polars\n",
    "- Construire des pipelines ETL performants en production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polars_vs_pandas",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ 1. Polars vs Pandas : Pourquoi changer ?\n",
    "\n",
    "Avant de plonger dans Polars, comprenons **pourquoi** cette biblioth√®que existe et ce qu'elle apporte.\n",
    "\n",
    "### 1.1 Les limitations de Pandas\n",
    "\n",
    "Pandas est formidable pour l'exploration de donn√©es, mais il a des **limitations structurelles** :\n",
    "\n",
    "| Limitation | Explication | Impact |\n",
    "|------------|-------------|--------|\n",
    "| **Single-threaded** | Le GIL Python bloque le parall√©lisme | N'utilise qu'1 CPU |\n",
    "| **Row-based en m√©moire** | Donn√©es stock√©es par ligne | Cache CPU inefficace |\n",
    "| **Eager execution** | Chaque op√©ration s'ex√©cute imm√©diatement | Pas d'optimisation globale |\n",
    "| **Copies fr√©quentes** | Beaucoup d'op√©rations copient les donn√©es | RAM x2 ou x3 |\n",
    "| **M√©moire gourmande** | ~5-10x la taille du fichier | Limite les gros datasets |\n",
    "\n",
    "### 1.2 Les forces de Polars\n",
    "\n",
    "| Aspect | Pandas | Polars |\n",
    "|--------|--------|--------|\n",
    "| **Backend** | NumPy (C) | Rust ü¶Ä |\n",
    "| **Threading** | Single (GIL) | Multi-threaded |\n",
    "| **M√©moire** | Row-based | Columnar (Arrow) |\n",
    "| **Execution** | Eager only | Eager + **Lazy** |\n",
    "| **Vitesse** | Baseline | **5-100x plus rapide** |\n",
    "| **Out-of-core** | ‚ùå | ‚úÖ (streaming) |\n",
    "| **Optimiseur** | ‚ùå | ‚úÖ Query planner |\n",
    "\n",
    "> üí° **En r√©sum√©** : Polars est con√ßu d√®s le d√©part pour la **performance** et les **gros volumes**, l√† o√π Pandas a √©t√© con√ßu pour l'**exploration interactive**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polars_info",
   "metadata": {},
   "source": [
    "> ‚ÑπÔ∏è **Le savais-tu ?**\n",
    ">\n",
    "> Polars a √©t√© cr√©√© en **2020** par **Ritchie Vink**, un ing√©nieur n√©erlandais frustr√© par la lenteur de Pandas.\n",
    ">\n",
    "> Le nom \"Polars\" fait r√©f√©rence √† l'**ours polaire** (üêª‚Äç‚ùÑÔ∏è) ‚Äî un clin d'≈ìil √† Pandas (üêº) tout en √©tant plus rapide et adapt√© aux environnements \"froids\" (haute performance).\n",
    ">\n",
    "> Polars est √©crit en **Rust**, un langage r√©put√© pour sa vitesse et sa s√©curit√© m√©moire.\n",
    ">\n",
    "> üìñ [Site officiel Polars](https://www.pola.rs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark",
   "metadata": {},
   "source": [
    "### 1.3 Benchmark concret\n",
    "\n",
    "Comparons Pandas et Polars sur une op√©ration simple : lire un CSV et faire une agr√©gation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_benchmark_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un fichier de test\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# G√©n√©rer 500K lignes\n",
    "categories = [\"Electronics\", \"Clothing\", \"Food\", \"Books\", \"Sports\"]\n",
    "n_rows = 500_000\n",
    "\n",
    "with open(\"data/benchmark.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"id\", \"category\", \"amount\", \"quantity\"])\n",
    "    for i in range(n_rows):\n",
    "        writer.writerow([\n",
    "            i,\n",
    "            random.choice(categories),\n",
    "            round(random.uniform(10, 1000), 2),\n",
    "            random.randint(1, 100)\n",
    "        ])\n",
    "\n",
    "print(f\"‚úÖ Fichier cr√©√© : data/benchmark.csv ({n_rows:,} lignes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark_pandas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Benchmark Pandas\n",
    "start = time.time()\n",
    "\n",
    "df_pandas = pd.read_csv(\"data/benchmark.csv\")\n",
    "result_pandas = (\n",
    "    df_pandas\n",
    "    .groupby(\"category\")\n",
    "    .agg({\"amount\": \"sum\", \"quantity\": \"mean\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "pandas_time = time.time() - start\n",
    "print(f\"üêº Pandas : {pandas_time:.3f} secondes\")\n",
    "print(result_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark_polars",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "\n",
    "# Benchmark Polars (Eager)\n",
    "start = time.time()\n",
    "\n",
    "df_polars = pl.read_csv(\"data/benchmark.csv\")\n",
    "result_polars = (\n",
    "    df_polars\n",
    "    .group_by(\"category\")\n",
    "    .agg(\n",
    "        pl.col(\"amount\").sum().alias(\"amount_sum\"),\n",
    "        pl.col(\"quantity\").mean().alias(\"quantity_mean\")\n",
    "    )\n",
    ")\n",
    "\n",
    "polars_time = time.time() - start\n",
    "print(f\"üêª‚Äç‚ùÑÔ∏è Polars : {polars_time:.3f} secondes\")\n",
    "print(f\"‚ö° Polars est {pandas_time/polars_time:.1f}x plus rapide !\")\n",
    "print(result_polars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "benchmark_polars_lazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark Polars (Lazy) - encore plus rapide !\n",
    "start = time.time()\n",
    "\n",
    "result_lazy = (\n",
    "    pl.scan_csv(\"data/benchmark.csv\")  # Lazy !\n",
    "    .group_by(\"category\")\n",
    "    .agg(\n",
    "        pl.col(\"amount\").sum().alias(\"amount_sum\"),\n",
    "        pl.col(\"quantity\").mean().alias(\"quantity_mean\")\n",
    "    )\n",
    "    .collect()  # Ex√©cution optimis√©e\n",
    ")\n",
    "\n",
    "lazy_time = time.time() - start\n",
    "print(f\"üöÄ Polars Lazy : {lazy_time:.3f} secondes\")\n",
    "print(f\"‚ö° Polars Lazy est {pandas_time/lazy_time:.1f}x plus rapide que Pandas !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèóÔ∏è 2. Comprendre l'architecture de Polars\n",
    "\n",
    "Pour bien utiliser Polars, il faut comprendre **pourquoi** il est si rapide.\n",
    "\n",
    "### 2.1 Columnar vs Row-based\n",
    "\n",
    "```text\n",
    "ROW-BASED (Pandas)                    COLUMNAR (Polars)\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ id  ‚îÇ name ‚îÇ age ‚îÇ                  ‚îÇ id:   [1, 2, 3]   ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  1  ‚îÇ Ana  ‚îÇ 25  ‚îÇ  ‚Üê Ligne 1       ‚îÇ name: [A, B, C]   ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  2  ‚îÇ Bob  ‚îÇ 30  ‚îÇ  ‚Üê Ligne 2       ‚îÇ age:  [25, 30, 22]‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "‚îÇ  3  ‚îÇ Cat  ‚îÇ 22  ‚îÇ  ‚Üê Ligne 3              ‚Üë\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   Colonnes contigu√´s\n",
    "        ‚Üë                              en m√©moire\n",
    "  Lignes contigu√´s\n",
    "  en m√©moire\n",
    "```\n",
    "\n",
    "**Pourquoi columnar est plus rapide ?**\n",
    "\n",
    "| Avantage | Explication |\n",
    "|----------|-------------|\n",
    "| **Cache CPU** | Donn√©es contigu√´s = moins de cache misses |\n",
    "| **SIMD** | Op√©rations vectoris√©es sur colonnes enti√®res |\n",
    "| **Compression** | Colonnes homog√®nes = meilleure compression |\n",
    "| **S√©lection** | Lire seulement les colonnes n√©cessaires |\n",
    "\n",
    "### 2.2 Apache Arrow : le format sous-jacent\n",
    "\n",
    "Polars utilise **Apache Arrow** comme format m√©moire :\n",
    "\n",
    "| Avantage | Description |\n",
    "|----------|-------------|\n",
    "| **Zero-copy** | Partage de donn√©es sans copie |\n",
    "| **Interop√©rabilit√©** | Compatible Spark, DuckDB, PyArrow |\n",
    "| **Standardis√©** | Format ouvert et document√© |\n",
    "\n",
    "### 2.3 Eager vs Lazy execution\n",
    "\n",
    "| Mode | Description | Quand l'utiliser |\n",
    "|------|-------------|------------------|\n",
    "| **Eager** | Ex√©cute imm√©diatement chaque op√©ration | Exploration, debug, petits datasets |\n",
    "| **Lazy** | Construit un plan, optimise, puis ex√©cute | Production, gros fichiers, pipelines |\n",
    "\n",
    "```python\n",
    "# Eager : r√©sultat imm√©diat\n",
    "df = pl.read_csv(\"data.csv\")        # Lit maintenant\n",
    "df = df.filter(pl.col(\"x\") > 5)     # Filtre maintenant\n",
    "\n",
    "# Lazy : plan d'ex√©cution\n",
    "lf = pl.scan_csv(\"data.csv\")        # Cr√©e un plan\n",
    "lf = lf.filter(pl.col(\"x\") > 5)     # Ajoute au plan\n",
    "df = lf.collect()                    # Ex√©cute tout (optimis√©)\n",
    "```\n",
    "\n",
    "### 2.4 Query Optimizer\n",
    "\n",
    "Le **Query Optimizer** de Polars applique automatiquement des optimisations :\n",
    "\n",
    "| Optimisation | Description |\n",
    "|--------------|-------------|\n",
    "| **Predicate pushdown** | Filtres appliqu√©s le plus t√¥t possible |\n",
    "| **Projection pruning** | Colonnes inutiles jamais lues |\n",
    "| **Common subexpression** | Calculs redondants factoris√©s |\n",
    "| **Parallelization** | Op√©rations distribu√©es sur tous les CPUs |\n",
    "\n",
    "```text\n",
    "PLAN ORIGINAL                    PLAN OPTIMIS√â\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê                    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "scan_csv(all cols)               scan_csv(only needed cols)\n",
    "      ‚îÇ                                ‚îÇ\n",
    "      ‚ñº                                ‚ñº\n",
    "with_columns(...)                filter(amount > 100)  ‚Üê Pushdown!\n",
    "      ‚îÇ                                ‚îÇ\n",
    "      ‚ñº                                ‚ñº\n",
    "filter(amount > 100)             with_columns(...)\n",
    "      ‚îÇ                                ‚îÇ\n",
    "      ‚ñº                                ‚ñº\n",
    "   result                           result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíª 3. Installation & Configuration\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "# Installation de base\n",
    "pip install polars\n",
    "\n",
    "# Avec toutes les features (recommand√©)\n",
    "pip install 'polars[all]'\n",
    "\n",
    "# Features sp√©cifiques\n",
    "pip install 'polars[pyarrow,pandas,numpy,fsspec]'\n",
    "```\n",
    "\n",
    "### V√©rification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_install",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "print(f\"‚úÖ Polars version : {pl.__version__}\")\n",
    "\n",
    "# Configuration de l'affichage\n",
    "pl.Config.set_tbl_rows(10)           # Lignes affich√©es\n",
    "pl.Config.set_tbl_cols(12)           # Colonnes affich√©es\n",
    "pl.Config.set_fmt_str_lengths(50)    # Longueur des strings\n",
    "\n",
    "# Voir le nombre de threads utilis√©s\n",
    "print(f\"üîß Threads disponibles : {pl.thread_pool_size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÇ 4. Charger & Exporter des donn√©es\n",
    "\n",
    "### 4.1 Formats support√©s\n",
    "\n",
    "| Format | Read (Eager) | Scan (Lazy) | Write |\n",
    "|--------|--------------|-------------|-------|\n",
    "| **CSV** | `read_csv()` | `scan_csv()` | `write_csv()` |\n",
    "| **Parquet** | `read_parquet()` | `scan_parquet()` | `write_parquet()` |\n",
    "| **JSON** | `read_json()` | `scan_ndjson()` | `write_json()` |\n",
    "| **Excel** | `read_excel()` | ‚ùå | `write_excel()` |\n",
    "| **Database** | `read_database()` | ‚ùå | ‚ùå |\n",
    "| **IPC/Feather** | `read_ipc()` | `scan_ipc()` | `write_ipc()` |\n",
    "\n",
    "### 4.2 Lecture Eager vs Lazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# ============ EAGER (tout en m√©moire) ============\n",
    "df = pl.read_csv(\"data/benchmark.csv\")\n",
    "print(\"Eager - Type:\", type(df))\n",
    "print(df.head(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ============ LAZY (plan d'ex√©cution) ============\n",
    "lf = pl.scan_csv(\"data/benchmark.csv\")\n",
    "print(\"Lazy - Type:\", type(lf))\n",
    "print(lf)  # Affiche le plan, pas les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "read_multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er plusieurs fichiers pour l'exemple\n",
    "import os\n",
    "os.makedirs(\"data/multi\", exist_ok=True)\n",
    "\n",
    "for i in range(3):\n",
    "    pl.DataFrame({\n",
    "        \"id\": range(i*100, (i+1)*100),\n",
    "        \"value\": [i*10 + j for j in range(100)]\n",
    "    }).write_csv(f\"data/multi/file_{i}.csv\")\n",
    "\n",
    "print(\"‚úÖ Fichiers cr√©√©s\")\n",
    "\n",
    "# Lire plusieurs fichiers avec glob pattern\n",
    "lf = pl.scan_csv(\"data/multi/*.csv\")\n",
    "print(f\"\\nNombre de lignes : {lf.collect().height}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "write_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âcriture\n",
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"age\": [25, 30, 35],\n",
    "    \"city\": [\"Paris\", \"Lyon\", \"Marseille\"]\n",
    "})\n",
    "\n",
    "# CSV\n",
    "df.write_csv(\"data/output.csv\")\n",
    "\n",
    "# Parquet (recommand√© pour la production)\n",
    "df.write_parquet(\"data/output.parquet\")\n",
    "\n",
    "# JSON\n",
    "df.write_json(\"data/output.json\")\n",
    "\n",
    "print(\"‚úÖ Fichiers export√©s\")\n",
    "\n",
    "# V√©rifier avec Parquet\n",
    "df_parquet = pl.read_parquet(\"data/output.parquet\")\n",
    "print(df_parquet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressions",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üî• 5. Expressions Polars ‚Äî Le c≈ìur du moteur\n",
    "\n",
    "> üß† **Les expressions sont ce qui rend Polars si puissant.** C'est un changement de paradigme par rapport √† Pandas.\n",
    "\n",
    "### 5.1 Philosophie : tout est expression\n",
    "\n",
    "```python\n",
    "# ‚ùå Pandas : op√©rations sur colonnes\n",
    "df[\"new_col\"] = df[\"a\"] + df[\"b\"]\n",
    "\n",
    "# ‚úÖ Polars : expressions\n",
    "df.with_columns(\n",
    "    (pl.col(\"a\") + pl.col(\"b\")).alias(\"new_col\")\n",
    ")\n",
    "```\n",
    "\n",
    "### 5.2 Expressions de base\n",
    "\n",
    "| Expression | Description | Exemple |\n",
    "|------------|-------------|---------|\n",
    "| `pl.col(\"x\")` | S√©lectionner une colonne | `pl.col(\"amount\")` |\n",
    "| `pl.col(\"x\", \"y\")` | Plusieurs colonnes | `pl.col(\"a\", \"b\", \"c\")` |\n",
    "| `pl.all()` | Toutes les colonnes | `df.select(pl.all())` |\n",
    "| `pl.exclude(\"x\")` | Toutes sauf x | `pl.exclude(\"id\")` |\n",
    "| `pl.lit(42)` | Valeur litt√©rale | `pl.lit(\"constant\")` |\n",
    "| `pl.col(\"*\")` | Toutes (autre syntaxe) | `pl.col(\"*\")` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressions_basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\"],\n",
    "    \"age\": [25, 30, 35, 28],\n",
    "    \"salary\": [50000, 60000, 75000, 55000],\n",
    "    \"department\": [\"IT\", \"HR\", \"IT\", \"Finance\"]\n",
    "})\n",
    "\n",
    "print(\"DataFrame original :\")\n",
    "print(df)\n",
    "\n",
    "# S√©lectionner des colonnes avec expressions\n",
    "print(\"\\nS√©lection avec expressions :\")\n",
    "print(\n",
    "    df.select(\n",
    "        pl.col(\"name\"),\n",
    "        pl.col(\"salary\") / 12,  # Salaire mensuel\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressions_conditional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expressions conditionnelles : when/then/otherwise\n",
    "print(\"Expressions conditionnelles :\")\n",
    "print(\n",
    "    df.with_columns(\n",
    "        pl.when(pl.col(\"age\") >= 30)\n",
    "          .then(pl.lit(\"Senior\"))\n",
    "          .otherwise(pl.lit(\"Junior\"))\n",
    "          .alias(\"level\"),\n",
    "        \n",
    "        pl.when(pl.col(\"salary\") > 60000)\n",
    "          .then(pl.lit(\"High\"))\n",
    "          .when(pl.col(\"salary\") > 50000)\n",
    "          .then(pl.lit(\"Medium\"))\n",
    "          .otherwise(pl.lit(\"Low\"))\n",
    "          .alias(\"salary_band\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressions_chaining",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cha√Ænage d'expressions\n",
    "print(\"Cha√Ænage d'expressions :\")\n",
    "print(\n",
    "    df.with_columns(\n",
    "        # String operations\n",
    "        pl.col(\"name\").str.to_uppercase().alias(\"NAME_UPPER\"),\n",
    "        pl.col(\"name\").str.len_chars().alias(\"name_length\"),\n",
    "        \n",
    "        # Math operations\n",
    "        (pl.col(\"salary\") * 1.1).round(2).alias(\"salary_raised\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manipulations",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üõ†Ô∏è 6. Manipulations de donn√©es essentielles\n",
    "\n",
    "### 6.1 S√©lection de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "select",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"data/benchmark.csv\")\n",
    "\n",
    "# S√©lection simple\n",
    "print(\"S√©lection simple :\")\n",
    "print(df.select(\"category\", \"amount\").head(3))\n",
    "\n",
    "# S√©lection avec transformation\n",
    "print(\"\\nS√©lection avec transformation :\")\n",
    "print(\n",
    "    df.select(\n",
    "        pl.col(\"category\"),\n",
    "        (pl.col(\"amount\") * pl.col(\"quantity\")).alias(\"total\")\n",
    "    ).head(3)\n",
    ")\n",
    "\n",
    "# S√©lection par type\n",
    "print(\"\\nColonnes num√©riques uniquement :\")\n",
    "print(df.select(pl.col(pl.Float64, pl.Int64)).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filter_section",
   "metadata": {},
   "source": [
    "### 6.2 Filtrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtre simple\n",
    "print(\"Filtre simple (amount > 500) :\")\n",
    "print(df.filter(pl.col(\"amount\") > 500).head(3))\n",
    "\n",
    "# Filtres multiples (AND)\n",
    "print(\"\\nFiltres multiples (AND) :\")\n",
    "print(\n",
    "    df.filter(\n",
    "        (pl.col(\"amount\") > 500) & \n",
    "        (pl.col(\"category\") == \"Electronics\")\n",
    "    ).head(3)\n",
    ")\n",
    "\n",
    "# Filtres multiples (OR)\n",
    "print(\"\\nFiltres multiples (OR) :\")\n",
    "print(\n",
    "    df.filter(\n",
    "        (pl.col(\"category\") == \"Electronics\") | \n",
    "        (pl.col(\"category\") == \"Books\")\n",
    "    ).head(3)\n",
    ")\n",
    "\n",
    "# Filtre avec is_in\n",
    "print(\"\\nFiltre avec is_in :\")\n",
    "print(\n",
    "    df.filter(\n",
    "        pl.col(\"category\").is_in([\"Electronics\", \"Books\"])\n",
    "    ).head(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "with_columns_section",
   "metadata": {},
   "source": [
    "### 6.3 Ajout / modification de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "with_columns",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ajout de colonnes :\")\n",
    "result = df.with_columns(\n",
    "    # Calcul\n",
    "    (pl.col(\"amount\") * pl.col(\"quantity\")).alias(\"total\"),\n",
    "    \n",
    "    # Valeur constante\n",
    "    pl.lit(\"USD\").alias(\"currency\"),\n",
    "    \n",
    "    # Transformation de colonne existante\n",
    "    pl.col(\"category\").str.to_uppercase().alias(\"CATEGORY\"),\n",
    "    \n",
    "    # Conditionnel\n",
    "    pl.when(pl.col(\"amount\") > 500)\n",
    "      .then(pl.lit(\"High\"))\n",
    "      .otherwise(pl.lit(\"Low\"))\n",
    "      .alias(\"amount_level\")\n",
    ")\n",
    "\n",
    "print(result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "groupby_section",
   "metadata": {},
   "source": [
    "### 6.4 GroupBy & Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "groupby",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GroupBy simple :\")\n",
    "print(\n",
    "    df.group_by(\"category\").agg(\n",
    "        pl.col(\"amount\").sum().alias(\"total_amount\"),\n",
    "        pl.col(\"amount\").mean().alias(\"avg_amount\"),\n",
    "        pl.col(\"amount\").max().alias(\"max_amount\"),\n",
    "        pl.len().alias(\"count\")\n",
    "    ).sort(\"total_amount\", descending=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "groupby_advanced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregations avanc√©es\n",
    "print(\"Aggregations avanc√©es :\")\n",
    "print(\n",
    "    df.group_by(\"category\").agg(\n",
    "        # Statistiques\n",
    "        pl.col(\"amount\").mean().alias(\"avg\"),\n",
    "        pl.col(\"amount\").std().alias(\"std\"),\n",
    "        pl.col(\"amount\").quantile(0.5).alias(\"median\"),\n",
    "        \n",
    "        # Comptages conditionnels\n",
    "        (pl.col(\"amount\") > 500).sum().alias(\"high_amount_count\"),\n",
    "        \n",
    "        # Premier/Dernier\n",
    "        pl.col(\"amount\").first().alias(\"first_amount\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sort_rename_section",
   "metadata": {},
   "source": [
    "### 6.5 Tri, renommage, suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sort_rename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tri\n",
    "print(\"Tri d√©croissant :\")\n",
    "print(df.sort(\"amount\", descending=True).head(3))\n",
    "\n",
    "# Tri multiple\n",
    "print(\"\\nTri multiple :\")\n",
    "print(df.sort([\"category\", \"amount\"], descending=[True, False]).head(5))\n",
    "\n",
    "# Renommer\n",
    "print(\"\\nRenommer :\")\n",
    "print(df.rename({\"amount\": \"montant\", \"quantity\": \"quantite\"}).head(2))\n",
    "\n",
    "# Supprimer des colonnes\n",
    "print(\"\\nSupprimer colonnes :\")\n",
    "print(df.drop(\"id\").head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joins_section",
   "metadata": {},
   "source": [
    "### 6.6 Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des DataFrames pour les joins\n",
    "orders = pl.DataFrame({\n",
    "    \"order_id\": [1, 2, 3, 4],\n",
    "    \"customer_id\": [101, 102, 101, 103],\n",
    "    \"amount\": [100, 200, 150, 300]\n",
    "})\n",
    "\n",
    "customers = pl.DataFrame({\n",
    "    \"customer_id\": [101, 102, 104],\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Diana\"]\n",
    "})\n",
    "\n",
    "print(\"Orders:\", orders)\n",
    "print(\"\\nCustomers:\", customers)\n",
    "\n",
    "# Inner join\n",
    "print(\"\\nInner Join :\")\n",
    "print(orders.join(customers, on=\"customer_id\", how=\"inner\"))\n",
    "\n",
    "# Left join\n",
    "print(\"\\nLeft Join :\")\n",
    "print(orders.join(customers, on=\"customer_id\", how=\"left\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dates_section",
   "metadata": {},
   "source": [
    "### 6.7 Dates et timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dates",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "df_dates = pl.DataFrame({\n",
    "    \"event\": [\"A\", \"B\", \"C\", \"D\"],\n",
    "    \"timestamp\": [\n",
    "        datetime(2024, 1, 15, 10, 30),\n",
    "        datetime(2024, 3, 20, 14, 45),\n",
    "        datetime(2024, 6, 5, 9, 0),\n",
    "        datetime(2024, 12, 25, 18, 30)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"DataFrame avec dates :\")\n",
    "print(df_dates)\n",
    "\n",
    "print(\"\\nExtractions de dates :\")\n",
    "print(\n",
    "    df_dates.with_columns(\n",
    "        pl.col(\"timestamp\").dt.year().alias(\"year\"),\n",
    "        pl.col(\"timestamp\").dt.month().alias(\"month\"),\n",
    "        pl.col(\"timestamp\").dt.day().alias(\"day\"),\n",
    "        pl.col(\"timestamp\").dt.hour().alias(\"hour\"),\n",
    "        pl.col(\"timestamp\").dt.weekday().alias(\"weekday\"),\n",
    "        pl.col(\"timestamp\").dt.strftime(\"%Y-%m-%d\").alias(\"date_str\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lazy_execution",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ 7. Lazy Execution ‚Äî Le Game Changer\n",
    "\n",
    "> üéØ **C'est ce qui rend Polars adapt√© √† la production et aux gros volumes.**\n",
    "\n",
    "### 7.1 Cr√©er un LazyFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lazy_create",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuis un fichier (recommand√©)\n",
    "lf = pl.scan_csv(\"data/benchmark.csv\")\n",
    "print(\"Type:\", type(lf))\n",
    "print(\"\\nLazyFrame (pas encore ex√©cut√©) :\")\n",
    "print(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lazy_from_df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuis un DataFrame existant\n",
    "df = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "lf = df.lazy()\n",
    "print(\"Converti en LazyFrame:\", type(lf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lazy_pipeline",
   "metadata": {},
   "source": [
    "### 7.2 Construire le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lazy_build",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline complet en Lazy\n",
    "pipeline = (\n",
    "    pl.scan_csv(\"data/benchmark.csv\")\n",
    "    .filter(pl.col(\"amount\") > 100)\n",
    "    .with_columns(\n",
    "        (pl.col(\"amount\") * pl.col(\"quantity\")).alias(\"total\"),\n",
    "        pl.col(\"category\").str.to_uppercase().alias(\"CATEGORY\")\n",
    "    )\n",
    "    .group_by(\"CATEGORY\")\n",
    "    .agg(\n",
    "        pl.col(\"total\").sum().alias(\"total_revenue\"),\n",
    "        pl.len().alias(\"transaction_count\")\n",
    "    )\n",
    "    .sort(\"total_revenue\", descending=True)\n",
    ")\n",
    "\n",
    "print(\"Pipeline d√©fini (pas encore ex√©cut√©) :\")\n",
    "print(pipeline)\n",
    "print(\"\\n‚ö†Ô∏è Rien n'a √©t√© lu ou calcul√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lazy_collect",
   "metadata": {},
   "source": [
    "### 7.3 Ex√©cuter avec .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lazy_execute",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "result = pipeline.collect()  # MAINTENANT √ßa s'ex√©cute\n",
    "print(f\"‚è±Ô∏è Temps d'ex√©cution : {time.time() - start:.3f}s\")\n",
    "print(\"\\nR√©sultat :\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lazy_explain",
   "metadata": {},
   "source": [
    "### 7.4 Voir le plan d'ex√©cution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan logique (ce que tu as √©crit)\n",
    "print(\"=== PLAN LOGIQUE ===\")\n",
    "print(pipeline.explain())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Plan optimis√© (ce que Polars ex√©cute r√©ellement)\n",
    "print(\"=== PLAN OPTIMIS√â ===\")\n",
    "print(pipeline.explain(optimized=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming",
   "metadata": {},
   "source": [
    "### 7.5 Streaming pour fichiers massifs\n",
    "\n",
    "Le mode **streaming** permet de traiter des fichiers plus grands que la RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming : traite par chunks\n",
    "result_streaming = (\n",
    "    pl.scan_csv(\"data/benchmark.csv\")\n",
    "    .filter(pl.col(\"category\") == \"Electronics\")\n",
    "    .group_by(\"category\")\n",
    "    .agg(pl.col(\"amount\").sum())\n",
    "    .collect(streaming=True)  # Mode streaming\n",
    ")\n",
    "\n",
    "print(\"R√©sultat avec streaming :\")\n",
    "print(result_streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lazy_diagram",
   "metadata": {},
   "source": [
    "### üñºÔ∏è Sch√©ma : Pipeline Lazy\n",
    "\n",
    "```text\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  scan_csv() ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  filter()   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇwith_columns()‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  group_by() ‚îÇ\n",
    "‚îÇ  (plan)     ‚îÇ     ‚îÇ  (plan)     ‚îÇ     ‚îÇ  (plan)     ‚îÇ     ‚îÇ  (plan)     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                                                   ‚îÇ\n",
    "                                                                   ‚ñº\n",
    "                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                                                            ‚îÇ  collect()  ‚îÇ\n",
    "                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                                                   ‚îÇ\n",
    "                                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                                                    ‚îÇ    Query Optimizer          ‚îÇ\n",
    "                                                    ‚îÇ  ‚Ä¢ Predicate pushdown       ‚îÇ\n",
    "                                                    ‚îÇ  ‚Ä¢ Column pruning           ‚îÇ\n",
    "                                                    ‚îÇ  ‚Ä¢ Parallel execution       ‚îÇ\n",
    "                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                                                   ‚îÇ\n",
    "                                                                   ‚ñº\n",
    "                                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                                                            ‚îÇ  DataFrame  ‚îÇ\n",
    "                                                            ‚îÇ  (r√©sultat) ‚îÇ\n",
    "                                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "migration",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ 8. Migration Pandas ‚Üí Polars\n",
    "\n",
    "### 8.1 Tableau de correspondance\n",
    "\n",
    "| Op√©ration | Pandas | Polars |\n",
    "|-----------|--------|--------|\n",
    "| Lire CSV | `pd.read_csv()` | `pl.read_csv()` / `pl.scan_csv()` |\n",
    "| Lire Parquet | `pd.read_parquet()` | `pl.read_parquet()` / `pl.scan_parquet()` |\n",
    "| S√©lection colonne | `df[\"col\"]` | `df.select(\"col\")` |\n",
    "| Plusieurs colonnes | `df[[\"a\", \"b\"]]` | `df.select(\"a\", \"b\")` |\n",
    "| Filtre | `df[df[\"x\"] > 5]` | `df.filter(pl.col(\"x\") > 5)` |\n",
    "| Nouvelle colonne | `df[\"new\"] = df[\"a\"] + 1` | `df.with_columns((pl.col(\"a\") + 1).alias(\"new\"))` |\n",
    "| GroupBy | `df.groupby(\"x\").agg({\"y\": \"sum\"})` | `df.group_by(\"x\").agg(pl.col(\"y\").sum())` |\n",
    "| Tri | `df.sort_values(\"x\")` | `df.sort(\"x\")` |\n",
    "| Renommer | `df.rename(columns={\"a\": \"b\"})` | `df.rename({\"a\": \"b\"})` |\n",
    "| Drop | `df.drop(columns=[\"x\"])` | `df.drop(\"x\")` |\n",
    "| Reset index | `df.reset_index()` | N/A (pas d'index) |\n",
    "| Apply | `df.apply(func)` | `df.map_rows(func)` ‚ö†Ô∏è √©viter |\n",
    "\n",
    "### 8.2 Interop√©rabilit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Cr√©er un DataFrame Pandas\n",
    "pandas_df = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\"],\n",
    "    \"age\": [25, 30]\n",
    "})\n",
    "\n",
    "# Pandas ‚Üí Polars\n",
    "polars_df = pl.from_pandas(pandas_df)\n",
    "print(\"Pandas ‚Üí Polars :\")\n",
    "print(polars_df)\n",
    "\n",
    "# Polars ‚Üí Pandas\n",
    "back_to_pandas = polars_df.to_pandas()\n",
    "print(\"\\nPolars ‚Üí Pandas :\")\n",
    "print(back_to_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "migration_diff",
   "metadata": {},
   "source": [
    "### 8.3 Diff√©rences cl√©s √† retenir\n",
    "\n",
    "| Aspect | Pandas | Polars |\n",
    "|--------|--------|--------|\n",
    "| **Index** | ‚úÖ Index par d√©faut | ‚ùå Pas d'index |\n",
    "| **Modification in-place** | ‚úÖ `inplace=True` | ‚ùå Toujours immutable |\n",
    "| **Typage** | Flexible | Strict |\n",
    "| **NaN vs null** | NaN (float) | null (natif) |\n",
    "| **Cha√Ænage** | Limit√© | Naturel et optimis√© |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "migration_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de migration compl√®te\n",
    "\n",
    "# ============ VERSION PANDAS ============\n",
    "# df = pd.read_csv(\"data.csv\")\n",
    "# df = df[df[\"amount\"] > 100]\n",
    "# df[\"total\"] = df[\"amount\"] * df[\"quantity\"]\n",
    "# result = df.groupby(\"category\").agg({\"total\": \"sum\"}).reset_index()\n",
    "\n",
    "# ============ VERSION POLARS (Eager) ============\n",
    "result_eager = (\n",
    "    pl.read_csv(\"data/benchmark.csv\")\n",
    "    .filter(pl.col(\"amount\") > 100)\n",
    "    .with_columns(\n",
    "        (pl.col(\"amount\") * pl.col(\"quantity\")).alias(\"total\")\n",
    "    )\n",
    "    .group_by(\"category\")\n",
    "    .agg(pl.col(\"total\").sum())\n",
    ")\n",
    "\n",
    "# ============ VERSION POLARS (Lazy - recommand√©) ============\n",
    "result_lazy = (\n",
    "    pl.scan_csv(\"data/benchmark.csv\")\n",
    "    .filter(pl.col(\"amount\") > 100)\n",
    "    .with_columns(\n",
    "        (pl.col(\"amount\") * pl.col(\"quantity\")).alias(\"total\")\n",
    "    )\n",
    "    .group_by(\"category\")\n",
    "    .agg(pl.col(\"total\").sum())\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "print(\"R√©sultat :\")\n",
    "print(result_lazy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è 9. Bonnes pratiques & Erreurs fr√©quentes\n",
    "\n",
    "### ‚ùå Erreurs fr√©quentes\n",
    "\n",
    "| Erreur | Probl√®me | Solution |\n",
    "|--------|----------|----------|\n",
    "| `.apply()` sur chaque ligne | Extr√™mement lent | Utiliser expressions natives |\n",
    "| `df[\"col\"]` style Pandas | Ne fonctionne pas | `df.select(\"col\")` ou `pl.col()` |\n",
    "| `read_csv()` sur 100 fichiers | Lent, beaucoup de RAM | `scan_csv(\"*.csv\")` + glob |\n",
    "| Oublier `.collect()` | Pas d'ex√©cution | Toujours `.collect()` √† la fin |\n",
    "| M√©langer eager/lazy | Erreurs de type | Rester coh√©rent dans le pipeline |\n",
    "| Pas d'alias sur les expressions | Noms de colonnes illisibles | Toujours `.alias(\"nom\")` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad_vs_good",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : apply() ligne par ligne\n",
    "# df.map_rows(lambda row: row[0] * 2)  # TR√àS LENT\n",
    "\n",
    "# ‚úÖ BON : expression native\n",
    "df = pl.DataFrame({\"x\": [1, 2, 3]})\n",
    "result = df.with_columns((pl.col(\"x\") * 2).alias(\"x_doubled\"))\n",
    "print(\"‚úÖ Expression native :\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "good_practices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : read_csv sur plusieurs fichiers s√©par√©ment\n",
    "# dfs = [pl.read_csv(f) for f in files]  # Pas optimis√©\n",
    "\n",
    "# ‚úÖ BON : scan_csv avec glob\n",
    "lf = pl.scan_csv(\"data/multi/*.csv\")\n",
    "print(\"‚úÖ Scan avec glob :\")\n",
    "print(lf.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices_table",
   "metadata": {},
   "source": [
    "### ‚úÖ Bonnes pratiques\n",
    "\n",
    "| Pratique | Pourquoi |\n",
    "|----------|----------|\n",
    "| **Utiliser Lazy en production** | Optimisation automatique |\n",
    "| **Pr√©f√©rer Parquet** | 10x plus rapide que CSV, compression |\n",
    "| **Cha√Æner les expressions** | Plus lisible, plus optimis√© |\n",
    "| **√âviter `.apply()`** | Utiliser expressions natives |\n",
    "| **Profiler avec `.explain()`** | Comprendre l'ex√©cution |\n",
    "| **Toujours `.alias()`** | Noms de colonnes explicites |\n",
    "| **`scan_*` pour gros fichiers** | Lazy = optimisations |\n",
    "| **Streaming pour > RAM** | `collect(streaming=True)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Quiz de fin de module\n",
    "\n",
    "R√©ponds aux questions suivantes pour v√©rifier tes acquis.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q1. Quel est le principal avantage de l'architecture columnar de Polars ?\n",
    "a) Plus facile √† lire pour les humains  \n",
    "b) Op√©rations vectoris√©es plus rapides et meilleure utilisation du cache CPU  \n",
    "c) Compatible avec Excel  \n",
    "d) Utilise moins de colonnes\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Le stockage columnar permet des op√©rations vectoris√©es (SIMD) et une meilleure utilisation du cache CPU car les donn√©es d'une colonne sont contigu√´s en m√©moire.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q2. Quelle est la diff√©rence entre `pl.read_csv()` et `pl.scan_csv()` ?\n",
    "a) `read_csv` est plus rapide  \n",
    "b) `scan_csv` cr√©e un LazyFrame et permet l'optimisation  \n",
    "c) `scan_csv` ne supporte pas les gros fichiers  \n",
    "d) Aucune diff√©rence\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî `scan_csv` cr√©e un LazyFrame (plan d'ex√©cution) qui sera optimis√© avant ex√©cution, tandis que `read_csv` charge imm√©diatement tout en m√©moire.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q3. Comment ajouter une nouvelle colonne en Polars ?\n",
    "a) `df[\"new\"] = df[\"old\"] * 2`  \n",
    "b) `df.with_columns((pl.col(\"old\") * 2).alias(\"new\"))`  \n",
    "c) `df.add_column(\"new\", df[\"old\"] * 2)`  \n",
    "d) `df.insert(\"new\", df[\"old\"] * 2)`\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî En Polars, on utilise `with_columns()` avec des expressions. La syntaxe `df[\"col\"]` style Pandas ne fonctionne pas.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q4. Que fait le Query Optimizer avec \"predicate pushdown\" ?\n",
    "a) Supprime les colonnes inutiles  \n",
    "b) Applique les filtres le plus t√¥t possible dans le pipeline  \n",
    "c) Parall√©lise les calculs  \n",
    "d) Compresse les donn√©es\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Le predicate pushdown d√©place les filtres le plus t√¥t possible, r√©duisant ainsi la quantit√© de donn√©es √† traiter dans les √©tapes suivantes.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q5. Quand utiliser `.collect()` ?\n",
    "a) Apr√®s chaque op√©ration  \n",
    "b) √Ä la fin du pipeline Lazy pour d√©clencher l'ex√©cution  \n",
    "c) Pour convertir en Pandas  \n",
    "d) Pour √©crire un fichier\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî `.collect()` d√©clenche l'ex√©cution d'un LazyFrame et retourne un DataFrame. Sans `.collect()`, rien n'est calcul√©.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q6. Pourquoi √©viter `.apply()` en Polars ?\n",
    "a) Ce n'est pas support√©  \n",
    "b) C'est lent car √ßa passe par Python pour chaque ligne  \n",
    "c) √áa modifie les donn√©es en place  \n",
    "d) √áa consomme trop de m√©moire\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî `.apply()` (ou `map_rows`) passe par Python pour chaque ligne, perdant tous les avantages du moteur Rust vectoris√©. Pr√©f√©rer les expressions natives.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q7. Quel format de fichier est recommand√© en production avec Polars ?\n",
    "a) CSV  \n",
    "b) JSON  \n",
    "c) Parquet  \n",
    "d) Excel\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : c** ‚Äî Parquet est columnar (comme Polars), compress√©, et supporte les types. Il est 10x+ plus rapide que CSV.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q8. Comment voir le plan d'ex√©cution optimis√© d'un LazyFrame ?\n",
    "a) `lf.show_plan()`  \n",
    "b) `lf.explain(optimized=True)`  \n",
    "c) `lf.describe()`  \n",
    "d) `print(lf)`\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî `.explain(optimized=True)` affiche le plan d'ex√©cution apr√®s les optimisations du Query Optimizer.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Mini-projet : Pipeline ETL Polars\n",
    "\n",
    "### üéØ Objectif\n",
    "Construire un pipeline ETL **complet en mode Lazy** qui :\n",
    "- Lit plusieurs fichiers CSV\n",
    "- Nettoie et transforme les donn√©es\n",
    "- Agr√®ge par cat√©gorie et p√©riode\n",
    "- Exporte en Parquet\n",
    "\n",
    "### üèóÔ∏è Architecture\n",
    "\n",
    "```text\n",
    "data/raw/*.csv\n",
    "      ‚îÇ\n",
    "      ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   scan_csv()    ‚îÇ  Lazy read (glob pattern)\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ    filter()     ‚îÇ  Nettoyage (nulls, invalides)\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ with_columns()  ‚îÇ  Enrichissement\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   group_by()    ‚îÇ  Agr√©gation\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ    collect()    ‚îÇ  Ex√©cution optimis√©e\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "         ‚îÇ\n",
    "         ‚ñº\n",
    "data/processed/output.parquet\n",
    "```\n",
    "\n",
    "### üìÅ Structure projet\n",
    "\n",
    "```text\n",
    "polars-etl-project/\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ raw/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transactions_01.csv\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transactions_02.csv\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transactions_03.csv\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ processed/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ output.parquet\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ etl_pipeline.py\n",
    "‚îî‚îÄ‚îÄ requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup : cr√©er les donn√©es de test\n",
    "import polars as pl\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "categories = [\"Electronics\", \"Clothing\", \"Food\", \"Books\", \"Sports\"]\n",
    "base_date = datetime(2024, 1, 1)\n",
    "\n",
    "# G√©n√©rer 3 fichiers CSV\n",
    "for file_num in range(1, 4):\n",
    "    n_rows = 10000\n",
    "    data = {\n",
    "        \"transaction_id\": range(file_num * 10000, file_num * 10000 + n_rows),\n",
    "        \"timestamp\": [base_date + timedelta(days=random.randint(0, 365)) for _ in range(n_rows)],\n",
    "        \"category\": [random.choice(categories) for _ in range(n_rows)],\n",
    "        \"amount\": [round(random.uniform(-50, 1000), 2) for _ in range(n_rows)],  # Certains n√©gatifs !\n",
    "        \"quantity\": [random.randint(0, 100) for _ in range(n_rows)],  # Certains √† 0 !\n",
    "        \"customer_id\": [random.randint(1000, 9999) for _ in range(n_rows)]\n",
    "    }\n",
    "    df = pl.DataFrame(data)\n",
    "    df.write_csv(f\"data/raw/transactions_{file_num:02d}.csv\")\n",
    "\n",
    "print(\"‚úÖ Donn√©es de test cr√©√©es (3 fichiers x 10,000 lignes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import time\n",
    "\n",
    "print(\"üöÄ D√©marrage du pipeline ETL Polars...\\n\")\n",
    "start = time.time()\n",
    "\n",
    "# ============ PIPELINE LAZY ============\n",
    "result = (\n",
    "    # 1. EXTRACT : Lire tous les CSV avec glob pattern\n",
    "    pl.scan_csv(\"data/raw/*.csv\")\n",
    "    \n",
    "    # 2. CLEAN : Filtrer les donn√©es invalides\n",
    "    .filter(\n",
    "        (pl.col(\"amount\") > 0) &           # Montants positifs\n",
    "        (pl.col(\"quantity\") > 0) &         # Quantit√©s positives\n",
    "        (pl.col(\"customer_id\").is_not_null())  # Pas de null\n",
    "    )\n",
    "    \n",
    "    # 3. TRANSFORM : Enrichir les donn√©es\n",
    "    .with_columns(\n",
    "        # Calculer le total\n",
    "        (pl.col(\"amount\") * pl.col(\"quantity\")).alias(\"total_revenue\"),\n",
    "        \n",
    "        # Extraire ann√©e et mois\n",
    "        pl.col(\"timestamp\").str.to_datetime().dt.year().alias(\"year\"),\n",
    "        pl.col(\"timestamp\").str.to_datetime().dt.month().alias(\"month\"),\n",
    "        \n",
    "        # Cat√©goriser les montants\n",
    "        pl.when(pl.col(\"amount\") > 500)\n",
    "          .then(pl.lit(\"High\"))\n",
    "          .when(pl.col(\"amount\") > 100)\n",
    "          .then(pl.lit(\"Medium\"))\n",
    "          .otherwise(pl.lit(\"Low\"))\n",
    "          .alias(\"amount_tier\"),\n",
    "        \n",
    "        # Uppercase category\n",
    "        pl.col(\"category\").str.to_uppercase().alias(\"category_upper\")\n",
    "    )\n",
    "    \n",
    "    # 4. AGGREGATE : Par cat√©gorie et mois\n",
    "    .group_by([\"year\", \"month\", \"category_upper\"])\n",
    "    .agg(\n",
    "        pl.col(\"total_revenue\").sum().alias(\"total_revenue\"),\n",
    "        pl.col(\"total_revenue\").mean().alias(\"avg_revenue\"),\n",
    "        pl.len().alias(\"transaction_count\"),\n",
    "        pl.col(\"customer_id\").n_unique().alias(\"unique_customers\"),\n",
    "        (pl.col(\"amount_tier\") == \"High\").sum().alias(\"high_value_count\")\n",
    "    )\n",
    "    \n",
    "    # 5. SORT\n",
    "    .sort([\"year\", \"month\", \"total_revenue\"], descending=[False, False, True])\n",
    "    \n",
    "    # 6. EXECUTE\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "execution_time = time.time() - start\n",
    "print(f\"‚è±Ô∏è Pipeline ex√©cut√© en {execution_time:.3f} secondes\")\n",
    "print(f\"üìä R√©sultat : {result.height} lignes, {result.width} colonnes\\n\")\n",
    "\n",
    "# Afficher un aper√ßu\n",
    "print(\"Aper√ßu des r√©sultats :\")\n",
    "print(result.head(10))\n",
    "\n",
    "# 7. EXPORT en Parquet\n",
    "result.write_parquet(\"data/processed/monthly_summary.parquet\")\n",
    "print(\"\\n‚úÖ R√©sultat export√© : data/processed/monthly_summary.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier le fichier Parquet\n",
    "print(\"üìñ Lecture du fichier Parquet export√© :\")\n",
    "df_check = pl.read_parquet(\"data/processed/monthly_summary.parquet\")\n",
    "print(df_check.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Ressources pour aller plus loin\n",
    "\n",
    "### üåê Documentation officielle\n",
    "- [Polars User Guide](https://docs.pola.rs/) ‚Äî Documentation compl√®te\n",
    "- [Polars API Reference](https://docs.pola.rs/api/python/stable/reference/) ‚Äî R√©f√©rence API\n",
    "- [Polars GitHub](https://github.com/pola-rs/polars) ‚Äî Code source\n",
    "\n",
    "### üìñ Tutoriels & Articles\n",
    "- [Polars vs Pandas Benchmark](https://www.pola.rs/benchmarks.html) ‚Äî Benchmarks officiels\n",
    "- [Modern Polars](https://kevinheavey.github.io/modern-polars/) ‚Äî Guide approfondi\n",
    "\n",
    "### üîß Outils compl√©mentaires\n",
    "- [DuckDB](https://duckdb.org/) ‚Äî SQL analytique ultra-rapide (compatible Polars)\n",
    "- [PyArrow](https://arrow.apache.org/docs/python/) ‚Äî Format Arrow sous-jacent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚û°Ô∏è Prochaine √©tape\n",
    "\n",
    "Maintenant que tu ma√Ætrises Polars, d√©couvrons d'autres outils **haute performance** pour Python !\n",
    "\n",
    "üëâ **Module suivant : `18_high_performance_python.ipynb`** ‚Äî Python Haute Performance\n",
    "\n",
    "Tu vas apprendre :\n",
    "- **Dask** : parall√©lisation de Pandas/NumPy\n",
    "- **Vaex** : traitement out-of-core\n",
    "- **multiprocessing** : parall√©lisme CPU\n",
    "- **concurrent.futures** : ThreadPool et ProcessPool\n",
    "- **async/await** : I/O asynchrone\n",
    "\n",
    "---\n",
    "\n",
    "üéâ **F√©licitations !** Tu as termin√© le module Polars pour Data Engineers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des fichiers temporaires (optionnel)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# D√©commenter pour nettoyer\n",
    "# if os.path.exists(\"data\"):\n",
    "#     shutil.rmtree(\"data\")\n",
    "#     print(\"üßπ Dossier data/ supprim√©\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
