{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üê≥ Docker pour Data Engineers\n",
    "\n",
    "Bienvenue dans ce module o√π tu vas apprendre √† **containeriser** tes applications, lancer des services data en quelques secondes, et packager tes pipelines ETL de mani√®re **reproductible et portable** ‚Äî des comp√©tences indispensables pour un Data Engineer moderne !\n",
    "\n",
    "---\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "| Niveau | Comp√©tence |\n",
    "|--------|------------|\n",
    "| ‚úÖ Requis | Avoir suivi les modules `01_intro_data_engineering` et `02_bash_for_data_engineers` |\n",
    "| ‚úÖ Requis | Connaissances de base en Python |\n",
    "| ‚úÖ Requis | Avoir acc√®s √† un terminal (Linux, Mac, ou Windows avec WSL) |\n",
    "\n",
    "## Objectifs du module\n",
    "\n",
    "√Ä la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Expliquer ce qu'est Docker et pourquoi il est essentiel en Data Engineering\n",
    "- Installer Docker sur Windows, macOS ou Linux\n",
    "- Lancer des services data (PostgreSQL, Kafka, Spark‚Ä¶) en une commande\n",
    "- √âcrire un Dockerfile pour packager un script ETL\n",
    "- Utiliser les volumes, r√©seaux et docker-compose\n",
    "- D√©bugger des containers comme un pro\n",
    "- Appliquer les bonnes pratiques professionnelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what_is_docker",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C'est quoi Docker ?\n",
    "\n",
    "> **Docker est un outil qui permet d'ex√©cuter des applications dans des environnements isol√©s, reproductibles et portables**, appel√©s *containers*.\n",
    "\n",
    "Au lieu d'installer une application (et toutes ses d√©pendances) **directement sur ton syst√®me**, tu la mets dans une \"bo√Æte\" (le container) avec tout ce dont elle a besoin.\n",
    "\n",
    "### Docker ‚â† Machine Virtuelle\n",
    "\n",
    "| Aspect | Machine Virtuelle (VM) | Container Docker |\n",
    "|--------|----------------------|------------------|\n",
    "| **Contenu** | OS complet + kernel + drivers + apps | App + libs + syst√®me minimal |\n",
    "| **Taille** | Plusieurs Go | Quelques Mo √† centaines de Mo |\n",
    "| **D√©marrage** | Minutes | Secondes/millisecondes |\n",
    "| **Performance** | Overhead important | Quasi-natif |\n",
    "| **Isolation** | Compl√®te (hyperviseur) | Au niveau processus |\n",
    "\n",
    "### Analogies pour bien comprendre\n",
    "\n",
    "| Analogie | Explication |\n",
    "|----------|-------------|\n",
    "| üß≥ **La valise pr√™te** | Un container = une valise d√©j√† remplie. Tu la prends, tu voyages, tu es op√©rationnel partout. |\n",
    "| üç± **Le tupperware** | Tu pr√©pares un plat, tu le mets dans une bo√Æte herm√©tique. Chez toi ou ailleurs : c'est le m√™me plat. |\n",
    "| üì¶ **Le zip complet** | Code + librairies + config dans un package. Mais avec la garantie que l'ex√©cution est **identique** partout. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "docker_info",
   "metadata": {},
   "source": [
    "> ‚ÑπÔ∏è **Le savais-tu ?**\n",
    ">\n",
    "> Docker a √©t√© cr√©√© en **2013** par Solomon Hykes chez dotCloud (devenu Docker, Inc.).\n",
    "> \n",
    "> Le nom vient des **dockers** (ouvriers portuaires) qui chargent et d√©chargent des **containers** sur les bateaux ‚Äî exactement ce que fait Docker avec les applications !\n",
    ">\n",
    "> üìñ [Histoire de Docker sur Wikipedia](https://en.wikipedia.org/wiki/Docker_(software))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why_docker",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Pourquoi Docker est indispensable pour un Data Engineer\n",
    "\n",
    "En Data Engineering, tu dois souvent :\n",
    "\n",
    "- Manipuler des **bases de donn√©es** (PostgreSQL, MySQL, MongoDB‚Ä¶)\n",
    "- Lancer des **brokers de messages** (Kafka, RabbitMQ‚Ä¶)\n",
    "- D√©ployer des **pipelines ETL**\n",
    "- Faire tourner des jobs **Spark** ou des APIs\n",
    "\n",
    "### ‚ùå Sans Docker\n",
    "\n",
    "| Probl√®me | Cons√©quence |\n",
    "|----------|-------------|\n",
    "| Installation manuelle complexe | Heures perdues en config |\n",
    "| Conflits de versions (Java, Python, drivers) | \"√áa marchait hier...\" |\n",
    "| Environnements diff√©rents (local ‚â† prod) | Bugs en production uniquement |\n",
    "| Onboarding difficile | Nouveaux = 2 jours pour installer |\n",
    "\n",
    "### ‚úÖ Avec Docker\n",
    "\n",
    "| Avantage | Exemple concret |\n",
    "|----------|----------------|\n",
    "| PostgreSQL en 1 commande | `docker run postgres:16` |\n",
    "| Test Kafka + Spark sur laptop | Stack compl√®te en local |\n",
    "| ETL packag√© et portable | Tourne identique partout |\n",
    "| Onboarding en 10 minutes | `docker-compose up` et c'est parti |\n",
    "\n",
    "> üí° En r√©sum√© : Docker est un **outil central** pour cr√©er des environnements data **reproductibles et industrialisables**. Fini le üòÖ *\"chez moi √ßa marche\"* !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concepts",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Concepts cl√©s Docker\n",
    "\n",
    "Avant d'aller plus loin, ma√Ætrise ces 6 notions fondamentales :\n",
    "\n",
    "| Concept | Description | Analogie |\n",
    "|---------|-------------|----------|\n",
    "| **Image** | Mod√®le fig√© (blueprint) contenant OS + d√©pendances + code | Une *recette* de cuisine |\n",
    "| **Container** | Instance en cours d'ex√©cution d'une image | Un *plat* pr√©par√© √† partir de la recette |\n",
    "| **Registry** | Magasin d'images (Docker Hub, ECR, GHCR) | Un *catalogue de recettes* en ligne |\n",
    "| **Volume** | Stockage persistant en dehors du container | Un *disque dur externe* branch√© |\n",
    "| **Network** | R√©seau virtuel entre containers | Un *r√©seau local* priv√© |\n",
    "| **Build context** | Fichiers envoy√©s √† Docker lors du build | Le *dossier de travail* |\n",
    "\n",
    "### Image Docker\n",
    "\n",
    "Une image contient :\n",
    "- Un syst√®me de base (ex: `python:3.11-slim`)\n",
    "- Des biblioth√®ques (pandas, pyarrow, pyspark‚Ä¶)\n",
    "- Ton code (scripts, fichiers de config)\n",
    "\n",
    "**On ne modifie pas une image** ‚Äî on en reconstruit une nouvelle √† partir d'un Dockerfile.\n",
    "\n",
    "### Container\n",
    "\n",
    "Un container est une **instance vivante** d'une image :\n",
    "- Tu cr√©es une image ‚Üí tu la *lances* ‚Üí tu obtiens un container\n",
    "- Tu peux d√©marrer, arr√™ter, supprimer un container sans toucher √† l'image\n",
    "- Plusieurs containers peuvent tourner √† partir de la m√™me image\n",
    "\n",
    "### Registry\n",
    "\n",
    "Un registry stocke et partage les images :\n",
    "- **Docker Hub** (public/priv√©) ‚Äî le plus connu\n",
    "- **GitHub Container Registry** (GHCR)\n",
    "- **AWS ECR**, **GCP Artifact Registry**, **Azure ACR**\n",
    "\n",
    "### Volume\n",
    "\n",
    "Les donn√©es ne doivent pas \"mourir\" avec le container :\n",
    "- **Sans volume** : container supprim√© = donn√©es perdues\n",
    "- **Avec volume** : donn√©es persistantes, partageables\n",
    "\n",
    "### Network\n",
    "\n",
    "Permet aux containers de communiquer entre eux :\n",
    "- Ex: container `etl` se connecte √† container `postgres`\n",
    "- Isolation du r√©seau de la machine h√¥te\n",
    "\n",
    "### Build context\n",
    "\n",
    "Quand tu fais `docker build -t mon-image .` :\n",
    "- Le `.` = tout ce que Docker envoie au daemon\n",
    "- Dossier de 10 Go = envoi de 10 Go \n",
    "- D'o√π l'importance du **`.dockerignore`** !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture",
   "metadata": {},
   "source": [
    "### Sch√©ma visuel : Architecture Docker\n",
    "\n",
    "```text\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                      DOCKER HOST                            ‚îÇ\n",
    "‚îÇ               (Laptop / Server / Cloud)                     ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                             ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ\n",
    "‚îÇ  ‚îÇ                  DOCKER ENGINE                      ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                     ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  IMAGE   ‚îÇ  ‚îÇ  IMAGE   ‚îÇ  ‚îÇ  IMAGE   ‚îÇ          ‚îÇ    ‚îÇ \n",
    "‚îÇ  ‚îÇ   ‚îÇ postgres ‚îÇ  ‚îÇ  python  ‚îÇ  ‚îÇ  spark   ‚îÇ          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ        ‚îÇ             ‚îÇ             ‚îÇ                ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ        ‚ñº             ‚ñº             ‚ñº                ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇCONTAINER ‚îÇ  ‚îÇCONTAINER ‚îÇ  ‚îÇCONTAINER ‚îÇ          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ de-postgres‚îÇ ‚îÇ  de-etl  ‚îÇ  ‚îÇ de-spark ‚îÇ         ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ        ‚îÇ                                            ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ        ‚ñº                                            ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  VOLUME  ‚îÇ       ‚îÇ   NETWORK    ‚îÇ               ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ pg_data  ‚îÇ       ‚îÇ  de-network  ‚îÇ               ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ    ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ\n",
    "‚îÇ                                                             ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Installation de Docker\n",
    "\n",
    "| Syst√®me | Comment installer |\n",
    "|---------|------------------|\n",
    "| ü™ü **Windows** | Docker Desktop + WSL2 |\n",
    "| üçé **macOS** | Docker Desktop (Intel ou Apple Silicon) |\n",
    "| üêß **Linux** | Docker Engine (apt/yum) |\n",
    "\n",
    "### ü™ü Windows (Docker Desktop + WSL2)\n",
    "\n",
    "**1. Activer WSL2 :**\n",
    "```powershell\n",
    "# Dans PowerShell en administrateur\n",
    "wsl --install\n",
    "```\n",
    "\n",
    "**2. T√©l√©charger Docker Desktop :**\n",
    "- üîó https://www.docker.com/products/docker-desktop/\n",
    "\n",
    "**3. Installer et red√©marrer**\n",
    "\n",
    "**4. Tester :**\n",
    "```powershell\n",
    "docker --version\n",
    "docker run --rm hello-world\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üçé macOS (Intel & Apple Silicon)\n",
    "\n",
    "**1. T√©l√©charger Docker Desktop :**\n",
    "- üîó https://www.docker.com/products/docker-desktop/\n",
    "- Choisir la version **Intel** ou **Apple Silicon (M1/M2/M3)**\n",
    "\n",
    "**2. Glisser l'app dans Applications**\n",
    "\n",
    "**3. Lancer Docker Desktop** (ic√¥ne üê≥ dans la barre)\n",
    "\n",
    "**4. Tester :**\n",
    "```bash\n",
    "docker --version\n",
    "docker run --rm hello-world\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üêß Linux (Ubuntu/Debian)\n",
    "\n",
    "```bash\n",
    "# 1. Mettre √† jour et installer les pr√©requis\n",
    "sudo apt-get update\n",
    "sudo apt-get install ca-certificates curl gnupg lsb-release\n",
    "\n",
    "# 2. Ajouter la cl√© GPG officielle\n",
    "sudo mkdir -p /etc/apt/keyrings\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n",
    "\n",
    "# 3. Ajouter le d√©p√¥t Docker\n",
    "echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "\n",
    "# 4. Installer Docker\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-ce docker-ce-cli containerd.io\n",
    "\n",
    "# 5. Tester\n",
    "sudo docker run --rm hello-world\n",
    "\n",
    "# 6. (Optionnel) Utiliser Docker sans sudo\n",
    "sudo usermod -aG docker $USER\n",
    "# Puis d√©connexion/reconnexion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_install",
   "metadata": {},
   "source": [
    "### V√©rifier ton installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_docker",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# V√©rifier la version de Docker\n",
    "docker --version\n",
    "\n",
    "# V√©rifier que Docker fonctionne\n",
    "docker run --rm hello-world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commands",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Commandes Docker essentielles\n",
    "\n",
    "Voici ton **cheat sheet** de base :\n",
    "\n",
    "### Lancer un container\n",
    "\n",
    "```bash\n",
    "docker run image                    # Lancer un container\n",
    "docker run -d image                 # En arri√®re-plan (detached)\n",
    "docker run -it image bash           # Mode interactif\n",
    "docker run --rm image               # Supprime le container √† la fin\n",
    "docker run --name mon-container image  # Nommer le container\n",
    "```\n",
    "\n",
    "### Lister\n",
    "\n",
    "```bash\n",
    "docker ps                           # Containers en cours\n",
    "docker ps -a                        # Tous les containers (y compris stopp√©s)\n",
    "docker images                       # Lister les images locales\n",
    "```\n",
    "\n",
    "### Stopper / Supprimer\n",
    "\n",
    "```bash\n",
    "docker stop CONTAINER_ID            # Arr√™ter un container\n",
    "docker rm CONTAINER_ID              # Supprimer un container\n",
    "docker rmi IMAGE_ID                 # Supprimer une image\n",
    "```\n",
    "\n",
    "### T√©l√©charger une image\n",
    "\n",
    "```bash\n",
    "docker pull postgres:16             # T√©l√©charger depuis Docker Hub\n",
    "```\n",
    "\n",
    "### Logs\n",
    "\n",
    "```bash\n",
    "docker logs CONTAINER_ID            # Voir les logs\n",
    "docker logs -f CONTAINER_ID         # Suivre les logs en temps r√©el\n",
    "```\n",
    "\n",
    "### Raccourcis utiles\n",
    "\n",
    "| Commande | Description |\n",
    "|----------|-------------|\n",
    "| `docker ps -a` | Voir tous les containers |\n",
    "| `docker logs -f` | Suivre les logs en live |\n",
    "| `docker exec -it <container> bash` | Entrer dans un container |\n",
    "| `docker system prune` | Nettoyer les ressources inutilis√©es |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "docker_commands_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Lister les images disponibles localement\n",
    "echo \"=== Images locales ===\"\n",
    "docker images\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Containers en cours ===\"\n",
    "docker ps\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Tous les containers ===\"\n",
    "docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "services",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Docker pour lancer des services Data\n",
    "\n",
    "Docker est **extr√™mement pratique** pour tester rapidement des services utilis√©s en Data Engineering.\n",
    "\n",
    "### PostgreSQL (exemple d√©taill√©)\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name demo-postgres \\\n",
    "  -e POSTGRES_USER=de_user \\\n",
    "  -e POSTGRES_PASSWORD=de_pass \\\n",
    "  -e POSTGRES_DB=de_db \\\n",
    "  -p 5432:5432 \\\n",
    "  postgres:16\n",
    "```\n",
    "\n",
    "**Connexion :**\n",
    "- Host: `localhost`\n",
    "- Port: `5432`\n",
    "- User: `de_user`\n",
    "- Password: `de_pass`\n",
    "- Database: `de_db`\n",
    "\n",
    "Tu peux ensuite te connecter avec DBeaver, psql, Python (psycopg2), etc.\n",
    "\n",
    "---\n",
    "\n",
    "### Autres services (one-liners)\n",
    "\n",
    "| Service | Commande |\n",
    "|---------|----------|\n",
    "| **Redis** | `docker run -d --name demo-redis -p 6379:6379 redis:latest` |\n",
    "| **MongoDB** | `docker run -d --name demo-mongo -p 27017:27017 mongo:latest` |\n",
    "| **Kafka** | `docker run -d --name demo-kafka -p 9092:9092 bitnami/kafka:latest` |\n",
    "| **Spark** | `docker run -it --name demo-spark bitnami/spark:latest pyspark` |\n",
    "| **Airflow** | `docker pull apache/airflow:latest` |\n",
    "| **Jupyter** | `docker run -p 8888:8888 jupyter/scipy-notebook` |\n",
    "\n",
    "> üí° **Astuce** : Pour Kafka et Airflow, pr√©f√®re `docker-compose` car ils n√©cessitent plusieurs services (Zookeeper, webserver, scheduler‚Ä¶), on le verra un peu plus en bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postgres_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Lancer PostgreSQL (si Docker est install√©)\n",
    "docker run -d \\\n",
    "  --name demo-postgres \\\n",
    "  -e POSTGRES_USER=de_user \\\n",
    "  -e POSTGRES_PASSWORD=de_pass \\\n",
    "  -e POSTGRES_DB=de_db \\\n",
    "  -p 5432:5432 \\\n",
    "  postgres:16\n",
    "\n",
    "echo \"PostgreSQL lanc√© sur localhost:5432\"\n",
    "\n",
    "# V√©rifier qu'il tourne\n",
    "docker ps --filter name=demo-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup_postgres",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Nettoyage : stopper et supprimer le container\n",
    "docker stop demo-postgres 2>/dev/null\n",
    "docker rm demo-postgres 2>/dev/null\n",
    "echo \"üßπ Container demo-postgres supprim√©\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dockerfile",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Dockerfile : cr√©er son image\n",
    "\n",
    "Le **Dockerfile** est un fichier texte qui d√©crit comment construire une image.\n",
    "\n",
    "### Instructions principales\n",
    "\n",
    "| Instruction | R√¥le | Exemple |\n",
    "|-------------|------|--------|\n",
    "| `FROM` | Image de base | `FROM python:3.11-slim` |\n",
    "| `WORKDIR` | R√©pertoire de travail | `WORKDIR /app` |\n",
    "| `COPY` | Copier des fichiers | `COPY etl.py .` |\n",
    "| `RUN` | Ex√©cuter une commande (build) | `RUN pip install pandas` |\n",
    "| `CMD` | Commande par d√©faut (run) | `CMD [\"python\", \"etl.py\"]` |\n",
    "| `ENTRYPOINT` | Point d'entr√©e fixe | `ENTRYPOINT [\"python\"]` |\n",
    "| `ENV` | Variable d'environnement | `ENV PYTHONUNBUFFERED=1` |\n",
    "| `EXPOSE` | Port expos√© (documentation) | `EXPOSE 8000` |\n",
    "\n",
    "### Structure de projet recommand√©e\n",
    "\n",
    "```text\n",
    "etl_project/\n",
    "‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îú‚îÄ‚îÄ .dockerignore\n",
    "‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ etl.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ utils.py\n",
    "‚îî‚îÄ‚îÄ data/               # ‚ö†Ô∏è Ne pas inclure dans l'image !\n",
    "    ‚îî‚îÄ‚îÄ input.csv\n",
    "```\n",
    "\n",
    "> üí° **Important** : Le Dockerfile doit √™tre √† la **racine du service** que tu veux packager.\n",
    "\n",
    "### Exemple : Dockerfile pour un ETL Python\n",
    "\n",
    "```dockerfile\n",
    "# 1. Image de base l√©g√®re\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# 2. Variables d'environnement\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "\n",
    "# 3. R√©pertoire de travail\n",
    "WORKDIR /app\n",
    "\n",
    "# 4. Copier et installer les d√©pendances (cache Docker)\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 5. Copier le code\n",
    "COPY src/ ./src/\n",
    "\n",
    "# 6. Commande par d√©faut\n",
    "CMD [\"python\", \"src/etl.py\"]\n",
    "```\n",
    "\n",
    "### Construire l'image\n",
    "\n",
    "```bash\n",
    "cd etl_project\n",
    "docker build -t etl-image:1.0 .\n",
    "```\n",
    "\n",
    "### Lancer le container\n",
    "\n",
    "```bash\n",
    "docker run --rm etl-image:1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dockerignore",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Le fichier `.dockerignore`\n",
    "\n",
    "Le `.dockerignore` emp√™che d'envoyer des fichiers inutiles dans le build context.\n",
    "\n",
    "### ‚ùå Sans `.dockerignore`\n",
    "\n",
    "- Images **√©normes** (datasets inclus)\n",
    "- Builds **lents** (envoi de Go de donn√©es)\n",
    "- **Fuites de secrets** (.env, cl√©s SSH)\n",
    "\n",
    "### ‚úÖ Exemple de `.dockerignore` (Data Engineer)\n",
    "\n",
    "```text\n",
    "# Donn√©es\n",
    "data/\n",
    "*.csv\n",
    "*.parquet\n",
    "*.json\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "venv/\n",
    ".venv/\n",
    "*.egg-info/\n",
    "\n",
    "# Secrets\n",
    ".env\n",
    "*.key\n",
    "*.pem\n",
    "secrets/\n",
    "\n",
    "# Notebooks\n",
    "*.ipynb\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# Git\n",
    ".git/\n",
    ".gitignore\n",
    "\n",
    "# IDE\n",
    ".idea/\n",
    ".vscode/\n",
    "*.swp\n",
    "\n",
    "# Logs\n",
    "logs/\n",
    "*.log\n",
    "\n",
    "# OS\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\n",
    "# Docker\n",
    "Dockerfile\n",
    "docker-compose*.yml\n",
    "```\n",
    "\n",
    "> üí° **R√®gle d'or** : le `.dockerignore` est **aussi important** que le Dockerfile !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multistage",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Multi-stage builds\n",
    "\n",
    "Les **multi-stage builds** permettent de cr√©er des images **plus l√©g√®res** en s√©parant :\n",
    "\n",
    "1. **Stage build** : compilation, installation des d√©pendances lourdes\n",
    "2. **Stage runtime** : uniquement ce qui est n√©cessaire pour ex√©cuter\n",
    "\n",
    "### Pourquoi c'est utile ?\n",
    "\n",
    "| Sans multi-stage | Avec multi-stage |\n",
    "|-----------------|------------------|\n",
    "| Image de 1.5 Go | Image de 200 Mo |\n",
    "| Outils de build inclus | Seulement le runtime |\n",
    "| Surface d'attaque large | S√©curit√© renforc√©e |\n",
    "\n",
    "### Exemple : ETL Python avec multi-stage\n",
    "\n",
    "```dockerfile\n",
    "# ============== STAGE 1 : BUILD ==============\n",
    "FROM python:3.11-slim AS builder\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Installer les d√©pendances dans un dossier isol√©\n",
    "COPY requirements.txt .\n",
    "RUN pip install --prefix=/install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# ============== STAGE 2 : RUNTIME ==============\n",
    "FROM python:3.11-slim AS runtime\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier seulement les d√©pendances install√©es\n",
    "COPY --from=builder /install /usr/local\n",
    "\n",
    "# Copier le code\n",
    "COPY src/ ./src/\n",
    "\n",
    "# Variables d'environnement\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "CMD [\"python\", \"src/etl.py\"]\n",
    "```\n",
    "\n",
    "**R√©sultat** : image finale **l√©g√®re** et **s√©curis√©e** ! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "volumes_networks",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Volumes & Networks\n",
    "\n",
    "### 9.1 Volumes : persister les donn√©es\n",
    "\n",
    "Les **volumes** permettent de stocker des donn√©es en dehors des containers.\n",
    "\n",
    "**Types de volumes :**\n",
    "\n",
    "| Type | Syntaxe | Usage |\n",
    "|------|---------|-------|\n",
    "| **Bind mount** | `-v /host/path:/container/path` | Donn√©es locales (dev) |\n",
    "| **Volume nomm√©** | `-v myvolume:/container/path` | Donn√©es persistantes (prod) |\n",
    "\n",
    "**Exemple : monter un dossier local**\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name etl-with-data \\\n",
    "  -v $(pwd)/data:/app/data \\\n",
    "  etl-image:1.0\n",
    "```\n",
    "\n",
    "- `$(pwd)/data` ‚Üí dossier sur ta machine\n",
    "- `/app/data` ‚Üí dossier dans le container\n",
    "- Tu supprimes le container ‚Üí les donn√©es restent dans `./data`\n",
    "\n",
    "---\n",
    "\n",
    "### 9.2 Networks : faire communiquer les containers\n",
    "\n",
    "Par d√©faut, Docker cr√©e un r√©seau `bridge`. Tu peux cr√©er un r√©seau d√©di√© :\n",
    "\n",
    "```bash\n",
    "# Cr√©er un r√©seau\n",
    "docker network create de-network\n",
    "\n",
    "# Lancer des containers sur ce r√©seau\n",
    "docker run -d --name de-postgres --network de-network postgres:16\n",
    "docker run -d --name de-etl --network de-network etl-image:1.0\n",
    "```\n",
    "\n",
    "**Avantage** : dans le code Python, tu te connectes √† `de-postgres` (nom du container) au lieu de `localhost` !\n",
    "\n",
    "```python\n",
    "# Dans etl.py\n",
    "conn = psycopg2.connect(\n",
    "    host=\"de-postgres\",  # Nom du container !\n",
    "    database=\"de_db\",\n",
    "    user=\"de_user\",\n",
    "    password=\"de_pass\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compose",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Docker Compose\n",
    "\n",
    "Quand tu as **plusieurs services** (Postgres + ETL + API‚Ä¶), tu ne veux pas tout lancer √† la main.\n",
    "\n",
    "`docker-compose.yml` permet de **d√©crire une stack compl√®te** et de la lancer avec **une seule commande**.\n",
    "\n",
    "### Structure projet avec docker-compose\n",
    "\n",
    "```text\n",
    "de-pipeline/\n",
    "‚îú‚îÄ‚îÄ docker-compose.yml      # √Ä la racine !\n",
    "‚îú‚îÄ‚îÄ etl/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ etl.py\n",
    "‚îî‚îÄ‚îÄ data/\n",
    "    ‚îî‚îÄ‚îÄ input.csv\n",
    "```\n",
    "\n",
    "### Exemple : PostgreSQL + ETL\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  postgres:\n",
    "    image: postgres:16\n",
    "    container_name: de-postgres\n",
    "    environment:\n",
    "      POSTGRES_USER: de_user\n",
    "      POSTGRES_PASSWORD: de_pass\n",
    "      POSTGRES_DB: de_db\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - pg_data:/var/lib/postgresql/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U de_user -d de_db\"]\n",
    "      interval: 5s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  etl:\n",
    "    build: ./etl\n",
    "    container_name: de-etl\n",
    "    depends_on:\n",
    "      postgres:\n",
    "        condition: service_healthy\n",
    "    environment:\n",
    "      DB_HOST: postgres\n",
    "      DB_USER: de_user\n",
    "      DB_PASSWORD: de_pass\n",
    "      DB_NAME: de_db\n",
    "    volumes:\n",
    "      - ./data:/app/data\n",
    "\n",
    "volumes:\n",
    "  pg_data:\n",
    "```\n",
    "\n",
    "### Commandes docker-compose\n",
    "\n",
    "```bash\n",
    "# Lancer la stack\n",
    "docker compose up -d\n",
    "\n",
    "# Voir les logs\n",
    "docker compose logs -f\n",
    "\n",
    "# Stopper la stack\n",
    "docker compose down\n",
    "\n",
    "# Stopper et supprimer les volumes\n",
    "docker compose down -v\n",
    "\n",
    "# Reconstruire les images\n",
    "docker compose up --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debug",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Debug Docker\n",
    "\n",
    "En Data Engineering, tu devras souvent **d√©bugger** un job qui tourne dans un container.\n",
    "\n",
    "### Voir les logs\n",
    "\n",
    "```bash\n",
    "docker logs de-etl                  # Voir les logs\n",
    "docker logs -f de-etl               # Suivre en temps r√©el\n",
    "docker logs --tail 100 de-etl       # Les 100 derni√®res lignes\n",
    "```\n",
    "\n",
    "### Entrer dans un container\n",
    "\n",
    "```bash\n",
    "docker exec -it de-etl bash         # Ouvrir un shell bash\n",
    "docker exec -it de-etl sh           # Pour images Alpine\n",
    "```\n",
    "\n",
    "**Cas d'usage :**\n",
    "- Inspecter les fichiers (`ls`, `cat`)\n",
    "- Tester une connexion DB (`psql`, `ping`)\n",
    "- V√©rifier les variables d'environnement (`env`)\n",
    "- Lancer un script manuellement (`python etl.py`)\n",
    "\n",
    "### Inspecter un container\n",
    "\n",
    "```bash\n",
    "docker inspect de-etl               # D√©tails complets (JSON)\n",
    "docker inspect --format='{{.NetworkSettings.IPAddress}}' de-etl  # IP du container\n",
    "```\n",
    "\n",
    "### Cas Data Engineering typiques\n",
    "\n",
    "| Probl√®me | Solution |\n",
    "|----------|----------|\n",
    "| ETL qui plante sans message | `docker logs de-etl` |\n",
    "| Connexion DB refus√©e | `docker exec -it de-etl bash` puis `ping postgres` |\n",
    "| Spark ne voit pas Kafka | V√©rifier les networks Docker |\n",
    "| Fichier introuvable | `docker exec -it de-etl ls /app/data` |\n",
    "| Variable d'env manquante | `docker exec -it de-etl env` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Erreurs fr√©quentes & Bonnes pratiques\n",
    "\n",
    "### ‚ùå Erreurs fr√©quentes\n",
    "\n",
    "| Erreur | Cons√©quence | Solution |\n",
    "|--------|-------------|----------|\n",
    "| Pas de `.dockerignore` | Images de plusieurs Go | Cr√©er un `.dockerignore` complet |\n",
    "| Tout en `latest` | Comportement non reproductible | Tags versionn√©s (`image:1.0.0`) |\n",
    "| Dockerfile mal plac√© | Build context gigantesque | Dockerfile √† la racine du service |\n",
    "| Secrets dans l'image | Fuite de credentials | Variables d'env ou secrets manager |\n",
    "| Pas de nettoyage | Disque satur√© | `docker system prune` r√©guli√®rement |\n",
    "| Donn√©es dans l'image | Image √©norme, non portable | Utiliser des volumes |\n",
    "| Versions non fix√©es | Builds cass√©s apr√®s mise √† jour | Fixer les versions dans `requirements.txt` |\n",
    "\n",
    "### ‚úÖ Bonnes pratiques\n",
    "\n",
    "| Pratique | Pourquoi |\n",
    "|----------|----------|\n",
    "| Images **slim** | `python:3.11-slim` = plus l√©ger et rapide |\n",
    "| **Multi-stage builds** | Images finales l√©g√®res |\n",
    "| **Tags versionn√©s** | `etl:1.0.0`, `etl:prod`, `etl:staging` |\n",
    "| **`.dockerignore`** | Builds rapides et s√©curis√©s |\n",
    "| **Healthchecks** | Savoir si un service est pr√™t |\n",
    "| **Volumes pour les donn√©es** | Persistance et portabilit√© |\n",
    "| **Nettoyage r√©gulier** | `docker system prune` |\n",
    "\n",
    "### üßπ Commandes de nettoyage\n",
    "\n",
    "```bash\n",
    "# Supprimer les containers arr√™t√©s\n",
    "docker container prune\n",
    "\n",
    "# Supprimer les images non utilis√©es\n",
    "docker image prune\n",
    "\n",
    "# Tout nettoyer (‚ö†Ô∏è attention en prod !)\n",
    "docker system prune -a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quiz de fin de module\n",
    "\n",
    "R√©ponds aux questions suivantes pour v√©rifier tes acquis.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q1. Quelle est la diff√©rence entre une image et un container Docker ?\n",
    "a) Une image est un container en cours d'ex√©cution  \n",
    "b) Un container est une instance en cours d'ex√©cution d'une image  \n",
    "c) C'est la m√™me chose  \n",
    "d) Une image contient plusieurs containers\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Une image est un mod√®le fig√©, un container est son ex√©cution vivante.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q2. Pourquoi le fichier `.dockerignore` est-il important ?\n",
    "a) Pour ignorer les erreurs Docker  \n",
    "b) Pour r√©duire la taille du build context et s√©curiser les builds  \n",
    "c) Pour ignorer les logs  \n",
    "d) C'est optionnel et inutile\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Il √©vite d'envoyer des fichiers inutiles (donn√©es, secrets) dans le build context.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q3. Quelle commande permet d'entrer dans un container en cours d'ex√©cution ?\n",
    "a) `docker run -it container bash`  \n",
    "b) `docker exec -it container bash`  \n",
    "c) `docker enter container`  \n",
    "d) `docker ssh container`\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî `docker exec -it <container> bash` ouvre un shell interactif.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q4. √Ä quoi servent les multi-stage builds ?\n",
    "a) √Ä lancer plusieurs containers en parall√®le  \n",
    "b) √Ä cr√©er des images plus l√©g√®res en s√©parant build et runtime  \n",
    "c) √Ä versionner les images  \n",
    "d) √Ä g√©rer les r√©seaux Docker\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Multi-stage = image finale l√©g√®re avec seulement le runtime n√©cessaire.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q5. O√π doit-on placer le fichier `docker-compose.yml` ?\n",
    "a) Dans le dossier `/etc/docker/`  \n",
    "b) √Ä la racine du projet multi-services  \n",
    "c) Dans chaque sous-dossier de service  \n",
    "d) N'importe o√π\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Le `docker-compose.yml` est √† la racine du projet, avec les services dans des sous-dossiers.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q6. Quelle commande permet de voir les logs d'un container en temps r√©el ?\n",
    "a) `docker logs container`  \n",
    "b) `docker logs -f container`  \n",
    "c) `docker watch container`  \n",
    "d) `docker tail container`\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî L'option `-f` (follow) suit les logs en temps r√©el.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mini-projet : ETL Dockeris√© complet\n",
    "\n",
    "### Objectif\n",
    "Cr√©er un **pipeline ETL Dockeris√©** qui lit un CSV, transforme les donn√©es, et les charge dans PostgreSQL.\n",
    "\n",
    "### Contexte\n",
    "Tu dois packager un job ETL Python avec Docker et le faire communiquer avec une base PostgreSQL, le tout orchestr√© par docker-compose.\n",
    "\n",
    "### Contraintes\n",
    "\n",
    "1. Cr√©er la structure de projet suivante :\n",
    "```text\n",
    "de-mini-projet/\n",
    "‚îú‚îÄ‚îÄ docker-compose.yml\n",
    "‚îú‚îÄ‚îÄ etl/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ .dockerignore\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ etl.py\n",
    "‚îî‚îÄ‚îÄ data/\n",
    "    ‚îî‚îÄ‚îÄ sales.csv\n",
    "```\n",
    "\n",
    "2. L'ETL doit :\n",
    "   - Lire `data/sales.csv`\n",
    "   - Calculer une colonne `total = quantity * price`\n",
    "   - Ins√©rer les donn√©es dans PostgreSQL\n",
    "\n",
    "3. Utiliser un **healthcheck** pour attendre que Postgres soit pr√™t\n",
    "\n",
    "4. Les donn√©es doivent √™tre mont√©es via un **volume**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_solution",
   "metadata": {},
   "source": [
    "### ‚úÖ Solution du mini-projet\n",
    "\n",
    "<details>\n",
    "<summary>üì• Afficher la solution compl√®te</summary>\n",
    "\n",
    "**1. `data/sales.csv`**\n",
    "```csv\n",
    "date,product,quantity,price\n",
    "2024-01-01,Laptop,5,999.99\n",
    "2024-01-02,Mouse,20,29.99\n",
    "2024-01-03,Keyboard,15,79.99\n",
    "2024-01-04,Monitor,8,299.99\n",
    "2024-01-05,Laptop,3,999.99\n",
    "```\n",
    "\n",
    "**2. `etl/requirements.txt`**\n",
    "```text\n",
    "pandas==2.1.4\n",
    "psycopg2-binary==2.9.9\n",
    "sqlalchemy==2.0.25\n",
    "```\n",
    "\n",
    "**3. `etl/.dockerignore`**\n",
    "```text\n",
    "__pycache__/\n",
    "*.pyc\n",
    ".env\n",
    "*.log\n",
    "```\n",
    "\n",
    "**4. `etl/Dockerfile`**\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY etl.py .\n",
    "\n",
    "CMD [\"python\", \"etl.py\"]\n",
    "```\n",
    "\n",
    "**5. `etl/etl.py`**\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def main():\n",
    "    # Configuration depuis variables d'environnement\n",
    "    db_host = os.environ.get('DB_HOST', 'localhost')\n",
    "    db_user = os.environ.get('DB_USER', 'de_user')\n",
    "    db_pass = os.environ.get('DB_PASSWORD', 'de_pass')\n",
    "    db_name = os.environ.get('DB_NAME', 'de_db')\n",
    "    \n",
    "    print(\"üöÄ D√©marrage de l'ETL...\")\n",
    "    \n",
    "    # Extract\n",
    "    print(\"üì• Lecture du fichier CSV...\")\n",
    "    df = pd.read_csv('/app/data/sales.csv')\n",
    "    print(f\"   {len(df)} lignes lues\")\n",
    "    \n",
    "    # Transform\n",
    "    print(\"üîÑ Transformation des donn√©es...\")\n",
    "    df['total'] = df['quantity'] * df['price']\n",
    "    df['loaded_at'] = pd.Timestamp.now()\n",
    "    \n",
    "    # Load\n",
    "    print(\"üì§ Chargement dans PostgreSQL...\")\n",
    "    engine = create_engine(f'postgresql://{db_user}:{db_pass}@{db_host}/{db_name}')\n",
    "    df.to_sql('sales', engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(\"‚úÖ ETL termin√© avec succ√®s !\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "**6. `docker-compose.yml`**\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  postgres:\n",
    "    image: postgres:16\n",
    "    container_name: de-postgres\n",
    "    environment:\n",
    "      POSTGRES_USER: de_user\n",
    "      POSTGRES_PASSWORD: de_pass\n",
    "      POSTGRES_DB: de_db\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - pg_data:/var/lib/postgresql/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U de_user -d de_db\"]\n",
    "      interval: 5s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  etl:\n",
    "    build: ./etl\n",
    "    container_name: de-etl\n",
    "    depends_on:\n",
    "      postgres:\n",
    "        condition: service_healthy\n",
    "    environment:\n",
    "      DB_HOST: postgres\n",
    "      DB_USER: de_user\n",
    "      DB_PASSWORD: de_pass\n",
    "      DB_NAME: de_db\n",
    "    volumes:\n",
    "      - ./data:/app/data\n",
    "\n",
    "volumes:\n",
    "  pg_data:\n",
    "```\n",
    "\n",
    "**7. Lancer le projet :**\n",
    "```bash\n",
    "cd de-mini-projet\n",
    "docker compose up --build\n",
    "```\n",
    "\n",
    "**8. V√©rifier les donn√©es dans Postgres :**\n",
    "```bash\n",
    "docker exec -it de-postgres psql -U de_user -d de_db -c \"SELECT * FROM sales;\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Ressources pour aller plus loin\n",
    "\n",
    "### üåê Documentation officielle\n",
    "- [Docker Docs](https://docs.docker.com/) ‚Äî Documentation officielle\n",
    "- [Docker Hub](https://hub.docker.com/) ‚Äî Registry d'images publiques\n",
    "- [Dockerfile reference](https://docs.docker.com/engine/reference/builder/) ‚Äî Toutes les instructions\n",
    "\n",
    "### üéÆ Pratique\n",
    "- [Play with Docker](https://labs.play-with-docker.com/) ‚Äî Environnement Docker gratuit en ligne\n",
    "- [Docker 101 Tutorial](https://www.docker.com/101-tutorial/) ‚Äî Tutoriel officiel interactif\n",
    "\n",
    "### üì¶ Images utiles pour Data Engineering\n",
    "- [postgres](https://hub.docker.com/_/postgres) ‚Äî Base de donn√©es relationnelle\n",
    "- [apache/airflow](https://hub.docker.com/r/apache/airflow) ‚Äî Orchestrateur\n",
    "- [bitnami/spark](https://hub.docker.com/r/bitnami/spark) ‚Äî Traitement distribu√©\n",
    "- [bitnami/kafka](https://hub.docker.com/r/bitnami/kafka) ‚Äî Streaming\n",
    "- [jupyter/scipy-notebook](https://hub.docker.com/r/jupyter/scipy-notebook) ‚Äî Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚û°Ô∏è Prochaine √©tape\n",
    "\n",
    "Maintenant que tu ma√Ætrises Docker, passons √† l'orchestration de containers **√† grande √©chelle** !\n",
    "\n",
    "üëâ **Module suivant : `15_kubernetes_fundamentals`** ‚Äî Orchestrer des containers avec Kubernetes\n",
    "\n",
    "Tu vas apprendre :\n",
    "- Pods, Deployments, Services\n",
    "- ConfigMaps, Secrets\n",
    "- Spark et Airflow sur Kubernetes\n",
    "\n",
    "---\n",
    "\n",
    "üéâ **F√©licitations !** Tu as termin√© le module Docker pour Data Engineers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
