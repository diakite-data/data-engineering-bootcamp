{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ğŸ³ Docker pour Data Engineers\n",
    "\n",
    "Bienvenue dans ce module oÃ¹ tu vas apprendre Ã  **containeriser** tes applications, lancer des services data en quelques secondes, et packager tes pipelines ETL de maniÃ¨re **reproductible et portable** â€” des compÃ©tences indispensables pour un Data Engineer moderne !\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ PrÃ©requis\n",
    "\n",
    "| Niveau | CompÃ©tence |\n",
    "|--------|------------|\n",
    "| âœ… Requis | Avoir suivi les modules `01_intro_data_engineering` et `02_bash_for_data_engineers` |\n",
    "| âœ… Requis | Connaissances de base en Python |\n",
    "| âœ… Requis | Avoir accÃ¨s Ã  un terminal (Linux, Mac, ou Windows avec WSL) |\n",
    "\n",
    "## ğŸ¯ Objectifs du module\n",
    "\n",
    "Ã€ la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Expliquer ce qu'est Docker et pourquoi il est essentiel en Data Engineering\n",
    "- Installer Docker sur Windows, macOS ou Linux\n",
    "- Lancer des services data (PostgreSQL, Kafka, Sparkâ€¦) en une commande\n",
    "- Ã‰crire un Dockerfile pour packager un script ETL\n",
    "- Utiliser les volumes, rÃ©seaux et docker-compose\n",
    "- DÃ©bugger des containers comme un pro\n",
    "- Appliquer les bonnes pratiques professionnelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what_is_docker",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§  C'est quoi Docker ?\n",
    "\n",
    "> ğŸ³ **Docker est un outil qui permet d'exÃ©cuter des applications dans des environnements isolÃ©s, reproductibles et portables**, appelÃ©s *containers*.\n",
    "\n",
    "Au lieu d'installer une application (et toutes ses dÃ©pendances) **directement sur ton systÃ¨me**, tu la mets dans une \"boÃ®te\" (le container) avec tout ce dont elle a besoin.\n",
    "\n",
    "### ğŸ”„ Docker â‰  Machine Virtuelle\n",
    "\n",
    "| Aspect | Machine Virtuelle (VM) | Container Docker |\n",
    "|--------|----------------------|------------------|\n",
    "| **Contenu** | OS complet + kernel + drivers + apps | App + libs + systÃ¨me minimal |\n",
    "| **Taille** | Plusieurs Go | Quelques Mo Ã  centaines de Mo |\n",
    "| **DÃ©marrage** | Minutes | Secondes/millisecondes |\n",
    "| **Performance** | Overhead important | Quasi-natif |\n",
    "| **Isolation** | ComplÃ¨te (hyperviseur) | Au niveau processus |\n",
    "\n",
    "### ğŸ¯ Analogies pour bien comprendre\n",
    "\n",
    "| Analogie | Explication |\n",
    "|----------|-------------|\n",
    "| ğŸ§³ **La valise prÃªte** | Un container = une valise dÃ©jÃ  remplie. Tu la prends, tu voyages, tu es opÃ©rationnel partout. |\n",
    "| ğŸ± **Le tupperware** | Tu prÃ©pares un plat, tu le mets dans une boÃ®te hermÃ©tique. Chez toi ou ailleurs : c'est le mÃªme plat. |\n",
    "| ğŸ“¦ **Le zip complet** | Code + librairies + config dans un package. Mais avec la garantie que l'exÃ©cution est **identique** partout. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "docker_info",
   "metadata": {},
   "source": [
    "> â„¹ï¸ **Le savais-tu ?**\n",
    ">\n",
    "> Docker a Ã©tÃ© crÃ©Ã© en **2013** par Solomon Hykes chez dotCloud (devenu Docker, Inc.).\n",
    "> \n",
    "> Le nom vient des **dockers** (ouvriers portuaires) qui chargent et dÃ©chargent des **containers** sur les bateaux â€” exactement ce que fait Docker avec les applications !\n",
    ">\n",
    "> ğŸ“– [Histoire de Docker sur Wikipedia](https://en.wikipedia.org/wiki/Docker_(software))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why_docker",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ 1. Pourquoi Docker est indispensable pour un Data Engineer\n",
    "\n",
    "En Data Engineering, tu dois souvent :\n",
    "\n",
    "- Manipuler des **bases de donnÃ©es** (PostgreSQL, MySQL, MongoDBâ€¦)\n",
    "- Lancer des **brokers de messages** (Kafka, RabbitMQâ€¦)\n",
    "- DÃ©ployer des **pipelines ETL**\n",
    "- Faire tourner des jobs **Spark** ou des APIs\n",
    "\n",
    "### âŒ Sans Docker\n",
    "\n",
    "| ProblÃ¨me | ConsÃ©quence |\n",
    "|----------|-------------|\n",
    "| Installation manuelle complexe | Heures perdues en config |\n",
    "| Conflits de versions (Java, Python, drivers) | \"Ã‡a marchait hier...\" |\n",
    "| Environnements diffÃ©rents (local â‰  prod) | Bugs en production uniquement |\n",
    "| Onboarding difficile | Nouveaux = 2 jours pour installer |\n",
    "\n",
    "### âœ… Avec Docker\n",
    "\n",
    "| Avantage | Exemple concret |\n",
    "|----------|----------------|\n",
    "| PostgreSQL en 1 commande | `docker run postgres:16` |\n",
    "| Test Kafka + Spark sur laptop | Stack complÃ¨te en local |\n",
    "| ETL packagÃ© et portable | Tourne identique partout |\n",
    "| Onboarding en 10 minutes | `docker-compose up` et c'est parti |\n",
    "\n",
    "> ğŸ’¡ En rÃ©sumÃ© : Docker est un **outil central** pour crÃ©er des environnements data **reproductibles et industrialisables**. Fini le ğŸ˜… *\"chez moi Ã§a marche\"* !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concepts",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”‘ 2. Concepts clÃ©s Docker\n",
    "\n",
    "Avant d'aller plus loin, maÃ®trise ces 6 notions fondamentales :\n",
    "\n",
    "| Concept | Description | Analogie |\n",
    "|---------|-------------|----------|\n",
    "| **Image** | ModÃ¨le figÃ© (blueprint) contenant OS + dÃ©pendances + code | Une *recette* de cuisine |\n",
    "| **Container** | Instance en cours d'exÃ©cution d'une image | Un *plat* prÃ©parÃ© Ã  partir de la recette |\n",
    "| **Registry** | Magasin d'images (Docker Hub, ECR, GHCR) | Un *catalogue de recettes* en ligne |\n",
    "| **Volume** | Stockage persistant en dehors du container | Un *disque dur externe* branchÃ© |\n",
    "| **Network** | RÃ©seau virtuel entre containers | Un *rÃ©seau local* privÃ© |\n",
    "| **Build context** | Fichiers envoyÃ©s Ã  Docker lors du build | Le *dossier de travail* |\n",
    "\n",
    "### ğŸ“¦ Image Docker\n",
    "\n",
    "Une image contient :\n",
    "- Un systÃ¨me de base (ex: `python:3.11-slim`)\n",
    "- Des bibliothÃ¨ques (pandas, pyarrow, pysparkâ€¦)\n",
    "- Ton code (scripts, fichiers de config)\n",
    "\n",
    "**On ne modifie pas une image** â€” on en reconstruit une nouvelle Ã  partir d'un Dockerfile.\n",
    "\n",
    "### ğŸƒ Container\n",
    "\n",
    "Un container est une **instance vivante** d'une image :\n",
    "- Tu crÃ©es une image â†’ tu la *lances* â†’ tu obtiens un container\n",
    "- Tu peux dÃ©marrer, arrÃªter, supprimer un container sans toucher Ã  l'image\n",
    "- Plusieurs containers peuvent tourner Ã  partir de la mÃªme image\n",
    "\n",
    "### ğŸŒ Registry\n",
    "\n",
    "Un registry stocke et partage les images :\n",
    "- **Docker Hub** (public/privÃ©) â€” le plus connu\n",
    "- **GitHub Container Registry** (GHCR)\n",
    "- **AWS ECR**, **GCP Artifact Registry**, **Azure ACR**\n",
    "\n",
    "### ğŸ’¾ Volume\n",
    "\n",
    "Les donnÃ©es ne doivent pas \"mourir\" avec le container :\n",
    "- **Sans volume** : container supprimÃ© = donnÃ©es perdues\n",
    "- **Avec volume** : donnÃ©es persistantes, partageables\n",
    "\n",
    "### ğŸ”— Network\n",
    "\n",
    "Permet aux containers de communiquer entre eux :\n",
    "- Ex: container `etl` se connecte Ã  container `postgres`\n",
    "- Isolation du rÃ©seau de la machine hÃ´te\n",
    "\n",
    "### ğŸ“ Build context\n",
    "\n",
    "Quand tu fais `docker build -t mon-image .` :\n",
    "- Le `.` = tout ce que Docker envoie au daemon\n",
    "- Dossier de 10 Go = envoi de 10 Go ğŸ¤¯\n",
    "- D'oÃ¹ l'importance du **`.dockerignore`** !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture",
   "metadata": {},
   "source": [
    "### ğŸ–¼ï¸ SchÃ©ma visuel : Architecture Docker\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      DOCKER HOST                            â”‚\n",
    "â”‚               (Laptop / Server / Cloud)                     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚  â”‚                  DOCKER ENGINE                       â”‚   â”‚\n",
    "â”‚  â”‚                                                      â”‚   â”‚\n",
    "â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”‚\n",
    "â”‚  â”‚   â”‚  IMAGE   â”‚  â”‚  IMAGE   â”‚  â”‚  IMAGE   â”‚         â”‚   â”‚\n",
    "â”‚  â”‚   â”‚ postgres â”‚  â”‚  python  â”‚  â”‚  spark   â”‚         â”‚   â”‚\n",
    "â”‚  â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚   â”‚\n",
    "â”‚  â”‚        â”‚             â”‚             â”‚                â”‚   â”‚\n",
    "â”‚  â”‚        â–¼             â–¼             â–¼                â”‚   â”‚\n",
    "â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”‚\n",
    "â”‚  â”‚   â”‚CONTAINER â”‚  â”‚CONTAINER â”‚  â”‚CONTAINER â”‚         â”‚   â”‚\n",
    "â”‚  â”‚   â”‚ de-postgresâ”‚ â”‚  de-etl  â”‚  â”‚ de-spark â”‚         â”‚   â”‚\n",
    "â”‚  â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚\n",
    "â”‚  â”‚        â”‚                                            â”‚   â”‚\n",
    "â”‚  â”‚        â–¼                                            â”‚   â”‚\n",
    "â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚\n",
    "â”‚  â”‚   â”‚  VOLUME  â”‚       â”‚   NETWORK    â”‚              â”‚   â”‚\n",
    "â”‚  â”‚   â”‚ pg_data  â”‚       â”‚  de-network  â”‚              â”‚   â”‚\n",
    "â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’» 3. Installation de Docker\n",
    "\n",
    "| SystÃ¨me | Comment installer |\n",
    "|---------|------------------|\n",
    "| ğŸªŸ **Windows** | Docker Desktop + WSL2 |\n",
    "| ğŸ **macOS** | Docker Desktop (Intel ou Apple Silicon) |\n",
    "| ğŸ§ **Linux** | Docker Engine (apt/yum) |\n",
    "\n",
    "### ğŸªŸ Windows (Docker Desktop + WSL2)\n",
    "\n",
    "**1. Activer WSL2 :**\n",
    "```powershell\n",
    "# Dans PowerShell en administrateur\n",
    "wsl --install\n",
    "```\n",
    "\n",
    "**2. TÃ©lÃ©charger Docker Desktop :**\n",
    "- ğŸ”— https://www.docker.com/products/docker-desktop/\n",
    "\n",
    "**3. Installer et redÃ©marrer**\n",
    "\n",
    "**4. Tester :**\n",
    "```powershell\n",
    "docker --version\n",
    "docker run --rm hello-world\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ macOS (Intel & Apple Silicon)\n",
    "\n",
    "**1. TÃ©lÃ©charger Docker Desktop :**\n",
    "- ğŸ”— https://www.docker.com/products/docker-desktop/\n",
    "- Choisir la version **Intel** ou **Apple Silicon (M1/M2/M3)**\n",
    "\n",
    "**2. Glisser l'app dans Applications**\n",
    "\n",
    "**3. Lancer Docker Desktop** (icÃ´ne ğŸ³ dans la barre)\n",
    "\n",
    "**4. Tester :**\n",
    "```bash\n",
    "docker --version\n",
    "docker run --rm hello-world\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§ Linux (Ubuntu/Debian)\n",
    "\n",
    "```bash\n",
    "# 1. Mettre Ã  jour et installer les prÃ©requis\n",
    "sudo apt-get update\n",
    "sudo apt-get install ca-certificates curl gnupg lsb-release\n",
    "\n",
    "# 2. Ajouter la clÃ© GPG officielle\n",
    "sudo mkdir -p /etc/apt/keyrings\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n",
    "\n",
    "# 3. Ajouter le dÃ©pÃ´t Docker\n",
    "echo \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "\n",
    "# 4. Installer Docker\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-ce docker-ce-cli containerd.io\n",
    "\n",
    "# 5. Tester\n",
    "sudo docker run --rm hello-world\n",
    "\n",
    "# 6. (Optionnel) Utiliser Docker sans sudo\n",
    "sudo usermod -aG docker $USER\n",
    "# Puis dÃ©connexion/reconnexion\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_install",
   "metadata": {},
   "source": [
    "### âœ… VÃ©rifier ton installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_docker",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# VÃ©rifier la version de Docker\n",
    "docker --version\n",
    "\n",
    "# VÃ©rifier que Docker fonctionne\n",
    "docker run --rm hello-world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commands",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ› ï¸ 4. Commandes Docker essentielles\n",
    "\n",
    "Voici ton **cheat sheet** de base :\n",
    "\n",
    "### ğŸƒ Lancer un container\n",
    "\n",
    "```bash\n",
    "docker run image                    # Lancer un container\n",
    "docker run -d image                 # En arriÃ¨re-plan (detached)\n",
    "docker run -it image bash           # Mode interactif\n",
    "docker run --rm image               # Supprime le container Ã  la fin\n",
    "docker run --name mon-container image  # Nommer le container\n",
    "```\n",
    "\n",
    "### ğŸ“‹ Lister\n",
    "\n",
    "```bash\n",
    "docker ps                           # Containers en cours\n",
    "docker ps -a                        # Tous les containers (y compris stoppÃ©s)\n",
    "docker images                       # Lister les images locales\n",
    "```\n",
    "\n",
    "### â¹ï¸ Stopper / Supprimer\n",
    "\n",
    "```bash\n",
    "docker stop CONTAINER_ID            # ArrÃªter un container\n",
    "docker rm CONTAINER_ID              # Supprimer un container\n",
    "docker rmi IMAGE_ID                 # Supprimer une image\n",
    "```\n",
    "\n",
    "### ğŸ“¥ TÃ©lÃ©charger une image\n",
    "\n",
    "```bash\n",
    "docker pull postgres:16             # TÃ©lÃ©charger depuis Docker Hub\n",
    "```\n",
    "\n",
    "### ğŸ“œ Logs\n",
    "\n",
    "```bash\n",
    "docker logs CONTAINER_ID            # Voir les logs\n",
    "docker logs -f CONTAINER_ID         # Suivre les logs en temps rÃ©el\n",
    "```\n",
    "\n",
    "### ğŸ”‘ Raccourcis utiles\n",
    "\n",
    "| Commande | Description |\n",
    "|----------|-------------|\n",
    "| `docker ps -a` | Voir tous les containers |\n",
    "| `docker logs -f` | Suivre les logs en live |\n",
    "| `docker exec -it <container> bash` | Entrer dans un container |\n",
    "| `docker system prune` | Nettoyer les ressources inutilisÃ©es |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "docker_commands_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Lister les images disponibles localement\n",
    "echo \"=== Images locales ===\"\n",
    "docker images\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Containers en cours ===\"\n",
    "docker ps\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Tous les containers ===\"\n",
    "docker ps -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "services",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ—„ï¸ 5. Docker pour lancer des services Data\n",
    "\n",
    "Docker est **extrÃªmement pratique** pour tester rapidement des services utilisÃ©s en Data Engineering.\n",
    "\n",
    "### ğŸ˜ PostgreSQL (exemple dÃ©taillÃ©)\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name demo-postgres \\\n",
    "  -e POSTGRES_USER=de_user \\\n",
    "  -e POSTGRES_PASSWORD=de_pass \\\n",
    "  -e POSTGRES_DB=de_db \\\n",
    "  -p 5432:5432 \\\n",
    "  postgres:16\n",
    "```\n",
    "\n",
    "**Connexion :**\n",
    "- Host: `localhost`\n",
    "- Port: `5432`\n",
    "- User: `de_user`\n",
    "- Password: `de_pass`\n",
    "- Database: `de_db`\n",
    "\n",
    "Tu peux ensuite te connecter avec DBeaver, psql, Python (psycopg2), etc.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Autres services (one-liners)\n",
    "\n",
    "| Service | Commande |\n",
    "|---------|----------|\n",
    "| **Redis** | `docker run -d --name demo-redis -p 6379:6379 redis:latest` |\n",
    "| **MongoDB** | `docker run -d --name demo-mongo -p 27017:27017 mongo:latest` |\n",
    "| **Kafka** | `docker run -d --name demo-kafka -p 9092:9092 bitnami/kafka:latest` |\n",
    "| **Spark** | `docker run -it --name demo-spark bitnami/spark:latest pyspark` |\n",
    "| **Airflow** | `docker pull apache/airflow:latest` |\n",
    "| **Jupyter** | `docker run -p 8888:8888 jupyter/scipy-notebook` |\n",
    "\n",
    "> ğŸ’¡ **Astuce** : Pour Kafka et Airflow, prÃ©fÃ¨re `docker-compose` car ils nÃ©cessitent plusieurs services (Zookeeper, webserver, schedulerâ€¦), on le verra un peu plus en bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postgres_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Lancer PostgreSQL (si Docker est installÃ©)\n",
    "docker run -d \\\n",
    "  --name demo-postgres \\\n",
    "  -e POSTGRES_USER=de_user \\\n",
    "  -e POSTGRES_PASSWORD=de_pass \\\n",
    "  -e POSTGRES_DB=de_db \\\n",
    "  -p 5432:5432 \\\n",
    "  postgres:16\n",
    "\n",
    "echo \"âœ… PostgreSQL lancÃ© sur localhost:5432\"\n",
    "\n",
    "# VÃ©rifier qu'il tourne\n",
    "docker ps --filter name=demo-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup_postgres",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Nettoyage : stopper et supprimer le container\n",
    "docker stop demo-postgres 2>/dev/null\n",
    "docker rm demo-postgres 2>/dev/null\n",
    "echo \"ğŸ§¹ Container demo-postgres supprimÃ©\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dockerfile",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“ 6. Dockerfile : crÃ©er son image\n",
    "\n",
    "Le **Dockerfile** est un fichier texte qui dÃ©crit comment construire une image.\n",
    "\n",
    "### ğŸ§± Instructions principales\n",
    "\n",
    "| Instruction | RÃ´le | Exemple |\n",
    "|-------------|------|--------|\n",
    "| `FROM` | Image de base | `FROM python:3.11-slim` |\n",
    "| `WORKDIR` | RÃ©pertoire de travail | `WORKDIR /app` |\n",
    "| `COPY` | Copier des fichiers | `COPY etl.py .` |\n",
    "| `RUN` | ExÃ©cuter une commande (build) | `RUN pip install pandas` |\n",
    "| `CMD` | Commande par dÃ©faut (run) | `CMD [\"python\", \"etl.py\"]` |\n",
    "| `ENTRYPOINT` | Point d'entrÃ©e fixe | `ENTRYPOINT [\"python\"]` |\n",
    "| `ENV` | Variable d'environnement | `ENV PYTHONUNBUFFERED=1` |\n",
    "| `EXPOSE` | Port exposÃ© (documentation) | `EXPOSE 8000` |\n",
    "\n",
    "### ğŸ“ Structure de projet recommandÃ©e\n",
    "\n",
    "```text\n",
    "etl_project/\n",
    "â”œâ”€â”€ Dockerfile\n",
    "â”œâ”€â”€ .dockerignore\n",
    "â”œâ”€â”€ requirements.txt\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â”œâ”€â”€ etl.py\n",
    "â”‚   â””â”€â”€ utils.py\n",
    "â””â”€â”€ data/               # âš ï¸ Ne pas inclure dans l'image !\n",
    "    â””â”€â”€ input.csv\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **Important** : Le Dockerfile doit Ãªtre Ã  la **racine du service** que tu veux packager.\n",
    "\n",
    "### ğŸ Exemple : Dockerfile pour un ETL Python\n",
    "\n",
    "```dockerfile\n",
    "# 1. Image de base lÃ©gÃ¨re\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# 2. Variables d'environnement\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "ENV PYTHONDONTWRITEBYTECODE=1\n",
    "\n",
    "# 3. RÃ©pertoire de travail\n",
    "WORKDIR /app\n",
    "\n",
    "# 4. Copier et installer les dÃ©pendances (cache Docker)\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 5. Copier le code\n",
    "COPY src/ ./src/\n",
    "\n",
    "# 6. Commande par dÃ©faut\n",
    "CMD [\"python\", \"src/etl.py\"]\n",
    "```\n",
    "\n",
    "### ğŸ”¨ Construire l'image\n",
    "\n",
    "```bash\n",
    "cd etl_project\n",
    "docker build -t etl-image:1.0 .\n",
    "```\n",
    "\n",
    "### ğŸƒ Lancer le container\n",
    "\n",
    "```bash\n",
    "docker run --rm etl-image:1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dockerignore",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§¹ 7. Le fichier `.dockerignore`\n",
    "\n",
    "Le `.dockerignore` empÃªche d'envoyer des fichiers inutiles dans le build context.\n",
    "\n",
    "### âŒ Sans `.dockerignore`\n",
    "\n",
    "- Images **Ã©normes** (datasets inclus)\n",
    "- Builds **lents** (envoi de Go de donnÃ©es)\n",
    "- **Fuites de secrets** (.env, clÃ©s SSH)\n",
    "\n",
    "### âœ… Exemple de `.dockerignore` (Data Engineer)\n",
    "\n",
    "```text\n",
    "# DonnÃ©es\n",
    "data/\n",
    "*.csv\n",
    "*.parquet\n",
    "*.json\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    "*.pyo\n",
    "venv/\n",
    ".venv/\n",
    "*.egg-info/\n",
    "\n",
    "# Secrets\n",
    ".env\n",
    "*.key\n",
    "*.pem\n",
    "secrets/\n",
    "\n",
    "# Notebooks\n",
    "*.ipynb\n",
    ".ipynb_checkpoints/\n",
    "\n",
    "# Git\n",
    ".git/\n",
    ".gitignore\n",
    "\n",
    "# IDE\n",
    ".idea/\n",
    ".vscode/\n",
    "*.swp\n",
    "\n",
    "# Logs\n",
    "logs/\n",
    "*.log\n",
    "\n",
    "# OS\n",
    ".DS_Store\n",
    "Thumbs.db\n",
    "\n",
    "# Docker\n",
    "Dockerfile\n",
    "docker-compose*.yml\n",
    "```\n",
    "\n",
    "> ğŸ’¡ **RÃ¨gle d'or** : le `.dockerignore` est **aussi important** que le Dockerfile !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multistage",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ—ï¸ 8. Multi-stage builds\n",
    "\n",
    "Les **multi-stage builds** permettent de crÃ©er des images **plus lÃ©gÃ¨res** en sÃ©parant :\n",
    "\n",
    "1. **Stage build** : compilation, installation des dÃ©pendances lourdes\n",
    "2. **Stage runtime** : uniquement ce qui est nÃ©cessaire pour exÃ©cuter\n",
    "\n",
    "### ğŸ¯ Pourquoi c'est utile ?\n",
    "\n",
    "| Sans multi-stage | Avec multi-stage |\n",
    "|-----------------|------------------|\n",
    "| Image de 1.5 Go | Image de 200 Mo |\n",
    "| Outils de build inclus | Seulement le runtime |\n",
    "| Surface d'attaque large | SÃ©curitÃ© renforcÃ©e |\n",
    "\n",
    "### ğŸ“ Exemple : ETL Python avec multi-stage\n",
    "\n",
    "```dockerfile\n",
    "# ============== STAGE 1 : BUILD ==============\n",
    "FROM python:3.11-slim AS builder\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Installer les dÃ©pendances dans un dossier isolÃ©\n",
    "COPY requirements.txt .\n",
    "RUN pip install --prefix=/install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# ============== STAGE 2 : RUNTIME ==============\n",
    "FROM python:3.11-slim AS runtime\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copier seulement les dÃ©pendances installÃ©es\n",
    "COPY --from=builder /install /usr/local\n",
    "\n",
    "# Copier le code\n",
    "COPY src/ ./src/\n",
    "\n",
    "# Variables d'environnement\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "CMD [\"python\", \"src/etl.py\"]\n",
    "```\n",
    "\n",
    "**RÃ©sultat** : image finale **lÃ©gÃ¨re** et **sÃ©curisÃ©e** ! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "volumes_networks",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ’¾ 9. Volumes & Networks\n",
    "\n",
    "### 9.1 Volumes : persister les donnÃ©es\n",
    "\n",
    "Les **volumes** permettent de stocker des donnÃ©es en dehors des containers.\n",
    "\n",
    "**Types de volumes :**\n",
    "\n",
    "| Type | Syntaxe | Usage |\n",
    "|------|---------|-------|\n",
    "| **Bind mount** | `-v /host/path:/container/path` | DonnÃ©es locales (dev) |\n",
    "| **Volume nommÃ©** | `-v myvolume:/container/path` | DonnÃ©es persistantes (prod) |\n",
    "\n",
    "**Exemple : monter un dossier local**\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "  --name etl-with-data \\\n",
    "  -v $(pwd)/data:/app/data \\\n",
    "  etl-image:1.0\n",
    "```\n",
    "\n",
    "- `$(pwd)/data` â†’ dossier sur ta machine\n",
    "- `/app/data` â†’ dossier dans le container\n",
    "- Tu supprimes le container â†’ les donnÃ©es restent dans `./data`\n",
    "\n",
    "---\n",
    "\n",
    "### 9.2 Networks : faire communiquer les containers\n",
    "\n",
    "Par dÃ©faut, Docker crÃ©e un rÃ©seau `bridge`. Tu peux crÃ©er un rÃ©seau dÃ©diÃ© :\n",
    "\n",
    "```bash\n",
    "# CrÃ©er un rÃ©seau\n",
    "docker network create de-network\n",
    "\n",
    "# Lancer des containers sur ce rÃ©seau\n",
    "docker run -d --name de-postgres --network de-network postgres:16\n",
    "docker run -d --name de-etl --network de-network etl-image:1.0\n",
    "```\n",
    "\n",
    "**Avantage** : dans le code Python, tu te connectes Ã  `de-postgres` (nom du container) au lieu de `localhost` !\n",
    "\n",
    "```python\n",
    "# Dans etl.py\n",
    "conn = psycopg2.connect(\n",
    "    host=\"de-postgres\",  # Nom du container !\n",
    "    database=\"de_db\",\n",
    "    user=\"de_user\",\n",
    "    password=\"de_pass\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compose",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¼ 10. Docker Compose\n",
    "\n",
    "Quand tu as **plusieurs services** (Postgres + ETL + APIâ€¦), tu ne veux pas tout lancer Ã  la main.\n",
    "\n",
    "`docker-compose.yml` permet de **dÃ©crire une stack complÃ¨te** et de la lancer avec **une seule commande**.\n",
    "\n",
    "### ğŸ“ Structure projet avec docker-compose\n",
    "\n",
    "```text\n",
    "de-pipeline/\n",
    "â”œâ”€â”€ docker-compose.yml      # Ã€ la racine !\n",
    "â”œâ”€â”€ etl/\n",
    "â”‚   â”œâ”€â”€ Dockerfile\n",
    "â”‚   â”œâ”€â”€ requirements.txt\n",
    "â”‚   â””â”€â”€ etl.py\n",
    "â””â”€â”€ data/\n",
    "    â””â”€â”€ input.csv\n",
    "```\n",
    "\n",
    "### ğŸ“ Exemple : PostgreSQL + ETL\n",
    "\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  postgres:\n",
    "    image: postgres:16\n",
    "    container_name: de-postgres\n",
    "    environment:\n",
    "      POSTGRES_USER: de_user\n",
    "      POSTGRES_PASSWORD: de_pass\n",
    "      POSTGRES_DB: de_db\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - pg_data:/var/lib/postgresql/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U de_user -d de_db\"]\n",
    "      interval: 5s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  etl:\n",
    "    build: ./etl\n",
    "    container_name: de-etl\n",
    "    depends_on:\n",
    "      postgres:\n",
    "        condition: service_healthy\n",
    "    environment:\n",
    "      DB_HOST: postgres\n",
    "      DB_USER: de_user\n",
    "      DB_PASSWORD: de_pass\n",
    "      DB_NAME: de_db\n",
    "    volumes:\n",
    "      - ./data:/app/data\n",
    "\n",
    "volumes:\n",
    "  pg_data:\n",
    "```\n",
    "\n",
    "### ğŸš€ Commandes docker-compose\n",
    "\n",
    "```bash\n",
    "# Lancer la stack\n",
    "docker compose up -d\n",
    "\n",
    "# Voir les logs\n",
    "docker compose logs -f\n",
    "\n",
    "# Stopper la stack\n",
    "docker compose down\n",
    "\n",
    "# Stopper et supprimer les volumes\n",
    "docker compose down -v\n",
    "\n",
    "# Reconstruire les images\n",
    "docker compose up --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debug",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ 11. Debug Docker\n",
    "\n",
    "En Data Engineering, tu devras souvent **dÃ©bugger** un job qui tourne dans un container.\n",
    "\n",
    "### ğŸ“œ Voir les logs\n",
    "\n",
    "```bash\n",
    "docker logs de-etl                  # Voir les logs\n",
    "docker logs -f de-etl               # Suivre en temps rÃ©el\n",
    "docker logs --tail 100 de-etl       # Les 100 derniÃ¨res lignes\n",
    "```\n",
    "\n",
    "### ğŸš Entrer dans un container\n",
    "\n",
    "```bash\n",
    "docker exec -it de-etl bash         # Ouvrir un shell bash\n",
    "docker exec -it de-etl sh           # Pour images Alpine\n",
    "```\n",
    "\n",
    "**Cas d'usage :**\n",
    "- Inspecter les fichiers (`ls`, `cat`)\n",
    "- Tester une connexion DB (`psql`, `ping`)\n",
    "- VÃ©rifier les variables d'environnement (`env`)\n",
    "- Lancer un script manuellement (`python etl.py`)\n",
    "\n",
    "### ğŸ” Inspecter un container\n",
    "\n",
    "```bash\n",
    "docker inspect de-etl               # DÃ©tails complets (JSON)\n",
    "docker inspect --format='{{.NetworkSettings.IPAddress}}' de-etl  # IP du container\n",
    "```\n",
    "\n",
    "### ğŸ› Cas Data Engineering typiques\n",
    "\n",
    "| ProblÃ¨me | Solution |\n",
    "|----------|----------|\n",
    "| ETL qui plante sans message | `docker logs de-etl` |\n",
    "| Connexion DB refusÃ©e | `docker exec -it de-etl bash` puis `ping postgres` |\n",
    "| Spark ne voit pas Kafka | VÃ©rifier les networks Docker |\n",
    "| Fichier introuvable | `docker exec -it de-etl ls /app/data` |\n",
    "| Variable d'env manquante | `docker exec -it de-etl env` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš ï¸ 12. Erreurs frÃ©quentes & Bonnes pratiques\n",
    "\n",
    "### âŒ Erreurs frÃ©quentes\n",
    "\n",
    "| Erreur | ConsÃ©quence | Solution |\n",
    "|--------|-------------|----------|\n",
    "| Pas de `.dockerignore` | Images de plusieurs Go | CrÃ©er un `.dockerignore` complet |\n",
    "| Tout en `latest` | Comportement non reproductible | Tags versionnÃ©s (`image:1.0.0`) |\n",
    "| Dockerfile mal placÃ© | Build context gigantesque | Dockerfile Ã  la racine du service |\n",
    "| Secrets dans l'image | Fuite de credentials | Variables d'env ou secrets manager |\n",
    "| Pas de nettoyage | Disque saturÃ© | `docker system prune` rÃ©guliÃ¨rement |\n",
    "| DonnÃ©es dans l'image | Image Ã©norme, non portable | Utiliser des volumes |\n",
    "| Versions non fixÃ©es | Builds cassÃ©s aprÃ¨s mise Ã  jour | Fixer les versions dans `requirements.txt` |\n",
    "\n",
    "### âœ… Bonnes pratiques\n",
    "\n",
    "| Pratique | Pourquoi |\n",
    "|----------|----------|\n",
    "| Images **slim** | `python:3.11-slim` = plus lÃ©ger et rapide |\n",
    "| **Multi-stage builds** | Images finales lÃ©gÃ¨res |\n",
    "| **Tags versionnÃ©s** | `etl:1.0.0`, `etl:prod`, `etl:staging` |\n",
    "| **`.dockerignore`** | Builds rapides et sÃ©curisÃ©s |\n",
    "| **Healthchecks** | Savoir si un service est prÃªt |\n",
    "| **Volumes pour les donnÃ©es** | Persistance et portabilitÃ© |\n",
    "| **Nettoyage rÃ©gulier** | `docker system prune` |\n",
    "\n",
    "### ğŸ§¹ Commandes de nettoyage\n",
    "\n",
    "```bash\n",
    "# Supprimer les containers arrÃªtÃ©s\n",
    "docker container prune\n",
    "\n",
    "# Supprimer les images non utilisÃ©es\n",
    "docker image prune\n",
    "\n",
    "# Tout nettoyer (âš ï¸ attention en prod !)\n",
    "docker system prune -a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª Quiz de fin de module\n",
    "\n",
    "RÃ©ponds aux questions suivantes pour vÃ©rifier tes acquis.\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q1. Quelle est la diffÃ©rence entre une image et un container Docker ?\n",
    "a) Une image est un container en cours d'exÃ©cution  \n",
    "b) Un container est une instance en cours d'exÃ©cution d'une image  \n",
    "c) C'est la mÃªme chose  \n",
    "d) Une image contient plusieurs containers\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Une image est un modÃ¨le figÃ©, un container est son exÃ©cution vivante.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q2. Pourquoi le fichier `.dockerignore` est-il important ?\n",
    "a) Pour ignorer les erreurs Docker  \n",
    "b) Pour rÃ©duire la taille du build context et sÃ©curiser les builds  \n",
    "c) Pour ignorer les logs  \n",
    "d) C'est optionnel et inutile\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Il Ã©vite d'envoyer des fichiers inutiles (donnÃ©es, secrets) dans le build context.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q3. Quelle commande permet d'entrer dans un container en cours d'exÃ©cution ?\n",
    "a) `docker run -it container bash`  \n",
    "b) `docker exec -it container bash`  \n",
    "c) `docker enter container`  \n",
    "d) `docker ssh container`\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” `docker exec -it <container> bash` ouvre un shell interactif.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q4. Ã€ quoi servent les multi-stage builds ?\n",
    "a) Ã€ lancer plusieurs containers en parallÃ¨le  \n",
    "b) Ã€ crÃ©er des images plus lÃ©gÃ¨res en sÃ©parant build et runtime  \n",
    "c) Ã€ versionner les images  \n",
    "d) Ã€ gÃ©rer les rÃ©seaux Docker\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Multi-stage = image finale lÃ©gÃ¨re avec seulement le runtime nÃ©cessaire.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q5. OÃ¹ doit-on placer le fichier `docker-compose.yml` ?\n",
    "a) Dans le dossier `/etc/docker/`  \n",
    "b) Ã€ la racine du projet multi-services  \n",
    "c) Dans chaque sous-dossier de service  \n",
    "d) N'importe oÃ¹\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Le `docker-compose.yml` est Ã  la racine du projet, avec les services dans des sous-dossiers.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q6. Quelle commande permet de voir les logs d'un container en temps rÃ©el ?\n",
    "a) `docker logs container`  \n",
    "b) `docker logs -f container`  \n",
    "c) `docker watch container`  \n",
    "d) `docker tail container`\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” L'option `-f` (follow) suit les logs en temps rÃ©el.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ Mini-projet : ETL DockerisÃ© complet\n",
    "\n",
    "### ğŸ¯ Objectif\n",
    "CrÃ©er un **pipeline ETL DockerisÃ©** qui lit un CSV, transforme les donnÃ©es, et les charge dans PostgreSQL.\n",
    "\n",
    "### ğŸ”§ Contexte\n",
    "Tu dois packager un job ETL Python avec Docker et le faire communiquer avec une base PostgreSQL, le tout orchestrÃ© par docker-compose.\n",
    "\n",
    "### ğŸ§  Contraintes\n",
    "\n",
    "1. CrÃ©er la structure de projet suivante :\n",
    "```text\n",
    "de-mini-projet/\n",
    "â”œâ”€â”€ docker-compose.yml\n",
    "â”œâ”€â”€ etl/\n",
    "â”‚   â”œâ”€â”€ Dockerfile\n",
    "â”‚   â”œâ”€â”€ .dockerignore\n",
    "â”‚   â”œâ”€â”€ requirements.txt\n",
    "â”‚   â””â”€â”€ etl.py\n",
    "â””â”€â”€ data/\n",
    "    â””â”€â”€ sales.csv\n",
    "```\n",
    "\n",
    "2. L'ETL doit :\n",
    "   - Lire `data/sales.csv`\n",
    "   - Calculer une colonne `total = quantity * price`\n",
    "   - InsÃ©rer les donnÃ©es dans PostgreSQL\n",
    "\n",
    "3. Utiliser un **healthcheck** pour attendre que Postgres soit prÃªt\n",
    "\n",
    "4. Les donnÃ©es doivent Ãªtre montÃ©es via un **volume**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_solution",
   "metadata": {},
   "source": [
    "### âœ… Solution du mini-projet\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ“¥ Afficher la solution complÃ¨te</summary>\n",
    "\n",
    "**1. `data/sales.csv`**\n",
    "```csv\n",
    "date,product,quantity,price\n",
    "2024-01-01,Laptop,5,999.99\n",
    "2024-01-02,Mouse,20,29.99\n",
    "2024-01-03,Keyboard,15,79.99\n",
    "2024-01-04,Monitor,8,299.99\n",
    "2024-01-05,Laptop,3,999.99\n",
    "```\n",
    "\n",
    "**2. `etl/requirements.txt`**\n",
    "```text\n",
    "pandas==2.1.4\n",
    "psycopg2-binary==2.9.9\n",
    "sqlalchemy==2.0.25\n",
    "```\n",
    "\n",
    "**3. `etl/.dockerignore`**\n",
    "```text\n",
    "__pycache__/\n",
    "*.pyc\n",
    ".env\n",
    "*.log\n",
    "```\n",
    "\n",
    "**4. `etl/Dockerfile`**\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY etl.py .\n",
    "\n",
    "CMD [\"python\", \"etl.py\"]\n",
    "```\n",
    "\n",
    "**5. `etl/etl.py`**\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def main():\n",
    "    # Configuration depuis variables d'environnement\n",
    "    db_host = os.environ.get('DB_HOST', 'localhost')\n",
    "    db_user = os.environ.get('DB_USER', 'de_user')\n",
    "    db_pass = os.environ.get('DB_PASSWORD', 'de_pass')\n",
    "    db_name = os.environ.get('DB_NAME', 'de_db')\n",
    "    \n",
    "    print(\"ğŸš€ DÃ©marrage de l'ETL...\")\n",
    "    \n",
    "    # Extract\n",
    "    print(\"ğŸ“¥ Lecture du fichier CSV...\")\n",
    "    df = pd.read_csv('/app/data/sales.csv')\n",
    "    print(f\"   {len(df)} lignes lues\")\n",
    "    \n",
    "    # Transform\n",
    "    print(\"ğŸ”„ Transformation des donnÃ©es...\")\n",
    "    df['total'] = df['quantity'] * df['price']\n",
    "    df['loaded_at'] = pd.Timestamp.now()\n",
    "    \n",
    "    # Load\n",
    "    print(\"ğŸ“¤ Chargement dans PostgreSQL...\")\n",
    "    engine = create_engine(f'postgresql://{db_user}:{db_pass}@{db_host}/{db_name}')\n",
    "    df.to_sql('sales', engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(\"âœ… ETL terminÃ© avec succÃ¨s !\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "**6. `docker-compose.yml`**\n",
    "```yaml\n",
    "version: \"3.9\"\n",
    "\n",
    "services:\n",
    "  postgres:\n",
    "    image: postgres:16\n",
    "    container_name: de-postgres\n",
    "    environment:\n",
    "      POSTGRES_USER: de_user\n",
    "      POSTGRES_PASSWORD: de_pass\n",
    "      POSTGRES_DB: de_db\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - pg_data:/var/lib/postgresql/data\n",
    "    healthcheck:\n",
    "      test: [\"CMD-SHELL\", \"pg_isready -U de_user -d de_db\"]\n",
    "      interval: 5s\n",
    "      timeout: 5s\n",
    "      retries: 5\n",
    "\n",
    "  etl:\n",
    "    build: ./etl\n",
    "    container_name: de-etl\n",
    "    depends_on:\n",
    "      postgres:\n",
    "        condition: service_healthy\n",
    "    environment:\n",
    "      DB_HOST: postgres\n",
    "      DB_USER: de_user\n",
    "      DB_PASSWORD: de_pass\n",
    "      DB_NAME: de_db\n",
    "    volumes:\n",
    "      - ./data:/app/data\n",
    "\n",
    "volumes:\n",
    "  pg_data:\n",
    "```\n",
    "\n",
    "**7. Lancer le projet :**\n",
    "```bash\n",
    "cd de-mini-projet\n",
    "docker compose up --build\n",
    "```\n",
    "\n",
    "**8. VÃ©rifier les donnÃ©es dans Postgres :**\n",
    "```bash\n",
    "docker exec -it de-postgres psql -U de_user -d de_db -c \"SELECT * FROM sales;\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Ressources pour aller plus loin\n",
    "\n",
    "### ğŸŒ Documentation officielle\n",
    "- [Docker Docs](https://docs.docker.com/) â€” Documentation officielle\n",
    "- [Docker Hub](https://hub.docker.com/) â€” Registry d'images publiques\n",
    "- [Dockerfile reference](https://docs.docker.com/engine/reference/builder/) â€” Toutes les instructions\n",
    "\n",
    "### ğŸ® Pratique\n",
    "- [Play with Docker](https://labs.play-with-docker.com/) â€” Environnement Docker gratuit en ligne\n",
    "- [Docker 101 Tutorial](https://www.docker.com/101-tutorial/) â€” Tutoriel officiel interactif\n",
    "\n",
    "### ğŸ“¦ Images utiles pour Data Engineering\n",
    "- [postgres](https://hub.docker.com/_/postgres) â€” Base de donnÃ©es relationnelle\n",
    "- [apache/airflow](https://hub.docker.com/r/apache/airflow) â€” Orchestrateur\n",
    "- [bitnami/spark](https://hub.docker.com/r/bitnami/spark) â€” Traitement distribuÃ©\n",
    "- [bitnami/kafka](https://hub.docker.com/r/bitnami/kafka) â€” Streaming\n",
    "- [jupyter/scipy-notebook](https://hub.docker.com/r/jupyter/scipy-notebook) â€” Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â¡ï¸ Prochaine Ã©tape\n",
    "\n",
    "Maintenant que tu maÃ®trises Docker, passons Ã  l'orchestration de containers **Ã  grande Ã©chelle** !\n",
    "\n",
    "ğŸ‘‰ **Module suivant : `15_kubernetes_fundamentals.ipynb`** â€” Orchestrer des containers avec Kubernetes\n",
    "\n",
    "Tu vas apprendre :\n",
    "- Pods, Deployments, Services\n",
    "- ConfigMaps, Secrets\n",
    "- Spark et Airflow sur Kubernetes\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‰ **FÃ©licitations !** Tu as terminÃ© le module Docker pour Data Engineers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
