{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ—ï¸ dbt (Data Build Tool) & Data Quality\n",
    "\n",
    "## Industrialiser les Transformations et Garantir la QualitÃ©\n",
    "\n",
    "Bienvenue dans ce module oÃ¹ tu vas apprendre Ã  **industrialiser** tes transformations SQL et Ã  **garantir la qualitÃ©** de tes donnÃ©es avec les outils standards de l'industrie.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ PrÃ©requis\n",
    "\n",
    "| Module | CompÃ©tence | Pourquoi ? |\n",
    "|--------|------------|------------|\n",
    "| âœ… 20 | Spark SQL | SQL avancÃ© |\n",
    "| âœ… 23 | Table Formats | Delta Lake comme cible |\n",
    "| âœ… 24 | Streaming | DonnÃ©es incrÃ©mentales |\n",
    "\n",
    "## ğŸ¯ Objectifs\n",
    "\n",
    "Ã€ la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Comprendre le concept de **Transformation-as-Code** (TaC)\n",
    "- MaÃ®triser **dbt** : Models, Sources, Tests, Documentation\n",
    "- ImplÃ©menter des **tests de qualitÃ©** avec dbt et Great Expectations\n",
    "- CrÃ©er des **modÃ¨les incrÃ©mentaux** performants\n",
    "- DÃ©ployer dbt dans un **pipeline CI/CD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š 1. Introduction â€” Le ProblÃ¨me Ã  RÃ©soudre\n",
    "\n",
    "### 1.1 Le chaos des transformations SQL\n",
    "\n",
    "Imagine une Ã©quipe data typique sans dbt :\n",
    "\n",
    "```\n",
    "SITUATION TYPIQUE SANS DBT :\n",
    "\n",
    "ğŸ“ scripts/\n",
    "â”œâ”€â”€ transform_users_v2_final_FINAL.sql      â† Quelle version utiliser ?\n",
    "â”œâ”€â”€ transform_users_v2_final.sql\n",
    "â”œâ”€â”€ transform_users_v2.sql\n",
    "â”œâ”€â”€ create_dashboard_table_john.sql         â† Qui a Ã©crit Ã§a ?\n",
    "â”œâ”€â”€ fix_bug_urgent.sql                      â† Ã‡a fait quoi exactement ?\n",
    "â””â”€â”€ old/\n",
    "    â””â”€â”€ ... 50 fichiers abandonnÃ©s\n",
    "\n",
    "PROBLÃˆMES :\n",
    "â€¢ Aucune traÃ§abilitÃ© (qui a modifiÃ© quoi ?)\n",
    "â€¢ Pas de tests (les donnÃ©es sont-elles correctes ?)\n",
    "â€¢ Pas de documentation (c'est quoi cette colonne ?)\n",
    "â€¢ Ordre d'exÃ©cution manuel (quelle requÃªte lancer en premier ?)\n",
    "â€¢ Pas de review de code (erreurs passent en production)\n",
    "```\n",
    "\n",
    "### 1.2 La solution : Transformation-as-Code (TaC)\n",
    "\n",
    "**Transformation-as-Code** applique les principes du dÃ©veloppement logiciel aux transformations de donnÃ©es :\n",
    "\n",
    "| Principe Dev | Application Data |\n",
    "|--------------|------------------|\n",
    "| **Versioning** | Transformations dans Git |\n",
    "| **Tests unitaires** | Tests sur les donnÃ©es |\n",
    "| **Documentation** | Auto-gÃ©nÃ©rÃ©e depuis le code |\n",
    "| **Code Review** | PR avant mise en production |\n",
    "| **CI/CD** | DÃ©ploiement automatisÃ© |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Qu'est-ce que dbt ?\n",
    "\n",
    "**dbt (Data Build Tool)** est un outil open-source qui permet de transformer les donnÃ©es dans ton Data Warehouse/Lakehouse en utilisant uniquement du SQL.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        dbt - Data Build Tool                    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   ENTRÃ‰E              TRAITEMENT              SORTIE            â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚\n",
    "â”‚   â”‚  Fichiersâ”‚       â”‚              â”‚       â”‚  Tables  â”‚       â”‚\n",
    "â”‚   â”‚  SQL +   â”‚  â”€â”€â”€â–¶ â”‚  dbt run     â”‚  â”€â”€â”€â–¶ â”‚  ou Vues â”‚       â”‚\n",
    "â”‚   â”‚  Jinja   â”‚       â”‚              â”‚       â”‚  testÃ©es â”‚       â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   + Tests automatiques                                          â”‚\n",
    "â”‚   + Documentation gÃ©nÃ©rÃ©e                                       â”‚\n",
    "â”‚   + Lineage (traÃ§abilitÃ©)                                       â”‚\n",
    "â”‚   + Gestion des dÃ©pendances                                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 1.4 Ce que dbt fait et ne fait PAS\n",
    "\n",
    "| dbt FAIT âœ… | dbt NE FAIT PAS âŒ |\n",
    "|-------------|--------------------|\n",
    "| Transformer (T de ELT) | Extraire les donnÃ©es (E) |\n",
    "| Tester les donnÃ©es | Charger les donnÃ©es (L) |\n",
    "| Documenter | Orchestrer (scheduling) |\n",
    "| GÃ©rer les dÃ©pendances | Calcul distribuÃ© |\n",
    "| Versionner | Ingestion temps rÃ©el |\n",
    "\n",
    "**dbt s'intÃ¨gre avec** : Spark (pour le calcul), Airflow (pour l'orchestration), Delta/Iceberg (pour le stockage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 dbt Core vs dbt Cloud\n",
    "\n",
    "| Aspect | dbt Core | dbt Cloud |\n",
    "|--------|----------|----------|\n",
    "| **Prix** | Gratuit (open-source) | Payant (SaaS) |\n",
    "| **Installation** | CLI local | IDE web |\n",
    "| **Scheduling** | Manuel (Airflow, cron) | IntÃ©grÃ© |\n",
    "| **CI/CD** | Ã€ configurer | IntÃ©grÃ© |\n",
    "| **IDE** | VS Code, vim, etc. | IDE web dÃ©diÃ© |\n",
    "| **Collaboration** | Via Git | Via plateforme |\n",
    "\n",
    "Dans ce module, nous utilisons **dbt Core** (CLI) car c'est ce que tu utiliseras dans un environnement Spark/Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 dbt dans l'architecture Data\n",
    "\n",
    "OÃ¹ se place dbt dans ton architecture ?\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         ARCHITECTURE MODERNE                            â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚   INGESTION          STOCKAGE           TRANSFORMATION      SERVING     â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚   â”‚ Kafka   â”‚       â”‚ Bronze  â”‚        â”‚             â”‚    â”‚ BI Tool â”‚  â”‚\n",
    "â”‚   â”‚ Spark   â”‚  â”€â”€â”€â–¶ â”‚ (Raw)   â”‚  â”€â”€â”€â–¶  â”‚    dbt      â”‚â”€â”€â”€â–¶â”‚ ML      â”‚  â”‚\n",
    "â”‚   â”‚ Airbyte â”‚       â”‚ Silver  â”‚        â”‚             â”‚    â”‚ API     â”‚  â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ Gold    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚                        â”‚\n",
    "â”‚                     Delta Lake            Tests &                      â”‚\n",
    "â”‚                     Iceberg               Documentation                â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚   â”‚                    ORCHESTRATION (Airflow / K8s)                â”‚  â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ 2. Installation et Structure d'un Projet dbt\n",
    "\n",
    "### 2.1 Installation\n",
    "\n",
    "dbt s'installe via pip avec un **adapter** spÃ©cifique Ã  ta base de donnÃ©es :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de dbt\n",
    "\n",
    "installation = '''\n",
    "# Adapter selon ton Data Warehouse/Lakehouse :\n",
    "\n",
    "pip install dbt-core              # Core (obligatoire)\n",
    "\n",
    "# + UN adapter selon ta cible :\n",
    "pip install dbt-postgres          # PostgreSQL\n",
    "pip install dbt-snowflake         # Snowflake\n",
    "pip install dbt-bigquery          # BigQuery\n",
    "pip install dbt-spark             # Spark (Databricks, EMR, local)\n",
    "pip install dbt-duckdb            # DuckDB (local, lÃ©ger)\n",
    "pip install dbt-trino             # Trino/Presto\n",
    "\n",
    "# VÃ©rifier l'installation\n",
    "dbt --version\n",
    "'''\n",
    "\n",
    "print(installation)\n",
    "print(\"\\nğŸ’¡ Pour ce module, on utilise dbt-duckdb (lÃ©ger, local) ou dbt-spark.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Initialisation d'un projet\n",
    "\n",
    "La commande `dbt init` crÃ©e la structure de base :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er un nouveau projet dbt\n",
    "\n",
    "init_project = '''\n",
    "# CrÃ©er un nouveau projet\n",
    "dbt init my_dbt_project\n",
    "\n",
    "# Structure crÃ©Ã©e :\n",
    "my_dbt_project/\n",
    "â”‚\n",
    "â”œâ”€â”€ dbt_project.yml          # Configuration principale du projet\n",
    "â”œâ”€â”€ profiles.yml             # Connexions aux bases (souvent dans ~/.dbt/)\n",
    "â”‚\n",
    "â”œâ”€â”€ models/                  # â­ TES TRANSFORMATIONS SQL\n",
    "â”‚   â””â”€â”€ example/\n",
    "â”‚       â”œâ”€â”€ my_first_model.sql\n",
    "â”‚       â””â”€â”€ schema.yml       # Tests et documentation\n",
    "â”‚\n",
    "â”œâ”€â”€ seeds/                   # DonnÃ©es statiques (CSV)\n",
    "â”‚\n",
    "â”œâ”€â”€ snapshots/               # Historisation (SCD Type 2)\n",
    "â”‚\n",
    "â”œâ”€â”€ macros/                  # Fonctions Jinja rÃ©utilisables\n",
    "â”‚\n",
    "â”œâ”€â”€ tests/                   # Tests SQL custom\n",
    "â”‚\n",
    "â”œâ”€â”€ analyses/                # RequÃªtes ad-hoc (non matÃ©rialisÃ©es)\n",
    "â”‚\n",
    "â””â”€â”€ target/                  # Fichiers compilÃ©s (gÃ©nÃ©rÃ©)\n",
    "'''\n",
    "\n",
    "print(init_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Le fichier dbt_project.yml\n",
    "\n",
    "C'est le **fichier de configuration principal** de ton projet. Il dÃ©finit le nom, la version, et les paramÃ¨tres par dÃ©faut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbt_project.yml - Configuration principale\n",
    "\n",
    "dbt_project_yml = '''\n",
    "# dbt_project.yml\n",
    "\n",
    "name: 'ecommerce_analytics'      # Nom du projet (sans espaces, sans tirets)\n",
    "version: '1.0.0'\n",
    "config-version: 2\n",
    "\n",
    "# Profil de connexion (dÃ©fini dans profiles.yml)\n",
    "profile: 'ecommerce_analytics'\n",
    "\n",
    "# Chemins des diffÃ©rents composants\n",
    "model-paths: [\"models\"]\n",
    "analysis-paths: [\"analyses\"]\n",
    "test-paths: [\"tests\"]\n",
    "seed-paths: [\"seeds\"]\n",
    "macro-paths: [\"macros\"]\n",
    "snapshot-paths: [\"snapshots\"]\n",
    "target-path: \"target\"           # OÃ¹ dbt Ã©crit les fichiers compilÃ©s\n",
    "clean-targets: [\"target\", \"dbt_packages\"]\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Configuration des modÃ¨les (TRÃˆS IMPORTANT)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "models:\n",
    "  ecommerce_analytics:           # Doit correspondre au \"name\" ci-dessus\n",
    "    \n",
    "    # Configuration par dÃ©faut pour TOUS les modÃ¨les\n",
    "    +materialized: view          # Par dÃ©faut : crÃ©er des vues\n",
    "    \n",
    "    # Configuration par dossier\n",
    "    staging:                     # Dossier models/staging/\n",
    "      +materialized: view\n",
    "      +schema: staging           # Ã‰crire dans le schÃ©ma \"staging\"\n",
    "    \n",
    "    silver:\n",
    "      +materialized: table       # Tables complÃ¨tes\n",
    "      +schema: silver\n",
    "    \n",
    "    gold:\n",
    "      +materialized: incremental # IncrÃ©mental pour la performance\n",
    "      +schema: gold\n",
    "'''\n",
    "\n",
    "print(dbt_project_yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Le fichier profiles.yml\n",
    "\n",
    "Ce fichier contient les **informations de connexion** Ã  ta base de donnÃ©es. Il est gÃ©nÃ©ralement stockÃ© dans `~/.dbt/profiles.yml` (pas dans le repo Git pour des raisons de sÃ©curitÃ©)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles.yml - Connexions aux bases de donnÃ©es\n",
    "\n",
    "profiles_yml = '''\n",
    "# ~/.dbt/profiles.yml\n",
    "\n",
    "ecommerce_analytics:             # Doit correspondre au \"profile\" dans dbt_project.yml\n",
    "  \n",
    "  target: dev                    # Environnement par dÃ©faut\n",
    "  \n",
    "  outputs:\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Environnement DEV (dÃ©veloppement local)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    dev:\n",
    "      type: duckdb               # Adapter DuckDB (lÃ©ger, local)\n",
    "      path: /tmp/dev.duckdb\n",
    "      threads: 4\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Environnement PROD (Spark/Databricks)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    prod:\n",
    "      type: spark\n",
    "      method: thrift             # ou \"odbc\", \"http\"\n",
    "      host: spark-thrift-server.company.com\n",
    "      port: 10001\n",
    "      schema: analytics\n",
    "      threads: 8\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Exemple Snowflake\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    snowflake_prod:\n",
    "      type: snowflake\n",
    "      account: xy12345.us-east-1\n",
    "      user: \"{{ env_var('SNOWFLAKE_USER') }}\"      # Variable d'environnement\n",
    "      password: \"{{ env_var('SNOWFLAKE_PASSWORD') }}\"\n",
    "      role: TRANSFORMER\n",
    "      database: ANALYTICS\n",
    "      warehouse: TRANSFORM_WH\n",
    "      schema: GOLD\n",
    "      threads: 8\n",
    "'''\n",
    "\n",
    "print(profiles_yml)\n",
    "print(\"\\nğŸ’¡ Utilise env_var() pour les secrets, jamais en dur !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š 3. Les Models â€” CÅ“ur de dbt\n",
    "\n",
    "### 3.1 Qu'est-ce qu'un Model ?\n",
    "\n",
    "Un **model** dbt est simplement un fichier SQL qui contient une requÃªte `SELECT`. dbt se charge de crÃ©er la table ou vue correspondante.\n",
    "\n",
    "```\n",
    "FICHIER SQL                           CE QUE DBT FAIT\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ -- models/users.sql    â”‚          â”‚ CREATE TABLE users AS   â”‚\n",
    "â”‚                        â”‚   â”€â”€â”€â–¶   â”‚ SELECT                  â”‚\n",
    "â”‚ SELECT                 â”‚          â”‚   id,                   â”‚\n",
    "â”‚   id,                  â”‚          â”‚   name,                 â”‚\n",
    "â”‚   name,                â”‚          â”‚   email                 â”‚\n",
    "â”‚   email                â”‚          â”‚ FROM raw.users          â”‚\n",
    "â”‚ FROM raw.users         â”‚          â”‚                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Tu Ã©cris le SELECT, dbt gÃ¨re le CREATE/INSERT !\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de model simple\n",
    "\n",
    "model_simple = '''\n",
    "-- models/staging/stg_orders.sql\n",
    "\n",
    "-- Configuration du model (optionnel, peut Ãªtre dans dbt_project.yml)\n",
    "{{ config(\n",
    "    materialized='view',\n",
    "    schema='staging'\n",
    ") }}\n",
    "\n",
    "-- Le SELECT qui dÃ©finit le model\n",
    "SELECT\n",
    "    order_id,\n",
    "    customer_id,\n",
    "    order_date,\n",
    "    CAST(amount AS DECIMAL(10, 2)) AS amount,\n",
    "    status,\n",
    "    created_at\n",
    "FROM {{ source('raw', 'orders') }}  -- RÃ©fÃ©rence Ã  une source externe\n",
    "WHERE order_date >= '2024-01-01'    -- Filtrer les donnÃ©es rÃ©centes\n",
    "'''\n",
    "\n",
    "print(model_simple)\n",
    "print(\"\\nğŸ’¡ Points clÃ©s :\")\n",
    "print(\"â€¢ {{ config(...) }} : Configuration spÃ©cifique au model\")\n",
    "print(\"â€¢ {{ source(...) }} : RÃ©fÃ©rence Ã  une table externe\")\n",
    "print(\"â€¢ Pas de CREATE TABLE : dbt le gÃ©nÃ¨re automatiquement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 La fonction ref() â€” La clÃ© de dbt\n",
    "\n",
    "**`ref()`** est LA fonction la plus importante de dbt. Elle permet de rÃ©fÃ©rencer un autre model, et dbt :\n",
    "1. Comprend la **dÃ©pendance** entre les models\n",
    "2. ExÃ©cute les models dans le **bon ordre**\n",
    "3. GÃ©nÃ¨re le **lineage** (traÃ§abilitÃ©)\n",
    "\n",
    "```\n",
    "SANS ref() (MAUVAIS)                 AVEC ref() (BON)\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ SELECT *                â”‚         â”‚ SELECT *                â”‚\n",
    "â”‚ FROM analytics.users    â”‚         â”‚ FROM {{ ref('users') }} â”‚\n",
    "â”‚                         â”‚         â”‚                         â”‚\n",
    "â”‚ âŒ SchÃ©ma hardcodÃ©      â”‚         â”‚ âœ… dbt rÃ©sout le schÃ©ma â”‚\n",
    "â”‚ âŒ Pas de dÃ©pendance    â”‚         â”‚ âœ… DÃ©pendance trackÃ©e   â”‚\n",
    "â”‚ âŒ Pas de lineage       â”‚         â”‚ âœ… Lineage automatique  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple avec ref()\n",
    "\n",
    "model_with_ref = '''\n",
    "-- models/silver/silver_orders.sql\n",
    "\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT\n",
    "    o.order_id,\n",
    "    o.customer_id,\n",
    "    c.customer_name,\n",
    "    c.customer_email,\n",
    "    o.order_date,\n",
    "    o.amount,\n",
    "    o.status\n",
    "FROM {{ ref('stg_orders') }} o           -- RÃ©fÃ©rence au model stg_orders\n",
    "LEFT JOIN {{ ref('stg_customers') }} c   -- RÃ©fÃ©rence au model stg_customers\n",
    "    ON o.customer_id = c.customer_id\n",
    "WHERE o.status != 'cancelled'\n",
    "'''\n",
    "\n",
    "print(model_with_ref)\n",
    "print(\"\\nğŸ“Š Ce que dbt comprend :\")\n",
    "print(\"\")\n",
    "print(\"   stg_orders â”€â”€â”€â”€â”€â”€â”\")\n",
    "print(\"                    â”œâ”€â”€â–¶ silver_orders\")\n",
    "print(\"   stg_customers â”€â”€â”€â”˜\")\n",
    "print(\"\")\n",
    "print(\"dbt exÃ©cutera stg_orders et stg_customers AVANT silver_orders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Les Sources â€” RÃ©fÃ©rencer les donnÃ©es externes\n",
    "\n",
    "Les **sources** reprÃ©sentent les donnÃ©es qui existent AVANT dbt (tables raw, donnÃ©es ingÃ©rÃ©es par Kafka/Spark, etc.).\n",
    "\n",
    "On les dÃ©finit dans un fichier `schema.yml` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finition des sources\n",
    "\n",
    "sources_yml = '''\n",
    "# models/staging/schema.yml\n",
    "\n",
    "version: 2\n",
    "\n",
    "sources:\n",
    "  - name: raw                      # Nom logique de la source\n",
    "    description: \"DonnÃ©es brutes ingÃ©rÃ©es par Kafka/Spark\"\n",
    "    database: bronze               # Base de donnÃ©es (optionnel)\n",
    "    schema: public                 # SchÃ©ma\n",
    "    \n",
    "    tables:\n",
    "      - name: orders\n",
    "        description: \"Commandes brutes\"\n",
    "        columns:\n",
    "          - name: order_id\n",
    "            description: \"Identifiant unique de la commande\"\n",
    "          - name: amount\n",
    "            description: \"Montant en euros\"\n",
    "        \n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        # FRESHNESS : VÃ©rifier que les donnÃ©es arrivent\n",
    "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "        loaded_at_field: created_at  # Colonne de timestamp\n",
    "        freshness:\n",
    "          warn_after: {count: 12, period: hour}   # Warning si > 12h\n",
    "          error_after: {count: 24, period: hour}  # Erreur si > 24h\n",
    "      \n",
    "      - name: customers\n",
    "        description: \"Clients\"\n",
    "        freshness:\n",
    "          warn_after: {count: 24, period: hour}\n",
    "          error_after: {count: 48, period: hour}\n",
    "'''\n",
    "\n",
    "print(sources_yml)\n",
    "print(\"\\nğŸ’¡ La freshness permet de dÃ©tecter les problÃ¨mes d'ingestion !\")\n",
    "print(\"   Commande : dbt source freshness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 source() vs ref()\n",
    "\n",
    "| Fonction | Utilisation | Exemple |\n",
    "|----------|-------------|--------|\n",
    "| `source()` | DonnÃ©es **externes** Ã  dbt | Tables raw, Kafka, APIs |\n",
    "| `ref()` | DonnÃ©es **crÃ©Ã©es par** dbt | Autres models |\n",
    "\n",
    "```\n",
    "Flux de donnÃ©es :\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   RAW TABLES    â”‚       â”‚   STAGING       â”‚       â”‚   SILVER/GOLD   â”‚\n",
    "â”‚   (externes)    â”‚       â”‚   (dbt)         â”‚       â”‚   (dbt)         â”‚\n",
    "â”‚                 â”‚       â”‚                 â”‚       â”‚                 â”‚\n",
    "â”‚   raw.orders    â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   stg_orders    â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   silver_orders â”‚\n",
    "â”‚                 â”‚       â”‚                 â”‚       â”‚                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚                         â”‚                         â”‚\n",
    "   source()                   ref()                     ref()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 MatÃ©rialisations\n",
    "\n",
    "La **matÃ©rialisation** dÃ©finit COMMENT dbt crÃ©e l'objet dans la base de donnÃ©es :\n",
    "\n",
    "| MatÃ©rialisation | Description | Quand l'utiliser |\n",
    "|-----------------|-------------|------------------|\n",
    "| **view** | CrÃ©e une vue SQL | Staging, peu de donnÃ©es |\n",
    "| **table** | CrÃ©e une table (full refresh) | Silver, taille moyenne |\n",
    "| **incremental** | Ajoute seulement les nouvelles lignes | Gold, gros volumes |\n",
    "| **ephemeral** | CTE (pas de table crÃ©Ã©e) | Sous-requÃªtes rÃ©utilisables |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des matÃ©rialisations\n",
    "\n",
    "materializations = '''\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VIEW : Pas de stockage, requÃªte Ã  chaque lecture\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "{{ config(materialized='view') }}\n",
    "SELECT * FROM {{ source('raw', 'events') }}\n",
    "\n",
    "-- dbt gÃ©nÃ¨re : CREATE VIEW ... AS SELECT ...\n",
    "-- âœ… Toujours Ã  jour\n",
    "-- âŒ Lent si requÃªte complexe\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# TABLE : Stockage physique, reconstruction complÃ¨te\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "{{ config(materialized='table') }}\n",
    "SELECT * FROM {{ ref('stg_events') }}\n",
    "\n",
    "-- dbt gÃ©nÃ¨re : CREATE TABLE ... AS SELECT ... (ou DROP + CREATE)\n",
    "-- âœ… Lecture rapide\n",
    "-- âŒ Rebuild complet Ã  chaque run\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# INCREMENTAL : Seulement les nouvelles donnÃ©es\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "{{ config(\n",
    "    materialized='incremental',\n",
    "    unique_key='event_id'           # Pour le MERGE/upsert\n",
    ") }}\n",
    "\n",
    "SELECT * FROM {{ ref('stg_events') }}\n",
    "{% if is_incremental() %}           -- Condition pour les runs incrÃ©mentaux\n",
    "WHERE event_time > (SELECT MAX(event_time) FROM {{ this }})\n",
    "{% endif %}\n",
    "\n",
    "-- dbt gÃ©nÃ¨re : INSERT INTO ... SELECT ... WHERE ...\n",
    "-- âœ… TrÃ¨s rapide pour gros volumes\n",
    "-- âŒ Plus complexe Ã  maintenir\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EPHEMERAL : CTE, pas de table\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "{{ config(materialized='ephemeral') }}\n",
    "SELECT DISTINCT customer_id FROM {{ ref('orders') }}\n",
    "\n",
    "-- dbt l'injecte comme CTE dans les models qui le ref()\n",
    "-- âœ… Pas de table supplÃ©mentaire\n",
    "-- âŒ RecalculÃ© Ã  chaque utilisation\n",
    "'''\n",
    "\n",
    "print(materializations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‹ï¸ Exercice 1 : CrÃ©er un projet dbt avec 3 models\n",
    "\n",
    "**Objectif** : CrÃ©er une structure dbt avec staging â†’ silver.\n",
    "\n",
    "```\n",
    "Structure Ã  crÃ©er :\n",
    "\n",
    "ecommerce_dbt/\n",
    "â”œâ”€â”€ dbt_project.yml\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ staging/\n",
    "â”‚   â”‚   â”œâ”€â”€ schema.yml          # Sources + tests\n",
    "â”‚   â”‚   â”œâ”€â”€ stg_orders.sql      # Nettoyage orders\n",
    "â”‚   â”‚   â””â”€â”€ stg_customers.sql   # Nettoyage customers\n",
    "â”‚   â””â”€â”€ silver/\n",
    "â”‚       â””â”€â”€ silver_orders.sql   # Join orders + customers\n",
    "```\n",
    "\n",
    "<details><summary>ğŸ’¡ Solution</summary>\n",
    "\n",
    "```sql\n",
    "-- models/staging/stg_orders.sql\n",
    "{{ config(materialized='view') }}\n",
    "SELECT\n",
    "    order_id,\n",
    "    customer_id,\n",
    "    CAST(amount AS DECIMAL(10,2)) AS amount,\n",
    "    order_date\n",
    "FROM {{ source('raw', 'orders') }}\n",
    "\n",
    "-- models/staging/stg_customers.sql\n",
    "{{ config(materialized='view') }}\n",
    "SELECT\n",
    "    customer_id,\n",
    "    TRIM(name) AS customer_name,\n",
    "    LOWER(email) AS email\n",
    "FROM {{ source('raw', 'customers') }}\n",
    "\n",
    "-- models/silver/silver_orders.sql\n",
    "{{ config(materialized='table') }}\n",
    "SELECT\n",
    "    o.order_id,\n",
    "    o.customer_id,\n",
    "    c.customer_name,\n",
    "    c.email,\n",
    "    o.amount,\n",
    "    o.order_date\n",
    "FROM {{ ref('stg_orders') }} o\n",
    "LEFT JOIN {{ ref('stg_customers') }} c USING (customer_id)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… 4. Tests de QualitÃ© dans dbt\n",
    "\n",
    "### 4.1 Pourquoi tester les donnÃ©es ?\n",
    "\n",
    "Les donnÃ©es, comme le code, peuvent avoir des **bugs** :\n",
    "\n",
    "| ProblÃ¨me | ConsÃ©quence | Test dbt |\n",
    "|----------|-------------|----------|\n",
    "| Doublons sur `order_id` | Revenus gonflÃ©s | `unique` |\n",
    "| `customer_id` manquant | Joins Ã©chouent | `not_null` |\n",
    "| Status invalide | Dashboard cassÃ© | `accepted_values` |\n",
    "| FK inexistante | DonnÃ©es orphelines | `relationships` |\n",
    "\n",
    "### 4.2 Tests GÃ©nÃ©riques (built-in)\n",
    "\n",
    "dbt fournit 4 tests de base, dÃ©finis dans `schema.yml` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests gÃ©nÃ©riques dans schema.yml\n",
    "\n",
    "generic_tests = '''\n",
    "# models/silver/schema.yml\n",
    "\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: silver_orders\n",
    "    description: \"Table des commandes enrichies avec infos clients\"\n",
    "    \n",
    "    columns:\n",
    "      - name: order_id\n",
    "        description: \"Identifiant unique de la commande\"\n",
    "        tests:\n",
    "          - unique              # Pas de doublons\n",
    "          - not_null            # Jamais NULL\n",
    "      \n",
    "      - name: customer_id\n",
    "        description: \"RÃ©fÃ©rence au client\"\n",
    "        tests:\n",
    "          - not_null\n",
    "          - relationships:      # ClÃ© Ã©trangÃ¨re\n",
    "              to: ref('stg_customers')\n",
    "              field: customer_id\n",
    "      \n",
    "      - name: status\n",
    "        description: \"Statut de la commande\"\n",
    "        tests:\n",
    "          - accepted_values:    # Valeurs autorisÃ©es\n",
    "              values: ['pending', 'shipped', 'delivered', 'cancelled']\n",
    "      \n",
    "      - name: amount\n",
    "        description: \"Montant en euros\"\n",
    "        tests:\n",
    "          - not_null\n",
    "'''\n",
    "\n",
    "print(generic_tests)\n",
    "print(\"\\n# ExÃ©cuter les tests :\")\n",
    "print(\"dbt test                    # Tous les tests\")\n",
    "print(\"dbt test --select silver_orders  # Tests d'un model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tests Singuliers (custom)\n",
    "\n",
    "Pour des validations complexes, tu peux Ã©crire des **tests SQL custom**. Un test rÃ©ussit s'il retourne **0 lignes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests singuliers (custom SQL)\n",
    "\n",
    "singular_tests = '''\n",
    "-- tests/assert_positive_amounts.sql\n",
    "\n",
    "-- Ce test Ã‰CHOUE si la requÃªte retourne des lignes\n",
    "-- (on cherche les cas problÃ©matiques)\n",
    "\n",
    "SELECT\n",
    "    order_id,\n",
    "    amount\n",
    "FROM {{ ref('silver_orders') }}\n",
    "WHERE amount <= 0\n",
    "\n",
    "-- Si cette requÃªte retourne des lignes = montants nÃ©gatifs ou nuls = Ã‰CHEC\n",
    "\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "-- tests/assert_orders_have_recent_dates.sql\n",
    "\n",
    "SELECT\n",
    "    order_id,\n",
    "    order_date\n",
    "FROM {{ ref('silver_orders') }}\n",
    "WHERE order_date < '2020-01-01'\n",
    "   OR order_date > CURRENT_DATE\n",
    "\n",
    "-- DÃ©tecte les dates suspectes (trop anciennes ou dans le futur)\n",
    "\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "-- tests/assert_revenue_consistency.sql\n",
    "\n",
    "-- VÃ©rifier que le total des commandes = total du dashboard\n",
    "SELECT 1\n",
    "FROM (\n",
    "    SELECT SUM(amount) AS orders_total FROM {{ ref('silver_orders') }}\n",
    ") orders\n",
    "JOIN (\n",
    "    SELECT SUM(revenue) AS dashboard_total FROM {{ ref('gold_dashboard') }}\n",
    ") dashboard\n",
    "ON 1=1\n",
    "WHERE ABS(orders_total - dashboard_total) > 0.01  -- TolÃ©rance\n",
    "'''\n",
    "\n",
    "print(singular_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Packages dbt : Tests avancÃ©s\n",
    "\n",
    "Le **dbt Hub** contient des packages avec des tests supplÃ©mentaires. Les plus utiles :\n",
    "\n",
    "| Package | Tests fournis |\n",
    "|---------|---------------|\n",
    "| **dbt-utils** | `surrogate_key`, `not_null_proportion`, `at_least_one` |\n",
    "| **dbt-expectations** | Tests style Great Expectations dans dbt |\n",
    "| **dbt-audit-helper** | `compare_relations` pour les migrations |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation et utilisation des packages dbt\n",
    "\n",
    "packages = '''\n",
    "# packages.yml (Ã  la racine du projet)\n",
    "\n",
    "packages:\n",
    "  - package: dbt-labs/dbt_utils\n",
    "    version: 1.1.1\n",
    "  \n",
    "  - package: calogica/dbt_expectations\n",
    "    version: 0.10.1\n",
    "  \n",
    "  - package: dbt-labs/audit_helper\n",
    "    version: 0.9.0\n",
    "\n",
    "# Installer les packages :\n",
    "# dbt deps\n",
    "'''\n",
    "\n",
    "usage_examples = '''\n",
    "# Utilisation dans schema.yml\n",
    "\n",
    "models:\n",
    "  - name: silver_orders\n",
    "    columns:\n",
    "      - name: order_id\n",
    "        tests:\n",
    "          - unique\n",
    "          - not_null\n",
    "      \n",
    "      - name: amount\n",
    "        tests:\n",
    "          # Test dbt-expectations : valeur entre 0 et 10000\n",
    "          - dbt_expectations.expect_column_values_to_be_between:\n",
    "              min_value: 0\n",
    "              max_value: 10000\n",
    "          \n",
    "          # Test dbt-utils : au moins 95% non-null\n",
    "          - dbt_utils.not_null_proportion:\n",
    "              at_least: 0.95\n",
    "      \n",
    "      - name: email\n",
    "        tests:\n",
    "          # Test dbt-expectations : format email\n",
    "          - dbt_expectations.expect_column_values_to_match_regex:\n",
    "              regex: \"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\"\n",
    "'''\n",
    "\n",
    "print(\"# packages.yml\")\n",
    "print(packages)\n",
    "print(\"\\n# Utilisation des tests avancÃ©s\")\n",
    "print(usage_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‹ï¸ Exercice 2 : Ajouter des tests de qualitÃ©\n",
    "\n",
    "**Objectif** : Ajouter des tests gÃ©nÃ©riques et un test singulier.\n",
    "\n",
    "```yaml\n",
    "# 1. Dans schema.yml, ajouter pour silver_orders :\n",
    "#    - order_id : unique, not_null\n",
    "#    - amount : not_null\n",
    "#    - status : accepted_values\n",
    "\n",
    "# 2. CrÃ©er un test singulier qui vÃ©rifie :\n",
    "#    - Aucune commande avec amount > 100000 (fraude potentielle)\n",
    "```\n",
    "\n",
    "<details><summary>ğŸ’¡ Solution</summary>\n",
    "\n",
    "```yaml\n",
    "# schema.yml\n",
    "models:\n",
    "  - name: silver_orders\n",
    "    columns:\n",
    "      - name: order_id\n",
    "        tests: [unique, not_null]\n",
    "      - name: amount\n",
    "        tests: [not_null]\n",
    "      - name: status\n",
    "        tests:\n",
    "          - accepted_values:\n",
    "              values: ['pending', 'shipped', 'delivered', 'cancelled']\n",
    "```\n",
    "\n",
    "```sql\n",
    "-- tests/assert_no_suspicious_amounts.sql\n",
    "SELECT order_id, amount\n",
    "FROM {{ ref('silver_orders') }}\n",
    "WHERE amount > 100000\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“– 5. Documentation et Lineage\n",
    "\n",
    "### 5.1 Documentation auto-gÃ©nÃ©rÃ©e\n",
    "\n",
    "dbt gÃ©nÃ¨re automatiquement un **site de documentation** Ã  partir des fichiers `schema.yml` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation complÃ¨te dans schema.yml\n",
    "\n",
    "documentation = '''\n",
    "# models/silver/schema.yml\n",
    "\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: silver_orders\n",
    "    description: |\n",
    "      Table des commandes enrichies avec les informations clients.\n",
    "      \n",
    "      **Source** : Kafka topic `orders` via Spark Streaming\n",
    "      **Refresh** : IncrÃ©mental toutes les heures\n",
    "      **Owner** : data-engineering@company.com\n",
    "      \n",
    "      ## RÃ¨gles mÃ©tier\n",
    "      - Les commandes annulÃ©es sont exclues\n",
    "      - Les montants sont en EUR\n",
    "    \n",
    "    columns:\n",
    "      - name: order_id\n",
    "        description: \"Identifiant unique de la commande (UUID)\"\n",
    "        tests: [unique, not_null]\n",
    "      \n",
    "      - name: customer_id\n",
    "        description: \"RÃ©fÃ©rence au client. Voir `stg_customers`.\"\n",
    "      \n",
    "      - name: amount\n",
    "        description: |\n",
    "          Montant total de la commande en EUR.\n",
    "          Inclut les taxes, exclut les frais de livraison.\n",
    "      \n",
    "      - name: order_date\n",
    "        description: \"Date de crÃ©ation de la commande (timezone UTC)\"\n",
    "'''\n",
    "\n",
    "print(documentation)\n",
    "print(\"\\n# GÃ©nÃ©rer et servir la documentation :\")\n",
    "print(\"dbt docs generate    # GÃ©nÃ¨re le site dans target/\")\n",
    "print(\"dbt docs serve       # Lance un serveur local (http://localhost:8080)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Le Lineage Graph\n",
    "\n",
    "Le **lineage** (traÃ§abilitÃ©) montre d'oÃ¹ viennent les donnÃ©es et oÃ¹ elles vont :\n",
    "\n",
    "```\n",
    "LINEAGE GRAPH GÃ‰NÃ‰RÃ‰ PAR DBT :\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   SOURCE    â”‚     â”‚   STAGING   â”‚     â”‚     SILVER      â”‚     â”‚     GOLD     â”‚\n",
    "â”‚             â”‚     â”‚             â”‚     â”‚                 â”‚     â”‚              â”‚\n",
    "â”‚ raw.orders  â”‚â”€â”€â”€â”€â–¶â”‚ stg_orders  â”‚â”€â”€â”€â”€â–¶â”‚                 â”‚     â”‚              â”‚\n",
    "â”‚             â”‚     â”‚             â”‚     â”‚  silver_orders  â”‚â”€â”€â”€â”€â–¶â”‚ gold_revenue â”‚\n",
    "â”‚ raw.customersâ”€â”€â”€â”€â–¶â”‚stg_customersâ”‚â”€â”€â”€â”€â–¶â”‚                 â”‚     â”‚              â”‚\n",
    "â”‚             â”‚     â”‚             â”‚     â”‚                 â”‚     â”‚              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Tu peux voir :\n",
    "â€¢ D'oÃ¹ vient chaque colonne (upstream)\n",
    "â€¢ Qui utilise cette table (downstream)\n",
    "â€¢ L'impact d'un changement\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¬ 6. Great Expectations â€” Tests AvancÃ©s\n",
    "\n",
    "### 6.1 Qu'est-ce que Great Expectations ?\n",
    "\n",
    "**Great Expectations (GE)** est un framework Python pour la **validation et le profiling** des donnÃ©es. Il complÃ¨te dbt :\n",
    "\n",
    "| Aspect | dbt | Great Expectations |\n",
    "|--------|-----|--------------------|\n",
    "| **Focus** | Transformation + Tests simples | Tests avancÃ©s + Profiling |\n",
    "| **Langage** | SQL/YAML | Python |\n",
    "| **Output** | Pass/Fail | Rapport HTML dÃ©taillÃ© |\n",
    "| **Profiling** | Non | Oui (auto-gÃ©nÃ©ration) |\n",
    "\n",
    "### 6.2 Concepts clÃ©s de GE\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    GREAT EXPECTATIONS                           â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   DATASOURCE          EXPECTATION SUITE        CHECKPOINT       â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚\n",
    "â”‚   â”‚ Connexionâ”‚       â”‚ Liste de rÃ¨gles  â”‚     â”‚ ExÃ©cutionâ”‚     â”‚\n",
    "â”‚   â”‚ aux data â”‚  â”€â”€â”€â–¶ â”‚ (expectations)   â”‚ â”€â”€â”€â–¶â”‚ + Rapportâ”‚     â”‚\n",
    "â”‚   â”‚          â”‚       â”‚                  â”‚     â”‚          â”‚     â”‚\n",
    "â”‚   â”‚ - Spark  â”‚       â”‚ - not_null       â”‚     â”‚ - Valide â”‚     â”‚\n",
    "â”‚   â”‚ - Pandas â”‚       â”‚ - between        â”‚     â”‚ - HTML   â”‚     â”‚\n",
    "â”‚   â”‚ - SQL    â”‚       â”‚ - regex          â”‚     â”‚ - Slack  â”‚     â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   DATA DOCS : Site web avec tous les rapports de validation    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation et setup de Great Expectations\n",
    "\n",
    "ge_setup = '''\n",
    "# Installation\n",
    "pip install great-expectations\n",
    "\n",
    "# Initialiser un projet GE\n",
    "great_expectations init\n",
    "\n",
    "# Structure crÃ©Ã©e :\n",
    "great_expectations/\n",
    "â”œâ”€â”€ great_expectations.yml      # Configuration principale\n",
    "â”œâ”€â”€ expectations/               # Suites d'expectations\n",
    "â”œâ”€â”€ checkpoints/                # DÃ©finitions des checkpoints\n",
    "â”œâ”€â”€ plugins/                    # Extensions custom\n",
    "â””â”€â”€ uncommitted/\n",
    "    â””â”€â”€ data_docs/              # Rapports HTML gÃ©nÃ©rÃ©s\n",
    "'''\n",
    "\n",
    "print(ge_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de Great Expectations avec Python\n",
    "\n",
    "ge_example = '''\n",
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 1. CrÃ©er un contexte GE\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "context = gx.get_context()\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 2. Connecter une datasource (Pandas, Spark, SQL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Exemple avec Pandas\n",
    "datasource = context.sources.add_pandas(name=\"my_pandas_ds\")\n",
    "data_asset = datasource.add_dataframe_asset(name=\"orders_df\")\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"s3://gold/orders/\")\n",
    "batch_request = data_asset.build_batch_request(dataframe=df)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 3. CrÃ©er une Expectation Suite\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "suite = context.add_expectation_suite(expectation_suite_name=\"orders_suite\")\n",
    "\n",
    "# Ajouter des expectations\n",
    "suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"order_id\"}\n",
    "    )\n",
    ")\n",
    "\n",
    "suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"amount\",\n",
    "            \"min_value\": 0,\n",
    "            \"max_value\": 50000,\n",
    "            \"mostly\": 0.99  # 99% des valeurs doivent Ãªtre dans cette plage\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "suite.add_expectation(\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_match_regex\",\n",
    "        kwargs={\n",
    "            \"column\": \"email\",\n",
    "            \"regex\": r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+$\"\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 4. CrÃ©er et exÃ©cuter un Checkpoint\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=\"orders_checkpoint\",\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": \"orders_suite\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ExÃ©cuter la validation\n",
    "result = checkpoint.run()\n",
    "\n",
    "print(f\"Validation rÃ©ussie : {result.success}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# 5. GÃ©nÃ©rer les Data Docs (rapport HTML)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "context.build_data_docs()\n",
    "context.open_data_docs()  # Ouvre dans le navigateur\n",
    "'''\n",
    "\n",
    "print(ge_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Data Profiling automatique\n",
    "\n",
    "GE peut **analyser tes donnÃ©es** et gÃ©nÃ©rer automatiquement des expectations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling automatique avec Great Expectations\n",
    "\n",
    "profiling = '''\n",
    "from great_expectations.profile.user_configurable_profiler import UserConfigurableProfiler\n",
    "\n",
    "# CrÃ©er un profiler\n",
    "profiler = UserConfigurableProfiler(\n",
    "    profile_dataset=validator,  # Validator avec les donnÃ©es\n",
    "    excluded_expectations=None,\n",
    "    ignored_columns=[],\n",
    "    not_null_only=False,\n",
    "    primary_or_compound_key=[\"order_id\"],\n",
    "    semantic_types_dict=None,\n",
    "    table_expectations_only=False,\n",
    "    value_set_threshold=\"many\"  # \"many\", \"few\", ou un nombre\n",
    ")\n",
    "\n",
    "# GÃ©nÃ©rer la suite d'expectations basÃ©e sur les donnÃ©es actuelles\n",
    "suite = profiler.build_suite()\n",
    "\n",
    "# Afficher les expectations gÃ©nÃ©rÃ©es\n",
    "print(f\"Nombre d'expectations gÃ©nÃ©rÃ©es : {len(suite.expectations)}\")\n",
    "for exp in suite.expectations[:5]:\n",
    "    print(f\"  - {exp.expectation_type}\")\n",
    "\n",
    "# Sauvegarder\n",
    "context.save_expectation_suite(suite, expectation_suite_name=\"orders_profiled\")\n",
    "'''\n",
    "\n",
    "print(profiling)\n",
    "print(\"\\nğŸ’¡ Le profiling auto-gÃ©nÃ¨re des expectations comme :\")\n",
    "print(\"â€¢ expect_column_values_to_be_in_set (pour les catÃ©gories)\")\n",
    "print(\"â€¢ expect_column_mean_to_be_between (pour les numÃ©riques)\")\n",
    "print(\"â€¢ expect_column_proportion_of_unique_values_to_be_between\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‹ï¸ Exercice 3 : Profiler une table Gold avec Great Expectations\n",
    "\n",
    "**Objectif** : CrÃ©er une suite d'expectations pour valider une table Gold.\n",
    "\n",
    "```python\n",
    "# 1. Charger la table gold_orders dans un DataFrame Pandas\n",
    "# 2. CrÃ©er une expectation suite avec :\n",
    "#    - order_id : not_null, unique\n",
    "#    - amount : between 0 and 100000, mostly 0.99\n",
    "#    - status : in_set ['pending', 'shipped', 'delivered']\n",
    "# 3. ExÃ©cuter la validation\n",
    "# 4. GÃ©nÃ©rer le rapport HTML\n",
    "```\n",
    "\n",
    "<details><summary>ğŸ’¡ Solution</summary>\n",
    "\n",
    "```python\n",
    "import great_expectations as gx\n",
    "\n",
    "context = gx.get_context()\n",
    "\n",
    "# CrÃ©er suite\n",
    "suite = context.add_expectation_suite(\"gold_orders_suite\")\n",
    "\n",
    "suite.add_expectation(ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "    kwargs={\"column\": \"order_id\"}\n",
    "))\n",
    "suite.add_expectation(ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_unique\",\n",
    "    kwargs={\"column\": \"order_id\"}\n",
    "))\n",
    "suite.add_expectation(ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_between\",\n",
    "    kwargs={\"column\": \"amount\", \"min_value\": 0, \"max_value\": 100000, \"mostly\": 0.99}\n",
    "))\n",
    "suite.add_expectation(ExpectationConfiguration(\n",
    "    expectation_type=\"expect_column_values_to_be_in_set\",\n",
    "    kwargs={\"column\": \"status\", \"value_set\": [\"pending\", \"shipped\", \"delivered\"]}\n",
    "))\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš¡ 7. dbt avec Spark/Lakehouse\n",
    "\n",
    "### 7.1 Configuration dbt-spark\n",
    "\n",
    "Pour utiliser dbt avec Spark (Databricks, EMR, local) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration dbt-spark\n",
    "\n",
    "spark_config = '''\n",
    "# ~/.dbt/profiles.yml pour Spark\n",
    "\n",
    "ecommerce_analytics:\n",
    "  target: dev\n",
    "  outputs:\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Databricks\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    databricks:\n",
    "      type: databricks\n",
    "      catalog: main              # Unity Catalog\n",
    "      schema: analytics\n",
    "      host: adb-xxx.azuredatabricks.net\n",
    "      http_path: /sql/1.0/warehouses/xxx\n",
    "      token: \"{{ env_var('DATABRICKS_TOKEN') }}\"\n",
    "      threads: 4\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Spark Thrift Server (EMR, local)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    spark_thrift:\n",
    "      type: spark\n",
    "      method: thrift\n",
    "      host: spark-thrift.company.com\n",
    "      port: 10001\n",
    "      user: dbt_user\n",
    "      schema: analytics\n",
    "      threads: 4\n",
    "    \n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    # Spark local (pour dev)\n",
    "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    spark_local:\n",
    "      type: spark\n",
    "      method: session\n",
    "      schema: default\n",
    "      threads: 1\n",
    "'''\n",
    "\n",
    "print(spark_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 MatÃ©rialisation incrÃ©mentale avec Delta Lake\n",
    "\n",
    "L'**incrÃ©mental** est crucial pour les gros volumes. Voici comment l'implÃ©menter proprement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model incrÃ©mental avec Delta Lake\n",
    "\n",
    "incremental_model = '''\n",
    "-- models/gold/gold_daily_revenue.sql\n",
    "\n",
    "{{ config(\n",
    "    materialized='incremental',\n",
    "    unique_key='date_customer_key',       -- Pour le MERGE\n",
    "    incremental_strategy='merge',         -- MERGE INTO (vs append, delete+insert)\n",
    "    file_format='delta',                  -- Format Delta Lake\n",
    "    partition_by=['order_date']           -- Partitionnement\n",
    ") }}\n",
    "\n",
    "WITH source_data AS (\n",
    "    SELECT\n",
    "        order_date,\n",
    "        customer_id,\n",
    "        SUM(amount) AS daily_revenue,\n",
    "        COUNT(*) AS order_count,\n",
    "        -- ClÃ© unique pour le MERGE\n",
    "        CONCAT(order_date, '-', customer_id) AS date_customer_key\n",
    "    FROM {{ ref('silver_orders') }}\n",
    "    \n",
    "    -- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    -- FILTRE INCRÃ‰MENTAL : Seulement les nouvelles donnÃ©es\n",
    "    -- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    {% if is_incremental() %}\n",
    "    WHERE order_date > (\n",
    "        SELECT MAX(order_date) - INTERVAL 1 DAY  -- Marge de sÃ©curitÃ©\n",
    "        FROM {{ this }}\n",
    "    )\n",
    "    {% endif %}\n",
    "    \n",
    "    GROUP BY order_date, customer_id\n",
    ")\n",
    "\n",
    "SELECT * FROM source_data\n",
    "'''\n",
    "\n",
    "print(incremental_model)\n",
    "print(\"\\nğŸ’¡ Explication :\")\n",
    "print(\"â€¢ is_incremental() : True si la table existe et ce n'est pas un --full-refresh\")\n",
    "print(\"â€¢ {{ this }} : RÃ©fÃ©rence Ã  la table actuelle\")\n",
    "print(\"â€¢ INTERVAL 1 DAY : Marge pour les donnÃ©es en retard (late data)\")\n",
    "print(\"\")\n",
    "print(\"# Commandes :\")\n",
    "print(\"dbt run --select gold_daily_revenue          # Run incrÃ©mental\")\n",
    "print(\"dbt run --select gold_daily_revenue --full-refresh  # Rebuild complet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Macros Jinja\n",
    "\n",
    "Les **macros** sont des fonctions rÃ©utilisables Ã©crites en Jinja. TrÃ¨s utiles pour Ã©viter la duplication de code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macros Jinja rÃ©utilisables\n",
    "\n",
    "macros = '''\n",
    "-- macros/deduplicate.sql\n",
    "\n",
    "{% macro deduplicate(relation, partition_by, order_by) %}\n",
    "    {#\n",
    "        DÃ©duplique une table en gardant la ligne la plus rÃ©cente.\n",
    "        \n",
    "        Args:\n",
    "            relation: La table source\n",
    "            partition_by: Colonne(s) pour identifier les doublons\n",
    "            order_by: Colonne pour dÃ©terminer quelle ligne garder\n",
    "    #}\n",
    "    \n",
    "    SELECT * FROM (\n",
    "        SELECT\n",
    "            *,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY {{ partition_by }}\n",
    "                ORDER BY {{ order_by }} DESC\n",
    "            ) AS _row_num\n",
    "        FROM {{ relation }}\n",
    "    )\n",
    "    WHERE _row_num = 1\n",
    "{% endmacro %}\n",
    "\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "-- macros/generate_surrogate_key.sql\n",
    "\n",
    "{% macro generate_surrogate_key(columns) %}\n",
    "    {#\n",
    "        GÃ©nÃ¨re une clÃ© surrogate Ã  partir de plusieurs colonnes.\n",
    "    #}\n",
    "    \n",
    "    MD5(CONCAT(\n",
    "        {% for col in columns %}\n",
    "            COALESCE(CAST({{ col }} AS STRING), '_null_')\n",
    "            {% if not loop.last %}, '-', {% endif %}\n",
    "        {% endfor %}\n",
    "    ))\n",
    "{% endmacro %}\n",
    "\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "-- macros/cents_to_euros.sql\n",
    "\n",
    "{% macro cents_to_euros(column_name) %}\n",
    "    ROUND({{ column_name }} / 100.0, 2)\n",
    "{% endmacro %}\n",
    "'''\n",
    "\n",
    "usage = '''\n",
    "-- Utilisation dans un model :\n",
    "\n",
    "-- models/silver/silver_orders.sql\n",
    "\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "WITH deduplicated AS (\n",
    "    {{ deduplicate(\n",
    "        relation=ref('stg_orders'),\n",
    "        partition_by='order_id',\n",
    "        order_by='updated_at'\n",
    "    ) }}\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    {{ generate_surrogate_key(['order_id', 'customer_id']) }} AS order_sk,\n",
    "    order_id,\n",
    "    customer_id,\n",
    "    {{ cents_to_euros('amount_cents') }} AS amount,\n",
    "    order_date\n",
    "FROM deduplicated\n",
    "'''\n",
    "\n",
    "print(\"# Macros\")\n",
    "print(macros)\n",
    "print(\"\\n# Utilisation\")\n",
    "print(usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ‹ï¸ Exercice 4 : CrÃ©er un model incrÃ©mental\n",
    "\n",
    "**Objectif** : CrÃ©er un model Gold incrÃ©mental pour les mÃ©triques journaliÃ¨res.\n",
    "\n",
    "```sql\n",
    "-- CrÃ©er gold_daily_metrics qui :\n",
    "-- 1. AgrÃ¨ge par date : total_orders, total_revenue, avg_order_value\n",
    "-- 2. Est incrÃ©mental sur order_date\n",
    "-- 3. Utilise une marge de 2 jours pour les late data\n",
    "```\n",
    "\n",
    "<details><summary>ğŸ’¡ Solution</summary>\n",
    "\n",
    "```sql\n",
    "{{ config(\n",
    "    materialized='incremental',\n",
    "    unique_key='order_date',\n",
    "    incremental_strategy='merge'\n",
    ") }}\n",
    "\n",
    "SELECT\n",
    "    order_date,\n",
    "    COUNT(*) AS total_orders,\n",
    "    SUM(amount) AS total_revenue,\n",
    "    AVG(amount) AS avg_order_value\n",
    "FROM {{ ref('silver_orders') }}\n",
    "{% if is_incremental() %}\n",
    "WHERE order_date >= (SELECT MAX(order_date) - INTERVAL 2 DAY FROM {{ this }})\n",
    "{% endif %}\n",
    "GROUP BY order_date\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ 8. CI/CD et Orchestration\n",
    "\n",
    "### 8.1 Workflow Git avec dbt\n",
    "\n",
    "```\n",
    "WORKFLOW RECOMMANDÃ‰ :\n",
    "\n",
    "1. DEVELOP (feature branch)\n",
    "   â””â”€â–¶ Modifier les models\n",
    "   â””â”€â–¶ dbt run --select +modified_model+  (test local)\n",
    "   â””â”€â–¶ dbt test --select +modified_model+\n",
    "\n",
    "2. PULL REQUEST\n",
    "   â””â”€â–¶ CI automatique : dbt build (run + test)\n",
    "   â””â”€â–¶ Review par un collÃ¨gue\n",
    "   â””â”€â–¶ Merge si tout est vert âœ…\n",
    "\n",
    "3. DEPLOY (main branch)\n",
    "   â””â”€â–¶ CD automatique : dbt run --target prod\n",
    "   â””â”€â–¶ dbt test --target prod\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GitHub Actions pour dbt CI/CD\n",
    "\n",
    "github_actions = '''\n",
    "# .github/workflows/dbt-ci.yml\n",
    "\n",
    "name: dbt CI/CD\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "  # CI : Tests sur Pull Request\n",
    "  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "  dbt-test:\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.event_name == 'pull_request'\n",
    "    \n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.11'\n",
    "      \n",
    "      - name: Install dbt\n",
    "        run: pip install dbt-core dbt-snowflake\n",
    "      \n",
    "      - name: Setup dbt profile\n",
    "        run: |\n",
    "          mkdir -p ~/.dbt\n",
    "          echo \"${{ secrets.DBT_PROFILES }}\" > ~/.dbt/profiles.yml\n",
    "      \n",
    "      - name: dbt deps\n",
    "        run: dbt deps\n",
    "      \n",
    "      - name: dbt build (run + test)\n",
    "        run: dbt build --target ci\n",
    "        env:\n",
    "          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}\n",
    "          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}\n",
    "          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}\n",
    "\n",
    "  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "  # CD : DÃ©ploiement sur main\n",
    "  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "  dbt-deploy:\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.ref == 'refs/heads/main' && github.event_name == 'push'\n",
    "    \n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "      \n",
    "      - name: Setup Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: '3.11'\n",
    "      \n",
    "      - name: Install dbt\n",
    "        run: pip install dbt-core dbt-snowflake\n",
    "      \n",
    "      - name: Setup dbt profile\n",
    "        run: |\n",
    "          mkdir -p ~/.dbt\n",
    "          echo \"${{ secrets.DBT_PROFILES }}\" > ~/.dbt/profiles.yml\n",
    "      \n",
    "      - name: dbt deps\n",
    "        run: dbt deps\n",
    "      \n",
    "      - name: dbt run (production)\n",
    "        run: dbt run --target prod\n",
    "      \n",
    "      - name: dbt test (production)\n",
    "        run: dbt test --target prod\n",
    "'''\n",
    "\n",
    "print(github_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Orchestration avec Airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAG Airflow pour dbt\n",
    "\n",
    "airflow_dag = '''\n",
    "# dags/dbt_daily_run.py\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "from airflow.utils.dates import days_ago\n",
    "\n",
    "# Configuration\n",
    "DBT_PROJECT_DIR = \"/opt/dbt/ecommerce_analytics\"\n",
    "DBT_PROFILES_DIR = \"/opt/dbt/profiles\"\n",
    "\n",
    "default_args = {\n",
    "    \"owner\": \"data-engineering\",\n",
    "    \"depends_on_past\": False,\n",
    "    \"retries\": 1,\n",
    "}\n",
    "\n",
    "with DAG(\n",
    "    dag_id=\"dbt_daily_run\",\n",
    "    default_args=default_args,\n",
    "    description=\"ExÃ©cution quotidienne de dbt\",\n",
    "    schedule_interval=\"0 6 * * *\",  # Tous les jours Ã  6h\n",
    "    start_date=days_ago(1),\n",
    "    catchup=False,\n",
    "    tags=[\"dbt\", \"analytics\"],\n",
    ") as dag:\n",
    "    \n",
    "    # VÃ©rifier la fraÃ®cheur des sources\n",
    "    dbt_source_freshness = BashOperator(\n",
    "        task_id=\"dbt_source_freshness\",\n",
    "        bash_command=f\"cd {DBT_PROJECT_DIR} && dbt source freshness --profiles-dir {DBT_PROFILES_DIR}\"\n",
    "    )\n",
    "    \n",
    "    # ExÃ©cuter les models\n",
    "    dbt_run = BashOperator(\n",
    "        task_id=\"dbt_run\",\n",
    "        bash_command=f\"cd {DBT_PROJECT_DIR} && dbt run --profiles-dir {DBT_PROFILES_DIR}\"\n",
    "    )\n",
    "    \n",
    "    # ExÃ©cuter les tests\n",
    "    dbt_test = BashOperator(\n",
    "        task_id=\"dbt_test\",\n",
    "        bash_command=f\"cd {DBT_PROJECT_DIR} && dbt test --profiles-dir {DBT_PROFILES_DIR}\"\n",
    "    )\n",
    "    \n",
    "    # GÃ©nÃ©rer la documentation\n",
    "    dbt_docs = BashOperator(\n",
    "        task_id=\"dbt_docs_generate\",\n",
    "        bash_command=f\"cd {DBT_PROJECT_DIR} && dbt docs generate --profiles-dir {DBT_PROFILES_DIR}\"\n",
    "    )\n",
    "    \n",
    "    # Ordre d'exÃ©cution\n",
    "    dbt_source_freshness >> dbt_run >> dbt_test >> dbt_docs\n",
    "'''\n",
    "\n",
    "print(airflow_dag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸš€ 9. Mini-Projet : Couche Gold IndustrialisÃ©e\n",
    "\n",
    "### ğŸ¯ Objectif\n",
    "\n",
    "CrÃ©er une couche Gold complÃ¨te avec dbt : models, tests, documentation, incrÃ©mental.\n",
    "\n",
    "```\n",
    "ARCHITECTURE DU PROJET :\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                         dbt Project                              â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  STAGING                 SILVER                    GOLD          â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚stg_ordersâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚silver_   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚gold_daily_   â”‚ â”‚\n",
    "â”‚  â”‚          â”‚           â”‚orders    â”‚           â”‚revenue       â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚(incremental) â”‚ â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚  â”‚stg_      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚\n",
    "â”‚  â”‚customers â”‚                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚gold_customer â”‚ â”‚\n",
    "â”‚                                                â”‚_summary      â”‚ â”‚\n",
    "â”‚                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  + Tests sur chaque model                                        â”‚\n",
    "â”‚  + Documentation complÃ¨te                                        â”‚\n",
    "â”‚  + Great Expectations pour validation finale                     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure complÃ¨te du mini-projet\n",
    "\n",
    "project_structure = '''\n",
    "ecommerce_dbt/\n",
    "â”œâ”€â”€ dbt_project.yml\n",
    "â”œâ”€â”€ packages.yml\n",
    "â”‚\n",
    "â”œâ”€â”€ models/\n",
    "â”‚   â”œâ”€â”€ staging/\n",
    "â”‚   â”‚   â”œâ”€â”€ _sources.yml         # Sources raw\n",
    "â”‚   â”‚   â”œâ”€â”€ stg_orders.sql\n",
    "â”‚   â”‚   â””â”€â”€ stg_customers.sql\n",
    "â”‚   â”‚\n",
    "â”‚   â”œâ”€â”€ silver/\n",
    "â”‚   â”‚   â”œâ”€â”€ _silver__models.yml  # Tests + docs\n",
    "â”‚   â”‚   â””â”€â”€ silver_orders.sql\n",
    "â”‚   â”‚\n",
    "â”‚   â””â”€â”€ gold/\n",
    "â”‚       â”œâ”€â”€ _gold__models.yml    # Tests + docs\n",
    "â”‚       â”œâ”€â”€ gold_daily_revenue.sql      # IncrÃ©mental\n",
    "â”‚       â””â”€â”€ gold_customer_summary.sql   # Table\n",
    "â”‚\n",
    "â”œâ”€â”€ macros/\n",
    "â”‚   â””â”€â”€ deduplicate.sql\n",
    "â”‚\n",
    "â”œâ”€â”€ tests/\n",
    "â”‚   â”œâ”€â”€ assert_positive_revenue.sql\n",
    "â”‚   â””â”€â”€ assert_no_future_dates.sql\n",
    "â”‚\n",
    "â””â”€â”€ great_expectations/\n",
    "    â””â”€â”€ expectations/\n",
    "        â””â”€â”€ gold_orders_suite.json\n",
    "'''\n",
    "\n",
    "print(project_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models du mini-projet\n",
    "\n",
    "models = '''\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "-- models/gold/gold_daily_revenue.sql\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "{{ config(\n",
    "    materialized='incremental',\n",
    "    unique_key='revenue_date',\n",
    "    incremental_strategy='merge'\n",
    ") }}\n",
    "\n",
    "SELECT\n",
    "    order_date AS revenue_date,\n",
    "    COUNT(DISTINCT order_id) AS total_orders,\n",
    "    COUNT(DISTINCT customer_id) AS unique_customers,\n",
    "    SUM(amount) AS total_revenue,\n",
    "    AVG(amount) AS avg_order_value,\n",
    "    CURRENT_TIMESTAMP() AS updated_at\n",
    "FROM {{ ref('silver_orders') }}\n",
    "{% if is_incremental() %}\n",
    "WHERE order_date >= (SELECT MAX(revenue_date) - INTERVAL 2 DAY FROM {{ this }})\n",
    "{% endif %}\n",
    "GROUP BY order_date\n",
    "\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "-- models/gold/gold_customer_summary.sql\n",
    "-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT\n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    email,\n",
    "    COUNT(DISTINCT order_id) AS lifetime_orders,\n",
    "    SUM(amount) AS lifetime_revenue,\n",
    "    AVG(amount) AS avg_order_value,\n",
    "    MIN(order_date) AS first_order_date,\n",
    "    MAX(order_date) AS last_order_date,\n",
    "    DATEDIFF(day, MIN(order_date), MAX(order_date)) AS customer_tenure_days\n",
    "FROM {{ ref('silver_orders') }}\n",
    "GROUP BY customer_id, customer_name, email\n",
    "'''\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª Quiz\n",
    "\n",
    "**Q1.** Qu'est-ce que la Transformation-as-Code ?\n",
    "<details><summary>R</summary>Appliquer les principes du dÃ©veloppement logiciel (versioning, tests, CI/CD) aux transformations de donnÃ©es.</details>\n",
    "\n",
    "**Q2.** Quel est le rÃ´le de `ref()` dans dbt ?\n",
    "<details><summary>R</summary>RÃ©fÃ©rencer un autre model dbt pour crÃ©er une dÃ©pendance et permettre le lineage automatique.</details>\n",
    "\n",
    "**Q3.** DiffÃ©rence entre `table` et `incremental` ?\n",
    "<details><summary>R</summary>`table` = rebuild complet Ã  chaque run. `incremental` = ajoute seulement les nouvelles lignes.</details>\n",
    "\n",
    "**Q4.** Test gÃ©nÃ©rique vs test singulier ?\n",
    "<details><summary>R</summary>GÃ©nÃ©rique = built-in (unique, not_null). Singulier = SQL custom dans tests/.</details>\n",
    "\n",
    "**Q5.** Comment dbt gÃ¨re l'ordre d'exÃ©cution ?\n",
    "<details><summary>R</summary>Via le DAG des dÃ©pendances crÃ©Ã© par les appels Ã  ref() et source().</details>\n",
    "\n",
    "**Q6.** Comment gÃ©nÃ©rer la documentation dbt ?\n",
    "<details><summary>R</summary>`dbt docs generate` puis `dbt docs serve`.</details>\n",
    "\n",
    "**Q7.** Qu'est-ce qu'un Checkpoint dans Great Expectations ?\n",
    "<details><summary>R</summary>ExÃ©cution d'une suite d'expectations sur une datasource avec gÃ©nÃ©ration de rapport.</details>\n",
    "\n",
    "**Q8.** Comment intÃ©grer dbt dans CI/CD ?\n",
    "<details><summary>R</summary>GitHub Actions : `dbt build` sur PR, `dbt run --target prod` sur merge.</details>\n",
    "\n",
    "**Q9.** Avantage de l'incrÃ©mental vs full-refresh ?\n",
    "<details><summary>R</summary>Performance : traite seulement les nouvelles donnÃ©es, pas tout recalculer.</details>\n",
    "\n",
    "**Q10.** RÃ´le de Jinja dans dbt ?\n",
    "<details><summary>R</summary>Templating SQL : variables, conditions, boucles, macros rÃ©utilisables.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Ressources\n",
    "\n",
    "- [dbt Documentation](https://docs.getdbt.com/)\n",
    "- [dbt Learn (cours gratuit)](https://courses.getdbt.com/)\n",
    "- [dbt Hub (packages)](https://hub.getdbt.com/)\n",
    "- [Great Expectations Documentation](https://docs.greatexpectations.io/)\n",
    "\n",
    "---\n",
    "\n",
    "## â¡ï¸ Prochaine Ã©tape\n",
    "\n",
    "ğŸ‘‰ **Module 26 : `26_projet_integrateur.ipynb`** â€” Projet Final\n",
    "\n",
    "SynthÃ¨se de toutes les compÃ©tences : **Kafka â†’ Spark on K8s â†’ Delta Lake â†’ dbt**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ RÃ©capitulatif\n",
    "\n",
    "| Concept | Appris |\n",
    "|---------|--------|\n",
    "| **dbt** | Models, ref(), source(), matÃ©rialisations |\n",
    "| **Tests** | GÃ©nÃ©riques, singuliers, dbt-expectations |\n",
    "| **Documentation** | schema.yml, dbt docs, lineage |\n",
    "| **Great Expectations** | Expectations, Checkpoints, Data Docs |\n",
    "| **IncrÃ©mental** | is_incremental(), unique_key, merge |\n",
    "| **CI/CD** | GitHub Actions, Airflow |\n",
    "\n",
    "ğŸ‰ **FÃ©licitations !** Tu maÃ®trises maintenant dbt et la Data Quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
