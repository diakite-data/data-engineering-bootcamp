{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ‚ò∏Ô∏è Spark on Kubernetes ‚Äî Production-Grade Deployment\n",
    "\n",
    "Bienvenue dans ce module o√π tu vas apprendre √† d√©ployer **Apache Spark sur Kubernetes**. C'est l'architecture moderne de r√©f√©rence pour ex√©cuter des workloads Spark en production.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Pr√©requis\n",
    "\n",
    "| Niveau | Module | Comp√©tence |\n",
    "|--------|--------|------------|\n",
    "| ‚úÖ Requis | Module 14 | Docker Fundamentals |\n",
    "| ‚úÖ Requis | Module 15 | Kubernetes Fundamentals |\n",
    "| ‚úÖ Requis | Module 16 | Kubernetes for Data Workloads |\n",
    "| ‚úÖ Requis | Module 19 | PySpark Advanced |\n",
    "| ‚úÖ Requis | Module 20 | Spark SQL Deep Dive |\n",
    "| üí° Recommand√© | - | Exp√©rience avec kubectl et Helm |\n",
    "\n",
    "## üéØ Objectifs du module\n",
    "\n",
    "√Ä la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Comprendre l'architecture **Spark on Kubernetes**\n",
    "- Construire une **image Docker Spark** optimis√©e\n",
    "- Configurer les **ressources Kubernetes** (RBAC, Secrets, PVC)\n",
    "- Lancer des jobs avec **spark-submit** sur K8s\n",
    "- Utiliser **Spark Operator** pour la production\n",
    "- Configurer l'**autoscaling** (Dynamic Allocation, KEDA)\n",
    "- Mettre en place le **monitoring** (Spark UI, Prometheus, Grafana)\n",
    "- **Debugger** les erreurs courantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö 1. Introduction ‚Äî Pourquoi Spark sur Kubernetes ?\n",
    "\n",
    "### 1.1 L'√©volution de l'infrastructure Spark\n",
    "\n",
    "```text\n",
    "2010s                              2020s+\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Hadoop/YARN   ‚îÇ                ‚îÇ   Kubernetes    ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ   ‚îÇ  Spark  ‚îÇ   ‚îÇ    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂   ‚îÇ   ‚îÇ  Spark  ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ   On-premise    ‚îÇ                ‚îÇ   Cloud-native  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### 1.2 Avantages de Kubernetes\n",
    "\n",
    "| Avantage | Description |\n",
    "|----------|-------------|\n",
    "| **Cloud-native** | M√™me infra que le reste de tes applications |\n",
    "| **Multi-cloud** | AWS, GCP, Azure, on-premise |\n",
    "| **Isolation** | Namespaces, RBAC, Network Policies |\n",
    "| **Autoscaling** | HPA, VPA, KEDA, Cluster Autoscaler |\n",
    "| **CI/CD** | Images Docker versionn√©es, GitOps |\n",
    "| **Cost optimization** | Spot instances, autoscaling down |\n",
    "| **Standardisation** | Plus besoin d'expertise Hadoop/YARN |\n",
    "\n",
    "### 1.3 Support officiel\n",
    "\n",
    "- **Spark 2.3** : Support exp√©rimental K8s\n",
    "- **Spark 3.0** : Support stable (GA)\n",
    "- **Spark 3.1+** : Am√©liorations (PVC, Pod templates)\n",
    "- **Spark 3.4+** : External shuffle service sur K8s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yarn_vs_k8s",
   "metadata": {},
   "source": [
    "### 1.4 üÜö Comparaison YARN vs Kubernetes\n",
    "\n",
    "| Aspect | YARN | Kubernetes |\n",
    "|--------|------|------------|\n",
    "| **√âcosyst√®me** | Hadoop-centric | Cloud-native, polyglot |\n",
    "| **Scheduling** | ResourceManager | kube-scheduler |\n",
    "| **Isolation** | Containers/cgroups | Pods, Namespaces, Network Policies |\n",
    "| **Scaling** | Manual ou scripts | HPA, VPA, KEDA, Cluster Autoscaler |\n",
    "| **Packaging** | JAR/ZIP sur HDFS | Images Docker |\n",
    "| **Secrets** | Hadoop credentials | K8s Secrets, Vault |\n",
    "| **Monitoring** | YARN UI, Ganglia | Prometheus, Grafana, native |\n",
    "| **Multi-tenancy** | Queues | Namespaces + RBAC |\n",
    "| **Data locality** | ‚úÖ Excellent | ‚ö†Ô∏è Limit√© (shuffle co√ªteux) |\n",
    "| **Courbe d'apprentissage** | Hadoop stack | K8s stack |\n",
    "| **Adoption 2024+** | Legacy | Standard moderne |\n",
    "\n",
    "```text\n",
    "üìä Quand choisir quoi ?\n",
    "\n",
    "YARN si :                           Kubernetes si :\n",
    "‚îú‚îÄ‚îÄ Cluster Hadoop existant         ‚îú‚îÄ‚îÄ Infrastructure cloud-native\n",
    "‚îú‚îÄ‚îÄ Data locality critique          ‚îú‚îÄ‚îÄ Multi-cloud ou hybrid\n",
    "‚îú‚îÄ‚îÄ √âquipe Hadoop experte           ‚îú‚îÄ‚îÄ CI/CD moderne (GitOps)\n",
    "‚îî‚îÄ‚îÄ Pas de migration pr√©vue         ‚îî‚îÄ‚îÄ Autoscaling avanc√© requis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architecture",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèóÔ∏è 2. Architecture Spark on Kubernetes\n",
    "\n",
    "### 2.1 Vue d'ensemble\n",
    "\n",
    "```text\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        KUBERNETES CLUSTER                       ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ                     Namespace: spark                      ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ   Driver Pod    ‚îÇ      ‚îÇ     Executor Pods       ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  Spark    ‚îÇ  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  ‚îÇ Exec  ‚îÇ ‚îÇ Exec  ‚îÇ   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  Driver   ‚îÇ  ‚îÇ      ‚îÇ  ‚îÇ  #1   ‚îÇ ‚îÇ  #2   ‚îÇ   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  - Spark UI     ‚îÇ      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  - Coordinateur ‚îÇ      ‚îÇ  ‚îÇ Exec  ‚îÇ ‚îÇ Exec  ‚îÇ   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ  ‚îÇ  #3   ‚îÇ ‚îÇ  #4   ‚îÇ   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ           ‚îÇ                ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ           ‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ           ‚ñº                                               ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  ConfigMaps     ‚îÇ      ‚îÇ       Secrets           ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  - spark-config ‚îÇ      ‚îÇ  - cloud credentials    ‚îÇ   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                           ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ              PersistentVolumeClaims                 ‚îÇ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îÇ  - checkpoints  - logs  - shuffle (optional)       ‚îÇ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### 2.2 R√¥les et responsabilit√©s\n",
    "\n",
    "| Composant | G√©r√© par | Responsabilit√© |\n",
    "|-----------|----------|----------------|\n",
    "| **Pods scheduling** | Kubernetes | Placement sur les nodes |\n",
    "| **Networking** | Kubernetes | Communication Driver ‚Üî Executors |\n",
    "| **Secrets** | Kubernetes | Credentials cloud/DB |\n",
    "| **Storage** | Kubernetes | PVC pour checkpoints/logs |\n",
    "| **Driver** | Spark | Coordination du job |\n",
    "| **Executors** | Spark | Ex√©cution des tasks |\n",
    "| **Shuffle** | Spark | √âchange de donn√©es entre stages |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "client_vs_cluster",
   "metadata": {},
   "source": [
    "### 2.3 Client Mode vs Cluster Mode\n",
    "\n",
    "```text\n",
    "CLIENT MODE                              CLUSTER MODE\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Local Machine‚îÇ                        ‚îÇ      Kubernetes Cluster      ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ\n",
    "‚îÇ  ‚îÇ Driver ‚îÇ  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ  ‚îÇ Driver ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ          ‚îÇ             ‚îÇ  ‚îÇ  Pod   ‚îÇ     ‚îÇ            ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ             ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ            ‚îÇ\n",
    "                          ‚îÇ             ‚îÇ        ‚ñ≤        ‚îÇ            ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ        ‚îÇ        ‚îÇ            ‚îÇ\n",
    "‚îÇ      K8s Cluster        ‚îÇ         ‚îÇ   ‚îÇ        ‚ñº        ‚ñº            ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
    "‚îÇ  ‚îÇExecutor‚îÇ ‚îÇExecutor‚îÇ‚óÄ‚îÄ‚îò         ‚îÇ   ‚îÇ  ‚îÇExecutor‚îÇ ‚îÇExecutor‚îÇ      ‚îÇ\n",
    "‚îÇ  ‚îÇ  Pod   ‚îÇ ‚îÇ  Pod   ‚îÇ            ‚îÇ   ‚îÇ  ‚îÇ  Pod   ‚îÇ ‚îÇ  Pod   ‚îÇ      ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "| Aspect | Client Mode | Cluster Mode |\n",
    "|--------|-------------|---------------|\n",
    "| **Driver** | Machine locale | Pod Kubernetes |\n",
    "| **Usage** | D√©veloppement, debug | Production |\n",
    "| **Spark UI** | localhost:4040 | Via Service/Ingress |\n",
    "| **R√©seau** | Doit atteindre le cluster | Interne au cluster |\n",
    "| **R√©silience** | ‚ùå Si local crash ‚Üí job perdu | ‚úÖ Pod peut √™tre reschedul√© |\n",
    "| **CI/CD** | ‚ùå Difficile | ‚úÖ Natif |\n",
    "\n",
    "> üí° **R√®gle** : Client mode pour le dev/debug, **Cluster mode pour la production**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_1",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 1 : Identifier les composants\n",
    "\n",
    "R√©ponds aux questions suivantes :\n",
    "\n",
    "1. Dans quel mode le Driver tourne-t-il en tant que Pod K8s ?\n",
    "2. Qui g√®re le scheduling des Executor Pods ?\n",
    "3. O√π sont stock√©s les credentials cloud ?\n",
    "\n",
    "<details><summary>üí° Voir les r√©ponses</summary>\n",
    "\n",
    "1. **Cluster mode** ‚Äî Le Driver est un Pod K8s\n",
    "2. **Kubernetes** (kube-scheduler) ‚Äî Spark demande des Pods, K8s les place\n",
    "3. **Kubernetes Secrets** ‚Äî Mont√©s dans les Pods Driver/Executor\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "docker_image",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üê≥ 3. Construire une Image Docker Spark\n",
    "\n",
    "### 3.1 Image de base\n",
    "\n",
    "Plusieurs options :\n",
    "\n",
    "| Image | Avantage | Inconv√©nient |\n",
    "|-------|----------|---------------|\n",
    "| `apache/spark` | Officielle | Basique |\n",
    "| `bitnami/spark` | Bien maintenue, non-root | Taille moyenne |\n",
    "| `gcr.io/spark-operator/spark` | Pour Spark Operator | Sp√©cifique |\n",
    "| Custom | Contr√¥le total | Plus de travail |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dockerfile_basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-docker/Dockerfile.basic\n",
    "# Image Spark de base\n",
    "FROM bitnami/spark:3.5\n",
    "\n",
    "# Passer en root pour installer des packages\n",
    "USER root\n",
    "\n",
    "# Installer des d√©pendances Python\n",
    "RUN pip install --no-cache-dir \\\n",
    "    boto3 \\\n",
    "    pyarrow \\\n",
    "    pandas\n",
    "\n",
    "# Copier l'application\n",
    "COPY app/ /app/\n",
    "\n",
    "# Revenir √† l'utilisateur non-root (s√©curit√©)\n",
    "USER 1001\n",
    "\n",
    "# D√©finir le working directory\n",
    "WORKDIR /app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dockerfile_advanced",
   "metadata": {},
   "source": [
    "### 3.2 Image production-grade avec JARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dockerfile_prod",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-docker/Dockerfile.production\n",
    "# ============================================\n",
    "# Spark Production Image\n",
    "# ============================================\n",
    "FROM bitnami/spark:3.5 AS base\n",
    "\n",
    "USER root\n",
    "\n",
    "# ---- D√©pendances syst√®me ----\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    curl \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# ---- D√©pendances Python ----\n",
    "COPY requirements.txt /tmp/\n",
    "RUN pip install --no-cache-dir -r /tmp/requirements.txt\n",
    "\n",
    "# ---- JARs pour connecteurs cloud ----\n",
    "# AWS S3\n",
    "RUN curl -sL https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar \\\n",
    "    -o /opt/bitnami/spark/jars/hadoop-aws-3.3.4.jar\n",
    "RUN curl -sL https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar \\\n",
    "    -o /opt/bitnami/spark/jars/aws-java-sdk-bundle-1.12.262.jar\n",
    "\n",
    "# ---- Application ----\n",
    "COPY app/ /app/\n",
    "\n",
    "# ---- S√©curit√© : non-root ----\n",
    "RUN chown -R 1001:1001 /app\n",
    "USER 1001\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# ---- Healthcheck ----\n",
    "HEALTHCHECK --interval=30s --timeout=10s --retries=3 \\\n",
    "    CMD curl -f http://localhost:4040/api/v1/applications || exit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requirements_txt",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-docker/requirements.txt\n",
    "# Python dependencies for Spark jobs\n",
    "boto3>=1.28.0\n",
    "pyarrow>=14.0.0\n",
    "pandas>=2.0.0\n",
    "requests>=2.31.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "docker_best_practices",
   "metadata": {},
   "source": [
    "### 3.3 Best practices Docker pour Spark\n",
    "\n",
    "| Pratique | Pourquoi | Comment |\n",
    "|----------|----------|----------|\n",
    "| **Non-root** | S√©curit√© | `USER 1001` |\n",
    "| **Multi-stage builds** | Image plus l√©g√®re | `FROM ... AS builder` |\n",
    "| **Layer caching** | Builds plus rapides | D√©pendances avant code |\n",
    "| **No cache pip** | Image plus l√©g√®re | `--no-cache-dir` |\n",
    "| **Healthcheck** | K8s liveness probe | `HEALTHCHECK` |\n",
    "| **Versioning** | Reproductibilit√© | Tags explicites (pas `latest`) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "docker_build_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commandes pour construire et pousser l'image\n",
    "docker_commands = \"\"\"\n",
    "# Construire l'image\n",
    "docker build -t my-registry/spark-app:1.0.0 -f Dockerfile.production .\n",
    "\n",
    "# Tester localement\n",
    "docker run --rm my-registry/spark-app:1.0.0 spark-submit --version\n",
    "\n",
    "# Pousser vers un registry\n",
    "docker push my-registry/spark-app:1.0.0\n",
    "\n",
    "# Pour Minikube (utiliser le Docker daemon de Minikube)\n",
    "eval $(minikube docker-env)\n",
    "docker build -t spark-app:1.0.0 .\n",
    "\"\"\"\n",
    "print(docker_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_2",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 2 : Construire une image Spark\n",
    "\n",
    "**Objectif** : Cr√©er un Dockerfile Spark avec :\n",
    "\n",
    "- Base `bitnami/spark:3.5`\n",
    "- D√©pendance Python : `numpy`\n",
    "- Un script `hello.py` qui affiche \"Hello Spark on K8s!\"\n",
    "\n",
    "<details><summary>üí° Solution</summary>\n",
    "\n",
    "```dockerfile\n",
    "FROM bitnami/spark:3.5\n",
    "\n",
    "USER root\n",
    "RUN pip install --no-cache-dir numpy\n",
    "\n",
    "COPY hello.py /app/hello.py\n",
    "\n",
    "USER 1001\n",
    "WORKDIR /app\n",
    "```\n",
    "\n",
    "```python\n",
    "# hello.py\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Hello\").getOrCreate()\n",
    "print(\"Hello Spark on K8s!\")\n",
    "spark.stop()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k8s_config",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è 4. Configuration Kubernetes pour Spark\n",
    "\n",
    "### 4.1 Namespace d√©di√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "namespace_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/namespace.yaml\n",
    "apiVersion: v1\n",
    "kind: Namespace\n",
    "metadata:\n",
    "  name: spark\n",
    "  labels:\n",
    "    app: spark\n",
    "    environment: development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rbac_intro",
   "metadata": {},
   "source": [
    "### 4.2 ServiceAccount & RBAC\n",
    "\n",
    "Spark a besoin de permissions pour :\n",
    "\n",
    "- Cr√©er des Pods (executors)\n",
    "- Lister/supprimer des Pods\n",
    "- Acc√©der aux ConfigMaps et Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rbac_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/rbac.yaml\n",
    "# ServiceAccount pour Spark\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: spark-sa\n",
    "  namespace: spark\n",
    "---\n",
    "# Role avec permissions minimales\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: Role\n",
    "metadata:\n",
    "  name: spark-role\n",
    "  namespace: spark\n",
    "rules:\n",
    "  # G√©rer les pods (executors)\n",
    "  - apiGroups: [\"\"]\n",
    "    resources: [\"pods\"]\n",
    "    verbs: [\"create\", \"get\", \"list\", \"watch\", \"delete\"]\n",
    "  # Logs des pods\n",
    "  - apiGroups: [\"\"]\n",
    "    resources: [\"pods/log\"]\n",
    "    verbs: [\"get\", \"list\"]\n",
    "  # ConfigMaps pour Spark config\n",
    "  - apiGroups: [\"\"]\n",
    "    resources: [\"configmaps\"]\n",
    "    verbs: [\"create\", \"get\", \"list\", \"watch\", \"delete\"]\n",
    "  # Services pour Spark UI\n",
    "  - apiGroups: [\"\"]\n",
    "    resources: [\"services\"]\n",
    "    verbs: [\"create\", \"get\", \"delete\"]\n",
    "  # PersistentVolumeClaims\n",
    "  - apiGroups: [\"\"]\n",
    "    resources: [\"persistentvolumeclaims\"]\n",
    "    verbs: [\"create\", \"get\", \"list\", \"delete\"]\n",
    "---\n",
    "# Binding Role ‚Üí ServiceAccount\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: RoleBinding\n",
    "metadata:\n",
    "  name: spark-role-binding\n",
    "  namespace: spark\n",
    "subjects:\n",
    "  - kind: ServiceAccount\n",
    "    name: spark-sa\n",
    "    namespace: spark\n",
    "roleRef:\n",
    "  kind: Role\n",
    "  name: spark-role\n",
    "  apiGroup: rbac.authorization.k8s.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secrets",
   "metadata": {},
   "source": [
    "### 4.3 Secrets (credentials cloud)\n",
    "\n",
    "> ‚ö†Ô∏è **Note** : En production, utilise un gestionnaire de secrets (Vault, AWS Secrets Manager, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secrets_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/secrets.yaml\n",
    "# Secret pour MinIO (ou S3)\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: minio-credentials\n",
    "  namespace: spark\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: \"minioadmin\"\n",
    "  AWS_SECRET_ACCESS_KEY: \"minioadmin\"\n",
    "  S3_ENDPOINT: \"http://minio.minio.svc.cluster.local:9000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_secret_cli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative : cr√©er le secret via CLI\n",
    "secret_command = \"\"\"\n",
    "kubectl create secret generic minio-credentials \\\n",
    "  --namespace=spark \\\n",
    "  --from-literal=AWS_ACCESS_KEY_ID=minioadmin \\\n",
    "  --from-literal=AWS_SECRET_ACCESS_KEY=minioadmin \\\n",
    "  --from-literal=S3_ENDPOINT=http://minio.minio.svc.cluster.local:9000\n",
    "\"\"\"\n",
    "print(secret_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pvc",
   "metadata": {},
   "source": [
    "### 4.4 PersistentVolumeClaims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pvc_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/pvc.yaml\n",
    "# PVC pour les logs Spark\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: spark-logs-pvc\n",
    "  namespace: spark\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteMany  # Plusieurs pods peuvent √©crire\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi\n",
    "  storageClassName: standard  # Adapter selon ton cluster\n",
    "---\n",
    "# PVC pour les checkpoints (streaming)\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: spark-checkpoints-pvc\n",
    "  namespace: spark\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteMany\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 20Gi\n",
    "  storageClassName: standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resource_quotas",
   "metadata": {},
   "source": [
    "### 4.5 ResourceQuotas & LimitRanges (optionnel mais recommand√©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quotas_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/quotas.yaml\n",
    "# Limiter les ressources du namespace Spark\n",
    "apiVersion: v1\n",
    "kind: ResourceQuota\n",
    "metadata:\n",
    "  name: spark-quota\n",
    "  namespace: spark\n",
    "spec:\n",
    "  hard:\n",
    "    requests.cpu: \"20\"        # Max 20 CPU demand√©s\n",
    "    requests.memory: \"40Gi\"   # Max 40 Gi m√©moire demand√©e\n",
    "    limits.cpu: \"40\"          # Max 40 CPU limites\n",
    "    limits.memory: \"80Gi\"     # Max 80 Gi m√©moire limites\n",
    "    pods: \"50\"                # Max 50 pods\n",
    "---\n",
    "# Defaults pour les pods sans spec\n",
    "apiVersion: v1\n",
    "kind: LimitRange\n",
    "metadata:\n",
    "  name: spark-limits\n",
    "  namespace: spark\n",
    "spec:\n",
    "  limits:\n",
    "    - type: Container\n",
    "      default:\n",
    "        cpu: \"1\"\n",
    "        memory: \"2Gi\"\n",
    "      defaultRequest:\n",
    "        cpu: \"500m\"\n",
    "        memory: \"1Gi\"\n",
    "      max:\n",
    "        cpu: \"8\"\n",
    "        memory: \"16Gi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_3",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 3 : Cr√©er les manifests RBAC\n",
    "\n",
    "**Question** : Pourquoi le ServiceAccount Spark a-t-il besoin de la permission `pods/log` ?\n",
    "\n",
    "<details><summary>üí° R√©ponse</summary>\n",
    "\n",
    "Le Driver Spark a besoin de lire les logs des Executor Pods pour :\n",
    "\n",
    "- Afficher les erreurs dans le Spark UI\n",
    "- Permettre le debugging via `kubectl logs`\n",
    "- Collecter les m√©triques d'ex√©cution\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_submit",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ 5. spark-submit sur Kubernetes\n",
    "\n",
    "### 5.1 Syntaxe de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_submit_basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_submit_basic = \"\"\"\n",
    "# Spark-submit basique sur K8s (cluster mode)\n",
    "spark-submit \\\n",
    "  --master k8s://https://<kubernetes-api-server>:6443 \\\n",
    "  --deploy-mode cluster \\\n",
    "  --name spark-pi \\\n",
    "  --conf spark.kubernetes.container.image=spark-app:1.0.0 \\\n",
    "  --conf spark.kubernetes.namespace=spark \\\n",
    "  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark-sa \\\n",
    "  local:///app/pi.py\n",
    "\"\"\"\n",
    "print(spark_submit_basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_submit_full",
   "metadata": {},
   "source": [
    "### 5.2 Commande compl√®te production-grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_submit_prod",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_submit_full = \"\"\"\n",
    "# Spark-submit complet pour production\n",
    "spark-submit \\\n",
    "  # === Master & Mode ===\n",
    "  --master k8s://https://$(kubectl config view -o jsonpath='{.clusters[0].cluster.server}') \\\n",
    "  --deploy-mode cluster \\\n",
    "  --name etl-job-$(date +%Y%m%d-%H%M%S) \\\n",
    "  \\\n",
    "  # === Image & Namespace ===\n",
    "  --conf spark.kubernetes.container.image=my-registry/spark-app:1.0.0 \\\n",
    "  --conf spark.kubernetes.namespace=spark \\\n",
    "  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark-sa \\\n",
    "  \\\n",
    "  # === Driver Resources ===\n",
    "  --conf spark.driver.cores=2 \\\n",
    "  --conf spark.driver.memory=4g \\\n",
    "  --conf spark.kubernetes.driver.request.cores=1 \\\n",
    "  --conf spark.kubernetes.driver.limit.cores=2 \\\n",
    "  \\\n",
    "  # === Executor Resources ===\n",
    "  --conf spark.executor.instances=4 \\\n",
    "  --conf spark.executor.cores=2 \\\n",
    "  --conf spark.executor.memory=4g \\\n",
    "  --conf spark.kubernetes.executor.request.cores=1 \\\n",
    "  --conf spark.kubernetes.executor.limit.cores=2 \\\n",
    "  \\\n",
    "  # === Secrets (environnement) ===\n",
    "  --conf spark.kubernetes.driver.secretKeyRef.AWS_ACCESS_KEY_ID=minio-credentials:AWS_ACCESS_KEY_ID \\\n",
    "  --conf spark.kubernetes.driver.secretKeyRef.AWS_SECRET_ACCESS_KEY=minio-credentials:AWS_SECRET_ACCESS_KEY \\\n",
    "  --conf spark.kubernetes.executor.secretKeyRef.AWS_ACCESS_KEY_ID=minio-credentials:AWS_ACCESS_KEY_ID \\\n",
    "  --conf spark.kubernetes.executor.secretKeyRef.AWS_SECRET_ACCESS_KEY=minio-credentials:AWS_SECRET_ACCESS_KEY \\\n",
    "  \\\n",
    "  # === S3/MinIO Config ===\n",
    "  --conf spark.hadoop.fs.s3a.endpoint=http://minio.minio.svc.cluster.local:9000 \\\n",
    "  --conf spark.hadoop.fs.s3a.path.style.access=true \\\n",
    "  --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \\\n",
    "  \\\n",
    "  # === Application ===\n",
    "  local:///app/etl_job.py \\\n",
    "  --input s3a://bronze/data \\\n",
    "  --output s3a://silver/data\n",
    "\"\"\"\n",
    "print(spark_submit_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_submit_configs",
   "metadata": {},
   "source": [
    "### 5.3 Configurations essentielles\n",
    "\n",
    "| Configuration | Description | Exemple |\n",
    "|---------------|-------------|---------|\n",
    "| `spark.kubernetes.container.image` | Image Docker Spark | `registry/spark:1.0` |\n",
    "| `spark.kubernetes.namespace` | Namespace K8s | `spark` |\n",
    "| `spark.kubernetes.authenticate.driver.serviceAccountName` | ServiceAccount | `spark-sa` |\n",
    "| `spark.executor.instances` | Nombre d'executors | `4` |\n",
    "| `spark.executor.cores` | Cores par executor | `2` |\n",
    "| `spark.executor.memory` | M√©moire par executor | `4g` |\n",
    "| `spark.kubernetes.driver.secretKeyRef.*` | Secrets ‚Üí env vars | Voir exemple |\n",
    "| `spark.kubernetes.executor.deleteOnTermination` | Cleanup | `true` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_ui_access",
   "metadata": {},
   "source": [
    "### 5.4 Acc√©der au Spark UI\n",
    "\n",
    "En cluster mode, le Spark UI est dans le Pod Driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_ui_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_ui_access = \"\"\"\n",
    "# 1. Trouver le pod Driver\n",
    "kubectl get pods -n spark -l spark-role=driver\n",
    "\n",
    "# 2. Port-forward vers le Spark UI\n",
    "kubectl port-forward -n spark <driver-pod-name> 4040:4040\n",
    "\n",
    "# 3. Ouvrir dans le navigateur\n",
    "# http://localhost:4040\n",
    "\n",
    "# Alternative : cr√©er un Service\n",
    "kubectl expose pod <driver-pod-name> -n spark \\\n",
    "  --port=4040 --target-port=4040 \\\n",
    "  --name=spark-ui --type=NodePort\n",
    "\"\"\"\n",
    "print(spark_ui_access)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_4",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 4 : Lancer un job Spark sur Minikube\n",
    "\n",
    "**√âtapes** :\n",
    "1. D√©marrer Minikube : `minikube start --cpus=4 --memory=8g`\n",
    "2. Cr√©er le namespace et RBAC\n",
    "3. Lancer le job `SparkPi` int√©gr√©\n",
    "\n",
    "<details><summary>üí° Solution</summary>\n",
    "\n",
    "```bash\n",
    "# 1. Setup\n",
    "minikube start --cpus=4 --memory=8g\n",
    "kubectl create namespace spark\n",
    "kubectl apply -f rbac.yaml\n",
    "\n",
    "# 2. Obtenir l'URL de l'API K8s\n",
    "K8S_API=$(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')\n",
    "\n",
    "# 3. Lancer SparkPi\n",
    "spark-submit \\\n",
    "  --master k8s://$K8S_API \\\n",
    "  --deploy-mode cluster \\\n",
    "  --name spark-pi \\\n",
    "  --conf spark.kubernetes.container.image=apache/spark:3.5.0 \\\n",
    "  --conf spark.kubernetes.namespace=spark \\\n",
    "  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark-sa \\\n",
    "  --conf spark.executor.instances=2 \\\n",
    "  local:///opt/spark/examples/src/main/python/pi.py 100\n",
    "\n",
    "# 4. V√©rifier\n",
    "kubectl get pods -n spark\n",
    "kubectl logs -n spark <driver-pod> | tail -20\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_operator",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéõÔ∏è 6. Spark Operator ‚Äî Production-Grade\n",
    "\n",
    "### 6.1 Pourquoi utiliser Spark Operator ?\n",
    "\n",
    "| spark-submit | Spark Operator |\n",
    "|--------------|----------------|\n",
    "| Commande CLI | Manifeste YAML d√©claratif |\n",
    "| Pas de retry automatique | Retry policy configurable |\n",
    "| Pas de scheduling | CronJob-like scheduling |\n",
    "| Difficile √† int√©grer CI/CD | GitOps natif |\n",
    "| Logs dispers√©s | Logs centralis√©s |\n",
    "\n",
    "### 6.2 Installation avec Helm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_operator_install",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_install = \"\"\"\n",
    "# Ajouter le repo Helm\n",
    "helm repo add spark-operator https://kubeflow.github.io/spark-operator\n",
    "helm repo update\n",
    "\n",
    "# Installer l'op√©rateur\n",
    "helm install spark-operator spark-operator/spark-operator \\\n",
    "  --namespace spark-operator \\\n",
    "  --create-namespace \\\n",
    "  --set webhook.enable=true \\\n",
    "  --set sparkJobNamespace=spark\n",
    "\n",
    "# V√©rifier\n",
    "kubectl get pods -n spark-operator\n",
    "\"\"\"\n",
    "print(operator_install)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_application_crd",
   "metadata": {},
   "source": [
    "### 6.3 SparkApplication CRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_application_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/spark-application.yaml\n",
    "apiVersion: sparkoperator.k8s.io/v1beta2\n",
    "kind: SparkApplication\n",
    "metadata:\n",
    "  name: etl-job\n",
    "  namespace: spark\n",
    "spec:\n",
    "  type: Python\n",
    "  pythonVersion: \"3\"\n",
    "  mode: cluster\n",
    "  image: my-registry/spark-app:1.0.0\n",
    "  imagePullPolicy: Always\n",
    "  mainApplicationFile: local:///app/etl_job.py\n",
    "  arguments:\n",
    "    - \"--input\"\n",
    "    - \"s3a://bronze/data\"\n",
    "    - \"--output\"\n",
    "    - \"s3a://silver/data\"\n",
    "  sparkVersion: \"3.5.0\"\n",
    "  \n",
    "  # Configuration Spark\n",
    "  sparkConf:\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": \"http://minio.minio.svc.cluster.local:9000\"\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": \"true\"\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\"\n",
    "  \n",
    "  # Restart policy\n",
    "  restartPolicy:\n",
    "    type: OnFailure\n",
    "    onFailureRetries: 3\n",
    "    onFailureRetryInterval: 30\n",
    "    onSubmissionFailureRetries: 3\n",
    "  \n",
    "  # Driver config\n",
    "  driver:\n",
    "    cores: 1\n",
    "    coreLimit: \"1200m\"\n",
    "    memory: \"2g\"\n",
    "    serviceAccount: spark-sa\n",
    "    labels:\n",
    "      app: spark-etl\n",
    "      role: driver\n",
    "    envSecretKeyRefs:\n",
    "      AWS_ACCESS_KEY_ID:\n",
    "        name: minio-credentials\n",
    "        key: AWS_ACCESS_KEY_ID\n",
    "      AWS_SECRET_ACCESS_KEY:\n",
    "        name: minio-credentials\n",
    "        key: AWS_SECRET_ACCESS_KEY\n",
    "  \n",
    "  # Executor config\n",
    "  executor:\n",
    "    cores: 2\n",
    "    coreLimit: \"2400m\"\n",
    "    instances: 4\n",
    "    memory: \"4g\"\n",
    "    labels:\n",
    "      app: spark-etl\n",
    "      role: executor\n",
    "    envSecretKeyRefs:\n",
    "      AWS_ACCESS_KEY_ID:\n",
    "        name: minio-credentials\n",
    "        key: AWS_ACCESS_KEY_ID\n",
    "      AWS_SECRET_ACCESS_KEY:\n",
    "        name: minio-credentials\n",
    "        key: AWS_SECRET_ACCESS_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled_spark",
   "metadata": {},
   "source": [
    "### 6.4 ScheduledSparkApplication (Cron jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled_spark_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/scheduled-spark.yaml\n",
    "apiVersion: sparkoperator.k8s.io/v1beta2\n",
    "kind: ScheduledSparkApplication\n",
    "metadata:\n",
    "  name: daily-etl\n",
    "  namespace: spark\n",
    "spec:\n",
    "  schedule: \"0 2 * * *\"  # Tous les jours √† 2h du matin\n",
    "  concurrencyPolicy: Forbid  # Ne pas lancer si le pr√©c√©dent tourne encore\n",
    "  successfulRunHistoryLimit: 5\n",
    "  failedRunHistoryLimit: 3\n",
    "  \n",
    "  template:\n",
    "    type: Python\n",
    "    pythonVersion: \"3\"\n",
    "    mode: cluster\n",
    "    image: my-registry/spark-app:1.0.0\n",
    "    mainApplicationFile: local:///app/daily_etl.py\n",
    "    sparkVersion: \"3.5.0\"\n",
    "    \n",
    "    restartPolicy:\n",
    "      type: OnFailure\n",
    "      onFailureRetries: 2\n",
    "    \n",
    "    driver:\n",
    "      cores: 1\n",
    "      memory: \"2g\"\n",
    "      serviceAccount: spark-sa\n",
    "    \n",
    "    executor:\n",
    "      cores: 2\n",
    "      instances: 3\n",
    "      memory: \"4g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_operator_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_commands = \"\"\"\n",
    "# Appliquer une SparkApplication\n",
    "kubectl apply -f spark-application.yaml\n",
    "\n",
    "# Voir le statut\n",
    "kubectl get sparkapplication -n spark\n",
    "kubectl describe sparkapplication etl-job -n spark\n",
    "\n",
    "# Voir les logs du driver\n",
    "kubectl logs -n spark -l spark-role=driver -f\n",
    "\n",
    "# Supprimer\n",
    "kubectl delete sparkapplication etl-job -n spark\n",
    "\"\"\"\n",
    "print(operator_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_5",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 5 : D√©ployer avec SparkOperator\n",
    "\n",
    "**Objectif** : Cr√©er une SparkApplication qui calcule Pi avec 1000 it√©rations.\n",
    "\n",
    "<details><summary>üí° Solution</summary>\n",
    "\n",
    "```yaml\n",
    "apiVersion: sparkoperator.k8s.io/v1beta2\n",
    "kind: SparkApplication\n",
    "metadata:\n",
    "  name: spark-pi\n",
    "  namespace: spark\n",
    "spec:\n",
    "  type: Python\n",
    "  pythonVersion: \"3\"\n",
    "  mode: cluster\n",
    "  image: apache/spark:3.5.0\n",
    "  mainApplicationFile: local:///opt/spark/examples/src/main/python/pi.py\n",
    "  arguments: [\"1000\"]\n",
    "  sparkVersion: \"3.5.0\"\n",
    "  \n",
    "  restartPolicy:\n",
    "    type: Never\n",
    "  \n",
    "  driver:\n",
    "    cores: 1\n",
    "    memory: \"1g\"\n",
    "    serviceAccount: spark-sa\n",
    "  \n",
    "  executor:\n",
    "    cores: 1\n",
    "    instances: 2\n",
    "    memory: \"1g\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autoscaling",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà 7. Autoscaling & Resource Management\n",
    "\n",
    "### 7.1 Dynamic Allocation (Spark natif)\n",
    "\n",
    "Spark peut ajuster dynamiquement le nombre d'executors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic_allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_allocation_config = \"\"\"\n",
    "# Dans sparkConf ou spark-submit\n",
    "spark.dynamicAllocation.enabled=true\n",
    "spark.dynamicAllocation.minExecutors=1\n",
    "spark.dynamicAllocation.maxExecutors=10\n",
    "spark.dynamicAllocation.initialExecutors=2\n",
    "spark.dynamicAllocation.executorIdleTimeout=60s\n",
    "spark.dynamicAllocation.schedulerBacklogTimeout=1s\n",
    "\n",
    "# Shuffle tracking (requis pour K8s)\n",
    "spark.dynamicAllocation.shuffleTracking.enabled=true\n",
    "spark.dynamicAllocation.shuffleTracking.timeout=600s\n",
    "\"\"\"\n",
    "print(dynamic_allocation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "autoscaling_options",
   "metadata": {},
   "source": [
    "### 7.2 Options d'autoscaling K8s\n",
    "\n",
    "| Type | Description | Use case |\n",
    "|------|-------------|----------|\n",
    "| **Dynamic Allocation** | Spark g√®re les executors | ‚úÖ Recommand√© pour batch |\n",
    "| **HPA** | Scale sur CPU/memory | ‚ö†Ô∏è Pas id√©al pour Spark |\n",
    "| **VPA** | Ajuste les ressources | üí° Pour dimensionnement initial |\n",
    "| **KEDA** | Scale sur √©v√©nements externes | ‚úÖ Id√©al pour streaming (Kafka lag) |\n",
    "| **Cluster Autoscaler** | Ajoute/retire des nodes | ‚úÖ Combin√© avec Dynamic Allocation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "keda_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/keda-scaledobject.yaml\n",
    "# KEDA ScaledObject pour Spark Streaming bas√© sur Kafka lag\n",
    "apiVersion: keda.sh/v1alpha1\n",
    "kind: ScaledObject\n",
    "metadata:\n",
    "  name: spark-streaming-scaler\n",
    "  namespace: spark\n",
    "spec:\n",
    "  scaleTargetRef:\n",
    "    name: spark-streaming  # Deployment √† scaler\n",
    "  minReplicaCount: 1\n",
    "  maxReplicaCount: 10\n",
    "  triggers:\n",
    "    - type: kafka\n",
    "      metadata:\n",
    "        bootstrapServers: kafka.kafka.svc.cluster.local:9092\n",
    "        consumerGroup: spark-streaming-group\n",
    "        topic: events\n",
    "        lagThreshold: \"100\"  # Scale si lag > 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "node_affinity",
   "metadata": {},
   "source": [
    "### 7.3 Node Affinity & Tolerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affinity_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/spark-with-affinity.yaml\n",
    "apiVersion: sparkoperator.k8s.io/v1beta2\n",
    "kind: SparkApplication\n",
    "metadata:\n",
    "  name: gpu-job\n",
    "  namespace: spark\n",
    "spec:\n",
    "  type: Python\n",
    "  mode: cluster\n",
    "  image: my-registry/spark-gpu:1.0.0\n",
    "  mainApplicationFile: local:///app/gpu_job.py\n",
    "  sparkVersion: \"3.5.0\"\n",
    "  \n",
    "  driver:\n",
    "    cores: 1\n",
    "    memory: \"2g\"\n",
    "    serviceAccount: spark-sa\n",
    "  \n",
    "  executor:\n",
    "    cores: 4\n",
    "    instances: 2\n",
    "    memory: \"8g\"\n",
    "    # Placer les executors sur des nodes avec GPU\n",
    "    affinity:\n",
    "      nodeAffinity:\n",
    "        requiredDuringSchedulingIgnoredDuringExecution:\n",
    "          nodeSelectorTerms:\n",
    "            - matchExpressions:\n",
    "                - key: node-type\n",
    "                  operator: In\n",
    "                  values:\n",
    "                    - gpu\n",
    "    # Tol√©rer les taints GPU\n",
    "    tolerations:\n",
    "      - key: \"nvidia.com/gpu\"\n",
    "        operator: \"Exists\"\n",
    "        effect: \"NoSchedule\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_6",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 6 : Configurer Dynamic Allocation\n",
    "\n",
    "**Objectif** : Modifier la SparkApplication pour avoir :\n",
    "\n",
    "- Min 2 executors\n",
    "- Max 8 executors\n",
    "- Initial 3 executors\n",
    "\n",
    "<details><summary>üí° Solution</summary>\n",
    "\n",
    "```yaml\n",
    "sparkConf:\n",
    "  \"spark.dynamicAllocation.enabled\": \"true\"\n",
    "  \"spark.dynamicAllocation.minExecutors\": \"2\"\n",
    "  \"spark.dynamicAllocation.maxExecutors\": \"8\"\n",
    "  \"spark.dynamicAllocation.initialExecutors\": \"3\"\n",
    "  \"spark.dynamicAllocation.shuffleTracking.enabled\": \"true\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitoring",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä 8. Monitoring & Observability\n",
    "\n",
    "### 8.1 Spark UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spark_ui_service",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/spark-ui-ingress.yaml\n",
    "# Service pour Spark UI\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: spark-ui\n",
    "  namespace: spark\n",
    "spec:\n",
    "  selector:\n",
    "    spark-role: driver\n",
    "  ports:\n",
    "    - port: 4040\n",
    "      targetPort: 4040\n",
    "  type: ClusterIP\n",
    "---\n",
    "# Ingress pour acc√®s externe\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: Ingress\n",
    "metadata:\n",
    "  name: spark-ui-ingress\n",
    "  namespace: spark\n",
    "spec:\n",
    "  rules:\n",
    "    - host: spark-ui.mycompany.com\n",
    "      http:\n",
    "        paths:\n",
    "          - path: /\n",
    "            pathType: Prefix\n",
    "            backend:\n",
    "              service:\n",
    "                name: spark-ui\n",
    "                port:\n",
    "                  number: 4040"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "history_server",
   "metadata": {},
   "source": [
    "### 8.2 Spark History Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "history_server_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/history-server.yaml\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: spark-history-server\n",
    "  namespace: spark\n",
    "spec:\n",
    "  replicas: 1\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: spark-history-server\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: spark-history-server\n",
    "    spec:\n",
    "      containers:\n",
    "        - name: history-server\n",
    "          image: bitnami/spark:3.5\n",
    "          command:\n",
    "            - /opt/bitnami/spark/sbin/start-history-server.sh\n",
    "          env:\n",
    "            - name: SPARK_HISTORY_OPTS\n",
    "              value: \"-Dspark.history.fs.logDirectory=s3a://spark-logs/history\"\n",
    "          ports:\n",
    "            - containerPort: 18080\n",
    "          envFrom:\n",
    "            - secretRef:\n",
    "                name: minio-credentials\n",
    "---\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: spark-history-server\n",
    "  namespace: spark\n",
    "spec:\n",
    "  selector:\n",
    "    app: spark-history-server\n",
    "  ports:\n",
    "    - port: 18080\n",
    "      targetPort: 18080\n",
    "  type: ClusterIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prometheus_grafana",
   "metadata": {},
   "source": [
    "### 8.3 Prometheus + Grafana\n",
    "\n",
    "Configuration Spark pour exposer les m√©triques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prometheus_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "prometheus_spark_config = \"\"\"\n",
    "# Dans sparkConf\n",
    "spark.metrics.conf.*.sink.prometheusServlet.class=org.apache.spark.metrics.sink.PrometheusServlet\n",
    "spark.metrics.conf.*.sink.prometheusServlet.path=/metrics/prometheus\n",
    "spark.metrics.conf.master.sink.prometheusServlet.path=/metrics/master/prometheus\n",
    "spark.metrics.conf.applications.sink.prometheusServlet.path=/metrics/applications/prometheus\n",
    "\n",
    "# Activer les m√©triques JVM\n",
    "spark.metrics.conf.*.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n",
    "\"\"\"\n",
    "print(prometheus_spark_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "servicemonitor_yaml",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/servicemonitor.yaml\n",
    "# ServiceMonitor pour Prometheus Operator\n",
    "apiVersion: monitoring.coreos.com/v1\n",
    "kind: ServiceMonitor\n",
    "metadata:\n",
    "  name: spark-monitor\n",
    "  namespace: spark\n",
    "  labels:\n",
    "    release: prometheus  # Match avec ton installation Prometheus\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      spark-role: driver\n",
    "  endpoints:\n",
    "    - port: spark-ui\n",
    "      path: /metrics/prometheus\n",
    "      interval: 15s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grafana_dashboards",
   "metadata": {},
   "source": [
    "### 8.4 Dashboards Grafana\n",
    "\n",
    "M√©triques cl√©s √† surveiller :\n",
    "\n",
    "| M√©trique | Description | Alerte si |\n",
    "|----------|-------------|------------|\n",
    "| `spark_executor_count` | Nombre d'executors actifs | < min expected |\n",
    "| `spark_executor_memory_used` | M√©moire utilis√©e | > 80% |\n",
    "| `spark_job_duration_seconds` | Dur√©e des jobs | > baseline √ó 2 |\n",
    "| `spark_task_failures_total` | Tasks √©chou√©es | > 0 |\n",
    "| `spark_shuffle_write_bytes` | Shuffle √©crit | Anomalies |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_7",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 7 : Exposer Spark UI\n",
    "\n",
    "**Objectif** : Acc√©der au Spark UI d'un job en cours.\n",
    "\n",
    "```bash\n",
    "# 1. Lister les pods driver\n",
    "kubectl get pods -n spark -l spark-role=driver\n",
    "\n",
    "# 2. Port-forward\n",
    "kubectl port-forward -n spark <driver-pod> 4040:4040\n",
    "\n",
    "# 3. Ouvrir http://localhost:4040\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debugging",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß 9. Debugging & Troubleshooting\n",
    "\n",
    "### 9.1 Erreurs courantes et solutions\n",
    "\n",
    "| Erreur | Cause | Solution |\n",
    "|--------|-------|----------|\n",
    "| `ImagePullBackOff` | Image introuvable | V√©rifier registry, credentials, tag |\n",
    "| `OOMKilled` | M√©moire insuffisante | Augmenter `memory`, r√©duire donn√©es |\n",
    "| `Forbidden` | RBAC manquant | V√©rifier Role/RoleBinding |\n",
    "| `Pending` (pods) | Ressources insuffisantes | V√©rifier quotas, cluster capacity |\n",
    "| `Connection refused` | Driver inaccessible | V√©rifier network policies, services |\n",
    "| `ClassNotFoundException` | JAR manquant | Ajouter dans l'image Docker |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debug_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_commands = \"\"\"\n",
    "# === Debugging Spark on K8s ===\n",
    "\n",
    "# 1. Voir les pods et leur statut\n",
    "kubectl get pods -n spark -o wide\n",
    "\n",
    "# 2. D√©tails d'un pod (√©v√©nements)\n",
    "kubectl describe pod <pod-name> -n spark\n",
    "\n",
    "# 3. Logs du driver\n",
    "kubectl logs -n spark -l spark-role=driver\n",
    "\n",
    "# 4. Logs d'un executor sp√©cifique\n",
    "kubectl logs -n spark <executor-pod-name>\n",
    "\n",
    "# 5. Logs en temps r√©el (follow)\n",
    "kubectl logs -n spark -l spark-role=driver -f\n",
    "\n",
    "# 6. Shell dans un pod (debug)\n",
    "kubectl exec -it <pod-name> -n spark -- /bin/bash\n",
    "\n",
    "# 7. V√©rifier les ressources du namespace\n",
    "kubectl describe resourcequota -n spark\n",
    "\n",
    "# 8. V√©rifier les events\n",
    "kubectl get events -n spark --sort-by='.lastTimestamp'\n",
    "\n",
    "# 9. SparkApplication status\n",
    "kubectl get sparkapplication -n spark\n",
    "kubectl describe sparkapplication <name> -n spark\n",
    "\"\"\"\n",
    "print(debug_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oomkilled_debug",
   "metadata": {},
   "source": [
    "### 9.2 Debugging OOMKilled\n",
    "\n",
    "```text\n",
    "üîç Sympt√¥me : Pod executor en √©tat OOMKilled\n",
    "\n",
    "Causes possibles :\n",
    "‚îú‚îÄ‚îÄ spark.executor.memory trop bas\n",
    "‚îú‚îÄ‚îÄ spark.executor.memoryOverhead mal configur√©\n",
    "‚îú‚îÄ‚îÄ Trop de donn√©es par partition\n",
    "‚îú‚îÄ‚îÄ Broadcast variables trop grandes\n",
    "‚îî‚îÄ‚îÄ Fuite m√©moire dans le code\n",
    "\n",
    "Solutions :\n",
    "‚îú‚îÄ‚îÄ Augmenter spark.executor.memory\n",
    "‚îú‚îÄ‚îÄ spark.executor.memoryOverhead = max(0.1 √ó memory, 384m)\n",
    "‚îú‚îÄ‚îÄ Repartitionner : df.repartition(200)\n",
    "‚îú‚îÄ‚îÄ R√©duire spark.sql.shuffle.partitions\n",
    "‚îî‚îÄ‚îÄ Utiliser spark.memory.fraction = 0.6 (default)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shuffle_debug",
   "metadata": {},
   "source": [
    "### 9.3 Debugging Shuffle failures\n",
    "\n",
    "Le shuffle est plus co√ªteux sur K8s (pas de data locality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shuffle_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_optimizations = \"\"\"\n",
    "# Optimisations shuffle pour K8s\n",
    "\n",
    "# Augmenter les timeouts\n",
    "spark.network.timeout=600s\n",
    "spark.shuffle.io.maxRetries=10\n",
    "spark.shuffle.io.retryWait=30s\n",
    "\n",
    "# Compression\n",
    "spark.shuffle.compress=true\n",
    "spark.shuffle.spill.compress=true\n",
    "\n",
    "# Buffer sizes\n",
    "spark.shuffle.file.buffer=64k\n",
    "spark.reducer.maxSizeInFlight=96m\n",
    "\n",
    "# Shuffle tracking (pour Dynamic Allocation)\n",
    "spark.dynamicAllocation.shuffleTracking.enabled=true\n",
    "\"\"\"\n",
    "print(shuffle_optimizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercise_8",
   "metadata": {},
   "source": [
    "### üèãÔ∏è Exercice 8 : Diagnostiquer un job qui √©choue\n",
    "\n",
    "**Sc√©nario** : Un job Spark √©choue avec le message \"Pod OOMKilled\".\n",
    "\n",
    "**Questions** :\n",
    "\n",
    "1. Quelle commande pour voir les events du pod ?\n",
    "2. Quelles configs Spark v√©rifier ?\n",
    "\n",
    "<details><summary>üí° Solution</summary>\n",
    "\n",
    "1. Commandes :\n",
    "```bash\n",
    "kubectl describe pod <pod-name> -n spark\n",
    "kubectl get events -n spark --field-selector involvedObject.name=<pod-name>\n",
    "```\n",
    "\n",
    "2. Configs √† v√©rifier :\n",
    "```\n",
    "spark.executor.memory\n",
    "spark.executor.memoryOverhead\n",
    "spark.kubernetes.executor.limit.memory\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimizations",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö° 10. Optimisations Spark on K8s\n",
    "\n",
    "### 10.1 Data Locality\n",
    "\n",
    "```text\n",
    "‚ö†Ô∏è Probl√®me : Pas de data locality sur K8s\n",
    "\n",
    "Sur YARN avec HDFS :\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Node 1               ‚îÇ\n",
    "‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n",
    "‚îÇ ‚îÇExecutor‚îÇ‚óÄ‚îÇ Data  ‚îÇ ‚îÇ  ‚Üê Data local (fast)\n",
    "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Sur K8s avec Object Storage :\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ Node 1               ‚îÇ      ‚îÇ S3/MinIO    ‚îÇ\n",
    "‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ (remote)    ‚îÇ  ‚Üê Network transfer\n",
    "‚îÇ ‚îÇExecutor‚îÇ           ‚îÇ      ‚îÇ             ‚îÇ\n",
    "‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "**Solutions** :\n",
    "\n",
    "- Utiliser des formats colonnaires (Parquet) optimis√©s\n",
    "- Configurer S3A/GCS pour le parall√©lisme\n",
    "- External Shuffle Service (Spark 3.4+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3a_optimizations",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3a_config = \"\"\"\n",
    "# Optimisations S3A pour Spark on K8s\n",
    "\n",
    "# Parall√©lisme\n",
    "spark.hadoop.fs.s3a.connection.maximum=200\n",
    "spark.hadoop.fs.s3a.threads.max=64\n",
    "spark.hadoop.fs.s3a.threads.core=16\n",
    "\n",
    "# Fast upload\n",
    "spark.hadoop.fs.s3a.fast.upload=true\n",
    "spark.hadoop.fs.s3a.fast.upload.buffer=bytebuffer\n",
    "spark.hadoop.fs.s3a.multipart.size=104857600  # 100MB\n",
    "\n",
    "# Committer (√©viter les renames S3)\n",
    "spark.sql.sources.commitProtocolClass=org.apache.spark.internal.io.cloud.PathOutputCommitProtocol\n",
    "spark.sql.parquet.output.committer.class=org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter\n",
    "\"\"\"\n",
    "print(s3a_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pod_templates",
   "metadata": {},
   "source": [
    "### 10.2 Pod Templates\n",
    "\n",
    "Pour des configurations avanc√©es des pods Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pod_template",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/executor-pod-template.yaml\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "spec:\n",
    "  containers:\n",
    "    - name: spark-executor\n",
    "      volumeMounts:\n",
    "        - name: spark-local-dir\n",
    "          mountPath: /tmp/spark\n",
    "      resources:\n",
    "        requests:\n",
    "          ephemeral-storage: \"10Gi\"\n",
    "        limits:\n",
    "          ephemeral-storage: \"20Gi\"\n",
    "  volumes:\n",
    "    - name: spark-local-dir\n",
    "      emptyDir:\n",
    "        medium: Memory  # Utiliser RAM pour shuffle local\n",
    "        sizeLimit: \"4Gi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pod_template_usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod_template_usage = \"\"\"\n",
    "# Utiliser le pod template dans spark-submit\n",
    "spark-submit \\\n",
    "  --conf spark.kubernetes.executor.podTemplateFile=/path/to/executor-pod-template.yaml \\\n",
    "  ...\n",
    "\n",
    "# Ou dans SparkApplication\n",
    "spec:\n",
    "  executor:\n",
    "    podTemplateFile: /path/to/executor-pod-template.yaml\n",
    "\"\"\"\n",
    "print(pod_template_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spot_instances",
   "metadata": {},
   "source": [
    "### 10.3 Spot/Preemptible Instances\n",
    "\n",
    "√âconomiser jusqu'√† 90% sur les co√ªts compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spot_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s/spark-with-spot.yaml\n",
    "apiVersion: sparkoperator.k8s.io/v1beta2\n",
    "kind: SparkApplication\n",
    "metadata:\n",
    "  name: spot-etl\n",
    "  namespace: spark\n",
    "spec:\n",
    "  type: Python\n",
    "  mode: cluster\n",
    "  image: my-registry/spark-app:1.0.0\n",
    "  mainApplicationFile: local:///app/etl.py\n",
    "  sparkVersion: \"3.5.0\"\n",
    "  \n",
    "  # Driver sur nodes stables (on-demand)\n",
    "  driver:\n",
    "    cores: 1\n",
    "    memory: \"2g\"\n",
    "    serviceAccount: spark-sa\n",
    "    affinity:\n",
    "      nodeAffinity:\n",
    "        requiredDuringSchedulingIgnoredDuringExecution:\n",
    "          nodeSelectorTerms:\n",
    "            - matchExpressions:\n",
    "                - key: node-type\n",
    "                  operator: In\n",
    "                  values:\n",
    "                    - on-demand\n",
    "  \n",
    "  # Executors sur spot instances\n",
    "  executor:\n",
    "    cores: 2\n",
    "    instances: 5\n",
    "    memory: \"4g\"\n",
    "    affinity:\n",
    "      nodeAffinity:\n",
    "        preferredDuringSchedulingIgnoredDuringExecution:\n",
    "          - weight: 100\n",
    "            preference:\n",
    "              matchExpressions:\n",
    "                - key: node-type\n",
    "                  operator: In\n",
    "                  values:\n",
    "                    - spot\n",
    "    tolerations:\n",
    "      - key: \"kubernetes.azure.com/scalesetpriority\"\n",
    "        operator: \"Equal\"\n",
    "        value: \"spot\"\n",
    "        effect: \"NoSchedule\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ 11. Mini-Projet : ETL Pipeline sur Kubernetes\n",
    "\n",
    "### üéØ Objectif\n",
    "\n",
    "D√©ployer un pipeline Spark complet sur K8s avec MinIO (Object Storage local).\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```text\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                     Kubernetes Cluster                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ   MinIO     ‚îÇ     ‚îÇ      Spark       ‚îÇ     ‚îÇ   MinIO     ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  (source)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    on K8s        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (output)   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ                  ‚îÇ     ‚îÇ             ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ bucket:     ‚îÇ     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ     ‚îÇ bucket:     ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ bronze/     ‚îÇ     ‚îÇ  ‚îÇ  Driver    ‚îÇ  ‚îÇ     ‚îÇ silver/     ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ   data.csv  ‚îÇ     ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     ‚îÇ   data.parquet‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ     ‚îÇ             ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ  ‚îÇExec‚îÇ ‚îÇExec‚îÇ   ‚îÇ     ‚îÇ             ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ             ‚îÇ     ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚îÇ             ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Structure du projet\n",
    "\n",
    "```\n",
    "spark-k8s-project/\n",
    "‚îú‚îÄ‚îÄ docker/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt\n",
    "‚îú‚îÄ‚îÄ app/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ etl_job.py\n",
    "‚îú‚îÄ‚îÄ manifests/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ rbac.yaml\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ minio-secret.yaml\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ spark-application.yaml\n",
    "‚îú‚îÄ‚îÄ data/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ sample.csv\n",
    "‚îî‚îÄ‚îÄ README.md\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_step1",
   "metadata": {},
   "source": [
    "### √âtape 1 : D√©ployer MinIO sur K8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minio_deploy",
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_deploy = \"\"\"\n",
    "# D√©ployer MinIO avec Helm\n",
    "helm repo add minio https://charts.min.io/\n",
    "helm repo update\n",
    "\n",
    "helm install minio minio/minio \\\n",
    "  --namespace minio \\\n",
    "  --create-namespace \\\n",
    "  --set rootUser=minioadmin \\\n",
    "  --set rootPassword=minioadmin \\\n",
    "  --set mode=standalone \\\n",
    "  --set resources.requests.memory=512Mi \\\n",
    "  --set persistence.size=10Gi\n",
    "\n",
    "# Port-forward pour acc√©der √† la console\n",
    "kubectl port-forward -n minio svc/minio-console 9001:9001\n",
    "\n",
    "# Cr√©er les buckets\n",
    "mc alias set myminio http://localhost:9000 minioadmin minioadmin\n",
    "mc mb myminio/bronze\n",
    "mc mb myminio/silver\n",
    "\n",
    "# Uploader des donn√©es de test\n",
    "mc cp data/sample.csv myminio/bronze/\n",
    "\"\"\"\n",
    "print(minio_deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_step2",
   "metadata": {},
   "source": [
    "### √âtape 2 : Code de l'application ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "etl_job_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s-project/app/etl_job.py\n",
    "\"\"\"\n",
    "ETL Job : Bronze ‚Üí Silver\n",
    "Lit des CSV depuis MinIO, transforme, et √©crit en Parquet.\n",
    "\"\"\"\n",
    "import argparse\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, upper, current_timestamp\n",
    "\n",
    "\n",
    "def create_spark_session():\n",
    "    \"\"\"Cr√©er une SparkSession configur√©e pour MinIO.\"\"\"\n",
    "    return SparkSession.builder \\\n",
    "        .appName(\"ETL Bronze to Silver\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "def extract(spark, input_path):\n",
    "    \"\"\"Lire les donn√©es brutes depuis le bucket Bronze.\"\"\"\n",
    "    print(f\"üì• Reading from {input_path}\")\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .csv(input_path)\n",
    "    print(f\"   Loaded {df.count()} rows\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform(df):\n",
    "    \"\"\"Appliquer les transformations m√©tier.\"\"\"\n",
    "    print(\"üîÑ Transforming data\")\n",
    "    transformed = df \\\n",
    "        .dropDuplicates() \\\n",
    "        .dropna() \\\n",
    "        .withColumn(\"processed_at\", current_timestamp())\n",
    "    \n",
    "    # Normalisation des colonnes string\n",
    "    for col_name, dtype in transformed.dtypes:\n",
    "        if dtype == \"string\":\n",
    "            transformed = transformed.withColumn(col_name, upper(col(col_name)))\n",
    "    \n",
    "    print(f\"   Transformed to {transformed.count()} rows\")\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def load(df, output_path):\n",
    "    \"\"\"√âcrire les donn√©es transform√©es dans le bucket Silver.\"\"\"\n",
    "    print(f\"üì§ Writing to {output_path}\")\n",
    "    df.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(output_path)\n",
    "    print(\"   Done!\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"ETL Job\")\n",
    "    parser.add_argument(\"--input\", required=True, help=\"Input path (s3a://...)\")\n",
    "    parser.add_argument(\"--output\", required=True, help=\"Output path (s3a://...)\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    spark = create_spark_session()\n",
    "    \n",
    "    try:\n",
    "        # ETL Pipeline\n",
    "        df = extract(spark, args.input)\n",
    "        transformed = transform(df)\n",
    "        load(transformed, args.output)\n",
    "        \n",
    "        print(\"‚úÖ ETL completed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ETL failed: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        spark.stop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_step3",
   "metadata": {},
   "source": [
    "### √âtape 3 : Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "project_dockerfile",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s-project/docker/Dockerfile\n",
    "FROM bitnami/spark:3.5\n",
    "\n",
    "USER root\n",
    "\n",
    "# D√©pendances Python\n",
    "RUN pip install --no-cache-dir pyarrow pandas\n",
    "\n",
    "# JARs pour S3/MinIO\n",
    "RUN curl -sL https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar \\\n",
    "    -o /opt/bitnami/spark/jars/hadoop-aws-3.3.4.jar && \\\n",
    "    curl -sL https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar \\\n",
    "    -o /opt/bitnami/spark/jars/aws-java-sdk-bundle-1.12.262.jar\n",
    "\n",
    "# Application\n",
    "COPY app/ /app/\n",
    "RUN chown -R 1001:1001 /app\n",
    "\n",
    "USER 1001\n",
    "WORKDIR /app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_step4",
   "metadata": {},
   "source": [
    "### √âtape 4 : Manifests Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "project_spark_app",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /tmp/spark-k8s-project/manifests/spark-application.yaml\n",
    "apiVersion: sparkoperator.k8s.io/v1beta2\n",
    "kind: SparkApplication\n",
    "metadata:\n",
    "  name: etl-bronze-silver\n",
    "  namespace: spark\n",
    "spec:\n",
    "  type: Python\n",
    "  pythonVersion: \"3\"\n",
    "  mode: cluster\n",
    "  image: spark-etl:1.0.0  # Image locale (Minikube)\n",
    "  imagePullPolicy: Never  # Pour Minikube\n",
    "  mainApplicationFile: local:///app/etl_job.py\n",
    "  arguments:\n",
    "    - \"--input\"\n",
    "    - \"s3a://bronze/sample.csv\"\n",
    "    - \"--output\"\n",
    "    - \"s3a://silver/data\"\n",
    "  sparkVersion: \"3.5.0\"\n",
    "  \n",
    "  sparkConf:\n",
    "    \"spark.hadoop.fs.s3a.endpoint\": \"http://minio.minio.svc.cluster.local:9000\"\n",
    "    \"spark.hadoop.fs.s3a.path.style.access\": \"true\"\n",
    "    \"spark.hadoop.fs.s3a.impl\": \"org.apache.hadoop.fs.s3a.S3AFileSystem\"\n",
    "  \n",
    "  restartPolicy:\n",
    "    type: OnFailure\n",
    "    onFailureRetries: 2\n",
    "  \n",
    "  driver:\n",
    "    cores: 1\n",
    "    memory: \"1g\"\n",
    "    serviceAccount: spark-sa\n",
    "    envSecretKeyRefs:\n",
    "      AWS_ACCESS_KEY_ID:\n",
    "        name: minio-credentials\n",
    "        key: AWS_ACCESS_KEY_ID\n",
    "      AWS_SECRET_ACCESS_KEY:\n",
    "        name: minio-credentials\n",
    "        key: AWS_SECRET_ACCESS_KEY\n",
    "  \n",
    "  executor:\n",
    "    cores: 1\n",
    "    instances: 2\n",
    "    memory: \"1g\"\n",
    "    envSecretKeyRefs:\n",
    "      AWS_ACCESS_KEY_ID:\n",
    "        name: minio-credentials\n",
    "        key: AWS_ACCESS_KEY_ID\n",
    "      AWS_SECRET_ACCESS_KEY:\n",
    "        name: minio-credentials\n",
    "        key: AWS_SECRET_ACCESS_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_step5",
   "metadata": {},
   "source": [
    "### √âtape 5 : D√©ploiement complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full_deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_script = \"\"\"\n",
    "#!/bin/bash\n",
    "set -e\n",
    "\n",
    "echo \"üöÄ D√©ploiement du pipeline ETL Spark on K8s\"\n",
    "\n",
    "# 1. Cr√©er le namespace et RBAC\n",
    "echo \"üìÅ Cr√©ation namespace et RBAC...\"\n",
    "kubectl apply -f manifests/namespace.yaml\n",
    "kubectl apply -f manifests/rbac.yaml\n",
    "kubectl apply -f manifests/minio-secret.yaml\n",
    "\n",
    "# 2. Build de l'image (Minikube)\n",
    "echo \"üê≥ Build de l'image Docker...\"\n",
    "eval $(minikube docker-env)\n",
    "docker build -t spark-etl:1.0.0 -f docker/Dockerfile .\n",
    "\n",
    "# 3. V√©rifier que MinIO est pr√™t\n",
    "echo \"‚è≥ Attente de MinIO...\"\n",
    "kubectl wait --for=condition=ready pod -l app=minio -n minio --timeout=120s\n",
    "\n",
    "# 4. Lancer le job Spark\n",
    "echo \"üî• Lancement du job Spark...\"\n",
    "kubectl apply -f manifests/spark-application.yaml\n",
    "\n",
    "# 5. Suivre le job\n",
    "echo \"üìä Suivi du job...\"\n",
    "kubectl get sparkapplication -n spark -w\n",
    "\"\"\"\n",
    "print(deployment_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_verify",
   "metadata": {},
   "source": [
    "### √âtape 6 : V√©rification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_commands = \"\"\"\n",
    "# V√©rifier le statut du job\n",
    "kubectl get sparkapplication -n spark\n",
    "\n",
    "# Voir les logs du driver\n",
    "kubectl logs -n spark -l spark-role=driver\n",
    "\n",
    "# V√©rifier les outputs dans MinIO\n",
    "mc ls myminio/silver/data/\n",
    "\n",
    "# Lire un sample des donn√©es\n",
    "mc cat myminio/silver/data/part-00000.parquet | head\n",
    "\"\"\"\n",
    "print(verify_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Quiz de fin de module\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q1. Quelle est la diff√©rence entre Client mode et Cluster mode ?\n",
    "a) Client mode est plus rapide  \n",
    "b) En Cluster mode, le Driver tourne dans un Pod K8s  \n",
    "c) Client mode ne supporte pas les executors  \n",
    "d) Cluster mode n√©cessite YARN\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî En Cluster mode, le Driver est un Pod K8s. En Client mode, il reste sur la machine locale.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q2. Pourquoi utiliser Spark Operator plut√¥t que spark-submit directement ?\n",
    "a) Spark Operator est plus rapide  \n",
    "b) spark-submit ne fonctionne pas sur K8s  \n",
    "c) Spark Operator permet des manifestes YAML d√©claratifs et des retries automatiques  \n",
    "d) Spark Operator ne n√©cessite pas de ServiceAccount\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : c** ‚Äî Spark Operator offre une approche d√©clarative (YAML), des retry policies, du scheduling, et une meilleure int√©gration CI/CD.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q3. Quel probl√®me r√©sout Dynamic Allocation ?\n",
    "a) La s√©curit√© des pods  \n",
    "b) L'ajustement automatique du nombre d'executors  \n",
    "c) Le stockage des logs  \n",
    "d) La communication r√©seau\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Dynamic Allocation permet √† Spark d'ajuster automatiquement le nombre d'executors selon la charge.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q4. Quelle config est requise pour Dynamic Allocation sur K8s ?\n",
    "a) `spark.dynamicAllocation.enabled=true` uniquement  \n",
    "b) `spark.dynamicAllocation.shuffleTracking.enabled=true`  \n",
    "c) `spark.kubernetes.allocation.batch.size=5`  \n",
    "d) Aucune config sp√©ciale\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Sur K8s (sans External Shuffle Service), shuffle tracking est requis pour que Dynamic Allocation fonctionne.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q5. Que signifie l'erreur `OOMKilled` ?\n",
    "a) Le pod n'a pas d'image  \n",
    "b) Le pod a d√©pass√© sa limite m√©moire  \n",
    "c) Le r√©seau est indisponible  \n",
    "d) Le ServiceAccount est invalide\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî OOMKilled signifie que le container a d√©pass√© sa limite m√©moire et a √©t√© tu√© par K8s.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q6. Quel est l'avantage principal de K8s sur YARN pour Spark ?\n",
    "a) Meilleure data locality  \n",
    "b) Infrastructure cloud-native et multi-cloud  \n",
    "c) Plus rapide  \n",
    "d) Moins de configuration\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî K8s offre une infrastructure cloud-native, standardis√©e, multi-cloud, avec autoscaling avanc√©.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q7. Comment exposer le Spark UI d'un job en cluster mode ?\n",
    "a) Il est automatiquement accessible sur localhost:4040  \n",
    "b) Via port-forward, Service, ou Ingress  \n",
    "c) Via YARN ResourceManager  \n",
    "d) Ce n'est pas possible en cluster mode\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî On utilise `kubectl port-forward`, un Service K8s, ou un Ingress pour exposer le Spark UI.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q8. Pourquoi le shuffle est-il plus co√ªteux sur K8s que sur YARN/HDFS ?\n",
    "a) K8s est plus lent  \n",
    "b) Pas de data locality ‚Äî les donn√©es doivent transiter par le r√©seau  \n",
    "c) Spark n'est pas optimis√© pour K8s  \n",
    "d) Les executors ont moins de m√©moire\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Sur YARN/HDFS, les donn√©es peuvent √™tre locales. Sur K8s avec Object Storage, tout passe par le r√©seau.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q9. Quel est le r√¥le du ServiceAccount dans Spark on K8s ?\n",
    "a) Stocker les credentials  \n",
    "b) Permettre au Driver de cr√©er des Executor Pods  \n",
    "c) G√©rer le Spark UI  \n",
    "d) Configurer le r√©seau\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : b** ‚Äî Le ServiceAccount donne au Driver les permissions RBAC pour cr√©er, lister et supprimer des Pods (executors).\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùì Q10. Comment √©conomiser sur les co√ªts compute avec Spark on K8s ?\n",
    "a) Utiliser moins d'executors  \n",
    "b) D√©sactiver le monitoring  \n",
    "c) Utiliser des Spot/Preemptible instances pour les executors  \n",
    "d) Ne pas utiliser de PVC\n",
    "\n",
    "<details><summary>üí° Voir la r√©ponse</summary>\n",
    "\n",
    "‚úÖ **R√©ponse : c** ‚Äî Les Spot instances peuvent co√ªter jusqu'√† 90% moins cher. Le Driver reste sur des nodes stables, les executors sur Spot.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Ressources pour aller plus loin\n",
    "\n",
    "### üåê Documentation officielle\n",
    "- [Spark on Kubernetes](https://spark.apache.org/docs/latest/running-on-kubernetes.html)\n",
    "- [Spark Operator GitHub](https://github.com/kubeflow/spark-operator)\n",
    "- [Spark Operator User Guide](https://www.kubeflow.org/docs/components/spark-operator/)\n",
    "\n",
    "### üìñ Articles & Tutoriels\n",
    "- [Databricks - Spark on K8s Best Practices](https://docs.databricks.com/)\n",
    "- [Google Cloud - Running Spark on GKE](https://cloud.google.com/kubernetes-engine/docs/tutorials/spark-on-gke)\n",
    "- [AWS - EMR on EKS](https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚û°Ô∏è Prochaine √©tape\n",
    "\n",
    "Maintenant que tu sais d√©ployer Spark sur Kubernetes, passons au **Cloud et Object Storage** !\n",
    "\n",
    "üëâ **Module suivant : `22_cloud_object_storage.ipynb`** ‚Äî Cloud & Object Storage\n",
    "\n",
    "Tu vas apprendre :\n",
    "\n",
    "- **Cloud Computing** : IaaS, PaaS, SaaS\n",
    "- **AWS, GCP, Azure** : Services Data Engineering\n",
    "- **Object Storage** : S3, GCS, Azure Blob\n",
    "- **MinIO** : Pratiquer localement\n",
    "\n",
    "---\n",
    "\n",
    "### üìù R√©capitulatif de ce module\n",
    "\n",
    "| Concept | Ce que tu as appris |\n",
    "|---------|--------------------|\n",
    "| **Architecture** | Driver/Executor Pods, Client vs Cluster mode |\n",
    "| **Docker Image** | Build, JARs, best practices |\n",
    "| **K8s Config** | RBAC, Secrets, PVC |\n",
    "| **spark-submit** | Configurations essentielles |\n",
    "| **Spark Operator** | SparkApplication, ScheduledSparkApplication |\n",
    "| **Autoscaling** | Dynamic Allocation, KEDA |\n",
    "| **Monitoring** | Spark UI, Prometheus, Grafana |\n",
    "| **Debugging** | Erreurs courantes, commandes kubectl |\n",
    "| **Optimisations** | S3A config, Pod templates, Spot instances |\n",
    "\n",
    "---\n",
    "\n",
    "üéâ **F√©licitations !** Tu as termin√© le module Spark on Kubernetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commandes de nettoyage\n",
    "cleanup_commands = \"\"\"\n",
    "# Supprimer les ressources Spark\n",
    "kubectl delete sparkapplication --all -n spark\n",
    "kubectl delete namespace spark\n",
    "\n",
    "# Supprimer Spark Operator\n",
    "helm uninstall spark-operator -n spark-operator\n",
    "kubectl delete namespace spark-operator\n",
    "\n",
    "# Supprimer MinIO\n",
    "helm uninstall minio -n minio\n",
    "kubectl delete namespace minio\n",
    "\n",
    "# Arr√™ter Minikube (optionnel)\n",
    "minikube stop\n",
    "\"\"\"\n",
    "print(cleanup_commands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
