{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# High Performance Python\n",
    "\n",
    "Bienvenue dans ce module oÃ¹ tu vas apprendre Ã  **accÃ©lÃ©rer considÃ©rablement** tes pipelines Python. Tu dÃ©couvriras comment contourner les limitations du GIL, parallÃ©liser tes traitements, et gÃ©rer des fichiers plus grands que ta RAM !\n",
    "\n",
    "---\n",
    "\n",
    "## PrÃ©requis\n",
    "\n",
    "| Niveau | CompÃ©tence |\n",
    "|--------|------------|\n",
    "| âœ… Requis | MaÃ®triser Python (fonctions, classes) |\n",
    "| âœ… Requis | Avoir suivi le module `17_polars_for_data_engineering` |\n",
    "| ğŸ’¡ RecommandÃ© | ConnaÃ®tre Pandas |\n",
    "\n",
    "## ğŸ¯ Objectifs du module\n",
    "\n",
    "Ã€ la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Comprendre le **GIL** et ses implications sur la performance\n",
    "- **Profiler** ton code pour identifier les vrais goulots d'Ã©tranglement\n",
    "- Utiliser **concurrent.futures** pour parallÃ©liser simplement\n",
    "- MaÃ®triser **asyncio** pour l'I/O massivement parallÃ¨le\n",
    "- Exploiter **Dask** pour traiter des fichiers plus grands que la RAM\n",
    "- Choisir le **bon outil** selon ton problÃ¨me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gil",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Le GIL : Comprendre la limitation fondamentale\n",
    "\n",
    "> **Cette section est essentielle** pour comprendre pourquoi certaines techniques fonctionnent et d'autres non.\n",
    "\n",
    "### 1.1 Qu'est-ce que le GIL ?\n",
    "\n",
    "Le **Global Interpreter Lock (GIL)** est un verrou interne Ã  Python qui **empÃªche deux threads d'exÃ©cuter du code Python en mÃªme temps**.\n",
    "\n",
    "#### Pourquoi le GIL existe ?\n",
    "\n",
    "Python gÃ¨re la mÃ©moire automatiquement (garbage collector). Sans le GIL, deux threads pourraient modifier le mÃªme objet simultanÃ©ment â†’ **corruption de mÃ©moire**. Le GIL est une solution simple mais qui limite la performance.\n",
    "\n",
    "#### Visualisation du GIL\n",
    "\n",
    "```text\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                          AVEC LE GIL (threading)                         â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  Thread 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘             â•‘\n",
    "â•‘  Thread 2: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             â•‘\n",
    "â•‘            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ temps    â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  â†’ Un seul thread s'exÃ©cute Ã  la fois !                                 â•‘\n",
    "â•‘  â†’ Les threads ALTERNENT, ils ne sont pas vraiment parallÃ¨les           â•‘\n",
    "â•‘  â†’ Pour du calcul CPU : PAS de gain de performance !                    â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                       SANS GIL (multiprocessing)                         â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  Process 1: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             â•‘\n",
    "â•‘  Process 2: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             â•‘\n",
    "â•‘             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ temps   â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  â†’ VRAIE exÃ©cution parallÃ¨le sur plusieurs CPUs !                       â•‘\n",
    "â•‘  â†’ Chaque process a son propre interprÃ©teur Python                      â•‘\n",
    "â•‘  â†’ Pour du calcul CPU : gain de performance proportionnel aux CPUs      â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n",
    "### 1.2 CPU-bound vs I/O-bound : La distinction CRUCIALE\n",
    "\n",
    "Avant de choisir une technique, tu DOIS savoir si ton problÃ¨me est **CPU-bound** ou **I/O-bound** :\n",
    "\n",
    "| Type | C'est quoi ? | Exemples | Le GIL bloque ? | Solution |\n",
    "|------|--------------|----------|-----------------|----------|\n",
    "| **CPU-bound** | Le CPU travaille en continu | Calculs mathÃ©matiques, transformations de donnÃ©es, parsing, compression | âœ… **OUI** | `multiprocessing`, `ProcessPoolExecutor` |\n",
    "| **I/O-bound** | Le CPU attend des donnÃ©es externes | RequÃªtes API, lecture fichiers, requÃªtes base de donnÃ©es | âŒ **NON** | `threading`, `asyncio` |\n",
    "\n",
    "#### Pourquoi le GIL ne bloque PAS l'I/O ?\n",
    "\n",
    "Quand Python attend une rÃ©ponse (rÃ©seau, disque, etc.), il **relÃ¢che le GIL** automatiquement :\n",
    "\n",
    "```text\n",
    "Thread 1:  [code Python]â”€â”€â–¶[attend rÃ©seau]â”€â”€â–¶[code Python]\n",
    "                 GIL â†“           â†“ GIL libre     â†“ GIL\n",
    "                 \n",
    "Thread 2:  [attend GIL]â”€â”€â–¶[code Python]â”€â”€â–¶[attend GIL]\n",
    "                              GIL â†“\n",
    "\n",
    "â†’ Pendant que Thread 1 attend le rÃ©seau, Thread 2 peut s'exÃ©cuter !\n",
    "```\n",
    "\n",
    "### 1.3 DÃ©monstration : GIL en action\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gil_info",
   "metadata": {},
   "source": [
    "> â„¹ï¸ **Le savais-tu ?**\n",
    ">\n",
    "> Le GIL a Ã©tÃ© introduit dans Python pour **simplifier la gestion de la mÃ©moire**. Il rend Python thread-safe par dÃ©faut, mais au prix de la performance multi-thread.\n",
    ">\n",
    "> Des projets comme **nogil** (Python 3.13+) et **subinterpreters** travaillent Ã  supprimer ou contourner cette limitation.\n",
    ">\n",
    "> En attendant, les Data Engineers utilisent **multiprocessing** pour contourner le GIL !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gil_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  DÃ‰MONSTRATION DU GIL : Threading vs Multiprocessing                     â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import time\n",
    "import threading\n",
    "from multiprocessing import Process\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION CPU-INTENSIVE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Cette fonction fait des calculs lourds (boucle + opÃ©rations mathÃ©matiques)\n",
    "# C'est du \"CPU-bound\" car le CPU travaille en continu sans attendre\n",
    "\n",
    "def cpu_intensive(n):\n",
    "    \"\"\"\n",
    "    TÃ¢che CPU-bound : calcul intensif.\n",
    "    \n",
    "    Args:\n",
    "        n: Nombre d'itÃ©rations (plus c'est grand, plus c'est long)\n",
    "    \n",
    "    Returns:\n",
    "        La somme des carrÃ©s de 0 Ã  n-1\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i ** 2  # OpÃ©ration CPU : Ã©lÃ©vation au carrÃ©\n",
    "    return total\n",
    "\n",
    "# ParamÃ¨tre : 5 millions d'itÃ©rations par appel\n",
    "N = 5_000_000\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DÃ‰MONSTRATION : Impact du GIL sur les tÃ¢ches CPU-bound\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TEST 1 : EXÃ‰CUTION SÃ‰QUENTIELLE (baseline)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# On exÃ©cute la fonction 2 fois, l'une aprÃ¨s l'autre\n",
    "# C'est notre rÃ©fÃ©rence pour mesurer le gain des autres mÃ©thodes\n",
    "\n",
    "print(\"\\n Test 1 : SÃ©quentiel (rÃ©fÃ©rence)\")\n",
    "start = time.time()\n",
    "\n",
    "cpu_intensive(N)  # Premier appel\n",
    "cpu_intensive(N)  # DeuxiÃ¨me appel (attend que le premier finisse)\n",
    "\n",
    "seq_time = time.time() - start\n",
    "print(f\"   Temps : {seq_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TEST 2 : THREADING (bloquÃ© par le GIL)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# On crÃ©e 2 threads qui exÃ©cutent cpu_intensive en \"parallÃ¨le\"\n",
    "# MAIS : le GIL empÃªche l'exÃ©cution simultanÃ©e !\n",
    "# RÃ©sultat attendu : temps SIMILAIRE au sÃ©quentiel (pas de gain)\n",
    "\n",
    "print(\"\\n Test 2 : Threading (2 threads)\")\n",
    "start = time.time()\n",
    "\n",
    "# CrÃ©er les threads\n",
    "t1 = threading.Thread(target=cpu_intensive, args=(N,))  # Thread 1\n",
    "t2 = threading.Thread(target=cpu_intensive, args=(N,))  # Thread 2\n",
    "\n",
    "# DÃ©marrer les threads\n",
    "t1.start()  # Lance Thread 1\n",
    "t2.start()  # Lance Thread 2 (mais GIL bloque l'exÃ©cution simultanÃ©e !)\n",
    "\n",
    "# Attendre que les threads finissent\n",
    "t1.join()  # Attend Thread 1\n",
    "t2.join()  # Attend Thread 2\n",
    "\n",
    "thread_time = time.time() - start\n",
    "print(f\"   Temps : {thread_time:.2f}s\")\n",
    "print(f\"   Pas plus rapide ! Le GIL empÃªche la parallÃ©lisation.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TEST 3 : MULTIPROCESSING (contourne le GIL)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# On crÃ©e 2 PROCESSUS sÃ©parÃ©s (pas des threads)\n",
    "# Chaque processus a son propre interprÃ©teur Python = son propre GIL\n",
    "# RÃ©sultat attendu : temps DIVISÃ‰ PAR 2 (vraie parallÃ©lisation)\n",
    "\n",
    "print(\"\\n Test 3 : Multiprocessing (2 processus)\")\n",
    "start = time.time()\n",
    "\n",
    "# CrÃ©er les processus\n",
    "p1 = Process(target=cpu_intensive, args=(N,))  # Processus 1\n",
    "p2 = Process(target=cpu_intensive, args=(N,))  # Processus 2\n",
    "\n",
    "# DÃ©marrer les processus\n",
    "p1.start()  # Lance Processus 1 sur CPU 1\n",
    "p2.start()  # Lance Processus 2 sur CPU 2 (VRAIMENT en parallÃ¨le !)\n",
    "\n",
    "# Attendre que les processus finissent\n",
    "p1.join()  # Attend Processus 1\n",
    "p2.join()  # Attend Processus 2\n",
    "\n",
    "proc_time = time.time() - start\n",
    "print(f\"   Temps : {proc_time:.2f}s\")\n",
    "print(f\"    ~2x plus rapide ! Le multiprocessing contourne le GIL.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# RÃ‰SUMÃ‰\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RÃ‰SUMÃ‰\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   SÃ©quentiel      : {seq_time:.2f}s (rÃ©fÃ©rence)\")\n",
    "print(f\"   Threading       : {thread_time:.2f}s (speedup : {seq_time/thread_time:.1f}x)\")\n",
    "print(f\"   Multiprocessing : {proc_time:.2f}s (speedup : {seq_time/proc_time:.1f}x)\")\n",
    "print()\n",
    "print(\"CONCLUSION :\")\n",
    "print(\"   Pour du CPU-bound â†’ utilise multiprocessing (ou ProcessPoolExecutor)\")\n",
    "print(\"   Pour de l\\'I/O-bound â†’ threading ou asyncio fonctionnent bien\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "profiling",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Identifier les goulots : Profiling\n",
    "\n",
    "> âš ï¸ **\"Premature optimization is the root of all evil\"** â€” Donald Knuth\n",
    ">\n",
    "> Avant d'optimiser, il faut **mesurer** pour identifier le vrai problÃ¨me.\n",
    "\n",
    "### 2.1 Outils de profiling\n",
    "\n",
    "| Outil | Usage | Comment l'utiliser |\n",
    "|-------|-------|--------------------|\n",
    "| `%%time` | Temps d'une cellule | Jupyter magic |\n",
    "| `%%timeit` | Temps moyen (plusieurs runs) | Jupyter magic |\n",
    "| `cProfile` | Profiling par fonction | `python -m cProfile script.py` |\n",
    "| `line_profiler` | Profiling ligne par ligne | `@profile` decorator |\n",
    "| `memory_profiler` | Usage RAM | `@profile` + `mprof run` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "profiling_time",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time - mesure le temps d'exÃ©cution d'une cellule\n",
    "import time\n",
    "\n",
    "def slow_function():\n",
    "    total = 0\n",
    "    for i in range(1_000_000):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "%time result = slow_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "profiling_timeit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit - moyenne sur plusieurs exÃ©cutions\n",
    "def fast_function():\n",
    "    return sum(range(1_000_000))\n",
    "\n",
    "%timeit fast_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "profiling_cprofile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "def main_pipeline():\n",
    "    \"\"\"Pipeline simulÃ© avec plusieurs Ã©tapes\"\"\"\n",
    "    data = list(range(100_000))\n",
    "    \n",
    "    # Ã‰tape 1 : transformation\n",
    "    transformed = [x ** 2 for x in data]\n",
    "    \n",
    "    # Ã‰tape 2 : filtrage\n",
    "    filtered = [x for x in transformed if x % 2 == 0]\n",
    "    \n",
    "    # Ã‰tape 3 : agrÃ©gation\n",
    "    result = sum(filtered)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Profiler le code\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "result = main_pipeline()\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "stream = StringIO()\n",
    "stats = pstats.Stats(profiler, stream=stream).sort_stats('cumulative')\n",
    "stats.print_stats(10)\n",
    "print(stream.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overview",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. StratÃ©gies de performance : Vue d'ensemble\n",
    "\n",
    "| Besoin | Solution | Quand l'utiliser |\n",
    "|--------|----------|------------------|\n",
    "| Multi-CPU (CPU-bound) | `ProcessPoolExecutor` | ETL lourd, calculs |\n",
    "| I/O parallÃ¨le (simple) | `ThreadPoolExecutor` | < 20 requÃªtes/fichiers |\n",
    "| I/O parallÃ¨le (massif) | `asyncio` | 100+ requÃªtes API |\n",
    "| Gros fichiers (> RAM) | Polars streaming, Dask | 10-100+ Go |\n",
    "| ParallÃ©lisation simple | `joblib` | Boucles, ML |\n",
    "\n",
    "### Arbre de dÃ©cision\n",
    "\n",
    "```text\n",
    "Ton problÃ¨me est...\n",
    "â”‚\n",
    "â”œâ”€â–¶ CPU-bound (calculs, transformations) ?\n",
    "â”‚   â”œâ”€â–¶ Simple/boucle â†’ joblib\n",
    "â”‚   â””â”€â–¶ Complexe/chunks â†’ ProcessPoolExecutor\n",
    "â”‚\n",
    "â”œâ”€â–¶ I/O-bound (API, fichiers, DB) ?\n",
    "â”‚   â”œâ”€â–¶ < 20 requÃªtes â†’ ThreadPoolExecutor\n",
    "â”‚   â””â”€â–¶ 100+ requÃªtes â†’ asyncio\n",
    "â”‚\n",
    "â””â”€â–¶ Gros fichiers (> RAM) ?\n",
    "    â”œâ”€â–¶ Single file, Polars-like â†’ Polars streaming\n",
    "    â”œâ”€â–¶ Multi-files, Pandas-like â†’ Dask\n",
    "    â””â”€â–¶ Cluster distribuÃ© â†’ Spark (module 19)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concurrent_futures",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. concurrent.futures â€” L'API moderne et simple\n",
    "\n",
    ">  **RecommandÃ©** : Plus simple que `multiprocessing` et `threading` bruts\n",
    ">  **Interface unifiÃ©e** : MÃªme API pour threads et processes\n",
    "\n",
    "### 4.1 ThreadPoolExecutor : Pour les tÃ¢ches I/O-bound\n",
    "\n",
    "Le `ThreadPoolExecutor` crÃ©e un **pool de threads rÃ©utilisables**. C'est idÃ©al pour :\n",
    "- TÃ©lÃ©charger plusieurs fichiers\n",
    "- Faire plusieurs requÃªtes API\n",
    "- Lire/Ã©crire plusieurs fichiers\n",
    "\n",
    "#### Comment Ã§a fonctionne ?\n",
    "\n",
    "```text\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                      ThreadPoolExecutor (5 workers)                       â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                          â•‘\n",
    "â•‘   TÃ¢ches Ã  faire : [T1, T2, T3, T4, T5, T6, T7, T8, T9, T10]            â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘   Pool de threads :                                                      â•‘\n",
    "â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â•‘\n",
    "â•‘   â”‚Thread 1 â”‚ â”‚Thread 2 â”‚ â”‚Thread 3 â”‚ â”‚Thread 4 â”‚ â”‚Thread 5 â”‚          â•‘\n",
    "â•‘   â”‚   T1    â”‚ â”‚   T2    â”‚ â”‚   T3    â”‚ â”‚   T4    â”‚ â”‚   T5    â”‚          â•‘\n",
    "â•‘   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â•‘\n",
    "â•‘        â”‚           â”‚           â”‚           â”‚           â”‚                 â•‘\n",
    "â•‘        â”‚ T1 fini   â”‚           â”‚           â”‚           â”‚                 â•‘\n",
    "â•‘        â–¼           â”‚           â”‚           â”‚           â”‚                 â•‘\n",
    "â•‘   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚           â”‚           â”‚           â”‚                 â•‘\n",
    "â•‘   â”‚Thread 1 â”‚      â”‚           â”‚           â”‚           â”‚                 â•‘\n",
    "â•‘   â”‚   T6    â”‚ â—€â”€â”€â”€â”€â”´â”€â”€ Les threads prennent la tÃ¢che suivante           â•‘\n",
    "â•‘   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          dÃ¨s qu'ils ont fini                              â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘   â†’ Max 5 tÃ¢ches en parallÃ¨le, les autres attendent                     â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threadpool_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ThreadPoolExecutor : ParallÃ©liser des tÃ¢ches I/O-bound                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION QUI SIMULE UNE TÃ‚CHE I/O (requÃªte API, lecture fichier, etc.)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def simulate_io_task(task_id):\n",
    "    \"\"\"\n",
    "    Simule une tÃ¢che I/O-bound (ex: requÃªte API).\n",
    "    \n",
    "    Dans la vraie vie, Ã§a pourrait Ãªtre :\n",
    "    - requests.get(\"https://api.example.com/data\")\n",
    "    - open(\"fichier.csv\").read()\n",
    "    - cursor.execute(\"SELECT * FROM table\")\n",
    "    \n",
    "    Args:\n",
    "        task_id: Identifiant de la tÃ¢che (pour le logging)\n",
    "    \n",
    "    Returns:\n",
    "        Message de confirmation\n",
    "    \"\"\"\n",
    "    print(f\"    TÃ¢che {task_id} : dÃ©but\")\n",
    "    time.sleep(0.5)  # Simule 500ms de latence rÃ©seau\n",
    "    print(f\"    TÃ¢che {task_id} : terminÃ©e\")\n",
    "    return f\"RÃ©sultat de la tÃ¢che {task_id}\"\n",
    "\n",
    "# Liste des tÃ¢ches Ã  effectuer (10 tÃ¢ches)\n",
    "tasks = list(range(10))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¬ ThreadPoolExecutor : ParallÃ©liser des tÃ¢ches I/O\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MÃ‰THODE 1 : SÃ‰QUENTIEL (pour comparer)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 10 tÃ¢ches Ã— 0.5s = 5s au total\n",
    "\n",
    "print(\"\\n MÃ©thode 1 : SÃ©quentiel\")\n",
    "print(\"-\" * 40)\n",
    "start = time.time()\n",
    "\n",
    "results_seq = [simulate_io_task(t) for t in tasks]\n",
    "\n",
    "seq_time = time.time() - start\n",
    "print(f\"\\n Temps sÃ©quentiel : {seq_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MÃ‰THODE 2 : THREADPOOLEXECUTOR\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Avec 5 workers : 10 tÃ¢ches / 5 workers = 2 vagues = ~1s\n",
    "\n",
    "print(\"\\n MÃ©thode 2 : ThreadPoolExecutor (5 workers)\")\n",
    "print(\"-\" * 40)\n",
    "start = time.time()\n",
    "\n",
    "# CrÃ©er un pool de 5 threads\n",
    "# with ... as : le pool se ferme automatiquement Ã  la fin\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    #\n",
    "    # executor.map() applique la fonction Ã  chaque Ã©lÃ©ment de la liste\n",
    "    # - Distribue les tÃ¢ches aux threads disponibles\n",
    "    # - Retourne les rÃ©sultats DANS L'ORDRE de la liste originale\n",
    "    # - Bloque jusqu'Ã  ce que toutes les tÃ¢ches soient terminÃ©es\n",
    "    #\n",
    "    results_parallel = list(executor.map(simulate_io_task, tasks))\n",
    "\n",
    "parallel_time = time.time() - start\n",
    "print(f\"\\n Temps parallÃ¨le : {parallel_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COMPARAISON\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARAISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   SÃ©quentiel : {seq_time:.2f}s\")\n",
    "print(f\"   ParallÃ¨le  : {parallel_time:.2f}s\")\n",
    "print(f\"   Speedup    : {seq_time/parallel_time:.1f}x plus rapide !\")\n",
    "print()\n",
    "print(\"Avec 5 workers pour 10 tÃ¢ches :\")\n",
    "print(\"   â†’ 2 vagues de 5 tÃ¢ches\")\n",
    "print(\"   â†’ 2 Ã— 0.5s = ~1s au lieu de 10 Ã— 0.5s = 5s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processpool",
   "metadata": {},
   "source": [
    "### 4.2 ProcessPoolExecutor (CPU-bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processpool_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ProcessPoolExecutor : ParallÃ©liser des tÃ¢ches CPU-bound                 â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "import os\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION CPU-INTENSIVE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def cpu_task(n):\n",
    "    \"\"\"\n",
    "    TÃ¢che CPU-bound : calcul intensif.\n",
    "    \n",
    "    Cette fonction fait travailler le CPU en continu.\n",
    "    Exemples rÃ©els : parsing, compression, transformations de donnÃ©es,\n",
    "    calculs mathÃ©matiques, feature engineering.\n",
    "    \n",
    "    Args:\n",
    "        n: Nombre d'itÃ©rations\n",
    "    \n",
    "    Returns:\n",
    "        Somme des carrÃ©s\n",
    "    \"\"\"\n",
    "    return sum(i ** 2 for i in range(n))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# DONNÃ‰ES Ã€ TRAITER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# On simule 8 \"chunks\" de donnÃ©es Ã  traiter\n",
    "# Chaque chunk nÃ©cessite 1 million d'itÃ©rations\n",
    "\n",
    "data_chunks = [1_000_000] * 8  # 8 chunks de 1M itÃ©rations chacun\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" ProcessPoolExecutor : ParallÃ©liser des tÃ¢ches CPU-bound\")\n",
    "print(\"=\" * 60)\n",
    "print(f\" CPUs disponibles : {os.cpu_count()}\")\n",
    "print(f\" Chunks Ã  traiter : {len(data_chunks)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MÃ‰THODE 1 : SÃ‰QUENTIEL\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n MÃ©thode 1 : SÃ©quentiel\")\n",
    "print(\"-\" * 40)\n",
    "start = time.time()\n",
    "\n",
    "results_seq = [cpu_task(chunk) for chunk in data_chunks]\n",
    "\n",
    "seq_time = time.time() - start\n",
    "print(f\" Temps sÃ©quentiel : {seq_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MÃ‰THODE 2 : PROCESSPOOL\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Chaque worker est un PROCESSUS sÃ©parÃ© avec son propre GIL\n",
    "# â†’ Vraie parallÃ©lisation sur plusieurs CPUs !\n",
    "\n",
    "print(\"\\n MÃ©thode 2 : ProcessPoolExecutor (4 workers)\")\n",
    "print(\"-\" * 40)\n",
    "start = time.time()\n",
    "\n",
    "# CrÃ©er un pool de 4 processus\n",
    "# Note : max_workers = nombre de CPUs est gÃ©nÃ©ralement optimal\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    #\n",
    "    # executor.map() distribue les chunks aux processus\n",
    "    # - Processus 1 traite chunk[0], chunk[4]\n",
    "    # - Processus 2 traite chunk[1], chunk[5]\n",
    "    # - etc.\n",
    "    #\n",
    "    results_parallel = list(executor.map(cpu_task, data_chunks))\n",
    "\n",
    "proc_time = time.time() - start\n",
    "print(f\" Temps parallÃ¨le : {proc_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COMPARAISON\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARAISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   SÃ©quentiel : {seq_time:.2f}s\")\n",
    "print(f\"   ParallÃ¨le  : {proc_time:.2f}s\")\n",
    "print(f\"   Speedup    : {seq_time/proc_time:.1f}x plus rapide !\")\n",
    "print()\n",
    "print(\"Explication :\")\n",
    "print(\"   â†’ 8 chunks avec 4 workers = 2 vagues\")\n",
    "print(\"   â†’ Chaque processus utilise 100% d'un CPU\")\n",
    "print(\"   â†’ Speedup thÃ©orique max = min(workers, chunks) = 4x\")\n",
    "print()\n",
    "print(\"âš ï¸ IMPORTANT :\")\n",
    "print(\"   â†’ ProcessPoolExecutor pour CPU-bound (contourne le GIL)\")\n",
    "print(\"   â†’ ThreadPoolExecutor pour I/O-bound (GIL pas bloquant)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "futures_advanced",
   "metadata": {},
   "source": [
    "### 4.3 Gestion avancÃ©e : submit() et as_completed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "futures_submit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  submit() et as_completed() : ContrÃ´le avancÃ© des tÃ¢ches                 â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# executor.map() est simple mais limitÃ© :\n",
    "# - Attend que TOUTES les tÃ¢ches finissent\n",
    "# - Retourne les rÃ©sultats dans l'ordre original\n",
    "#\n",
    "# submit() + as_completed() permet :\n",
    "# - Traiter les rÃ©sultats dÃ¨s qu'ils arrivent\n",
    "# - GÃ©rer les erreurs individuellement\n",
    "# - Ajouter des timeouts par tÃ¢che\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import random\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION AVEC TEMPS D'EXÃ‰CUTION VARIABLE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def fetch_data(task_id):\n",
    "    \"\"\"\n",
    "    Simule une requÃªte avec temps variable.\n",
    "    Certaines tÃ¢ches sont rapides, d'autres lentes.\n",
    "    \"\"\"\n",
    "    delay = random.uniform(0.1, 1.0)  # Entre 0.1s et 1s\n",
    "    time.sleep(delay)\n",
    "    \n",
    "    # Simuler une erreur alÃ©atoire (10% de chance)\n",
    "    if random.random() < 0.1:\n",
    "        raise Exception(f\"Erreur sur la tÃ¢che {task_id}\")\n",
    "    \n",
    "    return {\"task_id\": task_id, \"delay\": round(delay, 2)}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" submit() et as_completed() : ContrÃ´le avancÃ©\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# UTILISATION DE submit() + as_completed()\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Ã‰TAPE 1 : Soumettre les tÃ¢ches avec submit()\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # submit() retourne un objet Future (promesse de rÃ©sultat futur)\n",
    "    # On crÃ©e un dictionnaire {future: task_id} pour identifier les tÃ¢ches\n",
    "    \n",
    "    futures = {}\n",
    "    for i in range(5):\n",
    "        future = executor.submit(fetch_data, i)  # Soumet la tÃ¢che\n",
    "        futures[future] = i  # Associe le future Ã  l'ID de la tÃ¢che\n",
    "    \n",
    "    print(f\"\\n {len(futures)} tÃ¢ches soumises\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Ã‰TAPE 2 : Traiter les rÃ©sultats avec as_completed()\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # as_completed() itÃ¨re sur les futures dans l'ORDRE DE COMPLÃ‰TION\n",
    "    # (pas l'ordre de soumission !)\n",
    "    # â†’ La premiÃ¨re tÃ¢che terminÃ©e est traitÃ©e en premier\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        task_id = futures[future]  # RÃ©cupÃ©rer l'ID de la tÃ¢che\n",
    "        \n",
    "        try:\n",
    "            # future.result() rÃ©cupÃ¨re le rÃ©sultat\n",
    "            # timeout=5 : lÃ¨ve TimeoutError si > 5 secondes\n",
    "            result = future.result(timeout=5)\n",
    "            print(f\" TÃ¢che {task_id} terminÃ©e en {result['delay']}s\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Gestion individuelle des erreurs\n",
    "            print(f\"âŒ TÃ¢che {task_id} a Ã©chouÃ© : {e}\")\n",
    "\n",
    "print(\"\\n AVANTAGES de submit() + as_completed() :\")\n",
    "print(\"   â†’ Traiter les rÃ©sultats dÃ¨s qu'ils arrivent\")\n",
    "print(\"   â†’ GÃ©rer les erreurs individuellement\")\n",
    "print(\"   â†’ Ajouter des timeouts par tÃ¢che\")\n",
    "print(\"   â†’ Plus de contrÃ´le que executor.map()\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "futures_comparison",
   "metadata": {},
   "source": [
    "### 4.4 Quand utiliser quoi ?\n",
    "\n",
    "| Executor | GIL contournÃ© ? | Usage | Exemple |\n",
    "|----------|-----------------|-------|----------|\n",
    "| `ThreadPoolExecutor` | âŒ Non | I/O : API, fichiers | TÃ©lÃ©charger 50 fichiers |\n",
    "| `ProcessPoolExecutor` | âœ… Oui | CPU : calculs, ETL | Transformer 8 chunks de donnÃ©es |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiprocessing",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ 5. multiprocessing â€” ContrÃ´le avancÃ©\n",
    "\n",
    "Pour les cas oÃ¹ `concurrent.futures` ne suffit pas.\n",
    "\n",
    "### 5.1 Pool avec map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiprocessing_pool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  multiprocessing.Pool : Traitement parallÃ¨le avec partitioning           â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# Pool est utile quand tu veux :\n",
    "# - Partitionner des donnÃ©es en chunks\n",
    "# - Traiter chaque chunk en parallÃ¨le\n",
    "# - Combiner les rÃ©sultats\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import numpy as np\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION DE TRAITEMENT D'UN CHUNK\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def process_chunk(chunk):\n",
    "    \"\"\"\n",
    "    Traite un chunk de donnÃ©es.\n",
    "    \n",
    "    Dans la vraie vie :\n",
    "    - Transformation de donnÃ©es\n",
    "    - Feature engineering\n",
    "    - Calculs statistiques\n",
    "    \n",
    "    Args:\n",
    "        chunk: numpy array (portion des donnÃ©es)\n",
    "    \n",
    "    Returns:\n",
    "        RÃ©sultat du traitement (ici : somme des carrÃ©s)\n",
    "    \"\"\"\n",
    "    return np.sum(chunk ** 2)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" multiprocessing.Pool : Partitionner et parallÃ©liser\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 1 : CrÃ©er les donnÃ©es\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "big_array = np.random.rand(1_000_000)  # 1 million de valeurs\n",
    "print(f\"\\nğŸ“Š DonnÃ©es : {len(big_array):,} valeurs\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 2 : Partitionner en chunks\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# On divise les donnÃ©es en autant de chunks que de CPUs\n",
    "# Chaque CPU traitera un chunk\n",
    "\n",
    "n_workers = cpu_count()\n",
    "chunks = np.array_split(big_array, n_workers)\n",
    "\n",
    "print(f\" CPUs disponibles : {n_workers}\")\n",
    "print(f\" Chunks crÃ©Ã©s : {len(chunks)}\")\n",
    "print(f\"   Taille de chaque chunk : ~{len(chunks[0]):,} valeurs\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 3 : Traitement parallÃ¨le avec Pool\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n Traitement parallÃ¨le...\")\n",
    "\n",
    "# Pool() crÃ©e un pool de processus rÃ©utilisables\n",
    "# with ... as : le pool se ferme automatiquement Ã  la fin\n",
    "with Pool(processes=n_workers) as pool:\n",
    "    #\n",
    "    # pool.map() applique process_chunk Ã  chaque chunk\n",
    "    # - Les chunks sont distribuÃ©s aux processus disponibles\n",
    "    # - Chaque processus traite son chunk indÃ©pendamment\n",
    "    # - Les rÃ©sultats sont retournÃ©s dans l'ordre des chunks\n",
    "    #\n",
    "    results = pool.map(process_chunk, chunks)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 4 : Combiner les rÃ©sultats\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Chaque processus a calculÃ© la somme des carrÃ©s de son chunk\n",
    "# On additionne tous les rÃ©sultats partiels\n",
    "\n",
    "total = sum(results)\n",
    "print(f\"\\n RÃ©sultat total : {total:.2f}\")\n",
    "\n",
    "print(\"\\n PATTERN CLASSIQUE : Map-Reduce\")\n",
    "print(\"   1. SPLIT : Diviser les donnÃ©es en chunks\")\n",
    "print(\"   2. MAP : Traiter chaque chunk en parallÃ¨le\")\n",
    "print(\"   3. REDUCE : Combiner les rÃ©sultats (ici: sum)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiprocessing_starmap",
   "metadata": {},
   "source": [
    "### 5.2 starmap pour plusieurs arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starmap_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def process_with_params(data, multiplier, offset):\n",
    "    \"\"\"Fonction avec plusieurs paramÃ¨tres\"\"\"\n",
    "    return sum(data) * multiplier + offset\n",
    "\n",
    "# PrÃ©parer les arguments\n",
    "args_list = [\n",
    "    ([1, 2, 3], 2, 10),\n",
    "    ([4, 5, 6], 3, 20),\n",
    "    ([7, 8, 9], 4, 30),\n",
    "]\n",
    "\n",
    "with Pool(3) as pool:\n",
    "    results = pool.starmap(process_with_params, args_list)\n",
    "\n",
    "print(\"RÃ©sultats:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiprocessing_limits",
   "metadata": {},
   "source": [
    "### 5.3 Limites et prÃ©cautions\n",
    "\n",
    "| âš ï¸ Limite | Explication |\n",
    "|-----------|-------------|\n",
    "| **Overhead** | CrÃ©er des process prend du temps (~100ms) |\n",
    "| **SÃ©rialisation** | Les donnÃ©es sont copiÃ©es (pickle) |\n",
    "| **`if __name__ == \"__main__\"`** | Obligatoire sur Windows |\n",
    "| **MÃ©moire** | Chaque process a sa propre mÃ©moire |\n",
    "\n",
    "```python\n",
    "# âš ï¸ Toujours protÃ©ger avec if __name__ == \"__main__\"\n",
    "if __name__ == \"__main__\":\n",
    "    with Pool(4) as pool:\n",
    "        results = pool.map(my_func, data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asyncio",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. asyncio â€” I/O massivement parallÃ¨le\n",
    "\n",
    "> âœ… **IdÃ©al pour** : 100+ requÃªtes API, ingestion massive, crawling web\n",
    "> âŒ **Pas pour** : Calculs CPU-intensive\n",
    "\n",
    "### 6.1 Comprendre async/await\n",
    "\n",
    "`asyncio` utilise un modÃ¨le **single-thread non-bloquant**. Au lieu de crÃ©er plusieurs threads, un seul thread gÃ¨re plusieurs tÃ¢ches en **switchant** entre elles quand l'une attend.\n",
    "\n",
    "#### Comment Ã§a fonctionne ?\n",
    "\n",
    "```text\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                         asyncio : Single thread                          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  UN SEUL THREAD gÃ¨re plusieurs tÃ¢ches :                                 â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  TÃ¢che 1: [code]â”€â”€â–¶[await: attend API]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶[code]â”€â”€â–¶ done    â•‘\n",
    "â•‘                           â†“                              â†‘               â•‘\n",
    "â•‘                    Le thread switch                      â”‚               â•‘\n",
    "â•‘                           â†“                              â”‚               â•‘\n",
    "â•‘  TÃ¢che 2: [attend]â”€â”€â–¶[code]â”€â”€â–¶[await: attend DB]â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â–¶ done      â•‘\n",
    "â•‘                                      â†“                  â”‚               â•‘\n",
    "â•‘                               Le thread switch          â”‚               â•‘\n",
    "â•‘                                      â†“                  â”‚               â•‘\n",
    "â•‘  TÃ¢che 3: [attend]â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶[code]â”€â”€â–¶[await]â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â–¶ done      â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  â†’ Le thread ne reste jamais \"bloquÃ©\" Ã  attendre                        â•‘\n",
    "â•‘  â†’ DÃ¨s qu'une tÃ¢che attend, il passe Ã  une autre                        â•‘\n",
    "â•‘  â†’ TrÃ¨s efficace pour l'I/O : un seul thread peut gÃ©rer 1000+ requÃªtes  â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n",
    "### 6.2 Les mots-clÃ©s async/await\n",
    "\n",
    "| Mot-clÃ© | Ce que Ã§a fait | Quand l'utiliser |\n",
    "|---------|----------------|------------------|\n",
    "| `async def` | DÃ©clare une fonction **coroutine** | Fonctions qui font de l'I/O asynchrone |\n",
    "| `await` | **Attend** le rÃ©sultat d'une coroutine | Quand tu appelles une fonction async |\n",
    "| `asyncio.gather()` | Lance plusieurs coroutines **en parallÃ¨le** | Pour parallÃ©liser des tÃ¢ches |\n",
    "| `asyncio.run()` | Point d'entrÃ©e pour exÃ©cuter du code async | Dans un script (pas dans Jupyter) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asyncio_basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  asyncio : Comprendre async/await                                        â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION ASYNCHRONE (coroutine)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# \"async def\" crÃ©e une COROUTINE, pas une fonction normale\n",
    "# Une coroutine peut Ãªtre \"mise en pause\" avec await\n",
    "\n",
    "async def fetch_data(task_id):\n",
    "    \"\"\"\n",
    "    Simule une requÃªte API asynchrone.\n",
    "    \n",
    "    Dans la vraie vie, Ã§a serait :\n",
    "    - async with aiohttp.ClientSession() as session:\n",
    "    -     async with session.get(url) as response:\n",
    "    -         return await response.json()\n",
    "    \n",
    "    Args:\n",
    "        task_id: Identifiant de la tÃ¢che\n",
    "    \n",
    "    Returns:\n",
    "        RÃ©sultat simulÃ©\n",
    "    \"\"\"\n",
    "    print(f\"   TÃ¢che {task_id} : dÃ©but\")\n",
    "    \n",
    "    # await asyncio.sleep() = attente NON-BLOQUANTE\n",
    "    # Pendant que cette tÃ¢che attend, d'autres tÃ¢ches peuvent s'exÃ©cuter !\n",
    "    # C'est LA diffÃ©rence avec time.sleep() qui bloque tout\n",
    "    await asyncio.sleep(1)  # Simule 1s de latence rÃ©seau\n",
    "    \n",
    "    print(f\"   TÃ¢che {task_id} : terminÃ©e\")\n",
    "    return f\"result_{task_id}\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION PRINCIPALE ASYNCHRONE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Fonction principale qui orchestre les tÃ¢ches.\n",
    "    \n",
    "    asyncio.gather() lance plusieurs coroutines EN PARALLÃˆLE\n",
    "    et attend que TOUTES soient terminÃ©es.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"asyncio : Lancer 5 tÃ¢ches en parallÃ¨le\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # CrÃ©er une liste de coroutines (pas encore exÃ©cutÃ©es !)\n",
    "    # Note : fetch_data(i) retourne un objet coroutine, pas le rÃ©sultat\n",
    "    tasks = [fetch_data(i) for i in range(5)]\n",
    "    \n",
    "    print(f\"\\n {len(tasks)} tÃ¢ches crÃ©Ã©es\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # asyncio.gather() lance TOUTES les tÃ¢ches en parallÃ¨le\n",
    "    # - Les 5 tÃ¢ches dÃ©marrent en mÃªme temps\n",
    "    # - Chaque tÃ¢che attend 1s (await asyncio.sleep(1))\n",
    "    # - MAIS elles attendent en parallÃ¨le !\n",
    "    # - Temps total : ~1s au lieu de 5s\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    # *tasks \"dÃ©balle\" la liste : gather(task[0], task[1], task[2], ...)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EXÃ‰CUTION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Dans Jupyter : await main() fonctionne directement\n",
    "# Dans un script Python normal : asyncio.run(main())\n",
    "\n",
    "start = time.time()\n",
    "results = await main()  # Jupyter permet d'utiliser await directement\n",
    "total_time = time.time() - start\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RÃ‰SULTAT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\" Temps total : {total_time:.2f}s\")\n",
    "print(f\" RÃ©sultats : {results}\")\n",
    "print()\n",
    "print(\" EXPLICATION :\")\n",
    "print(\"   â†’ 5 tÃ¢ches de 1s chacune\")\n",
    "print(\"   â†’ En sÃ©quentiel : 5 Ã— 1s = 5s\")\n",
    "print(\"   â†’ En parallÃ¨le (asyncio) : ~1s (toutes en mÃªme temps)\")\n",
    "print()\n",
    "print(\"âš ï¸ IMPORTANT :\")\n",
    "print(\"   â†’ await asyncio.sleep() â‰  time.sleep()\")\n",
    "print(\"   â†’ asyncio.sleep() libÃ¨re le thread pour d'autres tÃ¢ches\")\n",
    "print(\"   â†’ time.sleep() bloque TOUT le programme\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asyncio_aiohttp",
   "metadata": {},
   "source": [
    "### 6.2 Exemple rÃ©el avec aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aiohttp_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation : pip install aiohttp\n",
    "import asyncio\n",
    "\n",
    "# Simulons aiohttp pour l'exemple (sans vraies requÃªtes)\n",
    "async def fetch_url(session, url):\n",
    "    \"\"\"Simule une requÃªte HTTP\"\"\"\n",
    "    await asyncio.sleep(0.1)  # Simule latence\n",
    "    return {\"url\": url, \"status\": 200}\n",
    "\n",
    "async def fetch_all_urls(urls):\n",
    "    \"\"\"Fetch toutes les URLs en parallÃ¨le\"\"\"\n",
    "    session = None  # En vrai : async with aiohttp.ClientSession() as session:\n",
    "    \n",
    "    tasks = [fetch_url(session, url) for url in urls]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return results\n",
    "\n",
    "# Simuler 20 URLs\n",
    "urls = [f\"https://api.example.com/data/{i}\" for i in range(20)]\n",
    "\n",
    "start = time.time()\n",
    "results = await fetch_all_urls(urls)\n",
    "print(f\" 20 requÃªtes en {time.time() - start:.2f}s\")\n",
    "print(f\" SuccÃ¨s : {len([r for r in results if isinstance(r, dict)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asyncio_semaphore",
   "metadata": {},
   "source": [
    "### 6.3 Semaphore : limiter les connexions simultanÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "semaphore_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Semaphore : Limiter le nombre de connexions simultanÃ©es                 â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# PROBLÃˆME : Tu veux faire 100 requÃªtes API, mais l'API limite Ã  5\n",
    "#            connexions simultanÃ©es (rate limiting).\n",
    "#\n",
    "# SOLUTION : Semaphore = un compteur qui limite les accÃ¨s concurrents\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ”¬ Semaphore : Limiter la concurrence\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CRÃ‰ER UN SEMAPHORE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Semaphore(5) = maximum 5 tÃ¢ches peuvent s'exÃ©cuter en mÃªme temps\n",
    "# Les autres attendent qu'une place se libÃ¨re\n",
    "\n",
    "MAX_CONCURRENT = 5\n",
    "semaphore = asyncio.Semaphore(MAX_CONCURRENT)\n",
    "\n",
    "print(f\"\\nğŸš¦ Semaphore crÃ©Ã© : max {MAX_CONCURRENT} tÃ¢ches simultanÃ©es\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION AVEC SEMAPHORE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "async def fetch_limited(task_id):\n",
    "    \"\"\"\n",
    "    Fait une requÃªte en respectant la limite de concurrence.\n",
    "    \n",
    "    async with semaphore :\n",
    "    - Tente d'acquÃ©rir le semaphore (dÃ©crÃ©mente le compteur)\n",
    "    - Si compteur = 0, ATTEND qu'une tÃ¢che se termine\n",
    "    - Ã€ la sortie du with, libÃ¨re le semaphore (incrÃ©mente le compteur)\n",
    "    \"\"\"\n",
    "    # async with semaphore : attend si dÃ©jÃ  5 tÃ¢ches en cours\n",
    "    async with semaphore:\n",
    "        print(f\"   TÃ¢che {task_id:2d} dÃ©marre (slot acquis)\")\n",
    "        await asyncio.sleep(0.5)  # Simule la requÃªte\n",
    "        print(f\"   TÃ¢che {task_id:2d} terminÃ©e (slot libÃ©rÃ©)\")\n",
    "        return task_id\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# EXÃ‰CUTION : 15 tÃ¢ches avec max 5 simultanÃ©es\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "async def main():\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(f\" Lancement de 15 tÃ¢ches (max {MAX_CONCURRENT} simultanÃ©es)\")\n",
    "    print(\"-\" * 40 + \"\\n\")\n",
    "    \n",
    "    # CrÃ©er 15 tÃ¢ches\n",
    "    tasks = [fetch_limited(i) for i in range(15)]\n",
    "    \n",
    "    # Lancer toutes les tÃ¢ches\n",
    "    # MAIS le semaphore limite Ã  5 simultanÃ©es !\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    return results\n",
    "\n",
    "start = time.time()\n",
    "results = await main()\n",
    "total_time = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RÃ‰SULTAT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Temps total : {total_time:.2f}s\")\n",
    "print(f\"TÃ¢ches complÃ©tÃ©es : {len(results)}\")\n",
    "\n",
    "print(\"\\n EXPLICATION :\")\n",
    "print(f\"   â†’ 15 tÃ¢ches de 0.5s chacune\")\n",
    "print(f\"   â†’ Max {MAX_CONCURRENT} simultanÃ©es = 3 vagues\")\n",
    "print(f\"   â†’ 3 vagues Ã— 0.5s = ~1.5s (au lieu de 7.5s sÃ©quentiel)\")\n",
    "print(\"\\n USE CASES :\")\n",
    "print(\"   â†’ Rate limiting API (ex: max 10 req/s)\")\n",
    "print(\"   â†’ Limiter les connexions DB\")\n",
    "print(\"   â†’ Ã‰viter de surcharger un service\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asyncio_when",
   "metadata": {},
   "source": [
    "### 6.4 Quand NE PAS utiliser asyncio\n",
    "\n",
    "| Situation | asyncio efficace ? | Alternative |\n",
    "|-----------|-------------------|-------------|\n",
    "| 100+ appels API | âœ… **Oui** | - |\n",
    "| Lecture S3/DB massives | âœ… **Oui** | - |\n",
    "| Calculs CPU | âŒ **Non** | ProcessPoolExecutor |\n",
    "| 5 requÃªtes simples | âŒ Overkill | ThreadPoolExecutor |\n",
    "| Code synchrone existant | âŒ Refactoring lourd | ThreadPoolExecutor |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dask",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Dask â€” Traiter des fichiers plus grands que la RAM\n",
    "\n",
    ">  **Le plus utile** quand tes donnÃ©es ne tiennent pas en mÃ©moire.\n",
    "\n",
    "### 7.1 Pourquoi Dask ?\n",
    "\n",
    "| ProblÃ¨me | Solution classique | Solution Dask |\n",
    "|----------|-------------------|---------------|\n",
    "| Fichier de 50 Go | MemoryError ! | âœ… TraitÃ© par chunks |\n",
    "| 1000 fichiers CSV | Boucle lente | âœ… ParallÃ©lisÃ© automatiquement |\n",
    "| Besoin d'apprendre une nouvelle API | ğŸ˜« | âœ… API quasi-identique Ã  Pandas |\n",
    "\n",
    "### 7.2 Comment Dask fonctionne ?\n",
    "\n",
    "```text\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    Dask : Lazy Evaluation + Partitions                   â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  Ã‰TAPE 1 : Lecture (LAZY - pas de chargement en mÃ©moire !)              â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  ddf = dd.read_csv(\"data/*.csv\")                                        â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  â†’ Dask SCANNE les fichiers (schÃ©ma, taille)                            â•‘\n",
    "â•‘  â†’ Mais NE CHARGE PAS les donnÃ©es !                                     â•‘\n",
    "â•‘  â†’ CrÃ©e un \"plan d'exÃ©cution\"                                           â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â•‘\n",
    "â•‘  â”‚ Partition 1 â”‚ â”‚ Partition 2 â”‚ â”‚ Partition 3 â”‚ â”‚ Partition 4 â”‚       â•‘\n",
    "â•‘  â”‚ (fichier 1) â”‚ â”‚ (fichier 2) â”‚ â”‚ (fichier 3) â”‚ â”‚ (fichier 4) â”‚       â•‘\n",
    "â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  Ã‰TAPE 2 : OpÃ©rations (LAZY - construit le plan)                        â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  result = ddf.groupby(\"col\").sum()   # Pas encore exÃ©cutÃ© !             â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  Ã‰TAPE 3 : compute() (EXÃ‰CUTION - traitement rÃ©el)                      â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                       â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  result.compute()                                                        â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘  â†’ Dask charge partition 1, la traite, la dÃ©charge                      â•‘\n",
    "â•‘  â†’ Puis partition 2, etc.                                               â•‘\n",
    "â•‘  â†’ Seule 1 partition en mÃ©moire Ã  la fois !                             â•‘\n",
    "â•‘  â†’ Utilise tous les CPUs pour traiter les partitions en parallÃ¨le       â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dask_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Dask DataFrame : Traiter des fichiers plus grands que la RAM            â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Installation : pip install \"dask[complete]\"\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 0 : CrÃ©er des fichiers de test\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"=\" * 60)\n",
    "print(\"CrÃ©ation des fichiers de test\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.makedirs(\"data/dask_demo\", exist_ok=True)\n",
    "\n",
    "for i in range(5):\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": range(i * 10000, (i + 1) * 10000),\n",
    "        \"category\": [f\"cat_{j % 5}\" for j in range(10000)],\n",
    "        \"amount\": [float(j % 1000) for j in range(10000)]\n",
    "    })\n",
    "    df.to_csv(f\"data/dask_demo/file_{i}.csv\", index=False)\n",
    "\n",
    "print(\"5 fichiers CSV crÃ©Ã©s (50,000 lignes au total)\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 1 : Lecture LAZY avec Dask\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ã‰tape 1 : Lecture avec Dask (LAZY)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# dd.read_csv() avec pattern glob : lit TOUS les fichiers correspondants\n",
    "# IMPORTANT : les donnÃ©es ne sont PAS chargÃ©es en mÃ©moire !\n",
    "ddf = dd.read_csv(\"data/dask_demo/*.csv\")\n",
    "\n",
    "print(f\"\\nType de l'objet : {type(ddf)}\")\n",
    "print(f\"Nombre de partitions : {ddf.npartitions}\")\n",
    "print(f\"   â†’ Chaque fichier = 1 partition\")\n",
    "print(f\"   â†’ Les partitions seront traitÃ©es indÃ©pendamment\")\n",
    "\n",
    "print(\"\\n SchÃ©ma des donnÃ©es (sans les charger) :\")\n",
    "print(ddf)\n",
    "\n",
    "print(\"\\nâš ï¸ IMPORTANT : Ã€ ce stade, les donnÃ©es ne sont PAS en mÃ©moire !\")\n",
    "print(\"   Dask a juste lu les en-tÃªtes et crÃ©Ã© un plan d'exÃ©cution.\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 2 : Pipeline de transformations (LAZY)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ã‰tape 2 : Pipeline de transformations (LAZY)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Toutes ces opÃ©rations sont LAZY : rien n'est calculÃ© !\n",
    "# Dask construit un graphe d'exÃ©cution (DAG) optimisÃ©\n",
    "\n",
    "result = (\n",
    "    ddf\n",
    "    # Filtrer : garder seulement les montants > 100\n",
    "    .query(\"amount > 100\")\n",
    "    \n",
    "    # CrÃ©er une nouvelle colonne\n",
    "    .assign(amount_doubled=ddf.amount * 2)\n",
    "    \n",
    "    # Grouper par catÃ©gorie et calculer la somme\n",
    "    .groupby(\"category\")\n",
    "    .amount.sum()\n",
    ")\n",
    "\n",
    "print(\"Pipeline dÃ©fini :\")\n",
    "print(\"   1. Filtrer amount > 100\")\n",
    "print(\"   2. CrÃ©er colonne amount_doubled\")\n",
    "print(\"   3. GroupBy category + sum\")\n",
    "print(\"\\n Toujours LAZY ! Rien n'est calculÃ©.\")\n",
    "print(f\"Type du rÃ©sultat : {type(result)}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Ã‰TAPE 3 : ExÃ©cution avec compute()\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Ã‰tape 3 : ExÃ©cution avec compute()\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# compute() dÃ©clenche l'exÃ©cution RÃ‰ELLE du pipeline\n",
    "# - Dask optimise le plan d'exÃ©cution\n",
    "# - Traite les partitions en parallÃ¨le (utilise tous les CPUs)\n",
    "# - Retourne un objet Pandas (DataFrame ou Series)\n",
    "final_result = result.compute()\n",
    "\n",
    "print(f\"\\n Temps d'exÃ©cution : {time.time() - start:.2f}s\")\n",
    "print(f\"Type du rÃ©sultat final : {type(final_result)}\")\n",
    "print(\"\\n RÃ©sultat :\")\n",
    "print(final_result)\n",
    "\n",
    "print(\"\\n CE QU'IL FAUT RETENIR :\")\n",
    "print(\"   â†’ dd.read_csv() : lecture lazy (pas de chargement)\")\n",
    "print(\"   â†’ OpÃ©rations (filter, groupby...) : construisent le plan\")\n",
    "print(\"   â†’ compute() : exÃ©cute le plan et retourne un Pandas\")\n",
    "print(\"   â†’ Une seule partition en mÃ©moire Ã  la fois !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dask_basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "# Lire TOUS les fichiers avec glob pattern (lazy !)\n",
    "ddf = dd.read_csv(\"data/dask_demo/*.csv\")\n",
    "\n",
    "print(\"Type:\", type(ddf))\n",
    "print(f\"Partitions: {ddf.npartitions}\")\n",
    "print(\"\\n Les donnÃ©es ne sont PAS encore chargÃ©es !\")\n",
    "print(ddf)  # Affiche le schÃ©ma, pas les donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dask_operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Dask (lazy)\n",
    "result = (\n",
    "    ddf\n",
    "    .filter(ddf.amount > 100)  # Filtrage\n",
    "    .assign(amount_doubled=ddf.amount * 2)  # Transformation\n",
    "    .groupby(\"category\")  # AgrÃ©gation\n",
    "    .amount.sum()\n",
    ")\n",
    "\n",
    "print(\"Pipeline dÃ©fini (lazy) :\")\n",
    "print(result)\n",
    "\n",
    "# ExÃ©cuter avec compute()\n",
    "start = time.time()\n",
    "final_result = result.compute()\n",
    "print(f\"\\n ExÃ©cution : {time.time() - start:.2f}s\")\n",
    "print(\"\\n RÃ©sultat :\")\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dask_vs_others",
   "metadata": {},
   "source": [
    "### 7.2 Dask vs Polars vs Spark\n",
    "\n",
    "| Aspect | Polars | Dask | Spark |\n",
    "|--------|--------|------|-------|\n",
    "| **Single machine** | â­â­â­ | â­â­ | â­ |\n",
    "| **Cluster** | âŒ | â­â­ | â­â­â­ |\n",
    "| **API** | Propre | Pandas-like | Propre |\n",
    "| **Setup** | Simple | Simple | Complexe |\n",
    "| **Vitesse (single node)** | â­â­â­ | â­â­ | â­ |\n",
    "| **Ã‰cosystÃ¨me** | Nouveau | Mature | TrÃ¨s mature |\n",
    "\n",
    "### 7.3 Quand utiliser Dask ?\n",
    "\n",
    "- âœ… Fichiers **> RAM** mais **< 100 Go**\n",
    "- âœ… Tu connais dÃ©jÃ  **Pandas**\n",
    "- âœ… Pas besoin d'un **cluster Spark**\n",
    "- âœ… Traitement **multi-fichiers**\n",
    "- âŒ Si single file < 10 Go â†’ utilise **Polars**\n",
    "- âŒ Si > 100 Go ou cluster â†’ utilise **Spark**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joblib",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. joblib â€” ParallÃ©lisation simple\n",
    "\n",
    ">  **Ultra-simple** â€” parfait pour parallÃ©liser une boucle rapidement\n",
    ">  TrÃ¨s utilisÃ© en **Data Science** (sklearn l'utilise en interne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joblib_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  joblib : ParallÃ©lisation ultra-simple                                   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# joblib est LA solution la plus simple pour parallÃ©liser une boucle\n",
    "# TrÃ¨s utilisÃ© en Data Science (scikit-learn l'utilise en interne)\n",
    "#\n",
    "# Installation : pip install joblib\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"joblib : ParallÃ©liser une boucle en 1 ligne\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FONCTION Ã€ PARALLÃ‰LISER\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def expensive_computation(x):\n",
    "    \"\"\"\n",
    "    Calcul coÃ»teux Ã  parallÃ©liser.\n",
    "    \n",
    "    Dans la vraie vie :\n",
    "    - EntraÃ®nement d'un modÃ¨le\n",
    "    - Transformation de fichier\n",
    "    - Calcul de features\n",
    "    \"\"\"\n",
    "    time.sleep(0.1)  # Simule un calcul de 100ms\n",
    "    return x ** 2\n",
    "\n",
    "# DonnÃ©es Ã  traiter\n",
    "data = list(range(20))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MÃ‰THODE 1 : SÃ‰QUENTIEL (classique)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n MÃ©thode 1 : List comprehension (sÃ©quentiel)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "start = time.time()\n",
    "results_seq = [expensive_computation(x) for x in data]\n",
    "seq_time = time.time() - start\n",
    "\n",
    "print(f\"Temps : {seq_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# MÃ‰THODE 2 : JOBLIB (parallÃ¨le)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nMÃ©thode 2 : joblib.Parallel (parallÃ¨le)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Parallel(n_jobs=-1)(delayed(func)(args) for args in data)               â•‘\n",
    "# â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "# â•‘                                                                          â•‘\n",
    "# â•‘  DÃ©composition :                                                         â•‘\n",
    "# â•‘                                                                          â•‘\n",
    "# â•‘  Parallel(n_jobs=-1)     â†’ CrÃ©e un pool de workers                      â•‘\n",
    "# â•‘                            n_jobs=-1 = utiliser TOUS les CPUs           â•‘\n",
    "# â•‘                            n_jobs=4 = utiliser 4 CPUs                   â•‘\n",
    "# â•‘                                                                          â•‘\n",
    "# â•‘  delayed(func)           â†’ Wrapper qui \"retarde\" l'exÃ©cution            â•‘\n",
    "# â•‘                            La fonction n'est pas appelÃ©e immÃ©diatement   â•‘\n",
    "# â•‘                                                                          â•‘\n",
    "# â•‘  delayed(func)(args)     â†’ PrÃ©pare l'appel func(args)                   â•‘\n",
    "# â•‘                            Retourne un \"callable\" diffÃ©rÃ©                â•‘\n",
    "# â•‘                                                                          â•‘\n",
    "# â•‘  for x in data           â†’ GÃ©nÃ¨re tous les appels diffÃ©rÃ©s              â•‘\n",
    "# â•‘                                                                          â•‘\n",
    "# â•‘  Le tout entre ()        â†’ Parallel distribue et exÃ©cute les appels     â•‘\n",
    "# â•‘                                                                          â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "results_parallel = Parallel(n_jobs=-1)(\n",
    "    delayed(expensive_computation)(x) for x in data\n",
    ")\n",
    "\n",
    "parallel_time = time.time() - start\n",
    "print(f\"Temps : {parallel_time:.2f}s\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# COMPARAISON\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARAISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"   SÃ©quentiel : {seq_time:.2f}s\")\n",
    "print(f\"   ParallÃ¨le  : {parallel_time:.2f}s\")\n",
    "print(f\"   Speedup    : {seq_time/parallel_time:.1f}x plus rapide !\")\n",
    "\n",
    "print(\"\\nğŸ’¡ SYNTAXE JOBLIB :\")\n",
    "print(\"   Parallel(n_jobs=-1)(delayed(func)(arg) for arg in data)\")\n",
    "print(\"         â”‚                   â”‚      â”‚         â”‚\")\n",
    "print(\"         â”‚                   â”‚      â”‚         â””â”€ DonnÃ©es Ã  traiter\")\n",
    "print(\"         â”‚                   â”‚      â””â”€ Argument de la fonction\")\n",
    "print(\"         â”‚                   â””â”€ Fonction Ã  parallÃ©liser\")\n",
    "print(\"         â””â”€ -1 = tous les CPUs\")\n",
    "\n",
    "print(\"\\nğŸ¯ QUAND UTILISER JOBLIB :\")\n",
    "print(\"   ParallÃ©liser une boucle simple\")\n",
    "print(\"   Data Science / ML (cross-validation, grid search)\")\n",
    "print(\"   Quand tu veux quelque chose qui marche vite\")\n",
    "print(\"   Pour du I/O massif (prÃ©fÃ¨re asyncio)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joblib_options",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def io_task(x):\n",
    "    time.sleep(0.1)\n",
    "    return x\n",
    "\n",
    "# Options utiles\n",
    "results = Parallel(\n",
    "    n_jobs=4,              # Nombre de workers\n",
    "    backend=\"threading\",   # \"threading\" pour I/O, \"loky\" (dÃ©faut) pour CPU\n",
    "    verbose=1              # Affiche la progression\n",
    ")(delayed(io_task)(x) for x in range(10))\n",
    "\n",
    "print(f\"\\n RÃ©sultats : {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decision_tree",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸŒ³ 9. Choisir la bonne technologie\n",
    "\n",
    "### RÃ©capitulatif\n",
    "\n",
    "| Outil | Type | GIL contournÃ© | ComplexitÃ© | Use case |\n",
    "|-------|------|---------------|------------|----------|\n",
    "| `ThreadPoolExecutor` | I/O | âŒ Non | â­ | < 20 requÃªtes/fichiers |\n",
    "| `ProcessPoolExecutor` | CPU | âœ… Oui | â­â­ | ETL, calculs |\n",
    "| `asyncio` | I/O | âŒ Non | â­â­â­ | 100+ requÃªtes API |\n",
    "| `joblib` | CPU/I/O | âœ… (loky) | â­ | Boucles simples, ML |\n",
    "| `Dask` | Big Data | âœ… Oui | â­â­ | Fichiers > RAM |\n",
    "\n",
    "### ğŸ–¼ï¸ Arbre de dÃ©cision visuel\n",
    "\n",
    "```text\n",
    "                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                    â”‚  Quel problÃ¨me? â”‚\n",
    "                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                             â”‚\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚                   â”‚                   â”‚\n",
    "         â–¼                   â–¼                   â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚CPU-boundâ”‚        â”‚I/O-boundâ”‚        â”‚Fichiers >RAMâ”‚\n",
    "    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                  â”‚                    â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”\n",
    "    â”‚         â”‚        â”‚         â”‚         â”‚         â”‚\n",
    "    â–¼         â–¼        â–¼         â–¼         â–¼         â–¼\n",
    " Simple?  Complex?  <20 req?  100+ req?  <100Go?  >100Go?\n",
    "    â”‚         â”‚        â”‚         â”‚         â”‚         â”‚\n",
    "    â–¼         â–¼        â–¼         â–¼         â–¼         â–¼\n",
    " joblib   Process   Thread    asyncio    Dask     Spark\n",
    "          Pool      Pool                        (mod 19)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Bonnes pratiques & Erreurs frÃ©quentes\n",
    "\n",
    "### âŒ Erreurs frÃ©quentes\n",
    "\n",
    "| Erreur | Pourquoi c'est faux | Solution |\n",
    "|--------|---------------------|----------|\n",
    "| Threading pour CPU | GIL bloque | `ProcessPoolExecutor` |\n",
    "| Async pour calculs | Pas de gain | `ProcessPoolExecutor` |\n",
    "| Pandas sur 50 Go | Crash RAM | Dask ou Polars streaming |\n",
    "| 100 workers pour 10 tÃ¢ches | Overhead inutile | Adapter au workload |\n",
    "| Pas de profiling | Optimise au hasard | Toujours profiler d'abord |\n",
    "| Oublier `if __name__` | Crash sur Windows | Toujours protÃ©ger |\n",
    "\n",
    "### âœ… Bonnes pratiques\n",
    "\n",
    "| Pratique | Pourquoi |\n",
    "|----------|----------|\n",
    "| **Profiler d'abord** | Identifier le vrai goulot |\n",
    "| **Ã‰crire en Parquet** | I/O plus rapide |\n",
    "| **Partitionner intelligemment** | Ã‰vite surcharge mÃ©moire |\n",
    "| **Tester avec peu de workers** | Puis augmenter progressivement |\n",
    "| **`if __name__ == \"__main__\"`** | Obligatoire pour multiprocessing |\n",
    "| **Utiliser `n_jobs=-1`** | Utilise tous les CPUs disponibles |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quiz de fin de module\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q1. Qu'est-ce que le GIL empÃªche en Python ?\n",
    "a) L'exÃ©cution de code Python  \n",
    "b) L'exÃ©cution simultanÃ©e de plusieurs threads Python  \n",
    "c) L'utilisation de la mÃ©moire  \n",
    "d) La lecture de fichiers\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Le GIL (Global Interpreter Lock) empÃªche l'exÃ©cution simultanÃ©e de plusieurs threads Python, les forÃ§ant Ã  s'exÃ©cuter en alternance.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q2. Pour un traitement CPU-intensive, quel outil utiliser ?\n",
    "a) `ThreadPoolExecutor`  \n",
    "b) `ProcessPoolExecutor`  \n",
    "c) `asyncio`  \n",
    "d) Tous sont Ã©quivalents\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” `ProcessPoolExecutor` contourne le GIL en utilisant des processus sÃ©parÃ©s, permettant une vraie parallÃ©lisation CPU.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q3. Quand utiliser `asyncio` ?\n",
    "a) Pour des calculs mathÃ©matiques complexes  \n",
    "b) Pour tÃ©lÃ©charger 100+ fichiers depuis une API  \n",
    "c) Pour trier un gros tableau  \n",
    "d) Pour compresser des fichiers\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” `asyncio` est idÃ©al pour l'I/O massivement parallÃ¨le (requÃªtes API, tÃ©lÃ©chargements). Les autres sont CPU-bound.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q4. Que fait `ddf.compute()` dans Dask ?\n",
    "a) DÃ©finit le pipeline  \n",
    "b) Affiche le schÃ©ma  \n",
    "c) DÃ©clenche l'exÃ©cution et retourne un DataFrame Pandas  \n",
    "d) Sauvegarde les donnÃ©es\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” `.compute()` dÃ©clenche l'exÃ©cution du pipeline lazy et retourne le rÃ©sultat sous forme de DataFrame Pandas.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q5. Que signifie `n_jobs=-1` dans joblib ?\n",
    "a) DÃ©sactive le parallÃ©lisme  \n",
    "b) Utilise un seul CPU  \n",
    "c) Utilise tous les CPUs disponibles  \n",
    "d) Erreur de configuration\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” `n_jobs=-1` indique Ã  joblib d'utiliser tous les CPUs disponibles sur la machine.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q6. Pourquoi `ThreadPoolExecutor` ne accÃ©lÃ¨re pas les calculs CPU ?\n",
    "a) Parce qu'il est mal implÃ©mentÃ©  \n",
    "b) Parce que le GIL force l'exÃ©cution sÃ©quentielle des threads Python  \n",
    "c) Parce qu'il utilise trop de mÃ©moire  \n",
    "d) Parce qu'il est obsolÃ¨te\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Le GIL empÃªche les threads Python de s'exÃ©cuter en parallÃ¨le. Pour du CPU-bound, il faut utiliser des processus.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q7. Pour traiter un fichier de 50 Go avec une API Pandas-like, quel outil choisir ?\n",
    "a) Pandas  \n",
    "b) Polars  \n",
    "c) Dask  \n",
    "d) asyncio\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” Dask permet de traiter des fichiers plus grands que la RAM avec une API similaire Ã  Pandas.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q8. Quelle est la premiÃ¨re Ã©tape avant d'optimiser du code ?\n",
    "a) Ajouter du multiprocessing  \n",
    "b) RÃ©Ã©crire en Rust  \n",
    "c) Profiler pour identifier le goulot d'Ã©tranglement  \n",
    "d) Utiliser asyncio\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” \"Premature optimization is the root of all evil\". Il faut d'abord mesurer pour savoir oÃ¹ optimiser.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mini-projet : Pipeline haute performance\n",
    "\n",
    "### Objectif\n",
    "Combiner plusieurs techniques pour crÃ©er un pipeline performant :\n",
    "- **ProcessPoolExecutor** pour transformation CPU-intensive\n",
    "- **Dask** pour agrÃ©gation\n",
    "- Export **Parquet**\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```text\n",
    "data/raw/*.csv\n",
    "      â”‚\n",
    "      â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ ProcessPoolExecutor â”‚  Transformation parallÃ¨le (CPU)\n",
    "â”‚  - Nettoyage        â”‚\n",
    "â”‚  - Feature eng.     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "data/intermediate/*.csv\n",
    "           â”‚\n",
    "           â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Dask DataFrame    â”‚  AgrÃ©gation (multi-fichiers)\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "data/processed/result.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup : crÃ©er les donnÃ©es de test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "os.makedirs(\"data/intermediate\", exist_ok=True)\n",
    "os.makedirs(\"data/processed\", exist_ok=True)\n",
    "\n",
    "# CrÃ©er 10 fichiers CSV (simule des logs)\n",
    "np.random.seed(42)\n",
    "categories = [\"web\", \"api\", \"db\", \"cache\", \"auth\"]\n",
    "statuses = [\"success\", \"error\", \"timeout\"]\n",
    "\n",
    "for i in range(10):\n",
    "    n_rows = 10000\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": pd.date_range(\"2024-01-01\", periods=n_rows, freq=\"s\"),\n",
    "        \"category\": np.random.choice(categories, n_rows),\n",
    "        \"status\": np.random.choice(statuses, n_rows, p=[0.8, 0.15, 0.05]),\n",
    "        \"response_time_ms\": np.random.exponential(100, n_rows),\n",
    "        \"bytes_sent\": np.random.randint(100, 10000, n_rows)\n",
    "    })\n",
    "    df.to_csv(f\"data/raw/logs_{i:02d}.csv\", index=False)\n",
    "\n",
    "print(\"10 fichiers CSV crÃ©Ã©s (100,000 lignes au total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_transform",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "def transform_file(filepath):\n",
    "    \"\"\"\n",
    "    Transformation CPU-intensive d'un fichier.\n",
    "    - Nettoyage\n",
    "    - Feature engineering\n",
    "    - Export intermÃ©diaire\n",
    "    \"\"\"\n",
    "    # Lire\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Nettoyage : filtrer les timeouts extrÃªmes\n",
    "    df = df[df[\"response_time_ms\"] < 10000]\n",
    "    \n",
    "    # Feature engineering (CPU-intensive)\n",
    "    df[\"response_time_log\"] = np.log1p(df[\"response_time_ms\"])\n",
    "    df[\"is_error\"] = (df[\"status\"] != \"success\").astype(int)\n",
    "    df[\"throughput\"] = df[\"bytes_sent\"] / (df[\"response_time_ms\"] + 1)\n",
    "    \n",
    "    # Extraction date\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"day_of_week\"] = df[\"timestamp\"].dt.dayofweek\n",
    "    \n",
    "    # Export intermÃ©diaire\n",
    "    output_path = filepath.replace(\"raw\", \"intermediate\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Liste des fichiers\n",
    "input_files = sorted(glob.glob(\"data/raw/*.csv\"))\n",
    "print(f\"ğŸ“ {len(input_files)} fichiers Ã  traiter\")\n",
    "\n",
    "# ============ TRANSFORMATION PARALLÃˆLE ============\n",
    "start = time.time()\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "    output_files = list(executor.map(transform_file, input_files))\n",
    "\n",
    "print(f\"\\nâ±ï¸ Transformation : {time.time() - start:.2f}s\")\n",
    "print(f\"{len(output_files)} fichiers transformÃ©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import time\n",
    "\n",
    "# ============ AGRÃ‰GATION AVEC DASK ============\n",
    "start = time.time()\n",
    "\n",
    "# Lire tous les fichiers intermÃ©diaires (lazy)\n",
    "ddf = dd.read_csv(\"data/intermediate/*.csv\")\n",
    "\n",
    "# Pipeline d'agrÃ©gation\n",
    "result = (\n",
    "    ddf\n",
    "    .groupby([\"category\", \"status\", \"hour\"])\n",
    "    .agg({\n",
    "        \"response_time_ms\": [\"mean\", \"max\", \"count\"],\n",
    "        \"bytes_sent\": \"sum\",\n",
    "        \"is_error\": \"sum\",\n",
    "        \"throughput\": \"mean\"\n",
    "    })\n",
    "    .compute()  # ExÃ©cution\n",
    ")\n",
    "\n",
    "# Aplatir les colonnes multi-index\n",
    "result.columns = ['_'.join(col).strip() for col in result.columns.values]\n",
    "result = result.reset_index()\n",
    "\n",
    "print(f\"â±ï¸ AgrÃ©gation Dask : {time.time() - start:.2f}s\")\n",
    "print(f\"\\nğŸ“Š RÃ©sultat : {len(result)} lignes\")\n",
    "print(result.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ EXPORT PARQUET ============\n",
    "result.to_parquet(\"data/processed/aggregated_logs.parquet\", index=False)\n",
    "print(\"âœ… RÃ©sultat exportÃ© : data/processed/aggregated_logs.parquet\")\n",
    "\n",
    "# VÃ©rification\n",
    "import os\n",
    "size_bytes = os.path.getsize(\"data/processed/aggregated_logs.parquet\")\n",
    "print(f\"ğŸ“¦ Taille : {size_bytes / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mini_project_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ RÃ‰SUMÃ‰ DU PIPELINE ============\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RÃ‰SUMÃ‰ DU PIPELINE HAUTE PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\"\"  \n",
    "1ï¸âƒ£ Input : 10 fichiers CSV (100K lignes)\n",
    "2ï¸âƒ£ Transformation : ProcessPoolExecutor (4 workers)\n",
    "   - Nettoyage\n",
    "   - Feature engineering\n",
    "3ï¸âƒ£ AgrÃ©gation : Dask DataFrame\n",
    "   - GroupBy multi-colonnes\n",
    "   - Aggregations multiples\n",
    "4ï¸âƒ£ Output : Parquet ({size_bytes / 1024:.1f} KB)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Ressources pour aller plus loin\n",
    "\n",
    "### ğŸŒ Documentation officielle\n",
    "- [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html) â€” Doc Python\n",
    "- [asyncio](https://docs.python.org/3/library/asyncio.html) â€” Doc Python\n",
    "- [Dask Documentation](https://docs.dask.org/) â€” Guide complet\n",
    "- [joblib](https://joblib.readthedocs.io/) â€” ParallÃ©lisation simple\n",
    "\n",
    "### ğŸ“– Articles & Tutoriels\n",
    "- [Real Python - Async IO](https://realpython.com/async-io-python/) â€” Tutoriel complet\n",
    "- [Speed Up Your Python Code](https://realpython.com/python-concurrency/) â€” Guide concurrence\n",
    "\n",
    "### ğŸ”§ Outils de profiling\n",
    "- [py-spy](https://github.com/benfred/py-spy) â€” Sampling profiler\n",
    "- [Scalene](https://github.com/plasma-umass/scalene) â€” CPU + mÃ©moire + GPU profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â¡ï¸ Prochaine Ã©tape\n",
    "\n",
    "Maintenant que tu maÃ®trises les techniques de performance en Python, passons au **traitement distribuÃ© Ã  grande Ã©chelle** avec Spark !\n",
    "\n",
    "ğŸ‘‰ **Module suivant : `19_pyspark_advanced`** â€” PySpark AvancÃ©\n",
    "\n",
    "Tu vas apprendre :\n",
    "- Architecture Spark (Driver, Executors)\n",
    "- RDDs et DataFrames Spark\n",
    "- Optimisations (partitioning, caching)\n",
    "- Spark sur Kubernetes\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ RÃ©capitulatif de ce module\n",
    "\n",
    "| Outil | Type | Quand l'utiliser |\n",
    "|-------|------|------------------|\n",
    "| `ThreadPoolExecutor` | I/O | < 20 requÃªtes/fichiers |\n",
    "| `ProcessPoolExecutor` | CPU | Calculs, transformations |\n",
    "| `asyncio` | I/O massif | 100+ requÃªtes API |\n",
    "| `joblib` | Simple | ParallÃ©liser une boucle |\n",
    "| `Dask` | Big Data | Fichiers > RAM, API Pandas |\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‰ **FÃ©licitations !** Tu as terminÃ© le module High Performance Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des fichiers temporaires (optionnel)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# DÃ©commenter pour nettoyer\n",
    "# for folder in [\"data/raw\", \"data/intermediate\", \"data/processed\", \"data/dask_demo\"]:\n",
    "#     if os.path.exists(folder):\n",
    "#         shutil.rmtree(folder)\n",
    "# print(\"ğŸ§¹ Fichiers temporaires supprimÃ©s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}