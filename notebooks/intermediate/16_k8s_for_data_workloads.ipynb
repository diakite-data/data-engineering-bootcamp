{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Kubernetes pour Workloads Data\n",
    "\n",
    "Bienvenue dans ce module oÃ¹ tu vas apprendre Ã  **dÃ©ployer et gÃ©rer des charges de travail data** sur Kubernetes. Tu dÃ©couvriras les patterns avancÃ©s pour les Jobs ETL, les bases de donnÃ©es, le scaling et le monitoring â€” le tout appliquÃ© au Data Engineering !\n",
    "\n",
    "---\n",
    "\n",
    "## PrÃ©requis\n",
    "\n",
    "| Niveau | CompÃ©tence |\n",
    "|--------|------------|\n",
    "| âœ… Requis | Avoir suivi le module `15_kubernetes_fundamentals` |\n",
    "| âœ… Requis | MaÃ®triser Pod, Deployment, Service, ConfigMap, Secret, PVC |\n",
    "| âœ… Requis | Savoir utiliser `kubectl` |\n",
    "| ğŸ’¡ RecommandÃ© | Cluster K8s local fonctionnel (Docker Desktop ou Minikube) |\n",
    "\n",
    "## Objectifs du module\n",
    "\n",
    "Ã€ la fin de ce module, tu seras capable de :\n",
    "\n",
    "- Comprendre ce qu'est un **workload data** et ses caractÃ©ristiques\n",
    "- Configurer des **Jobs et CronJobs avancÃ©s** pour des ETL robustes\n",
    "- DÃ©ployer des **bases de donnÃ©es avec StatefulSets**\n",
    "- Utiliser **Helm** pour dÃ©ployer des stacks data\n",
    "- GÃ©rer le **scaling et les ressources** pour des workloads gourmands\n",
    "- Mettre en place le **monitoring** de tes pipelines\n",
    "- Avoir un **aperÃ§u** de Spark et Airflow sur Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what_is_workload",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C'est quoi un \"Workload Data\" ?\n",
    "\n",
    "> ğŸ“Š Un **workload data** (charge de travail data) dÃ©signe toute tÃ¢che ou application dÃ©diÃ©e au **traitement, transformation, ou dÃ©placement de donnÃ©es**.\n",
    "\n",
    "En Data Engineering, les workloads typiques incluent :\n",
    "\n",
    "| Type | Description | Exemple concret |\n",
    "|------|-------------|----------------|\n",
    "| **Batch ETL** | Traitement planifiÃ© de donnÃ©es | Job Python qui transforme des CSV chaque nuit |\n",
    "| **Ingestion** | Chargement de donnÃ©es dans un systÃ¨me | CSV â†’ PostgreSQL, API â†’ Data Lake |\n",
    "| **Transformation** | Calculs et agrÃ©gations | Jointures, agrÃ©gations, nettoyage |\n",
    "| **Processing lourd** | Calculs intensifs en ressources | Feature engineering, ML preprocessing |\n",
    "| **Orchestration** | Coordination de plusieurs tÃ¢ches | DAG Airflow avec 10 Ã©tapes |\n",
    "\n",
    "### CaractÃ©ristiques des workloads data\n",
    "\n",
    "| CaractÃ©ristique | Explication |\n",
    "|-----------------|-------------|\n",
    "| **Ã‰phÃ©mÃ¨res** | S'exÃ©cutent puis se terminent (run-to-completion) |\n",
    "| **Gourmands** | Besoin de CPU et RAM significatifs |\n",
    "| **I/O intensifs** | Lecture/Ã©criture de grandes quantitÃ©s de donnÃ©es |\n",
    "| **PlanifiÃ©s** | Souvent exÃ©cutÃ©s selon un schedule (quotidien, horaire) |\n",
    "| **Reproductibles** | Doivent pouvoir Ãªtre relancÃ©s en cas d'Ã©chec |\n",
    "\n",
    "### Workloads data vs Applications classiques\n",
    "\n",
    "| Aspect | Application web | Workload data |\n",
    "|--------|-----------------|---------------|\n",
    "| DurÃ©e de vie | Continue (24/7) | Ã‰phÃ©mÃ¨re (minutes/heures) |\n",
    "| Ressource K8s | Deployment | Job / CronJob |\n",
    "| Scaling | Horizontal (replicas) | Vertical (plus de RAM/CPU) |\n",
    "| Ã‰tat final | Toujours running | Completed ou Failed |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "workload_info",
   "metadata": {},
   "source": [
    "> â„¹ï¸ **Le savais-tu ?**\n",
    ">\n",
    "> Le terme \"workload\" vient du monde des mainframes IBM des annÃ©es 1960, oÃ¹ il dÃ©signait la quantitÃ© de travail qu'une machine devait traiter.\n",
    ">\n",
    "> Aujourd'hui, dans le contexte cloud-native et Kubernetes, un workload dÃ©signe **toute unitÃ© de travail** dÃ©ployÃ©e sur un cluster : une app web, un job batch, un service de streaming, etc.\n",
    ">\n",
    "> Les \"data workloads\" sont simplement les workloads **spÃ©cialisÃ©s dans le traitement de donnÃ©es** !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k8s_recap",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Rappels Kubernetes essentiels\n",
    "\n",
    "Avant d'aller plus loin, voici un rÃ©capitulatif rapide des concepts K8s vus dans le module prÃ©cÃ©dent :\n",
    "\n",
    "| Ressource | RÃ´le | Usage Data Engineering |\n",
    "|-----------|------|------------------------|\n",
    "| **Pod** | UnitÃ© de base (1+ containers) | ExÃ©cute ton script ETL |\n",
    "| **Deployment** | GÃ¨re des replicas de pods | Apps long-running (API, workers) |\n",
    "| **Job** | TÃ¢che one-shot | ETL ponctuel, migration |\n",
    "| **CronJob** | Job planifiÃ© | ETL quotidien, rapport hebdo |\n",
    "| **Service** | Expose des pods | AccÃ¨s Ã  PostgreSQL, APIs |\n",
    "| **ConfigMap** | Config non sensible | Chemins, URLs, paramÃ¨tres |\n",
    "| **Secret** | Config sensible | Passwords, API keys |\n",
    "| **PVC** | Stockage persistant | DonnÃ©es PostgreSQL, fichiers |\n",
    "| **Namespace** | Isolation logique | Un namespace par projet |\n",
    "\n",
    "> ğŸ’¡ Si ces concepts ne sont pas clairs, revois le module `15_kubernetes_fundamentals` avant de continuer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jobs_advanced",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Jobs & CronJobs avancÃ©s\n",
    "\n",
    "Les **Jobs** et **CronJobs** sont les ressources K8s idÃ©ales pour les workloads data.\n",
    "\n",
    "### 2.1 Anatomie complÃ¨te d'un Job (ligne par ligne)\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  JOB : TÃ¢che qui s'exÃ©cute jusqu'Ã  complÃ©tion                            â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: batch/v1              # API pour les Jobs et CronJobs\n",
    "kind: Job                         # Type = Job (tÃ¢che one-shot)\n",
    "\n",
    "metadata:\n",
    "  name: etl-advanced-job          # Nom unique du job\n",
    "  namespace: data-pipeline        # Namespace cible\n",
    "  labels:\n",
    "    app: etl                      # Labels pour filtrer/monitorer\n",
    "    team: data-engineering\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  SPEC DU JOB : ParamÃ¨tres de comportement                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "spec:\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # COMPLETION ET PARALLÃ‰LISME\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  completions: 1                  # Nombre de succÃ¨s requis pour terminer\n",
    "                                  # Ex: 10 = le job doit rÃ©ussir 10 fois\n",
    "  \n",
    "  parallelism: 1                  # Combien de pods tournent EN MÃŠME TEMPS\n",
    "                                  # Ex: 3 = 3 pods en parallÃ¨le\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # GESTION DES Ã‰CHECS\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  backoffLimit: 3                 # Nombre de RETRIES avant Ã©chec dÃ©finitif\n",
    "                                  # Le pod sera relancÃ© 3 fois max si erreur\n",
    "  \n",
    "  activeDeadlineSeconds: 3600     # TIMEOUT global = 1 heure (3600 secondes)\n",
    "                                  # Si le job dÃ©passe ce temps â†’ Ã©chec\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # NETTOYAGE AUTOMATIQUE\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  ttlSecondsAfterFinished: 86400  # Auto-suppression 24h aprÃ¨s completion\n",
    "                                  # Sans Ã§a, les vieux jobs s'accumulent !\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # TEMPLATE DU POD (ce qui va Ãªtre exÃ©cutÃ©)\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: etl                  # Labels du pod (pour monitoring)\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: etl                 # Nom du container\n",
    "        image: my-etl:1.0         # Image Docker\n",
    "        \n",
    "        # Ressources (TOUJOURS les dÃ©finir pour les Jobs !)\n",
    "        resources:\n",
    "          requests:               # Minimum garanti\n",
    "            memory: \"512Mi\"       # 512 Mo de RAM minimum\n",
    "            cpu: \"500m\"           # 0.5 CPU minimum\n",
    "          limits:                 # Maximum autorisÃ©\n",
    "            memory: \"1Gi\"         # 1 Go max (OOMKilled si dÃ©passÃ©)\n",
    "            cpu: \"1000m\"          # 1 CPU max (throttled si dÃ©passÃ©)\n",
    "      \n",
    "      restartPolicy: OnFailure    # Que faire si le container crashe ?\n",
    "                                  # OnFailure = relancer le pod\n",
    "                                  # Never = ne pas relancer (backoffLimit gÃ¨re les retries)\n",
    "```\n",
    "\n",
    "### ParamÃ¨tres clÃ©s expliquÃ©s\n",
    "\n",
    "| ParamÃ¨tre | Que fait-il ? | Valeur typique ETL |\n",
    "|-----------|---------------|-------------------|\n",
    "| `completions` | Combien de succÃ¨s pour terminer le job ? | `1` (une seule exÃ©cution) |\n",
    "| `parallelism` | Combien de pods en mÃªme temps ? | `1` Ã  `N` selon le use case |\n",
    "| `backoffLimit` | Combien de tentatives en cas d'Ã©chec ? | `3` Ã  `5` |\n",
    "| `activeDeadlineSeconds` | Timeout global du job | `1800`-`7200` (30min-2h) |\n",
    "| `ttlSecondsAfterFinished` | Quand supprimer le job terminÃ© ? | `86400` (24h) |\n",
    "| `restartPolicy` | Que faire si crash ? | `OnFailure` ou `Never` |\n",
    "\n",
    "### 2.2 Pattern : Traitement parallÃ¨le de fichiers\n",
    "\n",
    "Imaginons que tu dois traiter **10 fichiers** avec **3 pods en parallÃ¨le** :\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  JOB PARALLÃˆLE : Chaque pod traite un fichier diffÃ©rent                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: batch/v1\n",
    "kind: Job\n",
    "metadata:\n",
    "  name: etl-parallel\n",
    "  namespace: data-pipeline\n",
    "\n",
    "spec:\n",
    "  completions: 10                 # 10 fichiers Ã  traiter = 10 succÃ¨s requis\n",
    "  parallelism: 3                  # 3 pods tournent en mÃªme temps\n",
    "  \n",
    "  completionMode: Indexed         # â­ IMPORTANT : Mode indexÃ©\n",
    "                                  # Chaque pod reÃ§oit un index unique (0, 1, 2, ..., 9)\n",
    "                                  # Permet de savoir quel fichier traiter !\n",
    "  \n",
    "  template:\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: etl\n",
    "        image: my-etl:1.0\n",
    "        command: [\"python\", \"etl.py\"]\n",
    "        \n",
    "        env:\n",
    "        # â­ RÃ©cupÃ©rer l'index du pod (0, 1, 2, ..., 9)\n",
    "        - name: FILE_INDEX\n",
    "          valueFrom:\n",
    "            fieldRef:             # RÃ©fÃ©rence Ã  un champ du pod lui-mÃªme\n",
    "              fieldPath: metadata.annotations['batch.kubernetes.io/job-completion-index']\n",
    "        \n",
    "        # Dans ton code Python :\n",
    "        # index = os.environ['FILE_INDEX']  # \"0\", \"1\", \"2\", ...\n",
    "        # file = f\"data_{index}.csv\"        # data_0.csv, data_1.csv, ...\n",
    "        \n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"200m\"\n",
    "          limits:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "      \n",
    "      restartPolicy: OnFailure\n",
    "```\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  FONCTIONNEMENT DU JOB PARALLÃˆLE INDEXÃ‰                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   completions: 10     parallelism: 3                           â”‚\n",
    "â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   Vague 1 : Pod-0, Pod-1, Pod-2 (en parallÃ¨le)                â”‚\n",
    "â”‚   Vague 2 : Pod-3, Pod-4, Pod-5 (quand les prÃ©cÃ©dents finissent)â”‚\n",
    "â”‚   Vague 3 : Pod-6, Pod-7, Pod-8                                â”‚\n",
    "â”‚   Vague 4 : Pod-9                                               â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â”‚   Chaque pod sait quel fichier traiter grÃ¢ce Ã  FILE_INDEX !    â”‚\n",
    "â”‚                                                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 2.3 CronJob avancÃ© (ligne par ligne)\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  CRONJOB : Job qui se lance automatiquement selon un schedule            â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: batch/v1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: etl-daily\n",
    "  namespace: data-pipeline\n",
    "\n",
    "spec:\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # SCHEDULE CRON (quand lancer le job ?)\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  #\n",
    "  # Format cron : minute heure jour-du-mois mois jour-de-semaine\n",
    "  #               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minute (0-59)\n",
    "  #               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ heure (0-23)\n",
    "  #               â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ jour du mois (1-31)\n",
    "  #               â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ mois (1-12)\n",
    "  #               â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ jour de semaine (0-6, 0=dimanche)\n",
    "  #               â”‚ â”‚ â”‚ â”‚ â”‚\n",
    "  #               * * * * *\n",
    "  #\n",
    "  schedule: \"0 2 * * *\"           # Tous les jours Ã  2h00 du matin\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # POLITIQUE DE CONCURRENCE\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  concurrencyPolicy: Forbid       # Que faire si le job prÃ©cÃ©dent tourne encore ?\n",
    "                                  #\n",
    "                                  # Forbid  = NE PAS lancer le nouveau (skip)\n",
    "                                  # Allow   = Lancer quand mÃªme (risque de doublons)\n",
    "                                  # Replace = Tuer l'ancien, lancer le nouveau\n",
    "                                  #\n",
    "                                  # â†’ Pour ETL : Forbid est le plus sÃ»r !\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # HISTORIQUE DES JOBS\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  successfulJobsHistoryLimit: 3   # Garder les 3 derniers jobs rÃ©ussis\n",
    "  failedJobsHistoryLimit: 2       # Garder les 2 derniers jobs Ã©chouÃ©s\n",
    "                                  # â†’ Permet de voir les logs des runs prÃ©cÃ©dentes\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # TOLÃ‰RANCE AU RETARD\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  startingDeadlineSeconds: 300    # Si le scheduler a du retard, combien de\n",
    "                                  # secondes de tolÃ©rance ? (ici 5 minutes)\n",
    "                                  # AprÃ¨s ce dÃ©lai, le job est considÃ©rÃ© \"manquÃ©\"\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # TEMPLATE DU JOB (ce qui est crÃ©Ã© Ã  chaque exÃ©cution)\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      backoffLimit: 3             # 3 retries si Ã©chec\n",
    "      activeDeadlineSeconds: 3600 # Timeout 1h\n",
    "      \n",
    "      template:\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: etl\n",
    "            image: my-etl:1.0\n",
    "            \n",
    "            # Charger la config depuis un ConfigMap\n",
    "            envFrom:\n",
    "            - configMapRef:\n",
    "                name: etl-config  # Toutes les clÃ©s du ConfigMap\n",
    "                                  # deviennent des variables d'environnement\n",
    "            \n",
    "            resources:\n",
    "              requests:\n",
    "                memory: \"512Mi\"\n",
    "                cpu: \"500m\"\n",
    "              limits:\n",
    "                memory: \"1Gi\"\n",
    "                cpu: \"1000m\"\n",
    "          \n",
    "          restartPolicy: OnFailure\n",
    "```\n",
    "\n",
    "### Expressions cron courantes\n",
    "\n",
    "| Expression | Signification | Use case |\n",
    "|------------|---------------|----------|\n",
    "| `0 2 * * *` | Tous les jours Ã  2h00 | ETL quotidien |\n",
    "| `0 */6 * * *` | Toutes les 6 heures | Synchro frÃ©quente |\n",
    "| `*/15 * * * *` | Toutes les 15 minutes | Near real-time |\n",
    "| `0 0 * * 0` | Tous les dimanches Ã  minuit | Rapport hebdo |\n",
    "| `0 8 1 * *` | Le 1er de chaque mois Ã  8h | Rapport mensuel |\n",
    "| `0 9-17 * * 1-5` | Toutes les heures de 9h Ã  17h, lun-ven | Heures de bureau |\n",
    "\n",
    "### 2.4 Commandes utiles pour les Jobs\n",
    "\n",
    "```bash\n",
    "# Lister les Jobs\n",
    "kubectl get jobs -n data-pipeline\n",
    "\n",
    "# Lister les CronJobs\n",
    "kubectl get cronjobs -n data-pipeline\n",
    "\n",
    "# Voir les dÃ©tails d'un CronJob\n",
    "kubectl describe cronjob etl-daily -n data-pipeline\n",
    "\n",
    "# â­ DÃ©clencher MANUELLEMENT un CronJob (pour tester)\n",
    "kubectl create job test-etl --from=cronjob/etl-daily -n data-pipeline\n",
    "\n",
    "# Voir les logs du job\n",
    "kubectl logs job/test-etl -n data-pipeline\n",
    "\n",
    "# Supprimer un job\n",
    "kubectl delete job test-etl -n data-pipeline\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "job_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Commandes utiles pour les Jobs\n",
    "\n",
    "echo \"=== Lister les Jobs ===\"\n",
    "kubectl get jobs\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Lister les CronJobs ===\"\n",
    "kubectl get cronjobs\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== DÃ©clencher manuellement un CronJob ===\"\n",
    "echo \"kubectl create job test-etl --from=cronjob/etl-daily\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Voir les logs d'un Job ===\"\n",
    "echo \"kubectl logs job/etl-job\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statefulsets",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. StatefulSets : Bases de donnÃ©es sur Kubernetes\n",
    "\n",
    "Les **StatefulSets** sont conÃ§us pour les applications **stateful** (avec Ã©tat) comme les bases de donnÃ©es.\n",
    "\n",
    "### 3.1 Deployment vs StatefulSet : comprendre la diffÃ©rence\n",
    "\n",
    "| Aspect | Deployment | StatefulSet |\n",
    "|--------|------------|-------------|\n",
    "| **Nom des pods** | AlÃ©atoire (`app-7d8f9...`) | Stable et ordonnÃ© (`app-0`, `app-1`, `app-2`) |\n",
    "| **Stockage** | PVC partagÃ© ou Ã©phÃ©mÃ¨re | PVC **unique par pod** (persistant) |\n",
    "| **Ordre de dÃ©marrage** | Tous en parallÃ¨le | SÃ©quentiel : 0 â†’ 1 â†’ 2 |\n",
    "| **Ordre d'arrÃªt** | Tous en parallÃ¨le | Inverse : 2 â†’ 1 â†’ 0 |\n",
    "| **RÃ©seau** | Service ClusterIP classique | Headless Service (DNS par pod) |\n",
    "| **Usage typique** | Apps stateless (API, web) | Bases de donnÃ©es, caches, queues |\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  DEPLOYMENT vs STATEFULSET                                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  DEPLOYMENT (stateless)          STATEFULSET (stateful)                â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚  â”‚ app-7d8f9.. â”‚                â”‚   app-0     â”‚ â† IdentitÃ© stable      â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚                               â”‚\n",
    "â”‚  â”‚ app-x2k4m.. â”‚                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   PVC-0     â”‚ â† Volume dÃ©diÃ©         â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\n",
    "â”‚  â”‚ app-p9n3q.. â”‚                                                       â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚                                  â”‚   app-1     â”‚                        â”‚\n",
    "â”‚  Tous partagent le mÃªme PVC     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                        â”‚\n",
    "â”‚  (ou pas de PVC)                       â”‚                               â”‚\n",
    "â”‚                                  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                        â”‚\n",
    "â”‚                                  â”‚   PVC-1     â”‚                        â”‚\n",
    "â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 3.2 PostgreSQL avec StatefulSet (ligne par ligne)\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  STATEFULSET : Pour applications avec Ã©tat (bases de donnÃ©es)            â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: apps/v1\n",
    "kind: StatefulSet\n",
    "metadata:\n",
    "  name: postgres\n",
    "  namespace: data-pipeline\n",
    "\n",
    "spec:\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # CONFIGURATION STATEFULSET\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  serviceName: postgres-headless  # â­ OBLIGATOIRE : Nom du Headless Service\n",
    "                                  # Permet le DNS : postgres-0.postgres-headless.data-pipeline.svc\n",
    "  \n",
    "  replicas: 1                     # Nombre de replicas (1 pour PostgreSQL simple)\n",
    "                                  # Pour un cluster PostgreSQL : 3 (1 primary + 2 replicas)\n",
    "  \n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: postgres               # SÃ©lecteur pour identifier les pods\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # TEMPLATE DU POD\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: postgres\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: postgres\n",
    "        image: postgres:16        # Image officielle PostgreSQL\n",
    "        \n",
    "        ports:\n",
    "        - containerPort: 5432     # Port PostgreSQL standard\n",
    "          name: postgres\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # VARIABLES D'ENVIRONNEMENT POSTGRESQL\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        env:\n",
    "        - name: POSTGRES_USER\n",
    "          value: \"de_user\"        # Utilisateur de la base\n",
    "        \n",
    "        - name: POSTGRES_PASSWORD\n",
    "          valueFrom:\n",
    "            secretKeyRef:\n",
    "              name: postgres-secret  # â­ Mot de passe depuis un Secret\n",
    "              key: password          # (ne jamais mettre en clair !)\n",
    "        \n",
    "        - name: POSTGRES_DB\n",
    "          value: \"de_db\"          # Nom de la base crÃ©Ã©e au dÃ©marrage\n",
    "        \n",
    "        - name: PGDATA\n",
    "          value: \"/var/lib/postgresql/data/pgdata\"  # OÃ¹ stocker les donnÃ©es\n",
    "                                  # /pgdata est un sous-dossier pour Ã©viter\n",
    "                                  # les problÃ¨mes de permissions avec le volume\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # MONTAGE DU VOLUME\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        volumeMounts:\n",
    "        - name: postgres-data     # Nom du volume (doit matcher volumeClaimTemplates)\n",
    "          mountPath: /var/lib/postgresql/data  # OÃ¹ monter dans le container\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # RESSOURCES\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        resources:\n",
    "          requests:\n",
    "            memory: \"256Mi\"\n",
    "            cpu: \"250m\"\n",
    "          limits:\n",
    "            memory: \"512Mi\"\n",
    "            cpu: \"500m\"\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # VOLUME CLAIM TEMPLATES : Un PVC par pod\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # C'est LA diffÃ©rence majeure avec un Deployment !\n",
    "  # Chaque pod obtient son propre PVC persistant :\n",
    "  # - postgres-0 â†’ postgres-data-postgres-0\n",
    "  # - postgres-1 â†’ postgres-data-postgres-1 (si replicas > 1)\n",
    "  #\n",
    "  volumeClaimTemplates:\n",
    "  - metadata:\n",
    "      name: postgres-data         # Nom du volume (rÃ©fÃ©rencÃ© dans volumeMounts)\n",
    "    spec:\n",
    "      accessModes: [\"ReadWriteOnce\"]  # Un seul pod peut Ã©crire Ã  la fois\n",
    "      resources:\n",
    "        requests:\n",
    "          storage: 5Gi            # Taille du disque\n",
    "      # storageClassName: fast-ssd  # Optionnel : type de stockage\n",
    "\n",
    "---\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  HEADLESS SERVICE : Permet le DNS par pod                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# \n",
    "# Un Headless Service (clusterIP: None) ne fait PAS de load balancing.\n",
    "# Il permet d'accÃ©der directement Ã  chaque pod via DNS :\n",
    "# - postgres-0.postgres-headless.data-pipeline.svc.cluster.local\n",
    "# - postgres-1.postgres-headless.data-pipeline.svc.cluster.local\n",
    "#\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres-headless         # Ce nom doit matcher spec.serviceName\n",
    "  namespace: data-pipeline\n",
    "spec:\n",
    "  clusterIP: None                 # HEADLESS = pas d'IP de cluster\n",
    "  selector:\n",
    "    app: postgres\n",
    "  ports:\n",
    "  - port: 5432\n",
    "    name: postgres\n",
    "\n",
    "---\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  SERVICE NORMAL : Pour accÃ©der facilement Ã  PostgreSQL                   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#\n",
    "# Ce service classique permet d'accÃ©der Ã  PostgreSQL via :\n",
    "# - postgres.data-pipeline.svc.cluster.local:5432\n",
    "# - Ou simplement \"postgres\" si tu es dans le mÃªme namespace\n",
    "#\n",
    "apiVersion: v1\n",
    "kind: Service\n",
    "metadata:\n",
    "  name: postgres\n",
    "  namespace: data-pipeline\n",
    "spec:\n",
    "  selector:\n",
    "    app: postgres\n",
    "  ports:\n",
    "  - port: 5432\n",
    "    targetPort: 5432\n",
    "```\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  COMMENT ACCÃ‰DER Ã€ POSTGRESQL DANS LE CLUSTER                           â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Depuis le mÃªme namespace :                                            â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚\n",
    "â”‚  Host: postgres                                                         â”‚\n",
    "â”‚  Port: 5432                                                             â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Depuis un autre namespace :                                           â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚\n",
    "â”‚  Host: postgres.data-pipeline.svc.cluster.local                        â”‚\n",
    "â”‚  Port: 5432                                                             â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Connection string Python (SQLAlchemy) :                               â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚\n",
    "â”‚  postgresql://de_user:password@postgres:5432/de_db                     â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 3.3 Le Secret pour le mot de passe\n",
    "\n",
    "```yaml\n",
    "# postgres-secret.yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: postgres-secret\n",
    "  namespace: data-pipeline\n",
    "type: Opaque\n",
    "stringData:                       # stringData = K8s encode en base64 automatiquement\n",
    "  password: \"SuperSecretPassword123\"\n",
    "```\n",
    "\n",
    "### âš ï¸ Recommandation production\n",
    "\n",
    "> **En production**, prÃ©fÃ¨re les **services managÃ©s** :\n",
    "> - AWS RDS / Aurora\n",
    "> - GCP Cloud SQL  \n",
    "> - Azure Database for PostgreSQL\n",
    ">\n",
    "> **Pourquoi ?**\n",
    "> - Haute disponibilitÃ© automatique\n",
    "> - Backups automatiques\n",
    "> - Patches de sÃ©curitÃ©\n",
    "> - Scaling facile\n",
    ">\n",
    "> **Les StatefulSets sont parfaits pour :**\n",
    "> - DÃ©veloppement local\n",
    "> - Tests d'intÃ©gration\n",
    "> - Environnements oÃ¹ tu veux tout contrÃ´ler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helm",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Helm : Package Manager Kubernetes\n",
    "\n",
    "**Helm** est le gestionnaire de packages pour Kubernetes â€” comme `apt` pour Ubuntu ou `pip` pour Python.\n",
    "\n",
    "### 4.1 Pourquoi Helm ?\n",
    "\n",
    "| Sans Helm | Avec Helm |\n",
    "|-----------|----------|\n",
    "| 10+ fichiers YAML Ã  gÃ©rer | 1 commande `helm install` |\n",
    "| Copier-coller entre environnements | `values.yaml` pour personnaliser |\n",
    "| Pas de versioning | Rollback facile |\n",
    "| Mise Ã  jour manuelle | `helm upgrade` |\n",
    "\n",
    "### 4.2 Concepts clÃ©s\n",
    "\n",
    "| Concept | Description | Analogie |\n",
    "|---------|-------------|----------|\n",
    "| **Chart** | Package K8s (templates + values) | Un package `.deb` ou `.rpm` |\n",
    "| **Release** | Instance dÃ©ployÃ©e d'un chart | Une installation du package |\n",
    "| **Repository** | Magasin de charts | Un `apt repository` |\n",
    "| **Values** | Configuration personnalisÃ©e | Un fichier de config |\n",
    "\n",
    "### 4.3 Installation de Helm\n",
    "\n",
    "```bash\n",
    "# macOS\n",
    "brew install helm\n",
    "\n",
    "# Linux\n",
    "curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n",
    "\n",
    "# VÃ©rifier\n",
    "helm version\n",
    "```\n",
    "\n",
    "### 4.4 Commandes essentielles\n",
    "\n",
    "```bash\n",
    "# Ajouter un repository\n",
    "helm repo add bitnami https://charts.bitnami.com/bitnami\n",
    "helm repo update\n",
    "\n",
    "# Rechercher un chart\n",
    "helm search repo postgresql\n",
    "\n",
    "# Voir les valeurs par dÃ©faut\n",
    "helm show values bitnami/postgresql\n",
    "\n",
    "# Installer un chart\n",
    "helm install my-postgres bitnami/postgresql \\\n",
    "  --namespace data \\\n",
    "  --create-namespace \\\n",
    "  --set auth.postgresPassword=mypassword\n",
    "\n",
    "# Lister les releases\n",
    "helm list -A\n",
    "\n",
    "# Mettre Ã  jour\n",
    "helm upgrade my-postgres bitnami/postgresql --set auth.postgresPassword=newpassword\n",
    "\n",
    "# Rollback\n",
    "helm rollback my-postgres 1\n",
    "\n",
    "# DÃ©sinstaller\n",
    "helm uninstall my-postgres -n data\n",
    "```\n",
    "\n",
    "### 4.5 Fichier values.yaml personnalisÃ©\n",
    "\n",
    "```yaml\n",
    "# postgres-values.yaml\n",
    "auth:\n",
    "  postgresPassword: \"de_password\"\n",
    "  database: \"de_db\"\n",
    "\n",
    "primary:\n",
    "  resources:\n",
    "    requests:\n",
    "      memory: \"256Mi\"\n",
    "      cpu: \"250m\"\n",
    "    limits:\n",
    "      memory: \"512Mi\"\n",
    "      cpu: \"500m\"\n",
    "  persistence:\n",
    "    size: 5Gi\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Installer avec le fichier values\n",
    "helm install my-postgres bitnami/postgresql -f postgres-values.yaml\n",
    "```\n",
    "\n",
    "### 4.6 Charts utiles pour Data Engineering\n",
    "\n",
    "| Chart | Repository | Usage |\n",
    "|-------|------------|-------|\n",
    "| `bitnami/postgresql` | bitnami | Base de donnÃ©es relationnelle |\n",
    "| `bitnami/redis` | bitnami | Cache, broker de messages |\n",
    "| `minio/minio` | minio | Object storage S3-compatible |\n",
    "| `apache-airflow/airflow` | apache-airflow | Orchestration (module 25) |\n",
    "| `bitnami/spark` | bitnami | Spark cluster (module 19) |\n",
    "\n",
    "```bash\n",
    "# Ajouter les repos utiles\n",
    "helm repo add bitnami https://charts.bitnami.com/bitnami\n",
    "helm repo add minio https://charts.min.io/\n",
    "helm repo add apache-airflow https://airflow.apache.org\n",
    "helm repo update\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helm_commands",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# VÃ©rifier l'installation de Helm\n",
    "echo \"=== Version Helm ===\"\n",
    "helm version --short 2>/dev/null || echo \"Helm non installÃ©\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Repositories configurÃ©s ===\"\n",
    "helm repo list 2>/dev/null || echo \"Aucun repo configurÃ©\"\n",
    "\n",
    "echo \"\"\n",
    "echo \"=== Releases dÃ©ployÃ©es ===\"\n",
    "helm list -A 2>/dev/null || echo \"Aucune release\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "storage",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Storage avancÃ© pour Workloads Data\n",
    "\n",
    "Le stockage est **critique** pour les workloads data. Voici les patterns recommandÃ©s.\n",
    "\n",
    "### 5.1 Quel stockage pour quel usage ?\n",
    "\n",
    "| Usage | Type de volume | CaractÃ©ristiques |\n",
    "|-------|----------------|------------------|\n",
    "| **Base de donnÃ©es** | PVC (StatefulSet) | Persistant, rapide (SSD) |\n",
    "| **Fichiers input** | PVC ou S3/MinIO | ExternalisÃ© si possible |\n",
    "| **Fichiers output** | PVC ou S3/MinIO | ExternalisÃ© pour durabilitÃ© |\n",
    "| **DonnÃ©es temporaires** | `emptyDir` | SupprimÃ© quand le pod meurt |\n",
    "| **Cache ultra-rapide** | `emptyDir` (Memory) | RAM disk, trÃ¨s rapide mais volatile |\n",
    "\n",
    "### 5.2 emptyDir : stockage Ã©phÃ©mÃ¨re (ligne par ligne)\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  VOLUMES Ã‰PHÃ‰MÃˆRES : DonnÃ©es temporaires pendant l'exÃ©cution             â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: etl-with-temp-storage\n",
    "spec:\n",
    "  containers:\n",
    "  - name: etl\n",
    "    image: my-etl:1.0\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # MONTAGE DES VOLUMES DANS LE CONTAINER\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    volumeMounts:\n",
    "    - name: tmp-data              # Volume pour fichiers temporaires\n",
    "      mountPath: /tmp/processing  # Accessible dans le container ici\n",
    "    \n",
    "    - name: cache                 # Volume cache en RAM\n",
    "      mountPath: /cache           # Accessible dans le container ici\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # DÃ‰FINITION DES VOLUMES\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  volumes:\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # EMPTYDIR SUR DISQUE\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # - CrÃ©Ã© quand le pod dÃ©marre\n",
    "  # - SupprimÃ© quand le pod meurt (mÃªme si le container restart)\n",
    "  # - StockÃ© sur le disque du node\n",
    "  # - Parfait pour : fichiers intermÃ©diaires, dÃ©compression, etc.\n",
    "  #\n",
    "  - name: tmp-data\n",
    "    emptyDir: {}                  # {} = valeurs par dÃ©faut (disque du node)\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # EMPTYDIR EN RAM (ULTRA-RAPIDE)\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # - StockÃ© en RAM (pas sur disque)\n",
    "  # - TRÃˆS rapide (lecture/Ã©criture)\n",
    "  # - ATTENTION : compte dans la limite mÃ©moire du pod !\n",
    "  # - Parfait pour : cache, donnÃ©es frÃ©quemment accÃ©dÃ©es\n",
    "  #\n",
    "  - name: cache\n",
    "    emptyDir:\n",
    "      medium: Memory              # â­ StockÃ© en RAM au lieu du disque\n",
    "      sizeLimit: 256Mi            # Limite de taille (compte dans limits.memory !)\n",
    "```\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  EMPTYDIR : CYCLE DE VIE                                                â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Pod dÃ©marre                                                            â”‚\n",
    "â”‚       â”‚                                                                 â”‚\n",
    "â”‚       â–¼                                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\n",
    "â”‚  â”‚  emptyDir   â”‚ â† Volume crÃ©Ã© (vide)                                  â”‚\n",
    "â”‚  â”‚   crÃ©Ã©      â”‚                                                        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\n",
    "â”‚       â”‚                                                                 â”‚\n",
    "â”‚       â–¼                                                                 â”‚\n",
    "â”‚  Container Ã©crit des fichiers...                                        â”‚\n",
    "â”‚       â”‚                                                                 â”‚\n",
    "â”‚       â–¼                                                                 â”‚\n",
    "â”‚  Container crash et redÃ©marre                                           â”‚\n",
    "â”‚       â”‚                                                                 â”‚\n",
    "â”‚       â–¼                                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\n",
    "â”‚  â”‚  DonnÃ©es    â”‚ â† Les donnÃ©es sont PRÃ‰SERVÃ‰ES                         â”‚\n",
    "â”‚  â”‚  intactes   â”‚   (tant que le POD existe)                            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\n",
    "â”‚       â”‚                                                                 â”‚\n",
    "â”‚       â–¼                                                                 â”‚\n",
    "â”‚  Pod supprimÃ©                                                           â”‚\n",
    "â”‚       â”‚                                                                 â”‚\n",
    "â”‚       â–¼                                                                 â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚\n",
    "â”‚  â”‚  emptyDir   â”‚ â† Volume SUPPRIMÃ‰ dÃ©finitivement                      â”‚\n",
    "â”‚  â”‚  supprimÃ©   â”‚                                                        â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 5.3 PVC avec StorageClass (ligne par ligne)\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  PVC : Demande de stockage persistant                                    â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: etl-data-pvc\n",
    "  namespace: data-pipeline\n",
    "\n",
    "spec:\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # STORAGE CLASS (quel type de stockage ?)\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # La StorageClass dÃ©finit :\n",
    "  # - Le type de disque (SSD, HDD)\n",
    "  # - Le provisioner (AWS EBS, GCP PD, Azure Disk, etc.)\n",
    "  # - Les options de rÃ©plication\n",
    "  #\n",
    "  # Pour voir les StorageClasses disponibles :\n",
    "  # kubectl get storageclasses\n",
    "  #\n",
    "  storageClassName: standard      # \"standard\" = souvent le dÃ©faut\n",
    "                                  # \"fast-ssd\", \"premium-ssd\" selon ton cloud\n",
    "                                  # Omit = utilise la StorageClass par dÃ©faut\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # MODE D'ACCÃˆS\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  accessModes:\n",
    "    - ReadWriteOnce               # RWO = 1 seul node peut monter en Ã©criture\n",
    "                                  # ReadWriteMany (RWX) = plusieurs nodes\n",
    "                                  # ReadOnlyMany (ROX) = plusieurs en lecture seule\n",
    "                                  #\n",
    "                                  # âš ï¸ RWX n'est pas supportÃ© par tous les providers !\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # TAILLE DEMANDÃ‰E\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 10Gi               # 10 Go de stockage\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Commandes utiles pour le storage\n",
    "kubectl get storageclasses                    # Voir les classes disponibles\n",
    "kubectl get pvc -n data-pipeline              # Voir les PVC\n",
    "kubectl get pv                                # Voir les PV (volumes provisionnÃ©s)\n",
    "kubectl describe pvc etl-data-pvc -n data-pipeline  # DÃ©tails d'un PVC\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Scaling & Gestion des ressources\n",
    "\n",
    "Les workloads data sont souvent **gourmands en ressources**. Voici comment les gÃ©rer.\n",
    "\n",
    "### 6.1 Requests vs Limits : comprendre la diffÃ©rence\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  requests:                       # MINIMUM garanti\n",
    "    memory: \"512Mi\"               # K8s rÃ©serve 512 Mo pour ce pod\n",
    "    cpu: \"500m\"                   # K8s rÃ©serve 0.5 CPU pour ce pod\n",
    "  limits:                         # MAXIMUM autorisÃ©\n",
    "    memory: \"2Gi\"                 # Si dÃ©passÃ© â†’ OOMKilled (pod tuÃ©)\n",
    "    cpu: \"2000m\"                  # Si dÃ©passÃ© â†’ Throttling (ralenti)\n",
    "```\n",
    "\n",
    "| Type | Ce que Ã§a fait | ConsÃ©quence si dÃ©passÃ© |\n",
    "|------|----------------|------------------------|\n",
    "| **requests** | Minimum **garanti** par K8s | Pod reste en `Pending` si pas assez de ressources sur le cluster |\n",
    "| **limits.memory** | Maximum de RAM | **OOMKilled** : le pod est tuÃ© immÃ©diatement |\n",
    "| **limits.cpu** | Maximum de CPU | **Throttling** : le pod est ralenti (pas tuÃ©) |\n",
    "\n",
    "### 6.2 HorizontalPodAutoscaler (ligne par ligne)\n",
    "\n",
    "Le **HPA** scale automatiquement le nombre de pods selon les mÃ©triques.\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  HPA : Scaling automatique basÃ© sur les mÃ©triques                        â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: autoscaling/v2\n",
    "kind: HorizontalPodAutoscaler\n",
    "metadata:\n",
    "  name: etl-worker-hpa\n",
    "  namespace: data-pipeline\n",
    "\n",
    "spec:\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # CIBLE : Quel Deployment scaler ?\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  scaleTargetRef:\n",
    "    apiVersion: apps/v1\n",
    "    kind: Deployment              # Type de ressource Ã  scaler\n",
    "    name: etl-worker              # Nom du Deployment\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # LIMITES DE SCALING\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  minReplicas: 2                  # Minimum 2 pods (mÃªme si charge faible)\n",
    "  maxReplicas: 10                 # Maximum 10 pods (limite les coÃ»ts)\n",
    "  \n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  # MÃ‰TRIQUES DE DÃ‰CISION\n",
    "  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  metrics:\n",
    "  # MÃ©trique CPU\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: cpu\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 70    # Si CPU > 70% en moyenne â†’ scale UP\n",
    "                                  # Si CPU < 70% en moyenne â†’ scale DOWN\n",
    "  \n",
    "  # MÃ©trique MÃ©moire\n",
    "  - type: Resource\n",
    "    resource:\n",
    "      name: memory\n",
    "      target:\n",
    "        type: Utilization\n",
    "        averageUtilization: 80    # Si RAM > 80% en moyenne â†’ scale UP\n",
    "```\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  FONCTIONNEMENT DU HPA                                                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  CPU actuel : 30%     CPU cible : 70%     Replicas : 2                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚\n",
    "â”‚  â†’ Charge faible, on reste Ã  2 replicas (minReplicas)                  â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  CPU actuel : 85%     CPU cible : 70%     Replicas : 2                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚\n",
    "â”‚  â†’ CPU > 70% ! HPA ajoute des pods â†’ 3 replicas                       â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  CPU actuel : 90%     CPU cible : 70%     Replicas : 3                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚\n",
    "â”‚  â†’ Toujours > 70% ! HPA ajoute encore â†’ 4 replicas                    â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  CPU actuel : 60%     CPU cible : 70%     Replicas : 4                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 â”‚\n",
    "â”‚  â†’ CPU < 70%, on attend un peu (cooldown)                              â”‚\n",
    "â”‚  â†’ Puis HPA rÃ©duit â†’ 3 replicas                                        â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### 6.3 ResourceQuota par namespace (ligne par ligne)\n",
    "\n",
    "Limite les ressources consommables par namespace (utile pour les Ã©quipes).\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  RESOURCEQUOTA : Limites globales par namespace                          â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "apiVersion: v1\n",
    "kind: ResourceQuota\n",
    "metadata:\n",
    "  name: data-team-quota\n",
    "  namespace: data-pipeline        # S'applique Ã  ce namespace uniquement\n",
    "\n",
    "spec:\n",
    "  hard:                           # Limites \"dures\" (ne peuvent pas Ãªtre dÃ©passÃ©es)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # LIMITES CPU\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    requests.cpu: \"10\"            # Total des requests CPU dans le namespace\n",
    "                                  # = maximum 10 CPU rÃ©servÃ©s\n",
    "    limits.cpu: \"20\"              # Total des limits CPU\n",
    "                                  # = maximum 20 CPU utilisables\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # LIMITES MÃ‰MOIRE\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    requests.memory: \"20Gi\"       # Total des requests mÃ©moire = 20 Go\n",
    "    limits.memory: \"40Gi\"         # Total des limits mÃ©moire = 40 Go\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # LIMITES D'OBJETS\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    pods: \"50\"                    # Maximum 50 pods dans ce namespace\n",
    "    persistentvolumeclaims: \"10\"  # Maximum 10 PVC\n",
    "    services: \"20\"                # Maximum 20 services\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Voir les quotas et leur utilisation\n",
    "kubectl describe resourcequota data-team-quota -n data-pipeline\n",
    "```\n",
    "\n",
    "### 6.4 Node Affinity : placer les pods sur des nodes spÃ©cifiques\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  NODE AFFINITY : ContrÃ´ler oÃ¹ les pods sont placÃ©s                       â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "spec:\n",
    "  affinity:\n",
    "    nodeAffinity:\n",
    "      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "      # RÃˆGLE OBLIGATOIRE (required)\n",
    "      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "      # Le pod NE SERA PAS schedulÃ© si aucun node ne match\n",
    "      #\n",
    "      requiredDuringSchedulingIgnoredDuringExecution:\n",
    "        nodeSelectorTerms:\n",
    "        - matchExpressions:\n",
    "          - key: node-type        # Label du node\n",
    "            operator: In          # In, NotIn, Exists, DoesNotExist, Gt, Lt\n",
    "            values:\n",
    "            - high-memory         # Nodes avec label \"node-type=high-memory\"\n",
    "            - high-cpu            # Ou \"node-type=high-cpu\"\n",
    "      \n",
    "      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "      # RÃˆGLE PRÃ‰FÃ‰RÃ‰E (preferred)\n",
    "      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "      # Le scheduler PRÃ‰FÃˆRE ces nodes, mais peut en choisir d'autres\n",
    "      #\n",
    "      preferredDuringSchedulingIgnoredDuringExecution:\n",
    "      - weight: 100               # Poids de la prÃ©fÃ©rence (1-100)\n",
    "        preference:\n",
    "          matchExpressions:\n",
    "          - key: zone\n",
    "            operator: In\n",
    "            values:\n",
    "            - eu-west-1a          # PrÃ©fÃ¨re les nodes dans eu-west-1a\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Voir les labels des nodes\n",
    "kubectl get nodes --show-labels\n",
    "\n",
    "# Ajouter un label Ã  un node\n",
    "kubectl label nodes node-1 node-type=high-memory\n",
    "```\n",
    "\n",
    "### 6.5 Taints & Tolerations : rÃ©server des nodes\n",
    "\n",
    "```bash\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TAINT : \"Marquer\" un node pour le rÃ©server\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Seuls les pods avec la Toleration correspondante peuvent y aller\n",
    "\n",
    "kubectl taint nodes node-1 workload=data:NoSchedule\n",
    "#                          â–²           â–²\n",
    "#                          â”‚           â””â”€â”€ Effet : NoSchedule, PreferNoSchedule, NoExecute\n",
    "#                          â””â”€â”€ ClÃ©=Valeur\n",
    "```\n",
    "\n",
    "```yaml\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  TOLERATION : Permet au pod d'aller sur un node \"taintÃ©\"                 â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "spec:\n",
    "  tolerations:\n",
    "  - key: \"workload\"               # ClÃ© du taint\n",
    "    operator: \"Equal\"             # Equal (clÃ©=valeur) ou Exists (clÃ© prÃ©sente)\n",
    "    value: \"data\"                 # Valeur du taint\n",
    "    effect: \"NoSchedule\"          # Effet Ã  tolÃ©rer\n",
    "```\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  TAINTS & TOLERATIONS : EXEMPLE                                         â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Node-1 (taint: workload=data:NoSchedule)                              â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”‚\n",
    "â”‚     â”‚                                                                   â”‚\n",
    "â”‚     â”œâ”€â”€ Pod ETL (avec toleration) âœ… â†’ Peut Ãªtre schedulÃ©              â”‚\n",
    "â”‚     â”‚                                                                   â”‚\n",
    "â”‚     â””â”€â”€ Pod Web (sans toleration) âŒ â†’ Ne peut PAS Ãªtre schedulÃ©       â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  Node-2 (pas de taint)                                                 â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚\n",
    "â”‚     â”‚                                                                   â”‚\n",
    "â”‚     â”œâ”€â”€ Pod ETL âœ… â†’ Peut Ãªtre schedulÃ©                                â”‚\n",
    "â”‚     â”‚                                                                   â”‚\n",
    "â”‚     â””â”€â”€ Pod Web âœ… â†’ Peut Ãªtre schedulÃ©                                â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚  â†’ Les nodes \"taintÃ©s\" sont RÃ‰SERVÃ‰S aux pods data !                   â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monitoring",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Monitoring & ObservabilitÃ©\n",
    "\n",
    "Surveiller tes workloads data est essentiel pour dÃ©tecter les problÃ¨mes.\n",
    "\n",
    "### 7.1 MÃ©triques de base avec kubectl\n",
    "\n",
    "```bash\n",
    "# CPU/RAM des pods (nÃ©cessite metrics-server)\n",
    "kubectl top pods\n",
    "kubectl top pods -n data-pipeline\n",
    "\n",
    "# CPU/RAM des nodes\n",
    "kubectl top nodes\n",
    "\n",
    "# Events (problÃ¨mes rÃ©cents)\n",
    "kubectl get events --sort-by='.lastTimestamp'\n",
    "kubectl get events -n data-pipeline\n",
    "```\n",
    "\n",
    "### 7.2 Prometheus + Grafana (aperÃ§u)\n",
    "\n",
    "La stack **Prometheus + Grafana** est le standard pour le monitoring K8s :\n",
    "\n",
    "| Outil | RÃ´le |\n",
    "|-------|------|\n",
    "| **Prometheus** | Collecte et stocke les mÃ©triques |\n",
    "| **Grafana** | Visualisation et dashboards |\n",
    "| **AlertManager** | Alertes (Slack, email, PagerDuty) |\n",
    "\n",
    "```bash\n",
    "# Installation rapide via Helm\n",
    "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n",
    "helm install monitoring prometheus-community/kube-prometheus-stack \\\n",
    "  --namespace monitoring \\\n",
    "  --create-namespace\n",
    "```\n",
    "\n",
    "### 7.3 Logs\n",
    "\n",
    "```bash\n",
    "# Logs d'un pod\n",
    "kubectl logs <pod>\n",
    "kubectl logs -f <pod>           # Follow\n",
    "kubectl logs -p <pod>           # Previous (aprÃ¨s crash)\n",
    "kubectl logs --tail=100 <pod>   # 100 derniÃ¨res lignes\n",
    "\n",
    "# Logs d'un Job\n",
    "kubectl logs job/<job-name>\n",
    "\n",
    "# Logs de tous les pods d'un label\n",
    "kubectl logs -l app=etl --all-containers\n",
    "```\n",
    "\n",
    "### 7.4 Centralisation des logs\n",
    "\n",
    "Pour les environnements de production, centralise les logs avec :\n",
    "\n",
    "| Solution | Description |\n",
    "|----------|-------------|\n",
    "| **ELK Stack** | Elasticsearch + Logstash + Kibana |\n",
    "| **Loki + Grafana** | Solution lÃ©gÃ¨re (recommandÃ©e) |\n",
    "| **Cloud native** | CloudWatch (AWS), Cloud Logging (GCP) |\n",
    "\n",
    "### 7.5 Dashboards utiles pour Data Engineering\n",
    "\n",
    "| Dashboard | MÃ©triques |\n",
    "|-----------|----------|\n",
    "| K8s Cluster Overview | CPU, RAM, pods par node |\n",
    "| Job Success Rate | Jobs succeeded vs failed |\n",
    "| Pod Resource Usage | Consommation vs requests/limits |\n",
    "| PVC Usage | Espace disque utilisÃ© |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spark_airflow_preview",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. AperÃ§u : Spark & Airflow sur Kubernetes\n",
    "\n",
    "> âš ï¸ **Note** : Cette section est un **aperÃ§u** pour te donner une vision d'ensemble.\n",
    "> - Spark sera dÃ©taillÃ© dans les **modules 19-22**\n",
    "> - Airflow sera dÃ©taillÃ© dans le **module 25**\n",
    "\n",
    "### 8.1 Spark on Kubernetes (aperÃ§u)\n",
    "\n",
    "**Pourquoi Spark sur K8s ?**\n",
    "- Pas besoin de cluster YARN ou Mesos dÃ©diÃ©\n",
    "- Ã‰lasticitÃ© native (pods crÃ©Ã©s Ã  la demande)\n",
    "- Parfait pour jobs ETL batch Ã©phÃ©mÃ¨res\n",
    "- IntÃ©gration cloud-native\n",
    "\n",
    "**Architecture simplifiÃ©e :**\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  spark-submit   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚\n",
    "         â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Driver Pod    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Executor Pod   â”‚ x N\n",
    "â”‚   (coordonne)   â”‚         â”‚  (traitement)   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Exemple de commande (aperÃ§u) :**\n",
    "\n",
    "```bash\n",
    "# Tu verras Ã§a en dÃ©tail dans le module 19\n",
    "spark-submit \\\n",
    "  --master k8s://https://<K8S_API> \\\n",
    "  --deploy-mode cluster \\\n",
    "  --conf spark.kubernetes.container.image=spark:3.5 \\\n",
    "  --conf spark.executor.instances=3 \\\n",
    "  local:///opt/spark/jobs/etl.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 8.2 Airflow on Kubernetes (aperÃ§u)\n",
    "\n",
    "**Pourquoi Airflow sur K8s ?**\n",
    "- ScalabilitÃ© des workers\n",
    "- Isolation parfaite des tÃ¢ches\n",
    "- **KubernetesExecutor** : 1 tÃ¢che = 1 pod\n",
    "\n",
    "**Architectures possibles :**\n",
    "\n",
    "| Executor | Description | Usage |\n",
    "|----------|-------------|-------|\n",
    "| LocalExecutor | Tout dans 1 pod | Dev/test |\n",
    "| CeleryExecutor | Workers via Redis | Production classique |\n",
    "| **KubernetesExecutor** | 1 pod par tÃ¢che | Production K8s native |\n",
    "\n",
    "**DÃ©ploiement via Helm (aperÃ§u) :**\n",
    "\n",
    "```bash\n",
    "# Tu verras Ã§a en dÃ©tail dans le module 25\n",
    "helm repo add apache-airflow https://airflow.apache.org\n",
    "helm install airflow apache-airflow/airflow \\\n",
    "  --namespace airflow \\\n",
    "  --set executor=KubernetesExecutor\n",
    "```\n",
    "\n",
    "**KubernetesPodOperator (aperÃ§u) :**\n",
    "\n",
    "```python\n",
    "# ExÃ©cuter une tÃ¢che dans un pod K8s dÃ©diÃ©\n",
    "from airflow.providers.cncf.kubernetes.operators.pod import KubernetesPodOperator\n",
    "\n",
    "etl_task = KubernetesPodOperator(\n",
    "    task_id=\"etl_task\",\n",
    "    namespace=\"data-pipeline\",\n",
    "    image=\"my-etl:1.0\",\n",
    "    cmds=[\"python\", \"etl.py\"],\n",
    "    name=\"etl-pod\",\n",
    ")\n",
    "```\n",
    "\n",
    "> ğŸ’¡ AprÃ¨s avoir terminÃ© les modules Spark (19-22), reviens sur cette section pour mieux comprendre l'intÃ©gration K8s !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "errors_best_practices",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Erreurs frÃ©quentes & Bonnes pratiques\n",
    "\n",
    "### âŒ Erreurs frÃ©quentes\n",
    "\n",
    "| Erreur | Cause | Solution |\n",
    "|--------|-------|----------|\n",
    "| `OOMKilled` | MÃ©moire insuffisante | Augmenter `limits.memory` |\n",
    "| `DeadlineExceeded` | Job trop long | Augmenter `activeDeadlineSeconds` |\n",
    "| `Pending` (Job) | Pas de ressources disponibles | VÃ©rifier quotas, rÃ©duire requests |\n",
    "| `CrashLoopBackOff` | App plante au dÃ©marrage | `kubectl logs <pod>` |\n",
    "| `ImagePullBackOff` | Image/registry incorrects | VÃ©rifier image, imagePullSecrets |\n",
    "| PVC `Pending` | Pas de PV disponible | VÃ©rifier StorageClass |\n",
    "| Job jamais nettoyÃ© | Pas de TTL | Ajouter `ttlSecondsAfterFinished` |\n",
    "\n",
    "### âœ… Bonnes pratiques pour workloads data\n",
    "\n",
    "| Pratique | Pourquoi |\n",
    "|----------|----------|\n",
    "| **Toujours dÃ©finir resources** | Ã‰vite OOM et problÃ¨mes de scheduling |\n",
    "| **TTL sur les Jobs** | Nettoyage automatique |\n",
    "| **Logs externalisÃ©s** | Ne pas dÃ©pendre des logs K8s |\n",
    "| **ConfigMaps pour paramÃ¨tres** | Pas de hardcoding |\n",
    "| **Secrets pour credentials** | SÃ©curitÃ© |\n",
    "| **Labels systÃ©matiques** | Filtrage et monitoring |\n",
    "| **Namespace par projet** | Isolation, quotas |\n",
    "| **Healthchecks** | K8s sait si l'app est prÃªte |\n",
    "\n",
    "### Labels recommandÃ©s pour workloads data\n",
    "\n",
    "```yaml\n",
    "metadata:\n",
    "  labels:\n",
    "    app: etl-pipeline\n",
    "    component: transform    # extract, transform, load\n",
    "    env: production\n",
    "    team: data-engineering\n",
    "    version: \"1.2.0\"\n",
    "    schedule: daily         # Pour les CronJobs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiz",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Quiz de fin de module\n",
    "\n",
    "RÃ©ponds aux questions suivantes pour vÃ©rifier tes acquis.\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q1. Qu'est-ce qu'un \"workload data\" ?\n",
    "a) Une application web qui affiche des donnÃ©es  \n",
    "b) Une charge de travail dÃ©diÃ©e au traitement, transformation ou dÃ©placement de donnÃ©es  \n",
    "c) Un dashboard de visualisation  \n",
    "d) Une base de donnÃ©es\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Un workload data est une tÃ¢che liÃ©e au traitement de donnÃ©es : ETL, transformations, ingestion, etc.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q2. Quel paramÃ¨tre permet de nettoyer automatiquement un Job terminÃ© aprÃ¨s 24h ?\n",
    "a) `backoffLimit: 24`  \n",
    "b) `ttlSecondsAfterFinished: 86400`  \n",
    "c) `activeDeadlineSeconds: 86400`  \n",
    "d) `cleanupAfter: 24h`\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” `ttlSecondsAfterFinished: 86400` supprime automatiquement le Job 24h aprÃ¨s sa completion.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q3. Quelle est la diffÃ©rence principale entre Deployment et StatefulSet ?\n",
    "a) Deployment est plus rÃ©cent  \n",
    "b) StatefulSet garantit une identitÃ© stable et un stockage persistant par pod  \n",
    "c) Deployment ne supporte pas les volumes  \n",
    "d) StatefulSet est uniquement pour les bases NoSQL\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” StatefulSet donne une identitÃ© stable (pod-0, pod-1) et un PVC par pod, idÃ©al pour les bases de donnÃ©es.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q4. Qu'est-ce que Helm ?\n",
    "a) Un outil de monitoring  \n",
    "b) Un package manager pour Kubernetes  \n",
    "c) Un orchestrateur de containers  \n",
    "d) Un systÃ¨me de logs\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : b** â€” Helm est le package manager de K8s, permettant d'installer des applications complexes avec une seule commande.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q5. Que signifie l'erreur `OOMKilled` ?\n",
    "a) Le pod a Ã©tÃ© tuÃ© par l'administrateur  \n",
    "b) L'image Docker est corrompue  \n",
    "c) Le container a dÃ©passÃ© sa limite de mÃ©moire  \n",
    "d) Le rÃ©seau est indisponible\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” OOMKilled (Out Of Memory Killed) signifie que le container a dÃ©passÃ© `limits.memory` et a Ã©tÃ© tuÃ© par K8s.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q6. Quel executor Airflow crÃ©e un pod K8s par tÃ¢che ?\n",
    "a) LocalExecutor  \n",
    "b) CeleryExecutor  \n",
    "c) KubernetesExecutor  \n",
    "d) SequentialExecutor\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” Le KubernetesExecutor lance chaque tÃ¢che Airflow dans un pod K8s dÃ©diÃ©.\n",
    "\n",
    "</details>\n",
    "\n",
    "---\n",
    "\n",
    "### â“ Q7. Quelle QoS class offre la meilleure protection contre l'Ã©viction ?\n",
    "a) BestEffort  \n",
    "b) Burstable  \n",
    "c) Guaranteed  \n",
    "d) Protected\n",
    "\n",
    "<details><summary>ğŸ’¡ Voir la rÃ©ponse</summary>\n",
    "\n",
    "âœ… **RÃ©ponse : c** â€” Les pods Guaranteed (requests = limits) sont les derniers Ã  Ãªtre Ã©vincÃ©s en cas de pression sur les ressources.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mini-projet : Pipeline ETL Python sur Kubernetes\n",
    "\n",
    "### Objectif\n",
    "DÃ©ployer un pipeline ETL **batch** complet sur Kubernetes, sans Spark (Python/pandas), avec :\n",
    "- **MinIO** : stockage des fichiers source (S3-compatible)\n",
    "- **PostgreSQL** : destination des donnÃ©es\n",
    "- **CronJob** : ETL planifiÃ© quotidiennement\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```text\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚      MinIO      â”‚â”€â”€â”€â”€â–¶â”‚   CronJob ETL   â”‚â”€â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚\n",
    "â”‚  (S3 / input)   â”‚     â”‚    (Python)     â”‚     â”‚    (output)     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚                       â”‚                       â”‚\n",
    "        â””â”€â”€â”€â”€â”€ Helm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€ Manifests â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Structure du projet\n",
    "\n",
    "```text\n",
    "k8s-etl-project/\n",
    "â”œâ”€â”€ helm-values/\n",
    "â”‚   â”œâ”€â”€ minio-values.yaml\n",
    "â”‚   â””â”€â”€ postgres-values.yaml\n",
    "â”œâ”€â”€ manifests/\n",
    "â”‚   â”œâ”€â”€ namespace.yaml\n",
    "â”‚   â”œâ”€â”€ etl-configmap.yaml\n",
    "â”‚   â”œâ”€â”€ etl-secret.yaml\n",
    "â”‚   â””â”€â”€ etl-cronjob.yaml\n",
    "â”œâ”€â”€ etl/\n",
    "â”‚   â”œâ”€â”€ Dockerfile\n",
    "â”‚   â”œâ”€â”€ requirements.txt\n",
    "â”‚   â””â”€â”€ etl.py\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ sales.csv\n",
    "â””â”€â”€ README.md\n",
    "```\n",
    "\n",
    "### Ã‰tapes\n",
    "\n",
    "1. CrÃ©er le namespace `data-pipeline`\n",
    "2. DÃ©ployer MinIO via Helm\n",
    "3. DÃ©ployer PostgreSQL via Helm\n",
    "4. Uploader les donnÃ©es dans MinIO\n",
    "5. Build & push l'image ETL\n",
    "6. DÃ©ployer le CronJob\n",
    "7. Tester manuellement\n",
    "8. VÃ©rifier les donnÃ©es dans PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini_project_solution",
   "metadata": {},
   "source": [
    "### âœ… Solution du mini-projet\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ“¥ Afficher la solution complÃ¨te</summary>\n",
    "\n",
    "**1. `manifests/namespace.yaml`**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Namespace\n",
    "metadata:\n",
    "  name: data-pipeline\n",
    "  labels:\n",
    "    team: data-engineering\n",
    "    project: etl-demo\n",
    "```\n",
    "\n",
    "**2. `helm-values/minio-values.yaml`**\n",
    "```yaml\n",
    "rootUser: admin\n",
    "rootPassword: minio123456\n",
    "persistence:\n",
    "  size: 5Gi\n",
    "resources:\n",
    "  requests:\n",
    "    memory: \"256Mi\"\n",
    "    cpu: \"100m\"\n",
    "```\n",
    "\n",
    "**3. `helm-values/postgres-values.yaml`**\n",
    "```yaml\n",
    "auth:\n",
    "  postgresPassword: \"postgres123\"\n",
    "  username: \"de_user\"\n",
    "  password: \"de_password\"\n",
    "  database: \"de_db\"\n",
    "primary:\n",
    "  resources:\n",
    "    requests:\n",
    "      memory: \"256Mi\"\n",
    "      cpu: \"250m\"\n",
    "  persistence:\n",
    "    size: 2Gi\n",
    "```\n",
    "\n",
    "**4. `manifests/etl-configmap.yaml`**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: ConfigMap\n",
    "metadata:\n",
    "  name: etl-config\n",
    "  namespace: data-pipeline\n",
    "data:\n",
    "  MINIO_ENDPOINT: \"minio.data-pipeline.svc.cluster.local:9000\"\n",
    "  MINIO_BUCKET: \"raw-data\"\n",
    "  MINIO_FILE: \"sales.csv\"\n",
    "  DB_HOST: \"postgres-postgresql.data-pipeline.svc.cluster.local\"\n",
    "  DB_PORT: \"5432\"\n",
    "  DB_NAME: \"de_db\"\n",
    "  DB_USER: \"de_user\"\n",
    "```\n",
    "\n",
    "**5. `manifests/etl-secret.yaml`**\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: etl-secret\n",
    "  namespace: data-pipeline\n",
    "type: Opaque\n",
    "stringData:\n",
    "  MINIO_ACCESS_KEY: \"admin\"\n",
    "  MINIO_SECRET_KEY: \"minio123456\"\n",
    "  DB_PASSWORD: \"de_password\"\n",
    "```\n",
    "\n",
    "**6. `manifests/etl-cronjob.yaml`**\n",
    "```yaml\n",
    "apiVersion: batch/v1\n",
    "kind: CronJob\n",
    "metadata:\n",
    "  name: etl-daily\n",
    "  namespace: data-pipeline\n",
    "  labels:\n",
    "    app: etl-pipeline\n",
    "    schedule: daily\n",
    "spec:\n",
    "  schedule: \"0 2 * * *\"  # Tous les jours Ã  2h\n",
    "  concurrencyPolicy: Forbid\n",
    "  successfulJobsHistoryLimit: 3\n",
    "  failedJobsHistoryLimit: 2\n",
    "  jobTemplate:\n",
    "    spec:\n",
    "      backoffLimit: 3\n",
    "      activeDeadlineSeconds: 1800\n",
    "      ttlSecondsAfterFinished: 86400\n",
    "      template:\n",
    "        metadata:\n",
    "          labels:\n",
    "            app: etl-job\n",
    "        spec:\n",
    "          containers:\n",
    "          - name: etl\n",
    "            image: my-etl:1.0  # Remplacer par ton image\n",
    "            envFrom:\n",
    "            - configMapRef:\n",
    "                name: etl-config\n",
    "            - secretRef:\n",
    "                name: etl-secret\n",
    "            resources:\n",
    "              requests:\n",
    "                memory: \"256Mi\"\n",
    "                cpu: \"200m\"\n",
    "              limits:\n",
    "                memory: \"512Mi\"\n",
    "                cpu: \"500m\"\n",
    "          restartPolicy: OnFailure\n",
    "```\n",
    "\n",
    "**7. `etl/requirements.txt`**\n",
    "```text\n",
    "pandas==2.1.4\n",
    "boto3==1.34.0\n",
    "psycopg2-binary==2.9.9\n",
    "sqlalchemy==2.0.25\n",
    "```\n",
    "\n",
    "**8. `etl/Dockerfile`**\n",
    "```dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "ENV PYTHONUNBUFFERED=1\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY etl.py .\n",
    "\n",
    "CMD [\"python\", \"etl.py\"]\n",
    "```\n",
    "\n",
    "**9. `etl/etl.py`**\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from sqlalchemy import create_engine\n",
    "from io import BytesIO\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸš€ DÃ©marrage ETL...\")\n",
    "    \n",
    "    # Config MinIO\n",
    "    minio_endpoint = os.environ['MINIO_ENDPOINT']\n",
    "    minio_access = os.environ['MINIO_ACCESS_KEY']\n",
    "    minio_secret = os.environ['MINIO_SECRET_KEY']\n",
    "    bucket = os.environ['MINIO_BUCKET']\n",
    "    file_key = os.environ['MINIO_FILE']\n",
    "    \n",
    "    # Config PostgreSQL\n",
    "    db_host = os.environ['DB_HOST']\n",
    "    db_port = os.environ['DB_PORT']\n",
    "    db_name = os.environ['DB_NAME']\n",
    "    db_user = os.environ['DB_USER']\n",
    "    db_pass = os.environ['DB_PASSWORD']\n",
    "    \n",
    "    # EXTRACT : Lire depuis MinIO\n",
    "    print(f\"ğŸ“¥ Lecture depuis MinIO: {bucket}/{file_key}\")\n",
    "    s3 = boto3.client(\n",
    "        's3',\n",
    "        endpoint_url=f'http://{minio_endpoint}',\n",
    "        aws_access_key_id=minio_access,\n",
    "        aws_secret_access_key=minio_secret\n",
    "    )\n",
    "    \n",
    "    response = s3.get_object(Bucket=bucket, Key=file_key)\n",
    "    df = pd.read_csv(BytesIO(response['Body'].read()))\n",
    "    print(f\"   {len(df)} lignes lues\")\n",
    "    \n",
    "    # TRANSFORM\n",
    "    print(\"ğŸ”„ Transformation...\")\n",
    "    df['total'] = df['quantity'] * df['price']\n",
    "    df['loaded_at'] = pd.Timestamp.now()\n",
    "    \n",
    "    # LOAD : Ã‰crire dans PostgreSQL\n",
    "    print(f\"ğŸ“¤ Chargement dans PostgreSQL...\")\n",
    "    engine = create_engine(\n",
    "        f'postgresql://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}'\n",
    "    )\n",
    "    df.to_sql('sales', engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(\"âœ… ETL terminÃ© avec succÃ¨s !\")\n",
    "    print(df.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "**10. Commandes de dÃ©ploiement**\n",
    "```bash\n",
    "# 1. CrÃ©er le namespace\n",
    "kubectl apply -f manifests/namespace.yaml\n",
    "\n",
    "# 2. Installer MinIO\n",
    "helm repo add minio https://charts.min.io/\n",
    "helm install minio minio/minio \\\n",
    "  -n data-pipeline \\\n",
    "  -f helm-values/minio-values.yaml\n",
    "\n",
    "# 3. Installer PostgreSQL\n",
    "helm repo add bitnami https://charts.bitnami.com/bitnami\n",
    "helm install postgres bitnami/postgresql \\\n",
    "  -n data-pipeline \\\n",
    "  -f helm-values/postgres-values.yaml\n",
    "\n",
    "# 4. Attendre que tout soit prÃªt\n",
    "kubectl get pods -n data-pipeline -w\n",
    "\n",
    "# 5. Upload data dans MinIO (via port-forward)\n",
    "kubectl port-forward svc/minio -n data-pipeline 9000:9000 &\n",
    "# Puis utiliser mc (MinIO client) ou l'UI\n",
    "\n",
    "# 6. Build & push image ETL\n",
    "cd etl\n",
    "docker build -t my-etl:1.0 .\n",
    "# docker push my-registry/my-etl:1.0\n",
    "\n",
    "# 7. DÃ©ployer les manifests\n",
    "kubectl apply -f manifests/etl-configmap.yaml\n",
    "kubectl apply -f manifests/etl-secret.yaml\n",
    "kubectl apply -f manifests/etl-cronjob.yaml\n",
    "\n",
    "# 8. Tester manuellement\n",
    "kubectl create job test-etl --from=cronjob/etl-daily -n data-pipeline\n",
    "\n",
    "# 9. Voir les logs\n",
    "kubectl logs -f job/test-etl -n data-pipeline\n",
    "\n",
    "# 10. VÃ©rifier dans PostgreSQL\n",
    "kubectl exec -it postgres-postgresql-0 -n data-pipeline -- \\\n",
    "  psql -U de_user -d de_db -c \"SELECT * FROM sales;\"\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resources",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Ressources pour aller plus loin\n",
    "\n",
    "### ğŸŒ Documentation officielle\n",
    "- [Kubernetes Jobs](https://kubernetes.io/docs/concepts/workloads/controllers/job/) â€” Documentation Jobs\n",
    "- [Kubernetes CronJobs](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/) â€” Documentation CronJobs\n",
    "- [StatefulSets](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) â€” Applications stateful\n",
    "- [Helm Docs](https://helm.sh/docs/) â€” Documentation Helm\n",
    "\n",
    "### ğŸ“¦ Charts Helm utiles\n",
    "- [Artifact Hub](https://artifacthub.io/) â€” Recherche de charts Helm\n",
    "- [Bitnami Charts](https://github.com/bitnami/charts) â€” Charts de qualitÃ© production\n",
    "\n",
    "### ğŸ”§ Outils\n",
    "- [k9s](https://k9scli.io/) â€” Terminal UI pour Kubernetes\n",
    "- [Lens](https://k8slens.dev/) â€” IDE Kubernetes\n",
    "- [MinIO Client (mc)](https://min.io/docs/minio/linux/reference/minio-mc.html) â€” CLI pour MinIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next_steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## â¡ï¸ Prochaine Ã©tape\n",
    "\n",
    "Maintenant que tu maÃ®trises les workloads data sur Kubernetes, passons au **traitement de donnÃ©es haute performance** avec Python !\n",
    "\n",
    "ğŸ‘‰ **Module suivant : `17_polars_for_data_engineering`** â€” Polars : le DataFrame ultra-rapide\n",
    "\n",
    "Tu vas apprendre :\n",
    "- Pourquoi Polars est plus rapide que Pandas\n",
    "- API lazy vs eager\n",
    "- Optimisations automatiques\n",
    "- Migration depuis Pandas\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‰ **FÃ©licitations !** Tu as terminÃ© le module Kubernetes pour Workloads Data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
