<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>ğŸš€ PySpark Advanced â€“ Bootcamp Data Engineering â€“ From Zero to Hero</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-fc8d3d93f0a84b7619e1f8ff6eb63d42.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-fc8d3d93f0a84b7619e1f8ff6eb63d42.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-fc8d3d93f0a84b7619e1f8ff6eb63d42.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-6a2c4b793c0becaeb94cc5bf146c1484.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-9829addb8a8859fb2d6fc218213bf783.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-6a2c4b793c0becaeb94cc5bf146c1484.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bootcamp Data Engineering â€“ From Zero to Hero</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/diakite-data/data-engineering-bootcamp"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../notebooks/intermediate/14_docker_for_data_engineers.html">IntermÃ©diaire</a></li><li class="breadcrumb-item"><a href="../../notebooks/intermediate/19_pyspark_advanced.html">ğŸš€ PySpark Advanced</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bootcamp Data Engineering â€“ From Zero to Hero</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">DÃ©butant</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/01_intro_data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ§  Introduction au Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/02_bash_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ§° Bash pour Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/03_git_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ“˜ Git pour Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/04_python_basics_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ“˜ Python â€“ Bases pour Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/05_python_data_processing_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ“Š Python for Data Processing - Complete Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/06_intro_relational_databases.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ—„ï¸ Introduction aux Bases de DonnÃ©es Relationnelles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/07_sql_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ˜ SQL for Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/08_intro_big_data_distributed.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ˜ Introduction au Big Data &amp; SystÃ¨mes DistribuÃ©s</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/09_mongodb_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸƒ MongoDB for Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/10_elasticsearch_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ” Elasticsearch for Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/11_pyspark_for_data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">âš¡ PySpark for Data Engineering</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/12_orchestration_pipelines.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">â° Orchestration de Pipelines Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/beginner/13_BONUS_fastapi_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸš€ BONUS : FastAPI pour Data Engineers</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">IntermÃ©diaire</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/14_docker_for_data_engineers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ³ Docker pour Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/15_kubernetes_fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">â˜¸ï¸ Kubernetes Fundamentals pour Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/16_k8s_for_data_workloads.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">â˜¸ï¸ Kubernetes pour Workloads Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/17_polars_for_data_engineering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ»â€â„ï¸ Polars pour Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/18_high_performance_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">âš¡ High Performance Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/19_pyspark_advanced.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">ğŸš€ PySpark Advanced</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/20_spark_sql_deep_dive.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ” Spark SQL Deep Dive &amp; Optimisation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/21_spark_on_kubernetes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">â˜¸ï¸ Spark on Kubernetes â€” Production-Grade Deployment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/22_cloud_and_object_storage.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">â˜ï¸ Cloud &amp; Object Storage for Data Engineers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/23_table_formats_delta_iceberg.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ’ Table Formats : Delta Lake &amp; Apache Iceberg</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/24_kafka_streaming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸŒŠ Kafka, Python &amp; Structured Streaming</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../notebooks/intermediate/25_dbt_data_quality.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ—ï¸ dbt (Data Build Tool) &amp; Data Quality</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#prÃ©requis" id="toc-prÃ©requis" class="nav-link active" data-scroll-target="#prÃ©requis">ğŸ“‹ PrÃ©requis</a></li>
  <li><a href="#objectifs-du-module" id="toc-objectifs-du-module" class="nav-link" data-scroll-target="#objectifs-du-module">ğŸ¯ Objectifs du module</a>
  <ul class="collapse">
  <li><a href="#objectif-concret" id="toc-objectif-concret" class="nav-link" data-scroll-target="#objectif-concret">ğŸ¯ Objectif concret</a></li>
  </ul></li>
  <li><a href="#rappels-spark-essentiels" id="toc-rappels-spark-essentiels" class="nav-link" data-scroll-target="#rappels-spark-essentiels">âš¡ 1. Rappels Spark Essentiels</a>
  <ul class="collapse">
  <li><a href="#sparksession" id="toc-sparksession" class="nav-link" data-scroll-target="#sparksession">1.1 SparkSession</a></li>
  <li><a href="#dataframe-vs-rdd" id="toc-dataframe-vs-rdd" class="nav-link" data-scroll-target="#dataframe-vs-rdd">1.2 DataFrame vs RDD</a></li>
  <li><a href="#transformations-vs-actions" id="toc-transformations-vs-actions" class="nav-link" data-scroll-target="#transformations-vs-actions">1.3 Transformations vs Actions</a></li>
  <li><a href="#lazy-evaluation" id="toc-lazy-evaluation" class="nav-link" data-scroll-target="#lazy-evaluation">1.4 Lazy Evaluation</a></li>
  </ul></li>
  <li><a href="#architecture-interne-ce-que-les-dÃ©butants-ne-savent-pas" id="toc-architecture-interne-ce-que-les-dÃ©butants-ne-savent-pas" class="nav-link" data-scroll-target="#architecture-interne-ce-que-les-dÃ©butants-ne-savent-pas">ğŸ§  2. Architecture Interne â€” Ce que les dÃ©butants ne savent pas</a>
  <ul class="collapse">
  <li><a href="#le-cycle-de-vie-dun-job-spark" id="toc-le-cycle-de-vie-dun-job-spark" class="nav-link" data-scroll-target="#le-cycle-de-vie-dun-job-spark">2.1 Le cycle de vie dâ€™un Job Spark</a></li>
  <li><a href="#catalyst-optimizer-larme-secrÃ¨te" id="toc-catalyst-optimizer-larme-secrÃ¨te" class="nav-link" data-scroll-target="#catalyst-optimizer-larme-secrÃ¨te">2.2 Catalyst Optimizer â€” Lâ€™arme secrÃ¨te</a></li>
  <li><a href="#tungsten-engine" id="toc-tungsten-engine" class="nav-link" data-scroll-target="#tungsten-engine">2.3 Tungsten Engine</a></li>
  </ul></li>
  <li><a href="#spark-submit-exÃ©cuter-spark-comme-un-pro" id="toc-spark-submit-exÃ©cuter-spark-comme-un-pro" class="nav-link" data-scroll-target="#spark-submit-exÃ©cuter-spark-comme-un-pro">ğŸ–¥ï¸ 3. spark-submit â€” ExÃ©cuter Spark comme un pro</a>
  <ul class="collapse">
  <li><a href="#pourquoi-spark-submit" id="toc-pourquoi-spark-submit" class="nav-link" data-scroll-target="#pourquoi-spark-submit">3.1 Pourquoi spark-submit ?</a></li>
  <li><a href="#deploy-modes" id="toc-deploy-modes" class="nav-link" data-scroll-target="#deploy-modes">3.2 Deploy Modes</a></li>
  <li><a href="#resource-managers-masters" id="toc-resource-managers-masters" class="nav-link" data-scroll-target="#resource-managers-masters">3.3 Resource Managers (Masters)</a></li>
  <li><a href="#syntaxe-complÃ¨te-spark-submit" id="toc-syntaxe-complÃ¨te-spark-submit" class="nav-link" data-scroll-target="#syntaxe-complÃ¨te-spark-submit">3.4 Syntaxe complÃ¨te spark-submit</a></li>
  <li><a href="#structure-projet-production" id="toc-structure-projet-production" class="nav-link" data-scroll-target="#structure-projet-production">3.5 Structure projet production</a></li>
  <li><a href="#packaging-pour-production" id="toc-packaging-pour-production" class="nav-link" data-scroll-target="#packaging-pour-production">3.6 Packaging pour production</a></li>
  </ul></li>
  <li><a href="#partitionnement-shuffle-la-source-de-lenteur" id="toc-partitionnement-shuffle-la-source-de-lenteur" class="nav-link" data-scroll-target="#partitionnement-shuffle-la-source-de-lenteur">ğŸ“¦ 4. Partitionnement &amp; Shuffle â€” LA source de lenteur</a>
  <ul class="collapse">
  <li><a href="#quest-ce-quun-shuffle" id="toc-quest-ce-quun-shuffle" class="nav-link" data-scroll-target="#quest-ce-quun-shuffle">4.1 Quâ€™est-ce quâ€™un Shuffle ?</a></li>
  <li><a href="#repartition-vs-coalesce" id="toc-repartition-vs-coalesce" class="nav-link" data-scroll-target="#repartition-vs-coalesce">4.2 repartition vs coalesce</a></li>
  <li><a href="#taille-optimale-des-partitions" id="toc-taille-optimale-des-partitions" class="nav-link" data-scroll-target="#taille-optimale-des-partitions">4.3 Taille optimale des partitions</a></li>
  <li><a href="#data-skew-le-tueur-de-performance" id="toc-data-skew-le-tueur-de-performance" class="nav-link" data-scroll-target="#data-skew-le-tueur-de-performance">4.4 Data Skew â€” Le tueur de performance</a></li>
  <li><a href="#caching-persistence" id="toc-caching-persistence" class="nav-link" data-scroll-target="#caching-persistence">4.5 Caching &amp; Persistence</a></li>
  </ul></li>
  <li><a href="#joins-avancÃ©s-la-compÃ©tence-qui-change-tout" id="toc-joins-avancÃ©s-la-compÃ©tence-qui-change-tout" class="nav-link" data-scroll-target="#joins-avancÃ©s-la-compÃ©tence-qui-change-tout">ğŸ”— 5. Joins AvancÃ©s â€” La compÃ©tence qui change tout</a>
  <ul class="collapse">
  <li><a href="#types-de-joins-internes-spark" id="toc-types-de-joins-internes-spark" class="nav-link" data-scroll-target="#types-de-joins-internes-spark">5.1 Types de Joins internes Spark</a></li>
  <li><a href="#broadcast-join-ton-meilleur-ami" id="toc-broadcast-join-ton-meilleur-ami" class="nav-link" data-scroll-target="#broadcast-join-ton-meilleur-ami">5.2 Broadcast Join â€” Ton meilleur ami</a></li>
  <li><a href="#configurer-le-seuil-de-broadcast" id="toc-configurer-le-seuil-de-broadcast" class="nav-link" data-scroll-target="#configurer-le-seuil-de-broadcast">5.3 Configurer le seuil de broadcast</a></li>
  <li><a href="#join-hints-spark-3.0" id="toc-join-hints-spark-3.0" class="nav-link" data-scroll-target="#join-hints-spark-3.0">5.4 Join Hints (Spark 3.0+)</a></li>
  <li><a href="#anti-pattern-join-sur-clÃ©-skewed" id="toc-anti-pattern-join-sur-clÃ©-skewed" class="nav-link" data-scroll-target="#anti-pattern-join-sur-clÃ©-skewed">5.5 Anti-pattern : Join sur clÃ© skewed</a></li>
  </ul></li>
  <li><a href="#lectureÃ©criture-optimisÃ©es" id="toc-lectureÃ©criture-optimisÃ©es" class="nav-link" data-scroll-target="#lectureÃ©criture-optimisÃ©es">ğŸ“ 6. Lecture/Ã‰criture OptimisÃ©es</a>
  <ul class="collapse">
  <li><a href="#formats-parquet-toujours" id="toc-formats-parquet-toujours" class="nav-link" data-scroll-target="#formats-parquet-toujours">6.1 Formats : Parquet toujours !</a></li>
  <li><a href="#predicate-pushdown" id="toc-predicate-pushdown" class="nav-link" data-scroll-target="#predicate-pushdown">6.2 Predicate Pushdown</a></li>
  <li><a href="#partitionnement-sur-disque" id="toc-partitionnement-sur-disque" class="nav-link" data-scroll-target="#partitionnement-sur-disque">6.3 Partitionnement sur disque</a></li>
  <li><a href="#schÃ©mas-explicites" id="toc-schÃ©mas-explicites" class="nav-link" data-scroll-target="#schÃ©mas-explicites">6.4 SchÃ©mas explicites</a></li>
  </ul></li>
  <li><a href="#udfs-le-piÃ¨ge-de-performance" id="toc-udfs-le-piÃ¨ge-de-performance" class="nav-link" data-scroll-target="#udfs-le-piÃ¨ge-de-performance">âš ï¸ 7. UDFs : Le piÃ¨ge de performance</a>
  <ul class="collapse">
  <li><a href="#pourquoi-les-python-udfs-sont-toxiques" id="toc-pourquoi-les-python-udfs-sont-toxiques" class="nav-link" data-scroll-target="#pourquoi-les-python-udfs-sont-toxiques">7.1 Pourquoi les Python UDFs sont toxiques</a></li>
  <li><a href="#hiÃ©rarchie-de-performance" id="toc-hiÃ©rarchie-de-performance" class="nav-link" data-scroll-target="#hiÃ©rarchie-de-performance">7.2 HiÃ©rarchie de performance</a></li>
  <li><a href="#remplacer-udf-par-expressions-natives" id="toc-remplacer-udf-par-expressions-natives" class="nav-link" data-scroll-target="#remplacer-udf-par-expressions-natives">7.3 Remplacer UDF par expressions natives</a></li>
  <li><a href="#pandas-udf-si-python-nÃ©cessaire" id="toc-pandas-udf-si-python-nÃ©cessaire" class="nav-link" data-scroll-target="#pandas-udf-si-python-nÃ©cessaire">7.4 Pandas UDF (si Python nÃ©cessaire)</a></li>
  </ul></li>
  <li><a href="#configuration-tuning" id="toc-configuration-tuning" class="nav-link" data-scroll-target="#configuration-tuning">âš™ï¸ 8. Configuration &amp; Tuning</a>
  <ul class="collapse">
  <li><a href="#paramÃ¨tres-essentiels" id="toc-paramÃ¨tres-essentiels" class="nav-link" data-scroll-target="#paramÃ¨tres-essentiels">8.1 ParamÃ¨tres essentiels</a></li>
  <li><a href="#dimensionnement-executors-vs-cores" id="toc-dimensionnement-executors-vs-cores" class="nav-link" data-scroll-target="#dimensionnement-executors-vs-cores">8.2 Dimensionnement : Executors vs Cores</a></li>
  <li><a href="#adaptive-query-execution-aqe" id="toc-adaptive-query-execution-aqe" class="nav-link" data-scroll-target="#adaptive-query-execution-aqe">8.3 Adaptive Query Execution (AQE)</a></li>
  </ul></li>
  <li><a href="#spark-ui-diagnostic" id="toc-spark-ui-diagnostic" class="nav-link" data-scroll-target="#spark-ui-diagnostic">ğŸ” 9. Spark UI &amp; Diagnostic</a>
  <ul class="collapse">
  <li><a href="#accÃ©der-Ã -spark-ui" id="toc-accÃ©der-Ã -spark-ui" class="nav-link" data-scroll-target="#accÃ©der-Ã -spark-ui">9.1 AccÃ©der Ã  Spark UI</a></li>
  <li><a href="#les-onglets-importants" id="toc-les-onglets-importants" class="nav-link" data-scroll-target="#les-onglets-importants">9.2 Les onglets importants</a></li>
  <li><a href="#mÃ©triques-Ã -surveiller" id="toc-mÃ©triques-Ã -surveiller" class="nav-link" data-scroll-target="#mÃ©triques-Ã -surveiller">9.3 MÃ©triques Ã  surveiller</a></li>
  <li><a href="#patterns-de-problÃ¨mes" id="toc-patterns-de-problÃ¨mes" class="nav-link" data-scroll-target="#patterns-de-problÃ¨mes">9.4 Patterns de problÃ¨mes</a></li>
  </ul></li>
  <li><a href="#bonnes-pratiques-anti-patterns" id="toc-bonnes-pratiques-anti-patterns" class="nav-link" data-scroll-target="#bonnes-pratiques-anti-patterns">âœ… 10. Bonnes pratiques &amp; Anti-patterns</a>
  <ul class="collapse">
  <li><a href="#anti-patterns-Ã -Ã©viter-absolument" id="toc-anti-patterns-Ã -Ã©viter-absolument" class="nav-link" data-scroll-target="#anti-patterns-Ã -Ã©viter-absolument">âŒ Anti-patterns (Ã  Ã©viter absolument)</a></li>
  <li><a href="#bonnes-pratiques" id="toc-bonnes-pratiques" class="nav-link" data-scroll-target="#bonnes-pratiques">âœ… Bonnes pratiques</a></li>
  </ul></li>
  <li><a href="#mini-projet-optimisation-dun-pipeline" id="toc-mini-projet-optimisation-dun-pipeline" class="nav-link" data-scroll-target="#mini-projet-optimisation-dun-pipeline">ğŸš€ Mini-Projet : Optimisation dâ€™un pipeline</a>
  <ul class="collapse">
  <li><a href="#objectif" id="toc-objectif" class="nav-link" data-scroll-target="#objectif">ğŸ¯ Objectif</a></li>
  <li><a href="#scÃ©nario-e-commerce-analytics" id="toc-scÃ©nario-e-commerce-analytics" class="nav-link" data-scroll-target="#scÃ©nario-e-commerce-analytics">ScÃ©nario : E-commerce Analytics</a></li>
  <li><a href="#architecture-cible" id="toc-architecture-cible" class="nav-link" data-scroll-target="#architecture-cible">Architecture cible</a></li>
  </ul></li>
  <li><a href="#quiz-de-fin-de-module" id="toc-quiz-de-fin-de-module" class="nav-link" data-scroll-target="#quiz-de-fin-de-module">ğŸ§ª Quiz de fin de module</a>
  <ul class="collapse">
  <li><a href="#q1.-quel-composant-de-spark-optimise-automatiquement-le-plan-de-requÃªte" id="toc-q1.-quel-composant-de-spark-optimise-automatiquement-le-plan-de-requÃªte" class="nav-link" data-scroll-target="#q1.-quel-composant-de-spark-optimise-automatiquement-le-plan-de-requÃªte">â“ Q1. Quel composant de Spark optimise automatiquement le plan de requÃªte ?</a></li>
  <li><a href="#q2.-quelle-opÃ©ration-cause-un-shuffle" id="toc-q2.-quelle-opÃ©ration-cause-un-shuffle" class="nav-link" data-scroll-target="#q2.-quelle-opÃ©ration-cause-un-shuffle">â“ Q2. Quelle opÃ©ration cause un shuffle ?</a></li>
  <li><a href="#q3.-quelle-mÃ©thode-utiliser-pour-rÃ©duire-le-nombre-de-partitions-sans-shuffle" id="toc-q3.-quelle-mÃ©thode-utiliser-pour-rÃ©duire-le-nombre-de-partitions-sans-shuffle" class="nav-link" data-scroll-target="#q3.-quelle-mÃ©thode-utiliser-pour-rÃ©duire-le-nombre-de-partitions-sans-shuffle">â“ Q3. Quelle mÃ©thode utiliser pour rÃ©duire le nombre de partitions SANS shuffle ?</a></li>
  <li><a href="#q4.-quelle-est-la-taille-optimale-dune-partition-spark" id="toc-q4.-quelle-est-la-taille-optimale-dune-partition-spark" class="nav-link" data-scroll-target="#q4.-quelle-est-la-taille-optimale-dune-partition-spark">â“ Q4. Quelle est la taille optimale dâ€™une partition Spark ?</a></li>
  <li><a href="#q5.-pour-joindre-une-table-de-10-gb-avec-une-table-de-50-mb-quelle-stratÃ©gie-utiliser" id="toc-q5.-pour-joindre-une-table-de-10-gb-avec-une-table-de-50-mb-quelle-stratÃ©gie-utiliser" class="nav-link" data-scroll-target="#q5.-pour-joindre-une-table-de-10-gb-avec-une-table-de-50-mb-quelle-stratÃ©gie-utiliser">â“ Q5. Pour joindre une table de 10 GB avec une table de 50 MB, quelle stratÃ©gie utiliser ?</a></li>
  <li><a href="#q6.-pourquoi-les-python-udfs-sont-ils-lents" id="toc-q6.-pourquoi-les-python-udfs-sont-ils-lents" class="nav-link" data-scroll-target="#q6.-pourquoi-les-python-udfs-sont-ils-lents">â“ Q6. Pourquoi les Python UDFs sont-ils lents ?</a></li>
  <li><a href="#q7.-que-signifie-spill-to-disk-dans-spark-ui" id="toc-q7.-que-signifie-spill-to-disk-dans-spark-ui" class="nav-link" data-scroll-target="#q7.-que-signifie-spill-to-disk-dans-spark-ui">â“ Q7. Que signifie â€œSpill to diskâ€ dans Spark UI ?</a></li>
  <li><a href="#q8.-quel-deploy-mode-utiliser-en-production" id="toc-q8.-quel-deploy-mode-utiliser-en-production" class="nav-link" data-scroll-target="#q8.-quel-deploy-mode-utiliser-en-production">â“ Q8. Quel deploy mode utiliser en production ?</a></li>
  <li><a href="#q9.-que-fait-laqe-adaptive-query-execution" id="toc-q9.-que-fait-laqe-adaptive-query-execution" class="nav-link" data-scroll-target="#q9.-que-fait-laqe-adaptive-query-execution">â“ Q9. Que fait lâ€™AQE (Adaptive Query Execution) ?</a></li>
  <li><a href="#q10.-combien-de-cores-par-executor-est-recommandÃ©" id="toc-q10.-combien-de-cores-par-executor-est-recommandÃ©" class="nav-link" data-scroll-target="#q10.-combien-de-cores-par-executor-est-recommandÃ©">â“ Q10. Combien de cores par executor est recommandÃ© ?</a></li>
  </ul></li>
  <li><a href="#ressources-pour-aller-plus-loin" id="toc-ressources-pour-aller-plus-loin" class="nav-link" data-scroll-target="#ressources-pour-aller-plus-loin">ğŸ“š Ressources pour aller plus loin</a>
  <ul class="collapse">
  <li><a href="#documentation-officielle" id="toc-documentation-officielle" class="nav-link" data-scroll-target="#documentation-officielle">ğŸŒ Documentation officielle</a></li>
  <li><a href="#articles-tutoriels" id="toc-articles-tutoriels" class="nav-link" data-scroll-target="#articles-tutoriels">ğŸ“– Articles &amp; Tutoriels</a></li>
  <li><a href="#outils" id="toc-outils" class="nav-link" data-scroll-target="#outils">ğŸ”§ Outils</a></li>
  </ul></li>
  <li><a href="#prochaine-Ã©tape" id="toc-prochaine-Ã©tape" class="nav-link" data-scroll-target="#prochaine-Ã©tape">â¡ï¸ Prochaine Ã©tape</a>
  <ul class="collapse">
  <li><a href="#rÃ©capitulatif-de-ce-module" id="toc-rÃ©capitulatif-de-ce-module" class="nav-link" data-scroll-target="#rÃ©capitulatif-de-ce-module">ğŸ“ RÃ©capitulatif de ce module</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="git@github.com:diakite-data/data-engineering-bootcamp.git/blob/main/notebooks/intermediate/19_pyspark_advanced.ipynb" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="git@github.com:diakite-data/data-engineering-bootcamp.git/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../notebooks/intermediate/14_docker_for_data_engineers.html">IntermÃ©diaire</a></li><li class="breadcrumb-item"><a href="../../notebooks/intermediate/19_pyspark_advanced.html">ğŸš€ PySpark Advanced</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">ğŸš€ PySpark Advanced</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Bienvenue dans ce module avancÃ© oÃ¹ tu vas apprendre Ã  <strong>optimiser Spark comme un expert</strong>. Tu dÃ©couvriras lâ€™architecture interne, les techniques dâ€™optimisation, et comment diagnostiquer et rÃ©soudre les problÃ¨mes de performance.</p>
<hr>
<section id="prÃ©requis" class="level2">
<h2 class="anchored" data-anchor-id="prÃ©requis">ğŸ“‹ PrÃ©requis</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Niveau</th>
<th>CompÃ©tence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>âœ… Requis</td>
<td>Module 11 : PySpark for Data Engineering (bases Spark)</td>
</tr>
<tr class="even">
<td>âœ… Requis</td>
<td>Module 18 : High Performance Python</td>
</tr>
<tr class="odd">
<td>ğŸ’¡ RecommandÃ©</td>
<td>ExpÃ©rience avec des datasets &gt; 1 Go</td>
</tr>
</tbody>
</table>
</section>
<section id="objectifs-du-module" class="level2">
<h2 class="anchored" data-anchor-id="objectifs-du-module">ğŸ¯ Objectifs du module</h2>
<p>Ã€ la fin de ce module, tu seras capable de :</p>
<ul>
<li>Comprendre lâ€™<strong>architecture interne</strong> de Spark (Catalyst, Tungsten)</li>
<li>ExÃ©cuter Spark en <strong>production</strong> avec <code>spark-submit</code></li>
<li><strong>Optimiser</strong> les partitions, shuffles et joins</li>
<li><strong>Diagnostiquer</strong> un job lent avec Spark UI</li>
<li>RÃ©duire le temps dâ€™exÃ©cution de <strong>80-90%</strong></li>
</ul>
<section id="objectif-concret" class="level3">
<h3 class="anchored" data-anchor-id="objectif-concret">ğŸ¯ Objectif concret</h3>
<blockquote class="blockquote">
<p><strong>Transformer un pipeline de 20 minutes en 2 minutes.</strong></p>
</blockquote>
<p>Câ€™est ce qui distingue un Data Engineer junior dâ€™un senior sur Spark.</p>
<hr>
</section>
</section>
<section id="rappels-spark-essentiels" class="level2">
<h2 class="anchored" data-anchor-id="rappels-spark-essentiels">âš¡ 1. Rappels Spark Essentiels</h2>
<blockquote class="blockquote">
<p>ğŸ’¡ <strong>Si tu as suivi le module 11 (PySpark for Data Engineering)</strong>, cette section est un rappel rapide.</p>
<p><strong>Sinon</strong>, commence par ce module avant de continuer â€” les concepts de base sont indispensables.</p>
</blockquote>
<section id="sparksession" class="level3">
<h3 class="anchored" data-anchor-id="sparksession">1.1 SparkSession</h3>
<div id="spark_session" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er une SparkSession (point d'entrÃ©e unique)</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>spark <span class="op">=</span> SparkSession.builder <span class="op">\</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    .appName(<span class="st">"PySpark Advanced"</span>) <span class="op">\</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    .config(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>) <span class="op">\</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    .getOrCreate()</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Spark version: </span><span class="sc">{</span>spark<span class="sc">.</span>version<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"App name: </span><span class="sc">{</span>spark<span class="sc">.</span>sparkContext<span class="sc">.</span>appName<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="dataframe-vs-rdd" class="level3">
<h3 class="anchored" data-anchor-id="dataframe-vs-rdd">1.2 DataFrame vs RDD</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Aspect</th>
<th>RDD</th>
<th>DataFrame</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>API</strong></td>
<td>Bas niveau</td>
<td>Haut niveau</td>
</tr>
<tr class="even">
<td><strong>Optimisation</strong></td>
<td>Manuelle</td>
<td>Catalyst (automatique)</td>
</tr>
<tr class="odd">
<td><strong>Performance</strong></td>
<td>Baseline</td>
<td>10-100x plus rapide</td>
</tr>
<tr class="even">
<td><strong>Usage</strong></td>
<td>Legacy, cas spÃ©ciaux</td>
<td><strong>Standard</strong></td>
</tr>
</tbody>
</table>
<p>ğŸ‘‰ <strong>RÃ¨gle : Toujours utiliser DataFrame/Dataset, jamais RDD</strong> (sauf cas trÃ¨s spÃ©cifiques).</p>
</section>
<section id="transformations-vs-actions" class="level3">
<h3 class="anchored" data-anchor-id="transformations-vs-actions">1.3 Transformations vs Actions</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 38%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Exemples</th>
<th>ExÃ©cution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Transformation</strong></td>
<td><code>filter</code>, <code>select</code>, <code>join</code>, <code>groupBy</code></td>
<td>Lazy (diffÃ©rÃ©e)</td>
</tr>
<tr class="even">
<td><strong>Action</strong></td>
<td><code>count</code>, <code>collect</code>, <code>write</code>, <code>show</code></td>
<td>ImmÃ©diate</td>
</tr>
</tbody>
</table>
</section>
<section id="lazy-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="lazy-evaluation">1.4 Lazy Evaluation</h3>
<pre class="text"><code>df.filter(...)     # Rien ne s'exÃ©cute
  .select(...)     # Rien ne s'exÃ©cute
  .groupBy(...)    # Rien ne s'exÃ©cute
  .count()         # MAINTENANT tout s'exÃ©cute !</code></pre>
<p><strong>Avantage</strong> : Spark peut optimiser lâ€™ensemble du pipeline avant exÃ©cution.</p>
<hr>
</section>
</section>
<section id="architecture-interne-ce-que-les-dÃ©butants-ne-savent-pas" class="level2">
<h2 class="anchored" data-anchor-id="architecture-interne-ce-que-les-dÃ©butants-ne-savent-pas">ğŸ§  2. Architecture Interne â€” Ce que les dÃ©butants ne savent pas</h2>
<blockquote class="blockquote">
<p>La vraie maÃ®trise de Spark commence ici. Comprendre lâ€™architecture interne te permet de <strong>prÃ©dire</strong> et <strong>rÃ©soudre</strong> les problÃ¨mes de performance.</p>
</blockquote>
<section id="le-cycle-de-vie-dun-job-spark" class="level3">
<h3 class="anchored" data-anchor-id="le-cycle-de-vie-dun-job-spark">2.1 Le cycle de vie dâ€™un Job Spark</h3>
<pre class="text"><code>Code Python/SQL
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Logical Plan     â”‚  Arbre d'opÃ©rations (ce que tu veux faire)
â”‚    (non optimisÃ©)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Catalyst       â”‚  ğŸ§  Optimiseur de requÃªtes
â”‚      Optimizer      â”‚  - Predicate pushdown
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Projection pruning
           â”‚             - Join reordering
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Physical Plan     â”‚  Comment exÃ©cuter (stratÃ©gie)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        DAG          â”‚  Directed Acyclic Graph
â”‚   (Stages + Tasks)  â”‚  - Stages = unitÃ©s de travail
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Tasks = exÃ©cution par partition
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Tungsten       â”‚  âš¡ ExÃ©cution optimisÃ©e
â”‚       Engine        â”‚  - Code generation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Off-heap memory</code></pre>
</section>
<section id="catalyst-optimizer-larme-secrÃ¨te" class="level3">
<h3 class="anchored" data-anchor-id="catalyst-optimizer-larme-secrÃ¨te">2.2 Catalyst Optimizer â€” Lâ€™arme secrÃ¨te</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 42%">
<col style="width: 39%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Optimisation</th>
<th>Description</th>
<th>Gain</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Predicate pushdown</strong></td>
<td>Filtre appliquÃ© Ã  la source (Parquet, DB)</td>
<td>I/O rÃ©duit drastiquement</td>
</tr>
<tr class="even">
<td><strong>Projection pruning</strong></td>
<td>Colonnes inutiles non lues</td>
<td>I/O rÃ©duit</td>
</tr>
<tr class="odd">
<td><strong>Constant folding</strong></td>
<td>Calculs constants prÃ©-calculÃ©s</td>
<td>CPU rÃ©duit</td>
</tr>
<tr class="even">
<td><strong>Join reordering</strong></td>
<td>Ordre optimal des joins</td>
<td>Shuffle rÃ©duit</td>
</tr>
</tbody>
</table>
</section>
<section id="tungsten-engine" class="level3">
<h3 class="anchored" data-anchor-id="tungsten-engine">2.3 Tungsten Engine</h3>
<ul>
<li><strong>Off-heap memory</strong> : stockage hors JVM â†’ Ã©vite le Garbage Collector</li>
<li><strong>Whole-stage code generation</strong> : gÃ©nÃ¨re du bytecode optimisÃ© Ã  la volÃ©e</li>
<li><strong>Vectorized execution</strong> : traitement par batch (comme Polars !)</li>
</ul>
<div id="explain_plan" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> col, <span class="bu">sum</span> <span class="im">as</span> spark_sum</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er des donnÃ©es de test</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [(i, <span class="ss">f"cat_</span><span class="sc">{</span>i <span class="op">%</span> <span class="dv">5</span><span class="sc">}</span><span class="ss">"</span>, <span class="bu">float</span>(i <span class="op">*</span> <span class="dv">10</span>)) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1000</span>)]</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.createDataFrame(data, [<span class="st">"id"</span>, <span class="st">"category"</span>, <span class="st">"amount"</span>])</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Pipeline avec transformations</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> (</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    df</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">filter</span>(col(<span class="st">"amount"</span>) <span class="op">&gt;</span> <span class="dv">100</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    .select(<span class="st">"category"</span>, <span class="st">"amount"</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    .groupBy(<span class="st">"category"</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    .agg(spark_sum(<span class="st">"amount"</span>).alias(<span class="st">"total"</span>))</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Voir le plan d'exÃ©cution</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"PLAN D'EXÃ‰CUTION (explain)"</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>result.explain(<span class="st">"formatted"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="explain_extended" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plan complet avec toutes les Ã©tapes</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"PLAN COMPLET (Parsed â†’ Analyzed â†’ Optimized â†’ Physical)"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>result.explain(<span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="spark-submit-exÃ©cuter-spark-comme-un-pro" class="level2">
<h2 class="anchored" data-anchor-id="spark-submit-exÃ©cuter-spark-comme-un-pro">ğŸ–¥ï¸ 3. spark-submit â€” ExÃ©cuter Spark comme un pro</h2>
<blockquote class="blockquote">
<p>ğŸ”¥ <strong>CompÃ©tence indispensable en entreprise.</strong> TrÃ¨s peu de formations lâ€™enseignent correctement.</p>
</blockquote>
<section id="pourquoi-spark-submit" class="level3">
<h3 class="anchored" data-anchor-id="pourquoi-spark-submit">3.1 Pourquoi spark-submit ?</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 41%">
<col style="width: 29%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th>Contexte</th>
<th>Outil</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Exploration, dÃ©veloppement</td>
<td>Notebooks (Jupyter, Databricks)</td>
<td>Dev, prototypage</td>
</tr>
<tr class="even">
<td><strong>Production, CI/CD, scheduling</strong></td>
<td><strong>spark-submit</strong></td>
<td>DÃ©ploiement rÃ©el</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>ğŸ’¡ <strong>En entreprise</strong>, <code>spark-submit</code> est rarement lancÃ© manuellement. Il est appelÃ© par : - <strong>Airflow</strong> (orchestration) â†’ Module 25 - <strong>CI/CD pipelines</strong> (GitLab CI, GitHub Actions) - <strong>Schedulers</strong> (cron, Kubernetes CronJobs)</p>
</blockquote>
</section>
<section id="deploy-modes" class="level3">
<h3 class="anchored" data-anchor-id="deploy-modes">3.2 Deploy Modes</h3>
<pre class="text"><code>CLIENT MODE                          CLUSTER MODE
â•â•â•â•â•â•â•â•â•â•â•                          â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚                      â”‚   Client    â”‚
â”‚   Machine   â”‚                      â”‚   Machine   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚                      â”‚             â”‚
â”‚  â”‚Driver â”‚  â”‚ â—„â”€â”€ Driver ici       â”‚  (submit)   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                             â”‚
       â”‚                                    â”‚
       â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cluster   â”‚                      â”‚   Cluster   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Exec 1 â”‚  â”‚                      â”‚  â”‚Driver â”‚  â”‚ â—„â”€â”€ Driver ici
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤  â”‚                      â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚Exec 2 â”‚  â”‚                      â”‚  â”‚Exec 1 â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤  â”‚                      â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚Exec 3 â”‚  â”‚                      â”‚  â”‚Exec 2 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usage: Debug, interactif            Usage: Production</code></pre>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Mode</th>
<th>Driver tourne sur</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>client</code></td>
<td>Machine qui soumet</td>
<td>Debug, logs visibles</td>
</tr>
<tr class="even">
<td><code>cluster</code></td>
<td>Worker du cluster</td>
<td><strong>Production</strong></td>
</tr>
</tbody>
</table>
</section>
<section id="resource-managers-masters" class="level3">
<h3 class="anchored" data-anchor-id="resource-managers-masters">3.3 Resource Managers (Masters)</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Master</th>
<th>Commande</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Local</td>
<td><code>--master local[*]</code></td>
<td>Dev/test (tous les cores)</td>
</tr>
<tr class="even">
<td>Local (N cores)</td>
<td><code>--master local[4]</code></td>
<td>Dev/test (4 cores)</td>
</tr>
<tr class="odd">
<td>Standalone</td>
<td><code>--master spark://host:7077</code></td>
<td>Cluster Spark simple</td>
</tr>
<tr class="even">
<td>YARN</td>
<td><code>--master yarn</code></td>
<td>Clusters Hadoop</td>
</tr>
<tr class="odd">
<td>Kubernetes</td>
<td><code>--master k8s://https://...</code></td>
<td>Cloud native</td>
</tr>
</tbody>
</table>
</section>
<section id="syntaxe-complÃ¨te-spark-submit" class="level3">
<h3 class="anchored" data-anchor-id="syntaxe-complÃ¨te-spark-submit">3.4 Syntaxe complÃ¨te spark-submit</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">spark-submit</span> <span class="dt">\</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># === Resource Manager ===</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--master</span> local<span class="pp">[</span><span class="ss">4</span><span class="pp">]</span> <span class="dt">\</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">--deploy-mode</span> client <span class="dt">\</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># === Ressources ===</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--driver-memory</span> 4g <span class="dt">\</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">--executor-memory</span> 8g <span class="dt">\</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">--executor-cores</span> 4 <span class="dt">\</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">--num-executors</span> 10 <span class="dt">\</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># === Configuration Spark ===</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--conf</span> spark.sql.shuffle.partitions=200 <span class="dt">\</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">--conf</span> spark.sql.adaptive.enabled=true <span class="dt">\</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">--conf</span> spark.executor.memoryOverhead=2g <span class="dt">\</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># === DÃ©pendances ===</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--packages</span> io.delta:delta-spark_2.12:3.2.0 <span class="dt">\</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">--jars</span> /path/to/postgres-42.7.jar <span class="dt">\</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">--py-files</span> utils.zip <span class="dt">\</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># === Application ===</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="ex">main.py</span> <span class="dt">\</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>  <span class="co"># === Arguments application ===</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>  <span class="ex">--date</span> 2024-01-01 <span class="dt">\</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">--env</span> prod</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="structure-projet-production" class="level3">
<h3 class="anchored" data-anchor-id="structure-projet-production">3.5 Structure projet production</h3>
<pre class="text"><code>spark_project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # Point d'entrÃ©e
â”‚   â”œâ”€â”€ etl/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extract.py
â”‚   â”‚   â”œâ”€â”€ transform.py
â”‚   â”‚   â””â”€â”€ load.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dev.yaml
â”‚   â””â”€â”€ prod.yaml
â”œâ”€â”€ jars/
â”‚   â””â”€â”€ postgres-42.7.jar
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_local.sh
â”‚   â””â”€â”€ run_cluster.sh
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_transform.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py                 # Pour crÃ©er .whl
â””â”€â”€ README.md</code></pre>
</section>
<section id="packaging-pour-production" class="level3">
<h3 class="anchored" data-anchor-id="packaging-pour-production">3.6 Packaging pour production</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># âŒ MAUVAIS : liste de fichiers (difficile Ã  maintenir)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">--py-files</span> utils.py,config.py,helpers.py</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># âœ… MIEUX : Package .zip</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> src/ <span class="kw">&amp;&amp;</span> <span class="fu">zip</span> <span class="at">-r</span> ../app.zip . <span class="kw">&amp;&amp;</span> <span class="bu">cd</span> ..</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="ex">spark-submit</span> <span class="at">--py-files</span> app.zip main.py</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co"># âœ… MEILLEUR : Wheel (.whl) - le plus propre</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> wheel . <span class="at">-w</span> dist/</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="ex">spark-submit</span> <span class="at">--py-files</span> dist/myproject-1.0.0-py3-none-any.whl main.py</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<blockquote class="blockquote">
<p>ğŸ’¡ <strong>En production</strong>, prÃ©fÃ¨re <code>.zip</code> ou <code>.whl</code> pour un dÃ©ploiement propre et versionnÃ©.</p>
</blockquote>
<div id="argparse_pattern" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pattern : arguments en ligne de commande (main.py)</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># === Exemple de main.py pour spark-submit ===</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>example_main <span class="op">=</span> <span class="st">'''</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="st">#!/usr/bin/env python3</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="st">"""Point d'entrÃ©e du job Spark."""</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="st">import argparse</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="st">from pyspark.sql import SparkSession</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="st">def parse_args():</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="st">    parser = argparse.ArgumentParser(description="ETL Pipeline")</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="st">    parser.add_argument("--date", required=True, help="Date de traitement (YYYY-MM-DD)")</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="st">    parser.add_argument("--env", default="dev", choices=["dev", "prod"])</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="st">    parser.add_argument("--input", required=True, help="Chemin input")</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="st">    parser.add_argument("--output", required=True, help="Chemin output")</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="st">    return parser.parse_args()</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="st">def main():</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a><span class="st">    args = parse_args()</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="st">    spark = SparkSession.builder </span><span class="op">\</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="st">        .appName(f"ETL-</span><span class="sc">{args.env}</span><span class="st">-</span><span class="sc">{args.date}</span><span class="st">") </span><span class="op">\</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="st">        .getOrCreate()</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="st">    # Charger les donnÃ©es</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="st">    df = spark.read.parquet(f"</span><span class="sc">{args.input}</span><span class="st">/date=</span><span class="sc">{args.date}</span><span class="st">")</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="st">    # Transformations...</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="st">    result = df.filter(df.amount &gt; 0)</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a><span class="st">    # Ã‰crire</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="st">    result.write.mode("overwrite").parquet(f"</span><span class="sc">{args.output}</span><span class="st">/date=</span><span class="sc">{args.date}</span><span class="st">")</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="st">    spark.stop()</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a><span class="st">if __name__ == "__main__":</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a><span class="st">    main()</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a><span class="st">'''</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(example_main)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="partitionnement-shuffle-la-source-de-lenteur" class="level2">
<h2 class="anchored" data-anchor-id="partitionnement-shuffle-la-source-de-lenteur">ğŸ“¦ 4. Partitionnement &amp; Shuffle â€” LA source de lenteur</h2>
<blockquote class="blockquote">
<p>âš ï¸ <strong>80% des problÃ¨mes de performance Spark viennent du shuffle et du partitionnement.</strong></p>
</blockquote>
<section id="quest-ce-quun-shuffle" class="level3">
<h3 class="anchored" data-anchor-id="quest-ce-quun-shuffle">4.1 Quâ€™est-ce quâ€™un Shuffle ?</h3>
<p>Le shuffle est la <strong>redistribution des donnÃ©es entre partitions</strong>. Il est nÃ©cessaire pour :</p>
<ul>
<li><code>groupBy</code>, <code>reduceByKey</code></li>
<li><code>join</code> (sauf broadcast)</li>
<li><code>distinct</code>, <code>repartition</code></li>
<li><code>orderBy</code> (tri global)</li>
</ul>
<pre class="text"><code>SHUFFLE = GOULOT D'Ã‰TRANGLEMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Stage 1                              Stage 2
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Partitionâ”‚                          â”‚Partitionâ”‚
â”‚    1    â”‚â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â–¶â”‚   1'    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚          â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚          â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Partitionâ”‚â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â–¶â”‚Partitionâ”‚
â”‚    2    â”‚       â”‚  SHUFFLE â”‚       â”‚   2'    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ (rÃ©seau) â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚          â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Partitionâ”‚â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â–¶â”‚Partitionâ”‚
â”‚    3    â”‚                          â”‚   3'    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CoÃ»t du Shuffle :
1. SÃ©rialisation des donnÃ©es
2. Ã‰criture sur disque (shuffle write)
3. Transfert rÃ©seau
4. Lecture depuis disque (shuffle read)
5. DÃ©sÃ©rialisation</code></pre>
</section>
<section id="repartition-vs-coalesce" class="level3">
<h3 class="anchored" data-anchor-id="repartition-vs-coalesce">4.2 repartition vs coalesce</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 36%">
<col style="width: 36%">
<col style="width: 28%">
</colgroup>
<thead>
<tr class="header">
<th>MÃ©thode</th>
<th>Shuffle</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>repartition(n)</code></td>
<td>âœ… <strong>Toujours</strong></td>
<td>Augmenter partitions, rÃ©Ã©quilibrer</td>
</tr>
<tr class="even">
<td><code>coalesce(n)</code></td>
<td>âŒ Non (si rÃ©duction)</td>
<td>RÃ©duire partitions avant write</td>
</tr>
</tbody>
</table>
<div id="partitions_demo" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> spark_partition_id</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er un DataFrame</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1000000</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Partitions initiales : </span><span class="sc">{</span>df<span class="sc">.</span>rdd<span class="sc">.</span>getNumPartitions()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># repartition = SHUFFLE (redistribue les donnÃ©es)</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>df_repart <span class="op">=</span> df.repartition(<span class="dv">10</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AprÃ¨s repartition(10) : </span><span class="sc">{</span>df_repart<span class="sc">.</span>rdd<span class="sc">.</span>getNumPartitions()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># coalesce = PAS DE SHUFFLE (combine les partitions existantes)</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>df_coal <span class="op">=</span> df_repart.coalesce(<span class="dv">3</span>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"AprÃ¨s coalesce(3) : </span><span class="sc">{</span>df_coal<span class="sc">.</span>rdd<span class="sc">.</span>getNumPartitions()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Voir la distribution des donnÃ©es par partition</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Distribution aprÃ¨s repartition(10):"</span>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>df_repart.groupBy(spark_partition_id().alias(<span class="st">"partition"</span>)).count().orderBy(<span class="st">"partition"</span>).show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="taille-optimale-des-partitions" class="level3">
<h3 class="anchored" data-anchor-id="taille-optimale-des-partitions">4.3 Taille optimale des partitions</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Taille partition</th>
<th>ProblÃ¨me</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Trop petit</strong> (&lt; 10 MB)</td>
<td>Overhead de scheduling, trop de tÃ¢ches</td>
</tr>
<tr class="even">
<td><strong>Optimal</strong> (128-256 MB)</td>
<td>âœ… Sweet spot</td>
</tr>
<tr class="odd">
<td><strong>Trop grand</strong> (&gt; 1 GB)</td>
<td>OOM, mauvaise parallÃ©lisation</td>
</tr>
</tbody>
</table>
<p><strong>Formule :</strong></p>
<pre><code>num_partitions = data_size_mb / target_partition_size_mb

Exemple : 50 GB de donnÃ©es
num_partitions = 50000 MB / 200 MB = 250 partitions</code></pre>
</section>
<section id="data-skew-le-tueur-de-performance" class="level3">
<h3 class="anchored" data-anchor-id="data-skew-le-tueur-de-performance">4.4 Data Skew â€” Le tueur de performance</h3>
<pre class="text"><code>Ã‰QUILIBRÃ‰ (bon)                     SKEWED (problÃ¨me !)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1M â”‚â”‚ 1M â”‚â”‚ 1M â”‚â”‚ 1M â”‚            â”‚100Kâ”‚â”‚100Kâ”‚â”‚100Kâ”‚â”‚        10M        â”‚
â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Temps: â–ˆâ–ˆâ–ˆâ–ˆ                         Temps: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
       4 tÃ¢ches parallÃ¨les                 â†‘
       = temps minimal                     Un seul executor bloquÃ© !
                                           Les autres attendent...</code></pre>
<p><strong>Techniques anti-skew :</strong></p>
<ol type="1">
<li><strong>Broadcast join</strong> : si une table est petite (&lt; 100 MB)</li>
<li><strong>Salting</strong> : ajouter une clÃ© alÃ©atoire pour distribuer</li>
<li><strong>AQE</strong> (Adaptive Query Execution) : Spark 3.0+ gÃ¨re automatiquement</li>
</ol>
<div id="aqe_config" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Activer AQE (recommandÃ© Spark 3.0+)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.coalescePartitions.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.skewJoin.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># VÃ©rifier la configuration</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"AQE enabled:"</span>, spark.conf.get(<span class="st">"spark.sql.adaptive.enabled"</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Skew Join enabled:"</span>, spark.conf.get(<span class="st">"spark.sql.adaptive.skewJoin.enabled"</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="caching-persistence" class="level3">
<h3 class="anchored" data-anchor-id="caching-persistence">4.5 Caching &amp; Persistence</h3>
<p><strong>Quand utiliser le cache ?</strong></p>
<ul>
<li>DataFrame rÃ©utilisÃ© dans <strong>plusieurs actions</strong></li>
<li>Calcul <strong>coÃ»teux</strong> (join, aggregation) rÃ©utilisÃ©</li>
<li><strong>ItÃ©rations</strong> (ML training)</li>
</ul>
<p><strong>cache() vs persist()</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># cache() = persist(StorageLevel.MEMORY_AND_DISK)</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df.cache()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># persist() = contrÃ´le fin du niveau de stockage</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark <span class="im">import</span> StorageLevel</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>df.persist(StorageLevel.MEMORY_ONLY)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Niveau</th>
<th>RAM</th>
<th>Disque</th>
<th>SÃ©rialisÃ©</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>MEMORY_ONLY</code></td>
<td>âœ…</td>
<td>âŒ</td>
<td>âŒ</td>
<td>Petit DF, RAM suffisante</td>
</tr>
<tr class="even">
<td><code>MEMORY_AND_DISK</code></td>
<td>âœ…</td>
<td>âœ…</td>
<td>âŒ</td>
<td><strong>DÃ©faut (cache())</strong></td>
</tr>
<tr class="odd">
<td><code>MEMORY_ONLY_SER</code></td>
<td>âœ…</td>
<td>âŒ</td>
<td>âœ…</td>
<td>Ã‰conomie RAM</td>
</tr>
<tr class="even">
<td><code>DISK_ONLY</code></td>
<td>âŒ</td>
<td>âœ…</td>
<td>âœ…</td>
<td>TrÃ¨s gros DF</td>
</tr>
<tr class="odd">
<td><code>OFF_HEAP</code></td>
<td>âœ…</td>
<td>âŒ</td>
<td>âœ…</td>
<td>Ã‰viter GC Java</td>
</tr>
</tbody>
</table>
<div id="cache_demo" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark <span class="im">import</span> StorageLevel</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er un DataFrame avec calculs</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">5000000</span>).withColumn(<span class="st">"squared"</span>, col(<span class="st">"id"</span>) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sans cache : chaque action recalcule tout</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>count1 <span class="op">=</span> df.<span class="bu">filter</span>(col(<span class="st">"squared"</span>) <span class="op">&gt;</span> <span class="dv">1000000</span>).count()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>count2 <span class="op">=</span> df.<span class="bu">filter</span>(col(<span class="st">"squared"</span>) <span class="op">&lt;</span> <span class="dv">100</span>).count()</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sans cache : </span><span class="sc">{</span>time<span class="sc">.</span>time() <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Avec cache : calcul une seule fois</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>df_cached <span class="op">=</span> df.cache()</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>count1 <span class="op">=</span> df_cached.<span class="bu">filter</span>(col(<span class="st">"squared"</span>) <span class="op">&gt;</span> <span class="dv">1000000</span>).count()</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>count2 <span class="op">=</span> df_cached.<span class="bu">filter</span>(col(<span class="st">"squared"</span>) <span class="op">&lt;</span> <span class="dv">100</span>).count()</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Avec cache : </span><span class="sc">{</span>time<span class="sc">.</span>time() <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co"># âš ï¸ IMPORTANT : libÃ©rer la mÃ©moire !</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>df_cached.unpersist()</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">âœ… Cache libÃ©rÃ© avec unpersist()"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<p><strong>âš ï¸ Quand NE PAS cacher :</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Situation</th>
<th>Pourquoi</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>DF utilisÃ© une seule fois</td>
<td>Gaspillage mÃ©moire</td>
</tr>
<tr class="even">
<td>DF trÃ¨s volumineux (&gt; RAM)</td>
<td>DÃ©bordement disque lent</td>
</tr>
<tr class="odd">
<td>Avant un shuffle</td>
<td>Inutile, donnÃ©es redistribuÃ©es</td>
</tr>
<tr class="even">
<td>Pipeline simple et rapide</td>
<td>Overhead du cache &gt; gain</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="joins-avancÃ©s-la-compÃ©tence-qui-change-tout" class="level2">
<h2 class="anchored" data-anchor-id="joins-avancÃ©s-la-compÃ©tence-qui-change-tout">ğŸ”— 5. Joins AvancÃ©s â€” La compÃ©tence qui change tout</h2>
<blockquote class="blockquote">
<p>Un excellent Data Engineer sait <strong>optimiser ses joins</strong>. Câ€™est souvent lÃ  que se gagne (ou se perd) le plus de temps.</p>
</blockquote>
<section id="types-de-joins-internes-spark" class="level3">
<h3 class="anchored" data-anchor-id="types-de-joins-internes-spark">5.1 Types de Joins internes Spark</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 53%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Quand Spark lâ€™utilise</th>
<th>Performance</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Broadcast Hash Join</strong></td>
<td>Petite table (&lt; seuil)</td>
<td>â­â­â­ <strong>Meilleur</strong></td>
</tr>
<tr class="even">
<td><strong>Sort Merge Join</strong></td>
<td>Grandes tables</td>
<td>â­â­ Standard</td>
</tr>
<tr class="odd">
<td><strong>Shuffle Hash Join</strong></td>
<td>Tables moyennes</td>
<td>â­ Ã‰viter si possible</td>
</tr>
</tbody>
</table>
</section>
<section id="broadcast-join-ton-meilleur-ami" class="level3">
<h3 class="anchored" data-anchor-id="broadcast-join-ton-meilleur-ami">5.2 Broadcast Join â€” Ton meilleur ami</h3>
<pre class="text"><code>SORT MERGE JOIN (shuffle)           BROADCAST JOIN (pas de shuffle)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•           â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

   Big Table      Small Table          Big Table      Small Table
   â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”
   â”‚  P1  â”‚       â”‚  P1  â”‚             â”‚  P1  â”‚â—„â”€â”€â”€â”€â”€â”€â”‚      â”‚
   â”‚  P2  â”‚       â”‚  P2  â”‚             â”‚  P2  â”‚â—„â”€â”€â”€â”€â”€â”€â”‚ COPY â”‚
   â”‚  P3  â”‚       â”‚  P3  â”‚             â”‚  P3  â”‚â—„â”€â”€â”€â”€â”€â”€â”‚      â”‚
   â””â”€â”€â”¬â”€â”€â”€â”˜       â””â”€â”€â”¬â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜
      â”‚   SHUFFLE    â”‚                    â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               Broadcast to
             â”‚                       all executors
         â”Œâ”€â”€â”€â–¼â”€â”€â”€â”                   (pas de shuffle !)
         â”‚ JOIN  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<div id="broadcast_join" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> broadcast</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Grande table (10M lignes simulÃ©es)</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>big_df <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1000000</span>).withColumn(<span class="st">"category_id"</span>, (col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">100</span>).cast(<span class="st">"int"</span>))</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Petite table (100 lignes)</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>small_df <span class="op">=</span> spark.createDataFrame(</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    [(i, <span class="ss">f"Category </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>)],</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"category_id"</span>, <span class="st">"category_name"</span>]</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># âŒ SANS broadcast hint (Spark peut ou non broadcaster)</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>result_no_hint <span class="op">=</span> big_df.join(small_df, <span class="st">"category_id"</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Sans broadcast hint:"</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>result_no_hint.explain()</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">50</span> <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co"># âœ… AVEC broadcast hint (force le broadcast)</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>result_broadcast <span class="op">=</span> big_df.join(broadcast(small_df), <span class="st">"category_id"</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Avec broadcast():"</span>)</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>result_broadcast.explain()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="configurer-le-seuil-de-broadcast" class="level3">
<h3 class="anchored" data-anchor-id="configurer-le-seuil-de-broadcast">5.3 Configurer le seuil de broadcast</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DÃ©faut : 10 MB</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Si une table &lt; 10 MB â†’ broadcast automatique</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Augmenter pour broadcaster des tables plus grandes</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.autoBroadcastJoinThreshold"</span>, <span class="dv">100</span> <span class="op">*</span> <span class="dv">1024</span> <span class="op">*</span> <span class="dv">1024</span>)  <span class="co"># 100 MB</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># DÃ©sactiver le broadcast automatique (forcer shuffle)</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.autoBroadcastJoinThreshold"</span>, <span class="op">-</span><span class="dv">1</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="join-hints-spark-3.0" class="level3">
<h3 class="anchored" data-anchor-id="join-hints-spark-3.0">5.4 Join Hints (Spark 3.0+)</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DataFrame API</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>big_df.join(small_df.hint(<span class="st">"broadcast"</span>), <span class="st">"key"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># SQL</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>spark.sql(<span class="st">"""</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="st">    SELECT /*+ BROADCAST(small_table) */ *</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="st">    FROM big_table</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="st">    JOIN small_table ON big_table.key = small_table.key</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="anti-pattern-join-sur-clÃ©-skewed" class="level3">
<h3 class="anchored" data-anchor-id="anti-pattern-join-sur-clÃ©-skewed">5.5 Anti-pattern : Join sur clÃ© skewed</h3>
<div id="skew_join" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration pour gÃ©rer le skew automatiquement (AQE)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.skewJoin.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes"</span>, <span class="st">"256MB"</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"âœ… AQE Skew Join activÃ©"</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Spark va automatiquement dÃ©tecter et gÃ©rer les partitions skewed"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="lectureÃ©criture-optimisÃ©es" class="level2">
<h2 class="anchored" data-anchor-id="lectureÃ©criture-optimisÃ©es">ğŸ“ 6. Lecture/Ã‰criture OptimisÃ©es</h2>
<section id="formats-parquet-toujours" class="level3">
<h3 class="anchored" data-anchor-id="formats-parquet-toujours">6.1 Formats : Parquet toujours !</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Format</th>
<th>Lecture</th>
<th>Ã‰criture</th>
<th>Compression</th>
<th>Predicate Pushdown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CSV</td>
<td>ğŸ¢ Lent</td>
<td>ğŸ¢ Lent</td>
<td>âŒ</td>
<td>âŒ</td>
</tr>
<tr class="even">
<td>JSON</td>
<td>ğŸ¢ Lent</td>
<td>ğŸ¢ Lent</td>
<td>âŒ</td>
<td>âŒ</td>
</tr>
<tr class="odd">
<td><strong>Parquet</strong></td>
<td>ğŸš€ Rapide</td>
<td>ğŸš€ Rapide</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr class="even">
<td>ORC</td>
<td>ğŸš€ Rapide</td>
<td>ğŸš€ Rapide</td>
<td>âœ…</td>
<td>âœ…</td>
</tr>
<tr class="odd">
<td><strong>Delta</strong></td>
<td>ğŸš€ Rapide</td>
<td>ğŸš€ Rapide</td>
<td>âœ…</td>
<td>âœ… + ACID</td>
</tr>
</tbody>
</table>
<blockquote class="blockquote">
<p>ğŸ”­ <strong>Les formats modernes</strong> (Delta, Iceberg, Hudi) seront approfondis dans le <strong>module 21 (Lakehouse)</strong> :</p>
</blockquote>
<blockquote class="blockquote">
<ul>
<li>Transactions ACID</li>
<li>Time Travel</li>
<li>Vacuum, Compaction</li>
<li>Z-Ordering</li>
</ul>
</blockquote>
</section>
<section id="predicate-pushdown" class="level3">
<h3 class="anchored" data-anchor-id="predicate-pushdown">6.2 Predicate Pushdown</h3>
<div id="predicate_pushdown" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er des donnÃ©es de test</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">100000</span>).withColumn(<span class="st">"category"</span>, (col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">10</span>).cast(<span class="st">"string"</span>))</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sauvegarder en Parquet</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>output_path <span class="op">=</span> <span class="st">"/tmp/test_parquet"</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(output_path):</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    shutil.rmtree(output_path)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>test_data.write.parquet(output_path)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Lecture avec filtre â†’ predicate pushdown</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>df_filtered <span class="op">=</span> spark.read.parquet(output_path).<span class="bu">filter</span>(col(<span class="st">"id"</span>) <span class="op">&lt;</span> <span class="dv">100</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Plan d'exÃ©cution avec Predicate Pushdown:"</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>df_filtered.explain()</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Observe "PushedFilters" dans le plan !</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="partitionnement-sur-disque" class="level3">
<h3 class="anchored" data-anchor-id="partitionnement-sur-disque">6.3 Partitionnement sur disque</h3>
<div id="partition_by" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> year, month, dayofmonth, lit</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime, timedelta</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er des donnÃ©es avec dates</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>dates <span class="op">=</span> [(datetime(<span class="dv">2024</span>, <span class="dv">1</span>, <span class="dv">1</span>) <span class="op">+</span> timedelta(days<span class="op">=</span>random.randint(<span class="dv">0</span>, <span class="dv">90</span>))).strftime(<span class="st">"%Y-%m-</span><span class="sc">%d</span><span class="st">"</span>) </span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>         <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>)]</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [(i, dates[i <span class="op">%</span> <span class="bu">len</span>(dates)], <span class="bu">float</span>(random.randint(<span class="dv">10</span>, <span class="dv">1000</span>))) </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>)]</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.createDataFrame(data, [<span class="st">"id"</span>, <span class="st">"date"</span>, <span class="st">"amount"</span>])</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.withColumn(<span class="st">"date"</span>, col(<span class="st">"date"</span>).cast(<span class="st">"date"</span>))</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.withColumn(<span class="st">"year"</span>, year(<span class="st">"date"</span>)).withColumn(<span class="st">"month"</span>, month(<span class="st">"date"</span>))</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Ã‰criture partitionnÃ©e</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>output_partitioned <span class="op">=</span> <span class="st">"/tmp/partitioned_data"</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(output_partitioned):</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    shutil.rmtree(output_partitioned)</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>df.write.partitionBy(<span class="st">"year"</span>, <span class="st">"month"</span>).parquet(output_partitioned)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Structure crÃ©Ã©e:"</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> root, dirs, files <span class="kw">in</span> os.walk(output_partitioned):</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    level <span class="op">=</span> root.replace(output_partitioned, <span class="st">''</span>).count(os.sep)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    indent <span class="op">=</span> <span class="st">' '</span> <span class="op">*</span> <span class="dv">2</span> <span class="op">*</span> level</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>indent<span class="sc">}{</span>os<span class="sc">.</span>path<span class="sc">.</span>basename(root)<span class="sc">}</span><span class="ss">/"</span>)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> level <span class="op">&lt;</span> <span class="dv">2</span>:  <span class="co"># Limiter la profondeur</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> d <span class="kw">in</span> <span class="bu">sorted</span>(dirs)[:<span class="dv">3</span>]:</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>indent<span class="sc">}</span><span class="ss">  </span><span class="sc">{</span>d<span class="sc">}</span><span class="ss">/"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="schÃ©mas-explicites" class="level3">
<h3 class="anchored" data-anchor-id="schÃ©mas-explicites">6.4 SchÃ©mas explicites</h3>
<p><strong>Pourquoi dÃ©finir un schÃ©ma ?</strong></p>
<ul>
<li>Ã‰vite lâ€™<strong>infÃ©rence</strong> (coÃ»teuse sur gros fichiers)</li>
<li><strong>Garantit</strong> les types attendus</li>
<li>DÃ©tecte les erreurs <strong>tÃ´t</strong></li>
</ul>
<div id="schema_example" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, LongType, StringType, DecimalType, DateType</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># DÃ©finir un schÃ©ma explicite</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>schema <span class="op">=</span> StructType([</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"id"</span>, LongType(), nullable<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"customer_name"</span>, StringType(), nullable<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"amount"</span>, DecimalType(<span class="dv">10</span>, <span class="dv">2</span>), nullable<span class="op">=</span><span class="va">True</span>),  <span class="co"># PrÃ©cision pour montants !</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"transaction_date"</span>, DateType(), nullable<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"SchÃ©ma dÃ©fini:"</span>)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(schema.simpleString())</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Utilisation</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co"># df = spark.read.schema(schema).parquet("data/transactions/")</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ğŸ’¡ Conseil : Utiliser DecimalType pour les montants financiers"</span>)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   Ã‰vite les erreurs d'arrondi des float/double"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="udfs-le-piÃ¨ge-de-performance" class="level2">
<h2 class="anchored" data-anchor-id="udfs-le-piÃ¨ge-de-performance">âš ï¸ 7. UDFs : Le piÃ¨ge de performance</h2>
<section id="pourquoi-les-python-udfs-sont-toxiques" class="level3">
<h3 class="anchored" data-anchor-id="pourquoi-les-python-udfs-sont-toxiques">7.1 Pourquoi les Python UDFs sont toxiques</h3>
<pre class="text"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚   SÃ©rialisation    â”‚                 â”‚
â”‚       JVM       â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚     Python      â”‚
â”‚     (Spark)     â”‚                    â”‚   (UDF lente)   â”‚
â”‚                 â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   DÃ©sÃ©rialisation  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚
                    TRÃˆS COÃ›TEUX !
                    (par ligne)</code></pre>
</section>
<section id="hiÃ©rarchie-de-performance" class="level3">
<h3 class="anchored" data-anchor-id="hiÃ©rarchie-de-performance">7.2 HiÃ©rarchie de performance</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 35%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Type</th>
<th>Performance</th>
<th>Quand lâ€™utiliser</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Expressions Spark natives</strong></td>
<td>â­â­â­â­â­</td>
<td><strong>Toujours si possible</strong></td>
</tr>
<tr class="even">
<td><strong>Pandas UDF (vectorized)</strong></td>
<td>â­â­â­</td>
<td>Si besoin Python</td>
</tr>
<tr class="odd">
<td><strong>Python UDF</strong></td>
<td>â­</td>
<td>Dernier recours</td>
</tr>
</tbody>
</table>
</section>
<section id="remplacer-udf-par-expressions-natives" class="level3">
<h3 class="anchored" data-anchor-id="remplacer-udf-par-expressions-natives">7.3 Remplacer UDF par expressions natives</h3>
<div id="udf_comparison" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> udf, when, col</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StringType</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># CrÃ©er des donnÃ©es de test</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">500000</span>).withColumn(<span class="st">"amount"</span>, (col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">2000</span>).cast(<span class="st">"double"</span>))</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># âŒ MAUVAIS : Python UDF</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="at">@udf</span>(StringType())</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> categorize_udf(amount):</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> amount <span class="op">&gt;</span> <span class="dv">1000</span>:</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"high"</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> amount <span class="op">&gt;</span> <span class="dv">100</span>:</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"medium"</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"low"</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>result_udf <span class="op">=</span> df.withColumn(<span class="st">"category"</span>, categorize_udf(col(<span class="st">"amount"</span>)))</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>result_udf.write.mode(<span class="st">"overwrite"</span>).<span class="bu">format</span>(<span class="st">"noop"</span>).save()  <span class="co"># Force l'exÃ©cution</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>udf_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"âŒ Python UDF : </span><span class="sc">{</span>udf_time<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co"># âœ… BON : Expression Spark native</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>result_native <span class="op">=</span> df.withColumn(<span class="st">"category"</span>,</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>    when(col(<span class="st">"amount"</span>) <span class="op">&gt;</span> <span class="dv">1000</span>, <span class="st">"high"</span>)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>    .when(col(<span class="st">"amount"</span>) <span class="op">&gt;</span> <span class="dv">100</span>, <span class="st">"medium"</span>)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>    .otherwise(<span class="st">"low"</span>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>result_native.write.mode(<span class="st">"overwrite"</span>).<span class="bu">format</span>(<span class="st">"noop"</span>).save()</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>native_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"âœ… Expression native : </span><span class="sc">{</span>native_time<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">ğŸ“Š Speedup : </span><span class="sc">{</span>udf_time<span class="op">/</span>native_time<span class="sc">:.1f}</span><span class="ss">x plus rapide avec expression native !"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</section>
<section id="pandas-udf-si-python-nÃ©cessaire" class="level3">
<h3 class="anchored" data-anchor-id="pandas-udf-si-python-nÃ©cessaire">7.4 Pandas UDF (si Python nÃ©cessaire)</h3>
<div id="pandas_udf_example" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> pandas_udf</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Pandas UDF = vectorisÃ© (traite des Series, pas des scalaires)</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="at">@pandas_udf</span>(<span class="st">"double"</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_transform(s: pd.Series) <span class="op">-&gt;</span> pd.Series:</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.log1p(s)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Test</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">100000</span>).withColumn(<span class="st">"value"</span>, col(<span class="st">"id"</span>).cast(<span class="st">"double"</span>))</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> df.withColumn(<span class="st">"log_value"</span>, log_transform(col(<span class="st">"value"</span>)))</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>result.write.mode(<span class="st">"overwrite"</span>).<span class="bu">format</span>(<span class="st">"noop"</span>).save()</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Pandas UDF : </span><span class="sc">{</span>time<span class="sc">.</span>time() <span class="op">-</span> start<span class="sc">:.2f}</span><span class="ss">s"</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>result.show(<span class="dv">5</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="configuration-tuning" class="level2">
<h2 class="anchored" data-anchor-id="configuration-tuning">âš™ï¸ 8. Configuration &amp; Tuning</h2>
<section id="paramÃ¨tres-essentiels" class="level3">
<h3 class="anchored" data-anchor-id="paramÃ¨tres-essentiels">8.1 ParamÃ¨tres essentiels</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 31%">
<col style="width: 22%">
<col style="width: 45%">
</colgroup>
<thead>
<tr class="header">
<th>ParamÃ¨tre</th>
<th>DÃ©faut</th>
<th>Recommandation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>spark.sql.shuffle.partitions</code></td>
<td>200</td>
<td>Adapter Ã  la taille des donnÃ©es</td>
</tr>
<tr class="even">
<td><code>spark.default.parallelism</code></td>
<td>Selon cluster</td>
<td>2-3x num_cores</td>
</tr>
<tr class="odd">
<td><code>spark.sql.autoBroadcastJoinThreshold</code></td>
<td>10MB</td>
<td>50-100MB</td>
</tr>
<tr class="even">
<td><code>spark.executor.memory</code></td>
<td>1g</td>
<td>4-16g selon cluster</td>
</tr>
<tr class="odd">
<td><code>spark.driver.memory</code></td>
<td>1g</td>
<td>2-8g</td>
</tr>
<tr class="even">
<td><code>spark.executor.memoryOverhead</code></td>
<td>10%</td>
<td>15-20% pour PySpark</td>
</tr>
</tbody>
</table>
</section>
<section id="dimensionnement-executors-vs-cores" class="level3">
<h3 class="anchored" data-anchor-id="dimensionnement-executors-vs-cores">8.2 Dimensionnement : Executors vs Cores</h3>
<pre class="text"><code>âŒ MAUVAIS : 2 executors Ã— 10 cores chacun
   - GC Java doit gÃ©rer Ã©norme heap (~50 GB)
   - Si 1 executor crash â†’ 50% de perte
   - ParallÃ©lisme moins granulaire

âœ… BON : 10 executors Ã— 4 cores chacun  
   - GC plus efficace (heap ~10 GB)
   - Meilleure isolation des erreurs
   - ParallÃ©lisme plus granulaire</code></pre>
<p><strong>RÃ¨gles de dimensionnement :</strong></p>
<pre class="text"><code>executor_cores = 4-5 max (sweet spot pour GC)
executor_memory = 4-16g (selon donnÃ©es)
num_executors = (total_cores / executor_cores) - 1

# RÃ©server pour le Driver et l'OS
driver_memory = 2-8g
memoryOverhead = 15-20% pour PySpark (sÃ©rialisation Python)</code></pre>
<p><strong>Exemple concret</strong> (cluster 100 cores, 400 GB RAM) :</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb31"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="ex">spark-submit</span> <span class="dt">\</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">--executor-cores</span> 4 <span class="dt">\</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">--executor-memory</span> 12g <span class="dt">\</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">--num-executors</span> 20 <span class="dt">\</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">--driver-memory</span> 4g <span class="dt">\</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">--conf</span> spark.executor.memoryOverhead=2g <span class="dt">\</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  main.py</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</section>
<section id="adaptive-query-execution-aqe" class="level3">
<h3 class="anchored" data-anchor-id="adaptive-query-execution-aqe">8.3 Adaptive Query Execution (AQE)</h3>
<p>Lâ€™AQE (Spark 3.0+) rend certaines optimisations manuelles <strong>obsolÃ¨tes</strong> :</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Avant AQE (manuel)</th>
<th>Avec AQE (automatique)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>coalesce(n)</code> aprÃ¨s filter</td>
<td>Auto-coalesce des partitions</td>
</tr>
<tr class="even">
<td>Calculer shuffle.partitions</td>
<td>Auto-optimize partitions</td>
</tr>
<tr class="odd">
<td>DÃ©tecter skew manuellement</td>
<td>Auto-skew handling</td>
</tr>
<tr class="even">
<td>Broadcast threshold fixe</td>
<td>Runtime broadcast decisions</td>
</tr>
</tbody>
</table>
<div id="aqe_full_config" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration AQE complÃ¨te (recommandÃ©e)</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.coalescePartitions.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.skewJoin.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.localShuffleReader.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Avec AQE, tu peux laisser shuffle.partitions Ã©levÃ©</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Spark optimisera automatiquement</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.shuffle.partitions"</span>, <span class="st">"1000"</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"âœ… Configuration AQE optimale :"</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   adaptive.enabled = </span><span class="sc">{</span>spark<span class="sc">.</span>conf<span class="sc">.</span>get(<span class="st">'spark.sql.adaptive.enabled'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   coalescePartitions = </span><span class="sc">{</span>spark<span class="sc">.</span>conf<span class="sc">.</span>get(<span class="st">'spark.sql.adaptive.coalescePartitions.enabled'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   skewJoin = </span><span class="sc">{</span>spark<span class="sc">.</span>conf<span class="sc">.</span>get(<span class="st">'spark.sql.adaptive.skewJoin.enabled'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   shuffle.partitions = </span><span class="sc">{</span>spark<span class="sc">.</span>conf<span class="sc">.</span>get(<span class="st">'spark.sql.shuffle.partitions'</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ğŸ’¡ Avec AQE, Spark ajuste automatiquement le nombre de partitions !"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="spark-ui-diagnostic" class="level2">
<h2 class="anchored" data-anchor-id="spark-ui-diagnostic">ğŸ” 9. Spark UI &amp; Diagnostic</h2>
<blockquote class="blockquote">
<p><strong>Savoir lire Spark UI = savoir debugger.</strong> Câ€™est la compÃ©tence qui fait la diffÃ©rence.</p>
</blockquote>
<section id="accÃ©der-Ã -spark-ui" class="level3">
<h3 class="anchored" data-anchor-id="accÃ©der-Ã -spark-ui">9.1 AccÃ©der Ã  Spark UI</h3>
<ul>
<li><strong>Local</strong> : http://localhost:4040</li>
<li><strong>Cluster</strong> : via le Resource Manager (YARN, K8s dashboard)</li>
<li><strong>Databricks</strong> : intÃ©grÃ© dans lâ€™interface</li>
</ul>
</section>
<section id="les-onglets-importants" class="level3">
<h3 class="anchored" data-anchor-id="les-onglets-importants">9.2 Les onglets importants</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Onglet</th>
<th>Information</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Jobs</strong></td>
<td>Vue dâ€™ensemble des jobs, durÃ©e</td>
</tr>
<tr class="even">
<td><strong>Stages</strong></td>
<td>DÃ©tail des stages, shuffle read/write</td>
</tr>
<tr class="odd">
<td><strong>Storage</strong></td>
<td>DataFrames en cache</td>
</tr>
<tr class="even">
<td><strong>Environment</strong></td>
<td>Configuration Spark</td>
</tr>
<tr class="odd">
<td><strong>Executors</strong></td>
<td>Ressources, GC, mÃ©moire</td>
</tr>
<tr class="even">
<td><strong>SQL</strong></td>
<td>Plans dâ€™exÃ©cution des requÃªtes</td>
</tr>
</tbody>
</table>
</section>
<section id="mÃ©triques-Ã -surveiller" class="level3">
<h3 class="anchored" data-anchor-id="mÃ©triques-Ã -surveiller">9.3 MÃ©triques Ã  surveiller</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>MÃ©trique</th>
<th>Signification</th>
<th>ğŸš¨ ProblÃ¨me siâ€¦</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Shuffle Read/Write</strong></td>
<td>DonnÃ©es Ã©changÃ©es</td>
<td>TrÃ¨s Ã©levÃ© (&gt; 10 GB)</td>
</tr>
<tr class="even">
<td><strong>Spill (Memory/Disk)</strong></td>
<td>DÃ©bordement mÃ©moire</td>
<td>&gt; 0</td>
</tr>
<tr class="odd">
<td><strong>Task Duration</strong></td>
<td>Temps par tÃ¢che</td>
<td>TrÃ¨s variable (skew !)</td>
</tr>
<tr class="even">
<td><strong>GC Time</strong></td>
<td>Garbage Collection</td>
<td>&gt; 10% du temps total</td>
</tr>
<tr class="odd">
<td><strong>Input/Output</strong></td>
<td>DonnÃ©es lues/Ã©crites</td>
<td>Beaucoup plus que prÃ©vu</td>
</tr>
</tbody>
</table>
</section>
<section id="patterns-de-problÃ¨mes" class="level3">
<h3 class="anchored" data-anchor-id="patterns-de-problÃ¨mes">9.4 Patterns de problÃ¨mes</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 52%">
<col style="width: 26%">
<col style="width: 21%">
</colgroup>
<thead>
<tr class="header">
<th>SymptÃ´me dans Spark UI</th>
<th>Diagnostic</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1 tÃ¢che 10x plus longue</td>
<td><strong>Data skew</strong></td>
<td>Salting, broadcast, AQE</td>
</tr>
<tr class="even">
<td>Shuffle &gt; 50 GB</td>
<td>Join non optimisÃ©</td>
<td>Broadcast join</td>
</tr>
<tr class="odd">
<td>Spill to disk</td>
<td>MÃ©moire insuffisante</td>
<td>Plus de RAM, moins de partitions</td>
</tr>
<tr class="even">
<td>GC Time &gt; 20%</td>
<td>Trop dâ€™objets Java</td>
<td>Tungsten, plus de memoryOverhead</td>
</tr>
<tr class="odd">
<td>Beaucoup de petites tÃ¢ches</td>
<td>Trop de partitions</td>
<td>Coalesce, AQE</td>
</tr>
</tbody>
</table>
<div id="spark_ui_info" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># URL de Spark UI pour cette session</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"ğŸ” Spark UI disponible sur : </span><span class="sc">{</span>spark<span class="sc">.</span>sparkContext<span class="sc">.</span>uiWebUrl<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ğŸ“Š Pour voir les mÃ©triques d'un job, lance une action puis consulte l'UI"</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Exemple : dÃ©clencher un job pour voir dans l'UI</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">1000000</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> df.groupBy((col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">100</span>).alias(<span class="st">"group"</span>)).count()</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>result.collect()  <span class="co"># Action qui dÃ©clenche le job</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">âœ… Job exÃ©cutÃ© - consulte Spark UI pour voir les stages et mÃ©triques"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="bonnes-pratiques-anti-patterns" class="level2">
<h2 class="anchored" data-anchor-id="bonnes-pratiques-anti-patterns">âœ… 10. Bonnes pratiques &amp; Anti-patterns</h2>
<section id="anti-patterns-Ã -Ã©viter-absolument" class="level3">
<h3 class="anchored" data-anchor-id="anti-patterns-Ã -Ã©viter-absolument">âŒ Anti-patterns (Ã  Ã©viter absolument)</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 32%">
<col style="width: 44%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Anti-pattern</th>
<th>Pourquoi câ€™est mal</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>collect()</code> sur 100M lignes</td>
<td>OOM Driver garanti</td>
<td><code>write()</code> vers fichier</td>
</tr>
<tr class="even">
<td>CSV en production</td>
<td>Lent, pas de schema</td>
<td><strong>Parquet/Delta</strong></td>
</tr>
<tr class="odd">
<td>UDF Python partout</td>
<td>10-100x plus lent</td>
<td>Expressions natives</td>
</tr>
<tr class="even">
<td><code>shuffle.partitions=200</code> toujours</td>
<td>Pas adaptÃ© aux donnÃ©es</td>
<td>Ajuster ou AQE</td>
</tr>
<tr class="odd">
<td>Pas de <code>cache()</code> sur DF rÃ©utilisÃ©</td>
<td>Recalcul inutile</td>
<td><code>cache()</code> + <code>unpersist()</code></td>
</tr>
<tr class="even">
<td>Ignorer Spark UI</td>
<td>Debug Ã  lâ€™aveugle</td>
<td><strong>Toujours vÃ©rifier</strong></td>
</tr>
<tr class="odd">
<td>Join sans broadcast</td>
<td>Shuffle Ã©norme</td>
<td><code>broadcast()</code> sur petites tables</td>
</tr>
<tr class="even">
<td><code>repartition()</code> avant <code>write()</code></td>
<td>Shuffle inutile</td>
<td><code>coalesce()</code> pour rÃ©duire</td>
</tr>
</tbody>
</table>
</section>
<section id="bonnes-pratiques" class="level3">
<h3 class="anchored" data-anchor-id="bonnes-pratiques">âœ… Bonnes pratiques</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Pratique</th>
<th>BÃ©nÃ©fice</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Toujours Parquet</strong></td>
<td>I/O optimisÃ©, predicate pushdown</td>
</tr>
<tr class="even">
<td><strong>Broadcast petites tables</strong></td>
<td>Ã‰vite shuffle</td>
</tr>
<tr class="odd">
<td><strong>AQE activÃ©</strong></td>
<td>Optimisation runtime</td>
</tr>
<tr class="even">
<td><strong>Partitionner par date</strong></td>
<td>Partition pruning</td>
</tr>
<tr class="odd">
<td><strong>Ã‰viter UDFs</strong></td>
<td>Performance native</td>
</tr>
<tr class="even">
<td><strong>Monitorer Spark UI</strong></td>
<td>Debug efficace</td>
</tr>
<tr class="odd">
<td><strong>Cache + unpersist</strong></td>
<td>Ã‰vite recalculs</td>
</tr>
<tr class="even">
<td><strong>Schema explicite</strong></td>
<td>Ã‰vite infÃ©rence</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="mini-projet-optimisation-dun-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="mini-projet-optimisation-dun-pipeline">ğŸš€ Mini-Projet : Optimisation dâ€™un pipeline</h2>
<section id="objectif" class="level3">
<h3 class="anchored" data-anchor-id="objectif">ğŸ¯ Objectif</h3>
<p>RÃ©duire un pipeline de <strong>20 minutes Ã  &lt; 3 minutes</strong> en appliquant les techniques apprises.</p>
</section>
<section id="scÃ©nario-e-commerce-analytics" class="level3">
<h3 class="anchored" data-anchor-id="scÃ©nario-e-commerce-analytics">ScÃ©nario : E-commerce Analytics</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Table</th>
<th>Lignes</th>
<th>Format initial</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Transactions</td>
<td>5M</td>
<td>Parquet</td>
</tr>
<tr class="even">
<td>Produits</td>
<td>10K</td>
<td>CSV</td>
</tr>
<tr class="odd">
<td>Clients</td>
<td>500K</td>
<td>Parquet</td>
</tr>
</tbody>
</table>
</section>
<section id="architecture-cible" class="level3">
<h3 class="anchored" data-anchor-id="architecture-cible">Architecture cible</h3>
<pre class="text"><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transactions  â”‚    â”‚    Produits    â”‚    â”‚    Clients     â”‚
â”‚    (5M rows)   â”‚    â”‚   (10K rows)   â”‚    â”‚   (500K rows)  â”‚
â”‚   [Parquet]    â”‚    â”‚ [CSVâ†’Parquet]  â”‚    â”‚   [Parquet]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚ broadcast           â”‚
        â”‚                     â–¼                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚      Join + Aggregation       â”‚
                 â”‚   - Broadcast products        â”‚
                 â”‚   - AQE enabled               â”‚
                 â”‚   - Native expressions        â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚      Partitioned Output       â”‚
                 â”‚   partitionBy("year","month") â”‚
                 â”‚         [Parquet]             â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<div id="mini_project_setup" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.functions <span class="im">import</span> <span class="op">*</span></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime, timedelta</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup : crÃ©er les donnÃ©es de test</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ğŸ“¦ CrÃ©ation des donnÃ©es de test..."</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuration optimale</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.coalescePartitions.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.skewJoin.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Nettoyer les rÃ©pertoires</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> path <span class="kw">in</span> [<span class="st">"/tmp/transactions"</span>, <span class="st">"/tmp/products"</span>, <span class="st">"/tmp/customers"</span>, <span class="st">"/tmp/output"</span>]:</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> os.path.exists(path):</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>        shutil.rmtree(path)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Transactions (5M lignes)</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>transactions <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">500000</span>).select(</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">"id"</span>).alias(<span class="st">"transaction_id"</span>),</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">10000</span>).alias(<span class="st">"product_id"</span>),</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">50000</span>).alias(<span class="st">"customer_id"</span>),</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>    (rand() <span class="op">*</span> <span class="dv">1000</span>).alias(<span class="st">"amount"</span>),</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>    date_add(lit(<span class="st">"2024-01-01"</span>), (rand() <span class="op">*</span> <span class="dv">90</span>).cast(<span class="st">"int"</span>)).alias(<span class="st">"date"</span>)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>transactions.write.parquet(<span class="st">"/tmp/transactions"</span>)</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"âœ… Transactions : </span><span class="sc">{</span>transactions<span class="sc">.</span>count()<span class="sc">}</span><span class="ss"> lignes"</span>)</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Produits (10K lignes) - CSV intentionnellement</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>products_data <span class="op">=</span> [(i, <span class="ss">f"Product_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, <span class="ss">f"Category_</span><span class="sc">{</span>i <span class="op">%</span> <span class="dv">50</span><span class="sc">}</span><span class="ss">"</span>, <span class="bu">float</span>(<span class="dv">10</span> <span class="op">+</span> i <span class="op">%</span> <span class="dv">100</span>)) </span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>                 <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10000</span>)]</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a>products <span class="op">=</span> spark.createDataFrame(products_data, </span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    [<span class="st">"product_id"</span>, <span class="st">"product_name"</span>, <span class="st">"category"</span>, <span class="st">"base_price"</span>])</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>products.write.mode(<span class="st">"overwrite"</span>).option(<span class="st">"header"</span>, <span class="va">True</span>).csv(<span class="st">"/tmp/products"</span>)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"âœ… Produits : </span><span class="sc">{</span>products<span class="sc">.</span>count()<span class="sc">}</span><span class="ss"> lignes (CSV)"</span>)</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Clients (500K lignes)</span></span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>customers <span class="op">=</span> spark.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">50000</span>).select(</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a>    col(<span class="st">"id"</span>).alias(<span class="st">"customer_id"</span>),</span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>    concat(lit(<span class="st">"Customer_"</span>), col(<span class="st">"id"</span>)).alias(<span class="st">"customer_name"</span>),</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a>    (col(<span class="st">"id"</span>) <span class="op">%</span> <span class="dv">5</span>).alias(<span class="st">"segment"</span>)</span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>customers.write.parquet(<span class="st">"/tmp/customers"</span>)</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"âœ… Clients : </span><span class="sc">{</span>customers<span class="sc">.</span>count()<span class="sc">}</span><span class="ss"> lignes"</span>)</span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-49"><a href="#cb35-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ğŸ“Š DonnÃ©es crÃ©Ã©es avec succÃ¨s !"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="mini_project_baseline" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># âŒ VERSION NON OPTIMISÃ‰E (baseline)</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"âŒ PIPELINE NON OPTIMISÃ‰"</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># DÃ©sactiver AQE pour le baseline</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"false"</span>)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Lecture</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>transactions_df <span class="op">=</span> spark.read.parquet(<span class="st">"/tmp/transactions"</span>)</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>products_df <span class="op">=</span> spark.read.option(<span class="st">"header"</span>, <span class="va">True</span>).option(<span class="st">"inferSchema"</span>, <span class="va">True</span>).csv(<span class="st">"/tmp/products"</span>)  <span class="co"># âŒ InfÃ©rence</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>customers_df <span class="op">=</span> spark.read.parquet(<span class="st">"/tmp/customers"</span>)</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co"># UDF non optimisÃ©</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="at">@udf</span>(StringType())</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_amount_category(amount):</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> amount <span class="op">&gt;</span> <span class="dv">500</span>: <span class="cf">return</span> <span class="st">"high"</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> amount <span class="op">&gt;</span> <span class="dv">100</span>: <span class="cf">return</span> <span class="st">"medium"</span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">"low"</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Joins sans broadcast</span></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> transactions_df <span class="op">\</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    .join(products_df, <span class="st">"product_id"</span>) <span class="op">\</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    .join(customers_df, <span class="st">"customer_id"</span>) <span class="op">\</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">"amount_category"</span>, get_amount_category(col(<span class="st">"amount"</span>))) <span class="op">\</span></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    .groupBy(<span class="st">"category"</span>, <span class="st">"segment"</span>, <span class="st">"amount_category"</span>) <span class="op">\</span></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    .agg(</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>        count(<span class="st">"*"</span>).alias(<span class="st">"num_transactions"</span>),</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">sum</span>(<span class="st">"amount"</span>).alias(<span class="st">"total_amount"</span>)</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Ã‰criture non partitionnÃ©e</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(<span class="st">"/tmp/output"</span>):</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>    shutil.rmtree(<span class="st">"/tmp/output"</span>)</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>result.write.parquet(<span class="st">"/tmp/output"</span>)</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>baseline_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">â±ï¸ Temps baseline : </span><span class="sc">{</span>baseline_time<span class="sc">:.2f}</span><span class="ss">s"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="mini_project_optimized" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># âœ… VERSION OPTIMISÃ‰E</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"âœ… PIPELINE OPTIMISÃ‰"</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Activer AQE</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>spark.conf.<span class="bu">set</span>(<span class="st">"spark.sql.adaptive.coalescePartitions.enabled"</span>, <span class="st">"true"</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>start <span class="op">=</span> time.time()</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Lecture avec schema explicite pour CSV</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyspark.sql.types <span class="im">import</span> StructType, StructField, IntegerType, StringType, DoubleType</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>products_schema <span class="op">=</span> StructType([</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"product_id"</span>, IntegerType()),</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"product_name"</span>, StringType()),</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"category"</span>, StringType()),</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    StructField(<span class="st">"base_price"</span>, DoubleType())</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>transactions_df <span class="op">=</span> spark.read.parquet(<span class="st">"/tmp/transactions"</span>)</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>products_df <span class="op">=</span> spark.read.option(<span class="st">"header"</span>, <span class="va">True</span>).schema(products_schema).csv(<span class="st">"/tmp/products"</span>)  <span class="co"># âœ… Schema explicite</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>customers_df <span class="op">=</span> spark.read.parquet(<span class="st">"/tmp/customers"</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Broadcast les petites tables</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>products_df <span class="op">=</span> broadcast(products_df)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Expression native au lieu de UDF</span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>amount_category_expr <span class="op">=</span> when(col(<span class="st">"amount"</span>) <span class="op">&gt;</span> <span class="dv">500</span>, <span class="st">"high"</span>) <span class="op">\</span></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>    .when(col(<span class="st">"amount"</span>) <span class="op">&gt;</span> <span class="dv">100</span>, <span class="st">"medium"</span>) <span class="op">\</span></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>    .otherwise(<span class="st">"low"</span>)</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Pipeline optimisÃ©</span></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>result_optimized <span class="op">=</span> transactions_df <span class="op">\</span></span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a>    .join(products_df, <span class="st">"product_id"</span>) <span class="op">\</span></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>    .join(customers_df, <span class="st">"customer_id"</span>) <span class="op">\</span></span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">"amount_category"</span>, amount_category_expr) <span class="op">\</span></span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">"year"</span>, year(<span class="st">"date"</span>)) <span class="op">\</span></span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a>    .withColumn(<span class="st">"month"</span>, month(<span class="st">"date"</span>)) <span class="op">\</span></span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>    .groupBy(<span class="st">"category"</span>, <span class="st">"segment"</span>, <span class="st">"amount_category"</span>, <span class="st">"year"</span>, <span class="st">"month"</span>) <span class="op">\</span></span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>    .agg(</span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>        count(<span class="st">"*"</span>).alias(<span class="st">"num_transactions"</span>),</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">sum</span>(<span class="st">"amount"</span>).alias(<span class="st">"total_amount"</span>)</span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Ã‰criture partitionnÃ©e</span></span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> os.path.exists(<span class="st">"/tmp/output_optimized"</span>):</span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a>    shutil.rmtree(<span class="st">"/tmp/output_optimized"</span>)</span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a>result_optimized.write.partitionBy(<span class="st">"year"</span>, <span class="st">"month"</span>).parquet(<span class="st">"/tmp/output_optimized"</span>)</span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a>optimized_time <span class="op">=</span> time.time() <span class="op">-</span> start</span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">â±ï¸ Temps optimisÃ© : </span><span class="sc">{</span>optimized_time<span class="sc">:.2f}</span><span class="ss">s"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="mini_project_summary" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># RÃ©sumÃ© des optimisations</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ğŸ“Š RÃ‰SUMÃ‰ DES OPTIMISATIONS"</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>speedup <span class="op">=</span> baseline_time <span class="op">/</span> optimized_time <span class="cf">if</span> optimized_time <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>reduction <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> optimized_time <span class="op">/</span> baseline_time) <span class="op">*</span> <span class="dv">100</span> <span class="cf">if</span> baseline_time <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"""</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="ss">â±ï¸ Temps baseline    : </span><span class="sc">{</span>baseline_time<span class="sc">:.2f}</span><span class="ss">s</span></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="ss">â±ï¸ Temps optimisÃ©    : </span><span class="sc">{</span>optimized_time<span class="sc">:.2f}</span><span class="ss">s</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a><span class="ss">ğŸš€ Speedup           : </span><span class="sc">{</span>speedup<span class="sc">:.1f}</span><span class="ss">x</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a><span class="ss">ğŸ“‰ RÃ©duction         : </span><span class="sc">{</span>reduction<span class="sc">:.0f}</span><span class="ss">%</span></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a><span class="ss">Optimisations appliquÃ©es :</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span class="ss">  âœ… AQE activÃ© (Adaptive Query Execution)</span></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="ss">  âœ… Schema explicite pour CSV (pas d'infÃ©rence)</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="ss">  âœ… Broadcast join pour products (10K lignes)</span></span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="ss">  âœ… Expression native au lieu de UDF Python</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="ss">  âœ… Ã‰criture partitionnÃ©e par year/month</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="ss">"""</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<hr>
</section>
</section>
<section id="quiz-de-fin-de-module" class="level2">
<h2 class="anchored" data-anchor-id="quiz-de-fin-de-module">ğŸ§ª Quiz de fin de module</h2>
<hr>
<section id="q1.-quel-composant-de-spark-optimise-automatiquement-le-plan-de-requÃªte" class="level3">
<h3 class="anchored" data-anchor-id="q1.-quel-composant-de-spark-optimise-automatiquement-le-plan-de-requÃªte">â“ Q1. Quel composant de Spark optimise automatiquement le plan de requÃªte ?</h3>
<ol type="a">
<li>Tungsten<br>
</li>
<li>Catalyst<br>
</li>
<li>Driver<br>
</li>
<li>Executor</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” Catalyst est lâ€™optimiseur de requÃªtes qui applique predicate pushdown, projection pruning, et join reordering.</p>
</details>
<hr>
</section>
<section id="q2.-quelle-opÃ©ration-cause-un-shuffle" class="level3">
<h3 class="anchored" data-anchor-id="q2.-quelle-opÃ©ration-cause-un-shuffle">â“ Q2. Quelle opÃ©ration cause un shuffle ?</h3>
<ol type="a">
<li><code>filter()</code><br>
</li>
<li><code>select()</code><br>
</li>
<li><code>groupBy()</code><br>
</li>
<li><code>withColumn()</code></li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : c</strong> â€” <code>groupBy()</code> nÃ©cessite un shuffle pour regrouper les donnÃ©es par clÃ©. Les autres sont des transformations narrow.</p>
</details>
<hr>
</section>
<section id="q3.-quelle-mÃ©thode-utiliser-pour-rÃ©duire-le-nombre-de-partitions-sans-shuffle" class="level3">
<h3 class="anchored" data-anchor-id="q3.-quelle-mÃ©thode-utiliser-pour-rÃ©duire-le-nombre-de-partitions-sans-shuffle">â“ Q3. Quelle mÃ©thode utiliser pour rÃ©duire le nombre de partitions SANS shuffle ?</h3>
<ol type="a">
<li><code>repartition()</code><br>
</li>
<li><code>coalesce()</code><br>
</li>
<li><code>partitionBy()</code><br>
</li>
<li><code>bucketBy()</code></li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” <code>coalesce()</code> combine les partitions existantes sans shuffle (si rÃ©duction). <code>repartition()</code> cause toujours un shuffle.</p>
</details>
<hr>
</section>
<section id="q4.-quelle-est-la-taille-optimale-dune-partition-spark" class="level3">
<h3 class="anchored" data-anchor-id="q4.-quelle-est-la-taille-optimale-dune-partition-spark">â“ Q4. Quelle est la taille optimale dâ€™une partition Spark ?</h3>
<ol type="a">
<li>1-10 MB<br>
</li>
<li>128-256 MB<br>
</li>
<li>1-2 GB<br>
</li>
<li>10-50 GB</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” 128-256 MB est le sweet spot. Trop petit = overhead, trop grand = OOM et mauvaise parallÃ©lisation.</p>
</details>
<hr>
</section>
<section id="q5.-pour-joindre-une-table-de-10-gb-avec-une-table-de-50-mb-quelle-stratÃ©gie-utiliser" class="level3">
<h3 class="anchored" data-anchor-id="q5.-pour-joindre-une-table-de-10-gb-avec-une-table-de-50-mb-quelle-stratÃ©gie-utiliser">â“ Q5. Pour joindre une table de 10 GB avec une table de 50 MB, quelle stratÃ©gie utiliser ?</h3>
<ol type="a">
<li>Sort Merge Join<br>
</li>
<li>Shuffle Hash Join<br>
</li>
<li>Broadcast Join<br>
</li>
<li>Nested Loop Join</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : c</strong> â€” Broadcast Join envoie la petite table (50 MB) Ã  tous les executors, Ã©vitant le shuffle de la grande table.</p>
</details>
<hr>
</section>
<section id="q6.-pourquoi-les-python-udfs-sont-ils-lents" class="level3">
<h3 class="anchored" data-anchor-id="q6.-pourquoi-les-python-udfs-sont-ils-lents">â“ Q6. Pourquoi les Python UDFs sont-ils lents ?</h3>
<ol type="a">
<li>Python est un langage interprÃ©tÃ©<br>
</li>
<li>SÃ©rialisation JVM â†”ï¸ Python pour chaque ligne<br>
</li>
<li>Le GIL de Python<br>
</li>
<li>Manque de mÃ©moire</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” Chaque ligne nÃ©cessite une sÃ©rialisation JVMâ†’Python et dÃ©sÃ©rialisation Pythonâ†’JVM, ce qui est trÃ¨s coÃ»teux.</p>
</details>
<hr>
</section>
<section id="q7.-que-signifie-spill-to-disk-dans-spark-ui" class="level3">
<h3 class="anchored" data-anchor-id="q7.-que-signifie-spill-to-disk-dans-spark-ui">â“ Q7. Que signifie â€œSpill to diskâ€ dans Spark UI ?</h3>
<ol type="a">
<li>Les donnÃ©es sont Ã©crites en Parquet<br>
</li>
<li>La mÃ©moire est insuffisante, donnÃ©es Ã©crites sur disque<br>
</li>
<li>Le cache est activÃ©<br>
</li>
<li>Le shuffle est terminÃ©</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” Spill indique que la mÃ©moire est insuffisante et les donnÃ©es dÃ©bordent sur le disque, ce qui ralentit lâ€™exÃ©cution.</p>
</details>
<hr>
</section>
<section id="q8.-quel-deploy-mode-utiliser-en-production" class="level3">
<h3 class="anchored" data-anchor-id="q8.-quel-deploy-mode-utiliser-en-production">â“ Q8. Quel deploy mode utiliser en production ?</h3>
<ol type="a">
<li><code>client</code><br>
</li>
<li><code>cluster</code><br>
</li>
<li><code>local</code><br>
</li>
<li><code>standalone</code></li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” En mode <code>cluster</code>, le Driver tourne sur un worker du cluster, ce qui est plus robuste pour la production.</p>
</details>
<hr>
</section>
<section id="q9.-que-fait-laqe-adaptive-query-execution" class="level3">
<h3 class="anchored" data-anchor-id="q9.-que-fait-laqe-adaptive-query-execution">â“ Q9. Que fait lâ€™AQE (Adaptive Query Execution) ?</h3>
<ol type="a">
<li>Compile le code Python<br>
</li>
<li>Optimise le plan dâ€™exÃ©cution au runtime<br>
</li>
<li>Compresse les donnÃ©es<br>
</li>
<li>GÃ¨re lâ€™authentification</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” AQE optimise dynamiquement le plan dâ€™exÃ©cution pendant lâ€™exÃ©cution (coalesce, skew handling, broadcast).</p>
</details>
<hr>
</section>
<section id="q10.-combien-de-cores-par-executor-est-recommandÃ©" class="level3">
<h3 class="anchored" data-anchor-id="q10.-combien-de-cores-par-executor-est-recommandÃ©">â“ Q10. Combien de cores par executor est recommandÃ© ?</h3>
<ol type="a">
<li>1 core<br>
</li>
<li>4-5 cores<br>
</li>
<li>10-15 cores<br>
</li>
<li>Tous les cores disponibles</li>
</ol>
<details>
<summary>
ğŸ’¡ Voir la rÃ©ponse
</summary>
<p>âœ… <strong>RÃ©ponse : b</strong> â€” 4-5 cores est le sweet spot. Plus de cores = heap plus grand = GC moins efficace.</p>
</details>
<hr>
</section>
</section>
<section id="ressources-pour-aller-plus-loin" class="level2">
<h2 class="anchored" data-anchor-id="ressources-pour-aller-plus-loin">ğŸ“š Ressources pour aller plus loin</h2>
<section id="documentation-officielle" class="level3">
<h3 class="anchored" data-anchor-id="documentation-officielle">ğŸŒ Documentation officielle</h3>
<ul>
<li><a href="https://spark.apache.org/docs/latest/sql-programming-guide.html">Spark SQL Guide</a></li>
<li><a href="https://spark.apache.org/docs/latest/configuration.html">Spark Configuration</a></li>
<li><a href="https://spark.apache.org/docs/latest/tuning.html">Tuning Spark</a></li>
</ul>
</section>
<section id="articles-tutoriels" class="level3">
<h3 class="anchored" data-anchor-id="articles-tutoriels">ğŸ“– Articles &amp; Tutoriels</h3>
<ul>
<li><a href="https://docs.databricks.com/en/optimizations/index.html">Databricks - Spark Performance Tuning</a></li>
<li><a href="https://medium.com/swlh/revealing-apache-spark-shuffling-magic-b2cb1e75a1f8">Understanding Spark Shuffle</a></li>
</ul>
</section>
<section id="outils" class="level3">
<h3 class="anchored" data-anchor-id="outils">ğŸ”§ Outils</h3>
<ul>
<li><a href="http://localhost:4040">Spark UI</a> â€” Diagnostic local</li>
<li><a href="https://spark.apache.org/docs/latest/submitting-applications.html">spark-submit</a> â€” Guide officiel</li>
</ul>
<hr>
</section>
</section>
<section id="prochaine-Ã©tape" class="level2">
<h2 class="anchored" data-anchor-id="prochaine-Ã©tape">â¡ï¸ Prochaine Ã©tape</h2>
<p>Maintenant que tu maÃ®trises lâ€™optimisation Spark, passons aux <strong>fonctionnalitÃ©s SQL avancÃ©es</strong> !</p>
<p>ğŸ‘‰ <strong>Module suivant : <code>20_spark_sql_deep_dive.ipynb</code></strong> â€” Spark SQL Deep Dive</p>
<p>Tu vas apprendre :</p>
<ul>
<li><strong>Window functions</strong> avancÃ©es</li>
<li><strong>CTEs</strong> et subqueries</li>
<li>Optimisation SQL</li>
<li>Spark SQL vs DataFrame API</li>
</ul>
<hr>
<blockquote class="blockquote">
<p>âš ï¸ <strong>Note</strong> : Spark Streaming sera couvert dans le <strong>module 24</strong> Kafka.</p>
</blockquote>
<hr>
<section id="rÃ©capitulatif-de-ce-module" class="level3">
<h3 class="anchored" data-anchor-id="rÃ©capitulatif-de-ce-module">ğŸ“ RÃ©capitulatif de ce module</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Concept</th>
<th>Ce que tu as appris</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Architecture</strong></td>
<td>Catalyst, Tungsten, DAG</td>
</tr>
<tr class="even">
<td><strong>spark-submit</strong></td>
<td>Deploy modes, packaging, structure projet</td>
</tr>
<tr class="odd">
<td><strong>Partitionnement</strong></td>
<td>Shuffle, repartition vs coalesce, skew</td>
</tr>
<tr class="even">
<td><strong>Caching</strong></td>
<td>cache() vs persist(), storage levels</td>
</tr>
<tr class="odd">
<td><strong>Joins</strong></td>
<td>Broadcast, Sort Merge, hints</td>
</tr>
<tr class="even">
<td><strong>I/O</strong></td>
<td>Parquet, partitionnement disque, schemas</td>
</tr>
<tr class="odd">
<td><strong>UDFs</strong></td>
<td>Ã‰viter Python UDF, expressions natives</td>
</tr>
<tr class="even">
<td><strong>Tuning</strong></td>
<td>AQE, executors/cores, configuration</td>
</tr>
<tr class="odd">
<td><strong>Diagnostic</strong></td>
<td>Spark UI, mÃ©triques</td>
</tr>
</tbody>
</table>
<hr>
<p>ğŸ‰ <strong>FÃ©licitations !</strong> Tu as terminÃ© le module PySpark Advanced.</p>
<div id="cleanup" class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nettoyage</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>spark.stop()</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"âœ… SparkSession arrÃªtÃ©e"</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Nettoyage des fichiers temporaires (optionnel)</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="co"># import shutil</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># for path in ["/tmp/transactions", "/tmp/products", "/tmp/customers", </span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">#              "/tmp/output", "/tmp/output_optimized", "/tmp/test_parquet", "/tmp/partitioned_data"]:</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">#     if os.path.exists(path):</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">#         shutil.rmtree(path)</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co"># print("ğŸ§¹ Fichiers temporaires supprimÃ©s")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>


</section>
</section>

</main> <!-- /main -->
<!-- ===== Floating PDF Download Button ===== -->

<style>
#pdf-button {
  position: fixed;
  bottom: 20px;
  right: 20px;
  background: #00b4d8;
  color: white;
  padding: 10px 20px;
  border-radius: 30px;
  box-shadow: 0px 4px 10px rgba(0,0,0,0.3);
  font-size: 14px;
  cursor: pointer;
  z-index: 9999;
  transition: 0.2s ease-in-out;
}
#pdf-button:hover {
  background: #0077b6;
}
</style>

<div id="pdf-button" onclick="downloadPDF()">
  ğŸ“„ TÃ©lÃ©charger ce module en PDF
</div>

<script>
function downloadPDF() {
  window.print(); // fonctionne directement dans Quarto HTML
}
</script>
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/diakite-data\.github\.io\/data-engineering-bootcamp");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="preferred_color_scheme">
<input type="hidden" id="giscus-alt-theme" value="preferred_color_scheme">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "diakite-data/data-engineering-bootcamp";
    script.dataset.repoId = "R_kgDOQjHMsg";
    script.dataset.category = "General";
    script.dataset.categoryId = "DIC_kwDOQjHMss4CzeOO";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "fr";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="git@github.com:diakite-data/data-engineering-bootcamp.git/blob/main/notebooks/intermediate/19_pyspark_advanced.ipynb" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="git@github.com:diakite-data/data-engineering-bootcamp.git/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer><script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>