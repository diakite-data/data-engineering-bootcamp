[
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "",
    "text": "Bienvenue dans ce module oÃ¹ tu vas apprendre les commandes Bash essentielles pour manipuler des fichiers, automatiser des tÃ¢ches, et interagir avec ton environnement systÃ¨me â€” des compÃ©tences indispensables pour un Data Engineer !",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#prÃ©requis",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#prÃ©requis",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "1 ğŸ“‹ PrÃ©requis",
    "text": "1 ğŸ“‹ PrÃ©requis\n\n\n\n\n\n\n\nNiveau\nCompÃ©tence\n\n\n\n\nâœ… Requis\nAvoir suivi le module 01_intro_data_engineering\n\n\nâœ… Requis\nAvoir accÃ¨s Ã  un terminal (Linux, Mac, ou Windows avec WSL/Git Bash)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#objectifs-du-module",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#objectifs-du-module",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "2 ğŸ¯ Objectifs du module",
    "text": "2 ğŸ¯ Objectifs du module\nÃ€ la fin de ce module, tu seras capable de : - Naviguer dans lâ€™arborescence de fichiers - Manipuler des fichiers et dossiers - Filtrer et rechercher dans des donnÃ©es - Ã‰crire des scripts Bash pour automatiser des tÃ¢ches - Planifier des jobs avec cron",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#cest-quoi-le-langage-bash",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#cest-quoi-le-langage-bash",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "3 ğŸ§  Câ€™est quoi le langage Bash ?",
    "text": "3 ğŸ§  Câ€™est quoi le langage Bash ?\nBash (abrÃ©viation de Bourne Again SHell) est un langage de commande et de script utilisÃ© dans la majoritÃ© des systÃ¨mes Unix/Linux (et mÃªme sous Windows via WSL ou Git Bash).\nIl te permet de :\n\nğŸ“‚ Naviguer dans les dossiers\n\nğŸ“„ Manipuler des fichiers et des donnÃ©es\n\nâš™ï¸ Automatiser des tÃ¢ches rÃ©pÃ©titives\n\nğŸ”„ Ã‰crire des scripts shell pour lancer des traitements de donnÃ©es\n\n\n\n3.1 ğŸ§° Pourquoi câ€™est utile pour un Data Engineer ?\n\n\n\n\n\n\n\nCas dâ€™usage\nExemple concret\n\n\n\n\nLancer des pipelines ETL\npython etl_pipeline.py && echo \"Success\" \\|\\| echo \"Failed\"\n\n\nÃ‰crire des jobs cron\nExtraction automatique de donnÃ©es chaque nuit Ã  2h\n\n\nManipuler des fichiers\nFusionner 100 fichiers CSV en un seul\n\n\nOrchestrer des outils\nLancer Docker, Spark, ou Airflow depuis un script\n\n\nAnalyser des logs\nTrouver toutes les erreurs dans les logs du jour\n\n\n\n\nğŸ’¡ En bref : le Bash est ton couteau suisse pour parler avec ton ordinateur et piloter lâ€™Ã©cosystÃ¨me data.\n\n\nâ„¹ï¸ Le savais-tu ?\nLe mot Bash signifie â€œBourne Again SHellâ€, un jeu de mots sur :\n\nLe shell Unix original : le Bourne Shell (sh), dÃ©veloppÃ© dans les annÃ©es 1970 par Stephen Bourne\nLâ€™expression anglaise â€œborn againâ€ = renaÃ®tre\n\nBash est donc une nouvelle version amÃ©liorÃ©e du shell Bourne, libre, puissante, et utilisÃ©e par dÃ©faut dans la plupart des systÃ¨mes Unix/Linux modernes.\nğŸ“– Biographie de Stephen R. Bourne sur Wikipedia",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#comment-accÃ©der-Ã -bash",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#comment-accÃ©der-Ã -bash",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "4 ğŸ’» Comment accÃ©der Ã  Bash ?",
    "text": "4 ğŸ’» Comment accÃ©der Ã  Bash ?\n\n\n\n\n\n\n\nSystÃ¨me\nComment y accÃ©der\n\n\n\n\nğŸ§ Linux\nBash est installÃ© par dÃ©faut. Ouvre un Terminal\n\n\nğŸ macOS\nOuvre Terminal (Applications â†’ Utilitaires â†’ Terminal)\n\n\nğŸªŸ Windows\nInstalle WSL (Windows Subsystem for Linux) ou Git Bash\n\n\n\n\n4.1 Installation de WSL sur Windows\n# Dans PowerShell en administrateur\nwsl --install\nAprÃ¨s redÃ©marrage, tu auras accÃ¨s Ã  un terminal Linux complet !\n\n\n4.2 VÃ©rifier ta version de Bash\nbash --version",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#navigation-exploration",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#navigation-exploration",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "5 ğŸ“ 1. Navigation & exploration",
    "text": "5 ğŸ“ 1. Navigation & exploration\nLes commandes de base pour se dÃ©placer dans lâ€™arborescence :\n\n\nCode\n%%bash\n# Affiche le chemin du dossier courant (Print Working Directory)\npwd\n\n# Liste les fichiers du dossier courant\nls\n\n# Liste avec dÃ©tails (permissions, taille, date)\nls -lh\n\n# Liste incluant les fichiers cachÃ©s\nls -la\n\n# Affiche l'arborescence (si installÃ©)\n# tree\n\n# Change de dossier\ncd /tmp\npwd\n\n# Revenir au dossier prÃ©cÃ©dent\ncd -\n\n# Aller au dossier home\ncd ~\n\n\n\n5.1 ğŸ”‘ Raccourcis de navigation essentiels\n\n\n\nSymbole\nSignification\nExemple\n\n\n\n\n.\nDossier courant\n./script.sh\n\n\n..\nDossier parent\ncd ..\n\n\n~\nDossier home\ncd ~\n\n\n/\nRacine du systÃ¨me\ncd /\n\n\n-\nDossier prÃ©cÃ©dent\ncd -",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#crÃ©ation-et-manipulation-de-fichiers",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#crÃ©ation-et-manipulation-de-fichiers",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "6 ğŸ“‚ 2. CrÃ©ation et manipulation de fichiers",
    "text": "6 ğŸ“‚ 2. CrÃ©ation et manipulation de fichiers\nCrÃ©er, copier, dÃ©placer, supprimer :\n\n\nCode\n%%bash\n# CrÃ©er un dossier\nmkdir data\n\n# CrÃ©er un dossier avec ses parents (pas d'erreur si existe)\nmkdir -p data/raw/2024\n\n# CrÃ©er un fichier vide\ntouch data/fichier.csv\n\n# CrÃ©er plusieurs fichiers\ntouch data/file1.csv data/file2.csv data/file3.csv\n\n# Copier un fichier\ncp data/fichier.csv data/fichier_backup.csv\n\n# Copier un dossier entier (rÃ©cursif)\ncp -r data/ data_backup/\n\n# DÃ©placer / Renommer un fichier\nmv data/fichier.csv data/nouveau_nom.csv\n\n# Supprimer un fichier\nrm data/file1.csv\n\n# Supprimer un dossier vide\nrmdir data/raw/2024\n\n# Supprimer un dossier et son contenu (âš ï¸ DANGEREUX)\nrm -r data_backup/",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#lecture-de-contenu",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#lecture-de-contenu",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "7 ğŸ“„ 3. Lecture de contenu",
    "text": "7 ğŸ“„ 3. Lecture de contenu\nLire, afficher, compter les lignes :\n\n\nCode\n%%bash\n# CrÃ©ons d'abord un fichier exemple\ncat &lt;&lt; 'EOF' &gt; ventes.csv\ndate,produit,quantite,prix\n2024-01-01,Laptop,5,999.99\n2024-01-02,Souris,20,29.99\n2024-01-03,Clavier,15,79.99\n2024-01-04,Ã‰cran,8,299.99\n2024-01-05,Laptop,3,999.99\n2024-01-06,Souris,25,29.99\n2024-01-07,Casque,12,149.99\nEOF\n\necho \"âœ… Fichier ventes.csv crÃ©Ã©\"\n\n\n\n\nCode\n%%bash\n# Affiche le contenu entier\necho \"=== cat ===\"\ncat ventes.csv\n\necho \"\"\necho \"=== head (3 premiÃ¨res lignes) ===\"\nhead -n 3 ventes.csv\n\necho \"\"\necho \"=== tail (2 derniÃ¨res lignes) ===\"\ntail -n 2 ventes.csv\n\necho \"\"\necho \"=== wc (comptage) ===\"\nwc -l ventes.csv    # Nombre de lignes\nwc -w ventes.csv    # Nombre de mots\nwc -c ventes.csv    # Nombre de caractÃ¨res\n\n\n\n7.1 ğŸ“– Lire des gros fichiers avec less\nPour les fichiers volumineux, utilise less qui permet de naviguer :\nless gros_fichier.csv\n\n\n\nTouche\nAction\n\n\n\n\nâ†“ ou j\nLigne suivante\n\n\nâ†‘ ou k\nLigne prÃ©cÃ©dente\n\n\nSpace\nPage suivante\n\n\nb\nPage prÃ©cÃ©dente\n\n\n/mot\nRechercher â€œmotâ€\n\n\nn\nOccurrence suivante\n\n\nq\nQuitter",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#recherche-filtrage",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#recherche-filtrage",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "8 ğŸ” 4. Recherche & filtrage",
    "text": "8 ğŸ” 4. Recherche & filtrage\nExtraire des informations prÃ©cises â€” essentiel pour un Data Engineer !\n\n\nCode\n%%bash\necho \"=== grep : recherche de motifs ===\"\n\n# Rechercher les lignes contenant \"Laptop\"\necho \"Lignes avec 'Laptop':\"\ngrep \"Laptop\" ventes.csv\n\necho \"\"\n# Recherche insensible Ã  la casse\necho \"Recherche insensible Ã  la casse (-i):\"\ngrep -i \"laptop\" ventes.csv\n\necho \"\"\n# Compter le nombre de correspondances\necho \"Nombre de lignes avec 'Souris':\"\ngrep -c \"Souris\" ventes.csv\n\necho \"\"\n# Afficher les numÃ©ros de ligne\necho \"Avec numÃ©ros de ligne (-n):\"\ngrep -n \"99.99\" ventes.csv\n\necho \"\"\n# Inverser la recherche (lignes qui NE contiennent PAS)\necho \"Lignes SANS 'Laptop' (-v):\"\ngrep -v \"Laptop\" ventes.csv\n\n\n\n\nCode\n%%bash\necho \"=== find : trouver des fichiers ===\"\n\n# CrÃ©er quelques fichiers pour l'exemple\nmkdir -p projet/data projet/scripts\ntouch projet/data/users.csv projet/data/sales.csv projet/data/old.json\ntouch projet/scripts/etl.py projet/scripts/utils.py\n\n# Trouver tous les fichiers .csv\necho \"Fichiers .csv:\"\nfind projet/ -name \"*.csv\"\n\necho \"\"\n# Trouver tous les fichiers .py\necho \"Fichiers .py:\"\nfind projet/ -name \"*.py\"\n\necho \"\"\n# Trouver les fichiers modifiÃ©s dans les derniÃ¨res 24h\necho \"Fichiers modifiÃ©s rÃ©cemment:\"\nfind projet/ -mtime -1 -type f\n\n# Nettoyage\nrm -r projet/\n\n\n\n\nCode\n%%bash\necho \"=== cut : extraire des colonnes ===\"\n\n# Extraire la 2Ã¨me colonne (produit)\necho \"Colonne 'produit':\"\ncut -d',' -f2 ventes.csv\n\necho \"\"\necho \"=== sort : trier ===\"\n# Trier par produit (2Ã¨me colonne)\necho \"TriÃ© par produit:\"\ntail -n +2 ventes.csv | sort -t',' -k2\n\necho \"\"\necho \"=== uniq : valeurs uniques ===\"\n# Liste des produits uniques\necho \"Produits uniques:\"\ncut -d',' -f2 ventes.csv | tail -n +2 | sort | uniq\n\necho \"\"\n# Compter les occurrences\necho \"Comptage par produit:\"\ncut -d',' -f2 ventes.csv | tail -n +2 | sort | uniq -c",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#pipes-redirections",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#pipes-redirections",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "9 ğŸ”— 5. Pipes & redirections",
    "text": "9 ğŸ”— 5. Pipes & redirections\nLe pipe (|) est lâ€™outil le plus puissant de Bash : il permet de chaÃ®ner des commandes en envoyant la sortie dâ€™une commande vers lâ€™entrÃ©e de la suivante.\n\n\nCode\n%%bash\necho \"=== Exemples de pipes ===\"\n\n# Trouver les ventes de Laptop et compter\necho \"Nombre de ventes Laptop:\"\ncat ventes.csv | grep \"Laptop\" | wc -l\n\necho \"\"\n# Top 3 des produits les plus vendus\necho \"Top 3 produits (par nombre de lignes):\"\ncut -d',' -f2 ventes.csv | tail -n +2 | sort | uniq -c | sort -rn | head -3\n\necho \"\"\n# Pipeline complexe : produits avec prix &gt; 100\necho \"Produits avec prix &gt; 100:\"\ntail -n +2 ventes.csv | awk -F',' '$4 &gt; 100 {print $2, $4}' | sort -u\n\n\n\n\nCode\n%%bash\necho \"=== Redirections ===\"\n\n# Rediriger vers un fichier (Ã©crase)\ngrep \"Laptop\" ventes.csv &gt; laptops.txt\necho \"Contenu de laptops.txt:\"\ncat laptops.txt\n\necho \"\"\n# Ajouter Ã  un fichier (append)\ngrep \"Ã‰cran\" ventes.csv &gt;&gt; laptops.txt\necho \"AprÃ¨s ajout:\"\ncat laptops.txt\n\necho \"\"\n# Rediriger les erreurs\nls fichier_inexistant 2&gt; erreurs.log\necho \"Erreur capturÃ©e:\"\ncat erreurs.log\n\n# Nettoyage\nrm -f laptops.txt erreurs.log\n\n\n\n9.1 ğŸ“‹ RÃ©capitulatif des redirections\n\n\n\n\n\n\n\n\nSymbole\nDescription\nExemple\n\n\n\n\n&gt;\nRedirige stdout vers fichier (Ã©crase)\necho \"hello\" &gt; file.txt\n\n\n&gt;&gt;\nRedirige stdout vers fichier (ajoute)\necho \"world\" &gt;&gt; file.txt\n\n\n2&gt;\nRedirige stderr vers fichier\ncmd 2&gt; errors.log\n\n\n&&gt;\nRedirige stdout ET stderr\ncmd &&gt; all.log\n\n\n&lt;\nUtilise fichier comme entrÃ©e\nwc -l &lt; file.txt\n\n\n\\|\nPipe : stdout â†’ stdin suivant\ncat file \\| grep mot",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#variables-et-boucles",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#variables-et-boucles",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "10 ğŸ” 6. Variables et boucles",
    "text": "10 ğŸ” 6. Variables et boucles\nAutomatiser avec des scripts bash :\n\n\nCode\n%%bash\necho \"=== Variables ===\"\n\n# DÃ©clarer une variable (PAS d'espace autour du =)\nnom=\"Data Engineer\"\nannee=2024\ndossier_data=\"/home/user/data\"\n\n# Utiliser une variable avec $\necho \"Bienvenue $nom !\"\necho \"Nous sommes en $annee\"\n\n# Utiliser ${} pour Ã©viter l'ambiguÃ¯tÃ©\necho \"Fichier: ${dossier_data}/ventes.csv\"\n\necho \"\"\necho \"=== Variables d'environnement ===\"\necho \"Home: $HOME\"\necho \"User: $USER\"\necho \"Shell: $SHELL\"\necho \"Path: $PATH\" | cut -c1-50  # TronquÃ© pour l'affichage\n\n\n\n\nCode\n%%bash\necho \"=== Boucle for ===\"\n\n# CrÃ©er des fichiers de test\nmkdir -p data_test\ntouch data_test/jan.csv data_test/feb.csv data_test/mar.csv\n\n# Boucle sur les fichiers CSV\nfor fichier in data_test/*.csv; do\n    echo \"ğŸ“„ Traitement de: $fichier\"\n    echo \"   Nom: $(basename \"$fichier\")\"\ndone\n\necho \"\"\necho \"=== Boucle avec sÃ©quence ===\"\nfor i in {1..5}; do\n    echo \"ItÃ©ration $i\"\ndone\n\necho \"\"\necho \"=== Boucle while ===\"\ncompteur=1\nwhile [ $compteur -le 3 ]; do\n    echo \"Compteur: $compteur\"\n    ((compteur++))\ndone\n\n# Nettoyage\nrm -r data_test/",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#conditions-ifelse",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#conditions-ifelse",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "11 ğŸ”€ 7. Conditions (if/else)",
    "text": "11 ğŸ”€ 7. Conditions (if/else)\nPrendre des dÃ©cisions dans tes scripts :\n\n\nCode\n%%bash\necho \"=== Conditions de base ===\"\n\n# VÃ©rifier si un fichier existe\nif [ -f \"ventes.csv\" ]; then\n    echo \"âœ… Le fichier ventes.csv existe\"\nelse\n    echo \"âŒ Le fichier n'existe pas\"\nfi\n\necho \"\"\n# VÃ©rifier si un dossier existe\nif [ -d \"/tmp\" ]; then\n    echo \"âœ… Le dossier /tmp existe\"\nfi\n\necho \"\"\n# Comparer des nombres\nnb_lignes=$(wc -l &lt; ventes.csv)\necho \"Nombre de lignes: $nb_lignes\"\n\nif [ $nb_lignes -gt 5 ]; then\n    echo \"ğŸ“Š Fichier volumineux (&gt; 5 lignes)\"\nelse\n    echo \"ğŸ“„ Petit fichier\"\nfi\n\n\n\n11.1 ğŸ“‹ OpÃ©rateurs de test\n\n\n\nTest fichiers\nDescription\n\n\n\n\n-f fichier\nFichier existe\n\n\n-d dossier\nDossier existe\n\n\n-r fichier\nFichier lisible\n\n\n-w fichier\nFichier modifiable\n\n\n-s fichier\nFichier non vide\n\n\n\n\n\n\nTest nombres\nDescription\n\n\n\n\n-eq\nÃ‰gal\n\n\n-ne\nDiffÃ©rent\n\n\n-gt\nPlus grand que\n\n\n-lt\nPlus petit que\n\n\n-ge\nPlus grand ou Ã©gal\n\n\n-le\nPlus petit ou Ã©gal\n\n\n\n\n\n\nTest chaÃ®nes\nDescription\n\n\n\n\n=\nÃ‰gal\n\n\n!=\nDiffÃ©rent\n\n\n-z\nChaÃ®ne vide\n\n\n-n\nChaÃ®ne non vide",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#crÃ©er-et-exÃ©cuter-un-script-bash",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#crÃ©er-et-exÃ©cuter-un-script-bash",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "12 âš™ï¸ 8. CrÃ©er et exÃ©cuter un script Bash",
    "text": "12 âš™ï¸ 8. CrÃ©er et exÃ©cuter un script Bash\nUn script Bash est simplement un fichier texte contenant des commandes :\n\n\nCode\n%%bash\n# CrÃ©er un script complet\ncat &lt;&lt; 'EOF' &gt; mon_script.sh\n#!/bin/bash\n# Script de traitement de donnÃ©es\n# Auteur: Data Engineer\n# Date: 2024\n\necho \"ğŸš€ DÃ©marrage du script\"\necho \"ğŸ“… Date: $(date)\"\necho \"ğŸ‘¤ Utilisateur: $USER\"\necho \"ğŸ“‚ Dossier: $(pwd)\"\n\n# VÃ©rifier si un argument est passÃ©\nif [ -z \"$1\" ]; then\n    echo \"âš ï¸ Usage: ./mon_script.sh &lt;nom_fichier&gt;\"\n    exit 1\nfi\n\necho \"ğŸ“„ Fichier Ã  traiter: $1\"\necho \"âœ… Script terminÃ©\"\nEOF\n\n# Rendre exÃ©cutable\nchmod +x mon_script.sh\n\n# ExÃ©cuter le script\necho \"=== ExÃ©cution sans argument ===\"\n./mon_script.sh\n\necho \"\"\necho \"=== ExÃ©cution avec argument ===\"\n./mon_script.sh ventes.csv\n\n# Nettoyage\nrm mon_script.sh",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#automatisation-avec-cron",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#automatisation-avec-cron",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "13 â° 9. Automatisation avec Cron",
    "text": "13 â° 9. Automatisation avec Cron\nCron permet de planifier lâ€™exÃ©cution automatique de scripts â€” indispensable pour les pipelines ETL !\n\n13.1 ğŸ“… Format dâ€™une ligne crontab\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ minute (0 - 59)\nâ”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ heure (0 - 23)\nâ”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ jour du mois (1 - 31)\nâ”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ mois (1 - 12)\nâ”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ jour de la semaine (0 - 6) (dimanche = 0)\nâ”‚ â”‚ â”‚ â”‚ â”‚\n* * * * * commande Ã  exÃ©cuter\n\n\n13.2 ğŸ”§ Exemples courants pour Data Engineers\n\n\n\nExpression\nDescription\nCas dâ€™usage\n\n\n\n\n0 2 * * *\nTous les jours Ã  2h\nETL nocturne\n\n\n*/15 * * * *\nToutes les 15 minutes\nMonitoring\n\n\n0 0 * * 0\nChaque dimanche Ã  minuit\nRapport hebdomadaire\n\n\n0 9 1 * *\nLe 1er de chaque mois Ã  9h\nRapport mensuel\n\n\n0 */4 * * *\nToutes les 4 heures\nSynchronisation donnÃ©es\n\n\n\n\n\n13.3 ğŸ’» Commandes cron\n# Ã‰diter la crontab\ncrontab -e\n\n# Lister les jobs planifiÃ©s\ncrontab -l\n\n# Supprimer tous les jobs\ncrontab -r\n\n\n13.4 ğŸ“ Exemple de crontab pour Data Engineer\n# ETL quotidien Ã  2h du matin\n0 2 * * * /home/user/scripts/etl_pipeline.sh &gt;&gt; /var/log/etl.log 2&gt;&1\n\n# Backup des donnÃ©es chaque dimanche Ã  3h\n0 3 * * 0 /home/user/scripts/backup.sh\n\n# Nettoyage des fichiers temporaires chaque jour Ã  4h\n0 4 * * * find /tmp -mtime +7 -delete\n\nğŸ’¡ Astuce : Utilise crontab.guru pour gÃ©nÃ©rer facilement des expressions cron !",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#exercice-pratique",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#exercice-pratique",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "14 âœ… Exercice pratique",
    "text": "14 âœ… Exercice pratique\n\n14.1 ğŸ§  Instructions\n\nCrÃ©e un dossier de travail nommÃ© mon_premier_script\nEntre dans ce dossier\nCrÃ©e un fichier script appelÃ© bonjour.sh\nÃ‰dite ce fichier et Ã©cris un script qui :\n\nAffiche â€œBonjour Data Engineer ğŸ‘‹â€\nAffiche la date du jour\nTe souhaite une bonne session\n\nRends le script exÃ©cutable\nCrÃ©e un sous-dossier nommÃ© data/ et place-y quelques fichiers .csv (mÃªme vides)\nAjoute une Ã©tape dans le script pour :\n\nAfficher tous les fichiers .csv prÃ©sents dans le dossier data/\nPour chaque fichier .csv, afficher son nom avec un message comme :\nğŸ‘‰ â€œFichier trouvÃ© : nom_du_fichier.csv âœ…â€\n\n\nğŸ“Œ Quelle structure utiliser ? (indice : boucle for)\n\n\n14.2 âœ… Correction\n\n\nğŸ“¥ Afficher la correction complÃ¨te\n\n#!/bin/bash\n\n# 1. ğŸ“¢ Afficher un message de bienvenue\necho \"Bonjour Data Engineer ğŸ‘‹\"\n\n# 2. ğŸ—“ï¸ Afficher la date du jour\necho \"Date: $(date)\"\n\n# 3. ğŸ’¬ Souhaiter une bonne session\necho \"Bonne session de travail ğŸ’ª\"\n\n# 4. ğŸ“ CrÃ©er le dossier 'data/' s'il n'existe pas\nmkdir -p data\n\n# 5. ğŸ—‚ï¸ CrÃ©er quelques fichiers de test\ntouch data/fichier1.csv data/fichier2.csv data/fichier3.csv\n\n# 6. ğŸ” Lister les fichiers CSV\necho \"\"\necho \"ğŸ” Recherche de fichiers CSV dans ./data...\"\n\nfor fichier in data/*.csv; do\n    if [ -f \"$fichier\" ]; then\n        echo \"Fichier trouvÃ© : $(basename \"$fichier\") âœ…\"\n    fi\ndone\n\n# 7. âœ… Fin du script\necho \"\"\necho \"Traitement terminÃ© âœ…\"",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#cheatsheet-bash-commandes-essentielles",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#cheatsheet-bash-commandes-essentielles",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "15 ğŸ“„ Cheatsheet Bash â€“ Commandes essentielles",
    "text": "15 ğŸ“„ Cheatsheet Bash â€“ Commandes essentielles\n\n\n\n\n\n\n\n\nCatÃ©gorie\nCommande\nDescription\n\n\n\n\nğŸ“ Navigation\npwd\nAffiche le chemin actuel\n\n\n\ncd dossier/\nSe dÃ©placer dans un dossier\n\n\n\nls -lh\nListe les fichiers avec dÃ©tails\n\n\nğŸ“„ Fichiers\ntouch nom.txt\nCrÃ©er un fichier vide\n\n\n\ncp fichier.txt dossier/\nCopier un fichier\n\n\n\nmv fichier.txt nouveau.txt\nRenommer ou dÃ©placer\n\n\n\nrm fichier.txt\nSupprimer un fichier\n\n\nğŸ“š Dossiers\nmkdir dossier/\nCrÃ©er un dossier\n\n\n\nmkdir -p a/b/c\nCrÃ©er avec parents\n\n\n\nrm -r dossier/\nSupprimer dossier + contenu\n\n\nğŸ“– Lecture\ncat fichier.txt\nAfficher tout le contenu\n\n\n\nhead -n 10 fichier.txt\n10 premiÃ¨res lignes\n\n\n\ntail -n 10 fichier.txt\n10 derniÃ¨res lignes\n\n\n\nwc -l fichier.txt\nCompter les lignes\n\n\nğŸ” Recherche\ngrep \"mot\" fichier.txt\nRechercher un mot\n\n\n\nfind . -name \"*.csv\"\nTrouver des fichiers\n\n\n\ncut -d',' -f1 fichier.csv\nExtraire une colonne\n\n\nğŸ”— Pipes\ncmd1 \\| cmd2\nChaÃ®ner des commandes\n\n\n\ncmd &gt; fichier.txt\nRediriger vers fichier\n\n\n\ncmd &gt;&gt; fichier.txt\nAjouter Ã  un fichier\n\n\nğŸ§  Scripts\nchmod +x script.sh\nRendre exÃ©cutable\n\n\n\n./script.sh\nLancer un script\n\n\nğŸ”„ Boucles\nfor f in *.csv; do ...; done\nBoucle sur fichiers\n\n\nâ° Cron\ncrontab -e\nÃ‰diter les tÃ¢ches planifiÃ©es\n\n\n\ncrontab -l\nLister les tÃ¢ches\n\n\n\nğŸ“¥ TÃ©lÃ©charger le Bash Cheatsheet PDF (fr)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#erreurs-classiques-Ã -Ã©viter",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#erreurs-classiques-Ã -Ã©viter",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "16 âš ï¸ Erreurs classiques Ã  Ã©viter",
    "text": "16 âš ï¸ Erreurs classiques Ã  Ã©viter\n\n\n\n\n\n\n\n\nâŒ Erreur\nğŸ’¥ ConsÃ©quence\nâœ… Bonne pratique\n\n\n\n\nrm -rf /\nSupprime TOUT le systÃ¨me !\nToujours vÃ©rifier le chemin avant rm -rf\n\n\n$fichier sans guillemets\nBug si espaces dans le nom\nUtiliser \"$fichier\"\n\n\nsudo sans rÃ©flÃ©chir\nÃ‰crase des fichiers systÃ¨me\nComprendre la commande avant dâ€™utiliser sudo\n\n\nScript non testÃ© en prod\nPerte de donnÃ©es\nToujours tester en sandbox dâ€™abord\n\n\nVAR = valeur (avec espaces)\nErreur de syntaxe\nVAR=valeur (sans espaces)\n\n\nOublier #!/bin/bash\nScript peut mal sâ€™exÃ©cuter\nToujours commencer par le shebang\n\n\n\n\nğŸ§  Conseil : Avant dâ€™exÃ©cuter une commande destructive (rm, mv), utilise echo pour voir ce qui serait affectÃ© :\n# Au lieu de :\nrm -rf data/*.csv\n\n# D'abord tester avec :\necho data/*.csv",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#quiz-de-fin-de-module",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#quiz-de-fin-de-module",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "17 ğŸ§ª Quiz de fin de module",
    "text": "17 ğŸ§ª Quiz de fin de module\nRÃ©ponds aux questions suivantes pour vÃ©rifier tes acquis.\n\n\n17.1 â“ Q1. Quelle commande affiche le chemin du dossier courant ?\n\ncd\n\npwd\n\nls\n\npath\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” pwd = Print Working Directory\n\n\n\n\n17.2 â“ Q2. Que fait la commande rm -rf mon_dossier/ ?\n\nRedÃ©marre lâ€™ordinateur\n\nRÃ©organise un fichier\n\nSupprime un dossier et son contenu\n\nReformate le disque\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” -r = rÃ©cursif, -f = force (sans confirmation)\n\n\n\n\n17.3 â“ Q3. Quelle commande affiche les 10 premiÃ¨res lignes dâ€™un fichier ?\n\nhead -n 10\n\ncat -10\n\nstart 10\n\ntop 10\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : a â€” head -n 10 fichier.txt\n\n\n\n\n17.4 â“ Q4. Pourquoi Ã©crire \"$fichier\" au lieu de $fichier ?\n\nPour que Bash reconnaisse les fichiers CSV\n\nPour faire du style\n\nPour Ã©viter les bugs avec les noms contenant des espaces\n\nÃ‡a nâ€™a pas dâ€™importance\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” Les guillemets protÃ¨gent les valeurs contenant des espaces\n\n\n\n\n17.5 â“ Q5. Que signifie le | (pipe) en Bash ?\n\nInterrompre une commande\n\nExÃ©cuter un script\n\nEnvoyer la sortie dâ€™une commande vers lâ€™entrÃ©e dâ€™une autre\n\nCrÃ©er un fichier temporaire\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” Le pipe chaÃ®ne les commandes : cmd1 | cmd2\n\n\n\n\n17.6 â“ Q6. Quelle expression cron exÃ©cute un script tous les jours Ã  2h du matin ?\n\n2 0 * * *\n\n0 2 * * *\n\n* 2 * * *\n\n0 0 2 * *\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” Format : minute heure jour mois jour_semaine",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#mini-projet-archiver-intelligemment-des-fichiers-csv",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#mini-projet-archiver-intelligemment-des-fichiers-csv",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "18 ğŸš€ Mini-projet : Archiver intelligemment des fichiers CSV",
    "text": "18 ğŸš€ Mini-projet : Archiver intelligemment des fichiers CSV\n\n18.1 ğŸ¯ Objectif\nCrÃ©er un script Bash rÃ©aliste qui automatise lâ€™archivage de fichiers .csv selon leur anciennetÃ©.\n\n\n18.2 ğŸ”§ Contexte\nTu travailles dans une Ã©quipe data. Chaque jour, des fichiers .csv sont dÃ©posÃ©s dans un dossier data/.\nTu dois crÃ©er un script qui :\n\nğŸ“¦ RepÃ¨re tous les fichiers .csv modifiÃ©s il y a plus de 7 jours\nğŸ—‚ï¸ Les archive dans un fichier .tar.gz nommÃ© archive_YYYYMMDD.tar.gz\nğŸ§¹ DÃ©place ces fichiers dans un dossier archive/\n\n\n\n18.3 ğŸ§  Contraintes\n\nLe script doit fonctionner mÃªme si aucun fichier nâ€™est Ã©ligible\nLâ€™archive doit Ãªtre horodatÃ©e automatiquement\nLe dossier archive/ doit Ãªtre crÃ©Ã© sâ€™il nâ€™existe pas\nAjouter du logging pour tracer les actions\n\n\n\n18.4 âœ… Solution du mini-projet\n\n\nğŸ“¥ Afficher la solution complÃ¨te\n\n#!/bin/bash\n#\n# Script: archive_csv.sh\n# Description: Archive les fichiers CSV de plus de 7 jours\n# Auteur: Data Engineer\n#\n\n# Configuration\nDATA_DIR=\"./data\"\nARCHIVE_DIR=\"./archive\"\nDAYS_OLD=7\nDATE_TAG=$(date +%Y%m%d)\nARCHIVE_NAME=\"archive_${DATE_TAG}.tar.gz\"\nLOG_FILE=\"archive.log\"\n\n# Fonction de logging\nlog() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" | tee -a \"$LOG_FILE\"\n}\n\nlog \"ğŸš€ DÃ©marrage du script d'archivage\"\n\n# VÃ©rifier que le dossier source existe\nif [ ! -d \"$DATA_DIR\" ]; then\n    log \"âŒ Erreur: Le dossier $DATA_DIR n'existe pas\"\n    exit 1\nfi\n\n# CrÃ©er le dossier d'archive si nÃ©cessaire\nmkdir -p \"$ARCHIVE_DIR\"\nlog \"ğŸ“ Dossier d'archive: $ARCHIVE_DIR\"\n\n# Trouver les fichiers CSV de plus de 7 jours\nOLD_FILES=$(find \"$DATA_DIR\" -name \"*.csv\" -mtime +$DAYS_OLD -type f)\n\n# VÃ©rifier s'il y a des fichiers Ã  archiver\nif [ -z \"$OLD_FILES\" ]; then\n    log \"â„¹ï¸ Aucun fichier CSV de plus de $DAYS_OLD jours trouvÃ©\"\n    exit 0\nfi\n\n# Compter les fichiers\nNB_FILES=$(echo \"$OLD_FILES\" | wc -l)\nlog \"ğŸ“Š $NB_FILES fichier(s) Ã  archiver\"\n\n# CrÃ©er l'archive\nlog \"ğŸ“¦ CrÃ©ation de l'archive $ARCHIVE_NAME...\"\necho \"$OLD_FILES\" | tar -czvf \"$ARCHIVE_DIR/$ARCHIVE_NAME\" -T -\n\nif [ $? -eq 0 ]; then\n    log \"âœ… Archive crÃ©Ã©e avec succÃ¨s\"\n    \n    # DÃ©placer les fichiers archivÃ©s\n    for file in $OLD_FILES; do\n        mv \"$file\" \"$ARCHIVE_DIR/\"\n        log \"   â†³ DÃ©placÃ©: $(basename \"$file\")\"\n    done\n    \n    log \"ğŸ‰ Archivage terminÃ© avec succÃ¨s\"\nelse\n    log \"âŒ Erreur lors de la crÃ©ation de l'archive\"\n    exit 1\nfi\nPour lâ€™utiliser :\nchmod +x archive_csv.sh\n./archive_csv.sh\nPour lâ€™automatiser avec cron (tous les jours Ã  3h) :\n0 3 * * * /home/user/scripts/archive_csv.sh",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "19 ğŸ“š Ressources pour aller plus loin",
    "text": "19 ğŸ“š Ressources pour aller plus loin\n\n19.1 ğŸŒ Sites & outils\n\nExplainShell â€” Explique nâ€™importe quelle commande Bash\nShellCheck â€” VÃ©rifie la syntaxe de tes scripts\nCrontab Guru â€” GÃ©nÃ©rateur dâ€™expressions cron\nLinux Command â€” Tutoriel complet\n\n\n\n19.2 ğŸ“– Documentation\n\nGNU Bash Manual\nAdvanced Bash-Scripting Guide\n\n\n\n19.3 ğŸ® Pratique\n\nOverTheWire - Bandit â€” Jeu pour apprendre Bash\nCmdchallenge â€” DÃ©fis en ligne de commande",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/02_bash_for_data_engineers.html#prochaine-Ã©tape",
    "href": "notebooks/beginner/02_bash_for_data_engineers.html#prochaine-Ã©tape",
    "title": "ğŸ§° Bash pour Data Engineers",
    "section": "20 â¡ï¸ Prochaine Ã©tape",
    "text": "20 â¡ï¸ Prochaine Ã©tape\nMaintenant que tu maÃ®trises Bash, passons Ã  un autre outil essentiel : Git !\nğŸ‘‰ Module suivant : 03_git_for_data_engineers.ipynb â€” Versionner ton code et collaborer\n\nğŸ‰ FÃ©licitations ! Tu as terminÃ© le module Bash pour Data Engineers.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§° Bash pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "",
    "text": "Ce notebook donne les bases de Python nÃ©cessaires pour la suite du parcours Data Engineering From Zero to Hero.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#prÃ©requis",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#prÃ©requis",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.1 ğŸ“‹ PrÃ©requis",
    "text": "0.1 ğŸ“‹ PrÃ©requis\n\n\n\nNiveau\nCompÃ©tence\n\n\n\n\nâœ… Requis\nAvoir suivi le module 03_git_for_data_engineers\n\n\nâœ… Requis\nSavoir utiliser un terminal (Bash)\n\n\nğŸŸ¡ Optionnel\nNotions de programmation dans un autre langage",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#objectifs-du-module",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#objectifs-du-module",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.2 ğŸ¯ Objectifs du module",
    "text": "0.2 ğŸ¯ Objectifs du module\nÃ€ la fin de ce notebook, tu seras capable de : - âœ… Installer et configurer ton environnement Python - âœ… CrÃ©er et gÃ©rer des environnements virtuels - âœ… Manipuler les types de base (nombres, chaÃ®nes, listes, dictionnaires) - âœ… Utiliser les conditions et boucles - âœ… Ã‰crire des fonctions et des classes simples - âœ… GÃ©rer les erreurs avec try / except - âœ… Lire et Ã©crire des fichiers (texte, JSON) - âœ… Utiliser le module logging pour tracer un script",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-python-pour-le-data-engineering",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-python-pour-le-data-engineering",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.3 ğŸ Pourquoi Python pour le Data Engineering ?",
    "text": "0.3 ğŸ Pourquoi Python pour le Data Engineering ?\n\n\n\n\n\n\n\nRaison\nDÃ©tail\n\n\n\n\nğŸ“š Ã‰cosystÃ¨me riche\nPandas, PySpark, Airflow, dbt, FastAPIâ€¦\n\n\nğŸ”§ Polyvalent\nScripts, APIs, pipelines, ML, automation\n\n\nğŸ¤ Standard de lâ€™industrie\nUtilisÃ© par Netflix, Spotify, Airbnbâ€¦\n\n\nğŸ“– Facile Ã  apprendre\nSyntaxe claire et lisible\n\n\nğŸ”— IntÃ©grations\nConnecteurs pour toutes les bases de donnÃ©es",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#installation-environnement",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#installation-environnement",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.4 0. Installation & Environnement ğŸ› ï¸",
    "text": "0.4 0. Installation & Environnement ğŸ› ï¸\nCette section explique comment installer Python, VS Code, Jupyter et vÃ©rifier que tout fonctionne. Les commandes sont donnÃ©es pour Windows, Linux et macOS.\n\n0.4.1 0.1 Installer Python\n\n0.4.1.1 Sous Windows\n\nAller sur le site officiel : https://www.python.org/downloads/\nTÃ©lÃ©charger la derniÃ¨re version stable de Python 3.x.\nLors de lâ€™installation :\n\nCocher â€œAdd Python to PATHâ€ en bas de la premiÃ¨re fenÃªtre ;\npuis cliquer sur Install Now.\n\n\n\n\n0.4.1.2 Sous Linux (Ubuntu / Debian)\nsudo apt update\nsudo apt install -y python3 python3-pip\n\n\n0.4.1.3 Sous macOS\n\nOption 1 : paquet officiel :\n\nTÃ©lÃ©charger un .pkg depuis https://www.python.org/downloads/mac-osx/\nInstaller comme une application classique.\n\nOption 2 (si Homebrew est installÃ©) :\n\nbrew install python\n\n\n\n0.4.2 0.2 VÃ©rifier lâ€™installation de Python\nOuvrir un terminal (ou PowerShell sous Windows) puis taper :\npython --version   # ou parfois: python3 --version\nTu dois voir une version du type : Python 3.12.x.\nâš ï¸ Erreurs frÃ©quentes : - python nâ€™est pas reconnu â†’ Python nâ€™est pas dans le PATH ; - sur Linux/macOS, il faut parfois utiliser python3 au lieu de python.\n\n\n0.4.3 0.3 Installer Visual Studio Code (VS Code)\n\nTÃ©lÃ©charger VS Code : https://code.visualstudio.com/\nInstaller la version adaptÃ©e Ã  ton systÃ¨me (Windows, Linux, macOS).\nLancer VS Code.\n\nVS Code servira Ã  : - Ã©diter des scripts .py ; - ouvrir des notebooks Jupyter (.ipynb) ; - organiser un projet de data engineering complet.\n\n\n0.4.4 0.4 Extensions VS Code : Python & Jupyter\nDans VS Code, aller dans lâ€™onglet Extensions (icÃ´ne de blocs Ã  gauche), puis :\n\nRechercher â€œPythonâ€ (Ã©diteur : Microsoft) et lâ€™installer ;\nRechercher â€œJupyterâ€ (Ã©diteur : Microsoft) et lâ€™installer.\n\nEnsuite, ouvrir un fichier .py ou .ipynb : VS Code proposera de sÃ©lectionner un interprÃ©teur Python (en bas Ã  droite). Choisir ton installation Python 3.x.\n\n\n0.4.5 0.5 Installer Jupyter Notebook\nDans un terminal (avec Python installÃ©) :\npython -m pip install notebook\nPuis lancer Jupyter :\njupyter notebook\nUn navigateur sâ€™ouvrira sur http://localhost:8888 et affichera la liste des fichiers.\n\n\n0.4.6 0.6 Premier test Python\nDans un terminal :\n&gt;&gt;&gt; print(\"Hello Data Engineer\")\nTu dois voir :\nHello Data Engineer",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#environnements-virtuels",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#environnements-virtuels",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.5 0.7 Environnements virtuels ğŸ”’",
    "text": "0.5 0.7 Environnements virtuels ğŸ”’\nUn environnement virtuel isole les dÃ©pendances de chaque projet. Câ€™est indispensable en Data Engineering pour Ã©viter les conflits de versions.\n\n0.5.1 Pourquoi utiliser un environnement virtuel ?\n\n\n\n\n\n\n\nâŒ Sans environnement virtuel\nâœ… Avec environnement virtuel\n\n\n\n\nTous les projets partagent les mÃªmes packages\nChaque projet a ses propres packages\n\n\nConflits de versions\nIsolation complÃ¨te\n\n\nDifficile Ã  reproduire\nReproductible avec requirements.txt\n\n\n\n\n\n0.5.2 Option 1 : venv (intÃ©grÃ© Ã  Python)\n# CrÃ©er un environnement virtuel\npython -m venv mon_env\n\n# Activer l'environnement\n# Windows\nmon_env\\Scripts\\activate\n\n# Linux / macOS\nsource mon_env/bin/activate\n\n# Tu verras (mon_env) au dÃ©but de ta ligne de commande\n\n# DÃ©sactiver l'environnement\ndeactivate\n\n\n0.5.3 Option 2 : conda (Anaconda/Miniconda)\n# CrÃ©er un environnement\nconda create -n mon_projet python=3.11\n\n# Activer\nconda activate mon_projet\n\n# DÃ©sactiver\nconda deactivate\n\n# Lister les environnements\nconda env list\n\n\n0.5.4 ğŸ’¡ Recommandation pour Data Engineers\n\n\n\nOutil\nQuand lâ€™utiliser\n\n\n\n\nvenv\nProjets Python purs, lÃ©gers, CI/CD\n\n\nconda\nData Science, dÃ©pendances complexes (NumPy, Spark)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#gestion-des-packages-avec-pip",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#gestion-des-packages-avec-pip",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.6 0.8 Gestion des packages avec pip ğŸ“¦",
    "text": "0.6 0.8 Gestion des packages avec pip ğŸ“¦\npip est le gestionnaire de packages Python. Tu lâ€™utiliseras pour installer les librairies Data Engineering.\n\n0.6.1 Commandes essentielles\n# Installer un package\npip install pandas\n\n# Installer une version spÃ©cifique\npip install pandas==2.0.0\n\n# Installer plusieurs packages\npip install pandas numpy requests\n\n# Mettre Ã  jour un package\npip install --upgrade pandas\n\n# DÃ©sinstaller\npip uninstall pandas\n\n# Lister les packages installÃ©s\npip list\n\n# Voir les infos d'un package\npip show pandas\n\n\n0.6.2 Le fichier requirements.txt\nCe fichier liste toutes les dÃ©pendances dâ€™un projet. Indispensable pour la reproductibilitÃ©.\n# GÃ©nÃ©rer le fichier Ã  partir de l'environnement actuel\npip freeze &gt; requirements.txt\n\n# Installer toutes les dÃ©pendances d'un projet\npip install -r requirements.txt\n\n\n0.6.3 Exemple de requirements.txt pour Data Engineering\n# Data Processing\npandas&gt;=2.0.0\nnumpy&gt;=1.24.0\npyarrow&gt;=12.0.0\n\n# APIs\nrequests&gt;=2.28.0\nfastapi&gt;=0.100.0\n\n# Database\nsqlalchemy&gt;=2.0.0\npsycopg2-binary&gt;=2.9.0\n\n# Testing\npytest&gt;=7.0.0\n\nğŸ’¡ Bonne pratique : Toujours travailler dans un environnement virtuel avant dâ€™installer des packages !",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#variables-et-types",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#variables-et-types",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.7 1. Variables et Types ğŸ”¤",
    "text": "0.7 1. Variables et Types ğŸ”¤\nUne variable est un nom qui rÃ©fÃ©rence une valeur en mÃ©moire.\nPython possÃ¨de plusieurs types intÃ©grÃ©s (builtins). Voici ceux Ã  maÃ®triser absolument en Data Engineering :\n\n\n\n\n\n\n\n\n\nCatÃ©gorie\nType\nExemple\nUsage Data Engineering\n\n\n\n\nNumÃ©rique\nint\n3, 42, -5\nComptage, index, tailles, IDs\n\n\n\nfloat\n3.14, 0.99\nPrix, mesures, statistiques\n\n\nTexte\nstr\n\"Abidjan\"\nParsing CSV/JSON, nettoyage, logs\n\n\nBoolÃ©en\nbool\nTrue, False\nConditions, filtres, validation\n\n\nSÃ©quences ordonnÃ©es\nlist\n[1,2,3]\nLignes CSV, sÃ©ries numÃ©riques\n\n\n\ntuple\n(200, \"OK\")\nValeurs fixes, clÃ©s composites\n\n\nMapping\ndict\n{\"id\":1,\"ville\":\"Paris\"}\nJSON, API, MongoDB\n\n\nEnsemble (unique)\nset\n{\"python\",\"data\"}\nDÃ©duplication (emails, tags)\n\n\nBinaire\nbytes\nb\"abc\"\nFichiers binaires, images, rÃ©seau\n\n\n\n\n\n0.7.0.1 Exemples de variables\nage = 30              # int\npi = 3.14             # float\nnom = \"Alice\"         # str\nest_data_engineer = True  # bool\n\nprint(age, type(age))\nprint(pi, type(pi))\nprint(nom, type(nom))\nprint(est_data_engineer, type(est_data_engineer))\n\n\n0.7.1 Conversion de types\nIl est frÃ©quent de convertir des chaÃ®nes en nombres, par exemple aprÃ¨s lecture dâ€™un fichier.\nage_str = \"25\"\nage_int = int(age_str)\nâš ï¸ Erreurs frÃ©quentes : - Essayer de convertir une chaÃ®ne non numÃ©rique : int(\"abc\") â†’ ValueError ; - Additionner directement un str et un int : - \"25\" + 3 âŒ - int(\"25\") + 3 âœ”ï¸",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#conditions-et-boucles",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#conditions-et-boucles",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.8 ğŸ” 2. Conditions et Boucles",
    "text": "0.8 ğŸ” 2. Conditions et Boucles\nLes conditions permettent de prendre des dÃ©cisions dans le code.\nLes boucles permettent de rÃ©pÃ©ter des actions automatiquement.\n\nğŸ’¡ En Data Engineering, ces structures sont essentielles pour : - Filtrer des donnÃ©es (conditions) - Traiter plusieurs fichiers (boucles) - Valider des rÃ¨gles mÃ©tier (conditions) - Parcourir des bases de donnÃ©es (boucles)\n\n\n\n0.8.1 ğŸ¯ 2.1 Conditions (if / elif / else)\nLes conditions testent des critÃ¨res et exÃ©cutent du code selon le rÃ©sultat.\n\n0.8.1.1 Syntaxe de base\nage = 20\n\nif age &lt; 18:\n    print(\"Mineur\")\nelif age == 18:\n    print(\"Tout juste majeur\")\nelse:\n    print(\"Majeur\")\nFonctionnement : 1. if : PremiÃ¨re condition testÃ©e 2. elif : Condition alternative (si if est fausse) 3. else : Cas par dÃ©faut (si toutes les conditions sont fausses)\n\n\n0.8.1.2 OpÃ©rateurs de comparaison\n\n\n\nOpÃ©rateur\nSignification\nExemple\n\n\n\n\n==\nÃ‰gal Ã \nage == 18\n\n\n!=\nDiffÃ©rent de\nage != 18\n\n\n&lt;\nInfÃ©rieur Ã \nage &lt; 18\n\n\n&lt;=\nInfÃ©rieur ou Ã©gal\nage &lt;= 18\n\n\n&gt;\nSupÃ©rieur Ã \nage &gt; 18\n\n\n&gt;=\nSupÃ©rieur ou Ã©gal\nage &gt;= 18\n\n\n\n\n\n0.8.1.3 Conditions multiples\nage = 25\npays = \"France\"\n\n# OpÃ©rateur AND (et)\nif age &gt;= 18 and pays == \"France\":\n    print(\"Peut voter en France\")\n\n# OpÃ©rateur OR (ou)\nif age &lt; 18 or age &gt; 65:\n    print(\"Tarif rÃ©duit\")\n\n# OpÃ©rateur NOT (nÃ©gation)\nif not (age &lt; 18):\n    print(\"Majeur\")\n\n\n\n\n0.8.2 ğŸ”„ 2.2 Boucles (for et while)\nLes boucles permettent dâ€™exÃ©cuter du code de maniÃ¨re rÃ©pÃ©tÃ©e.\n\n0.8.2.1 Boucle for : Parcourir une sÃ©quence\n# Parcourir une liste\nnoms = [\"Alice\", \"Bob\", \"Charlie\"]\n\nfor nom in noms:\n    print(f\"Bonjour {nom}\")\n\n# RÃ©sultat :\n# Bonjour Alice\n# Bonjour Bob\n# Bonjour Charlie\n\n\n0.8.2.2 Boucle avec range()\n# range(n) gÃ©nÃ¨re les nombres de 0 Ã  n-1\nfor i in range(5):\n    print(f\"ItÃ©ration {i}\")\n\n# RÃ©sultat : 0, 1, 2, 3, 4\n\n# range(dÃ©but, fin, pas)\nfor i in range(0, 10, 2):\n    print(i)  # 0, 2, 4, 6, 8\n\n\n0.8.2.3 Boucle while : RÃ©pÃ©ter tant quâ€™une condition est vraie\ncompteur = 0\n\nwhile compteur &lt; 3:\n    print(f\"Compteur = {compteur}\")\n    compteur += 1  # âš ï¸ IMPORTANT : incrÃ©mentation obligatoire\n\n# RÃ©sultat :\n# Compteur = 0\n# Compteur = 1\n# Compteur = 2\n\n\n0.8.2.4 ContrÃ´le de flux : break et continue\n# break : Sortir immÃ©diatement de la boucle\nfor i in range(10):\n    if i == 5:\n        break  # ArrÃªte la boucle Ã  5\n    print(i)  # Affiche 0, 1, 2, 3, 4\n\n# continue : Passer Ã  l'itÃ©ration suivante\nfor i in range(5):\n    if i == 2:\n        continue  # Saute l'itÃ©ration quand i=2\n    print(i)  # Affiche 0, 1, 3, 4\n\n\n0.8.2.5 ğŸ“Œ Cas dâ€™usage Data Engineering\n# Exemple 1 : Traitement de fichiers multiples\nfichiers = [\"users_2024_01.csv\", \"users_2024_02.csv\", \"users_2024_03.csv\"]\n\nfor fichier in fichiers:\n    print(f\"Traitement de {fichier}...\")\n    # Ici : logique de lecture/transformation\n    # df = pd.read_csv(fichier)\n    # process(df)\n\n# Exemple 2 : Nettoyage de donnÃ©es\nposts = [\n    {\"text\": \"Hello\", \"likes\": 10},\n    {\"text\": \"\", \"likes\": 5},       # âš ï¸ Texte vide\n    {\"text\": \"Python\", \"likes\": 20}\n]\n\nposts_valides = []\n\nfor post in posts:\n    # Skip les posts vides\n    if not post[\"text\"].strip():\n        continue\n    \n    # Nettoyer et garder\n    post[\"text\"] = post[\"text\"].strip().lower()\n    posts_valides.append(post)\n\nprint(posts_valides)\n# [{'text': 'hello', 'likes': 10}, {'text': 'python', 'likes': 20}]\n\n# Exemple 3 : Retry logic (tentatives multiples)\nmax_tentatives = 3\ntentative = 0\nsucces = False\n\nwhile tentative &lt; max_tentatives and not succes:\n    print(f\"Tentative {tentative + 1}...\")\n    \n    # Simulation d'une connexion\n    # succes = tenter_connexion()\n    \n    tentative += 1\n    \n    if not succes and tentative &lt; max_tentatives:\n        print(\"Ã‰chec, nouvelle tentative...\")\n\n\n\n\n0.8.3 ğŸ” 2.3 Boucles avancÃ©es : enumerate() et zip()\n\n0.8.3.1 enumerate() : Obtenir lâ€™index ET la valeur\nfruits = [\"pomme\", \"banane\", \"orange\"]\n\n# Sans enumerate (moins pratique)\nfor i in range(len(fruits)):\n    print(f\"{i}: {fruits[i]}\")\n\n# Avec enumerate (recommandÃ©)\nfor index, fruit in enumerate(fruits):\n    print(f\"{index}: {fruit}\")\n\n# Avec enumerate dÃ©marrant Ã  1\nfor num, fruit in enumerate(fruits, start=1):\n    print(f\"Fruit #{num}: {fruit}\")\n\n\n0.8.3.2 zip() : Parcourir plusieurs listes simultanÃ©ment\nnoms = [\"Alice\", \"Bob\", \"Charlie\"]\nages = [25, 30, 35]\nvilles = [\"Paris\", \"Lyon\", \"Marseille\"]\n\nfor nom, age, ville in zip(noms, ages, villes):\n    print(f\"{nom} a {age} ans et habite Ã  {ville}\")\n\n# RÃ©sultat :\n# Alice a 25 ans et habite Ã  Paris\n# Bob a 30 ans et habite Ã  Lyon\n# Charlie a 35 ans et habite Ã  Marseille\n\n\n\n\n0.8.4 âš ï¸ Erreurs frÃ©quentes et bonnes pratiques\n\n\n\n\n\n\n\n\nâŒ Erreur\nâœ… Correction\nğŸ’¡ Explication\n\n\n\n\nOublier : aprÃ¨s if/for/while\nif age &gt; 18:\nSyntaxe obligatoire\n\n\nMauvaise indentation\nUtiliser 4 espaces\nPython est sensible Ã  lâ€™indentation\n\n\nBoucle infinie while\nToujours incrÃ©menter\ncompteur += 1\n\n\nModifier liste pendant for\nCrÃ©er nouvelle liste\nÃ‰vite comportements imprÃ©visibles\n\n\n= au lieu de ==\nif age == 18:\n= assigne, == compare\n\n\n\nExemples dâ€™erreurs :\n# âŒ Erreur 1 : Oublier le :\nif age &gt; 18\n    print(\"Majeur\")  # SyntaxError\n\n# âœ… Correction\nif age &gt; 18:\n    print(\"Majeur\")\n\n# âŒ Erreur 2 : Boucle infinie\ncompteur = 0\nwhile compteur &lt; 5:\n    print(compteur)\n    # Oubli d'incrÃ©menter â†’ boucle infinie !\n\n# âœ… Correction\ncompteur = 0\nwhile compteur &lt; 5:\n    print(compteur)\n    compteur += 1\n\n# âŒ Erreur 3 : Modifier liste pendant boucle\nnombres = [1, 2, 3, 4, 5]\nfor n in nombres:\n    if n % 2 == 0:\n        nombres.remove(n)  # âš ï¸ Comportement imprÃ©visible\n\n# âœ… Correction : List comprehension\nnombres = [1, 2, 3, 4, 5]\nnombres_impairs = [n for n in nombres if n % 2 != 0]\n\n\n\n0.8.5 ğŸ“š RÃ©capitulatif\n\n\n\nStructure\nUsage\nExemple\n\n\n\n\nif/elif/else\nPrendre des dÃ©cisions\nValidation, filtrage\n\n\nfor\nParcourir sÃ©quences\nTraiter fichiers, lignes\n\n\nwhile\nRÃ©pÃ©ter tant queâ€¦\nRetry logic, polling\n\n\nbreak\nSortir de boucle\nArrÃªt prÃ©maturÃ©\n\n\ncontinue\nSauter itÃ©ration\nSkip donnÃ©es invalides\n\n\nenumerate()\nIndex + valeur\nNumÃ©rotation\n\n\nzip()\nCombiner listes\nJoindre donnÃ©es parallÃ¨les\n\n\n\n\n\n\n0.8.6 ğŸ¯ Points clÃ©s Ã  retenir\n\nConditions : Utilisent == pour comparer (pas =)\nIndentation : 4 espaces obligatoires aprÃ¨s :\nwhile : Toujours prÃ©voir une sortie de boucle\nfor : PrÃ©fÃ©rer enumerate() si besoin de lâ€™index\nList comprehension : Alternative Ã©lÃ©gante aux boucles simples",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#structures-de-donnÃ©es",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#structures-de-donnÃ©es",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.9 3. Structures de donnÃ©es ğŸ§±",
    "text": "0.9 3. Structures de donnÃ©es ğŸ§±\nPython propose plusieurs structures trÃ¨s utilisÃ©es en data engineering.\n\n\n\nStructure\nOrdonnÃ©\nModifiable\nDuplicats\nAccÃ¨s principal\n\n\n\n\nlist\nâœ”ï¸\nâœ”ï¸\nâœ”ï¸\nindex (0, 1, 2â€¦)\n\n\ndict\nâœ”ï¸ (3.7+)\nâœ”ï¸\nclÃ©s uniques\nclÃ© (\"nom\")\n\n\ntuple\nâœ”ï¸\nâŒ\nâœ”ï¸\nindex\n\n\nset\nâŒ\nâœ”ï¸\nâŒ\nappartenance (in)\n\n\n\n\n0.9.1 3.1 Listes (list)\nUne liste est une sÃ©quence ordonnÃ©e et modifiable.\n# CrÃ©ation d'une liste\nnombres = [10, 20, 30, 40]\n\n# AccÃ¨s par index\nprint(nombres[0])   # 10\nprint(nombres[2])   # 30\n\n# Ajout en fin de liste\nnombres.append(50)\nprint(\"AprÃ¨s append :\", nombres)\n\n# Insertion Ã  une position prÃ©cise\nnombres.insert(1, 15)\nprint(\"AprÃ¨s insert :\", nombres)\n\n# Modification d'un Ã©lÃ©ment\nnombres[0] = 5\nprint(\"AprÃ¨s modification :\", nombres)\n\n# Suppression par valeur\nnombres.remove(30)\nprint(\"AprÃ¨s remove :\", nombres)\n\n# Suppression par index\ndel nombres[0]\nprint(\"AprÃ¨s del :\", nombres)\n\n0.9.1.1 CrÃ©ation dynamique de listes\nOn crÃ©e trÃ¨s souvent des listes Ã  partir dâ€™autres listes, avec une boucle ou une list comprehension.\nnombres = [1, 2, 3, 4, 5, 6]\n\n# Version avec boucle\npairs = []\nfor n in nombres:\n    if n % 2 == 0:\n        pairs.append(n)\n\nprint(\"Pairs (boucle) :\", pairs)\n\n# Version list comprehension\npairs2 = [n for n in nombres if n % 2 == 0]\nprint(\"Pairs (list comprehension) :\", pairs2)\nâš ï¸ Erreurs frÃ©quentes avec les listes : - nombres[10] alors que la liste a moins dâ€™Ã©lÃ©ments â†’ IndexError ; - nombres.remove(999) alors que 999 nâ€™est pas dans la liste â†’ ValueError.\n\n\n\n0.9.2 3.2 Dictionnaires (dict)\nUn dictionnaire stocke des paires clÃ© â†’ valeur. Câ€™est lâ€™Ã©quivalent naturel des objets JSON, trÃ¨s utilisÃ© pour les APIs et NoSQL.\nutilisateur = {\n    \"id\": 1,\n    \"nom\": \"Alice\",\n    \"ville\": \"Abidjan\"\n}\n\n# AccÃ¨s Ã  une valeur par clÃ©\nprint(utilisateur[\"nom\"])  # Alice\n\n# Ajout / modification\nutilisateur[\"age\"] = 30\nutilisateur[\"ville\"] = \"BouakÃ©\"\n\n# Suppression\ndel utilisateur[\"id\"]\n\nprint(utilisateur)\n\n0.9.2.1 AccÃ¨s sÃ©curisÃ© avec .get()\nUtiliser dict.get() permet dâ€™Ã©viter un KeyError si la clÃ© nâ€™existe pas.\nprint(utilisateur.get(\"email\"))           # None\nprint(utilisateur.get(\"email\", \"Inconnu\"))  # Inconnu\n\n\n0.9.2.2 CrÃ©ation dynamique : comptage dâ€™occurrences\nnoms = [\"bob\", \"alice\", \"bob\", \"charlie\", \"alice\"]\ncompte = {}\n\nfor n in noms:\n    compte[n] = compte.get(n, 0) + 1\n\nprint(compte)  # {'bob': 2, 'alice': 2, 'charlie': 1}\nâš ï¸ Erreurs frÃ©quentes avec les dictionnaires : - utilisateur[\"email\"] alors que la clÃ© nâ€™existe pas â†’ KeyError ; - supposer quâ€™un dictionnaire est indexÃ© comme une liste (utilisateur[0]).\n\n\n\n0.9.3 3.3 Tuples (tuple)\nUn tuple est comme une liste non modifiable (immutable). On lâ€™utilise pour reprÃ©senter des collections fixes de valeurs : coordonnÃ©es, dates, etc.\ncoord = (5.0, 10.0)\nprint(coord[0])  # 5.0\nprint(coord[1])  # 10.0\n\n# coord[0] = 20.0  # âŒ TypeError : un tuple n'est pas modifiable\nEn data engineering, les tuples sont utiles pour : - retourner plusieurs valeurs depuis une fonction ; - reprÃ©senter des clÃ©s composites (ex : (annÃ©e, mois)).\n\n\n0.9.4 3.4 Ensembles (set)\nUn ensemble (set) contient des valeurs uniques, sans ordre garanti. TrÃ¨s utile pour dÃ©dupliquer une liste.\ntags = {\"python\", \"data\", \"python\"}\nprint(tags)  # 'python' n'apparaÃ®t qu'une seule fois\n\n# Ajout\ntags.add(\"engineer\")\n\n# Suppression (erreur si absent)\ntags.remove(\"data\")\n\n# Suppression sans erreur si absent\ntags.discard(\"ai\")\n\nprint(tags)\nğŸ’¡ Exemple de dÃ©duplication :\nemails = [\"a@test.com\", \"b@test.com\", \"a@test.com\"]\nemails_uniques = list(set(emails))\nprint(emails_uniques)\nâš ï¸ Erreurs frÃ©quentes : - Compter sur lâ€™ordre dâ€™un set (lâ€™ordre nâ€™est pas garanti) ; - Utiliser remove() pour un Ã©lÃ©ment possiblement absent â†’ prÃ©fÃ©rer discard().\n\n\n0.9.5 ğŸ§± 3.5 Mini-exercice â€” Structures de donnÃ©es\nğŸ“Œ DonnÃ©es\nlogs = [\n    {\"user\": \"alice\", \"status\": 200},\n    {\"user\": \"bob\", \"status\": 500},\n    {\"user\": \"alice\", \"status\": 404},\n    {\"user\": \"bob\", \"status\": 200},\n]\nğŸ¯ Objectifs 1. CrÃ©er la liste de tous les utilisateurs (list) 2. CrÃ©er la liste unique des utilisateurs (set) 3. CrÃ©er un dictionnaire qui compte le nombre de requÃªtes par utilisateur (dict)\n# Ã€ toi de jouer ğŸ˜Š\n\nlogs = [\n    {\"user\": \"alice\", \"status\": 200},\n    {\"user\": \"bob\", \"status\": 500},\n    {\"user\": \"alice\", \"status\": 404},\n    {\"user\": \"bob\", \"status\": 200},\n]\n\nutilisateurs = []            # TODO\nutilisateurs_uniques = set() # TODO\ncompte_par_user = {}         # TODO\n\nprint(utilisateurs)\nprint(utilisateurs_uniques)\nprint(compte_par_user)\n\n\nğŸ’¡ Correction (cliquer pour afficher)\n\nlogs = [\n    {\"user\": \"alice\", \"status\": 200},\n    {\"user\": \"bob\", \"status\": 500},\n    {\"user\": \"alice\", \"status\": 404},\n    {\"user\": \"bob\", \"status\": 200},\n]\n\nutilisateurs = []\nutilisateurs_uniques = set()\ncompte_par_user = {}\n\nfor log in logs:\n    user = log[\"user\"]\n    utilisateurs.append(user)\n    utilisateurs_uniques.add(user)\n    compte_par_user[user] = compte_par_user.get(user, 0) + 1\n\nprint(utilisateurs)\nprint(utilisateurs_uniques)\nprint(compte_par_user)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#fonctions",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#fonctions",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "0.10 4. Fonctions",
    "text": "0.10 4. Fonctions\nUne fonction permet de : - rÃ©utiliser du code ; - encapsuler de la logique mÃ©tier (nettoyage, validationâ€¦) ; - sÃ©curiser la qualitÃ© de donnÃ©es (type, structureâ€¦).\nSyntaxe gÃ©nÃ©rale :\ndef nom(param1, param2=valeur_par_defaut) -&gt; type_retour:\n    # traitement\n    return resultat\nExemple :\ndef somme(a: int, b: int) -&gt; int:\n    \"\"\"Retourne la somme de deux entiers.\"\"\"\n    return a + b\n\nresultat = somme(3, 5)\nprint(\"RÃ©sultat :\", resultat)\n\n0.10.1 âœ”ï¸ 4.1 Fonction pure (sans effet externe)\ndef normaliser_nom(nom: str) -&gt; str:\n    \"\"\"Nettoie un nom : supprime espaces, met en minuscule et capitalise.\"\"\"\n    return nom.strip().lower().capitalize()\n\nprint(normaliser_nom(\"  aLiCe  \"))  # Alice\n\n\n0.10.2 âš™ï¸ 4.2 ParamÃ¨tres + valeurs par dÃ©faut\ndef calculer_total(prix: float, quantite: int = 1, taxe: float = 0.18) -&gt; float:\n    \"\"\"Retourne le prix total avec taxe.\"\"\"\n    return prix * quantite * (1 + taxe)\n\nprint(calculer_total(2000))  \nprint(calculer_total(2000, quantite=3, taxe=0.09))\n\n\n0.10.3 ğŸ“Š 4.3 Retourner plusieurs valeurs (tuple)\ndef stats_notes(notes: list[int]) -&gt; tuple[float, float]:\n    \"\"\"Retourne moyenne et maximum d'une liste de notes.\"\"\"\n    moyenne = sum(notes) / len(notes)\n    maxi = max(notes)\n    return moyenne, maxi\n\nm, mx = stats_notes([14, 9, 18])\nprint(\"Moyenne:\", m, \"Max:\", mx)\n\n\n0.10.4 ğŸ”— 4.4 Fonctions qui manipulent un dictionnaire\ndef extraire_champ(data: dict, champ: str, default=None):\n    \"\"\"RÃ©cupÃ¨re un champ d'un dict, Ã©vite KeyError.\"\"\"\n    return data.get(champ, default)\n\nuser = {\"nom\": \"Sara\", \"ville\": \"Paris\"}\nprint(extraire_champ(user, \"nom\"))         # Sara\nprint(extraire_champ(user, \"age\", \"N/A\"))  # N/A\nâš ï¸ Erreurs frÃ©quentes : - Oublier les parenthÃ¨ses lors de lâ€™appel : somme au lieu de somme(3, 5) ; - Oublier return â†’ la fonction retourne None ; - Ne pas respecter le nombre dâ€™arguments attendus.\nâŒ Mauvaise pratique :\ndef ajouter(element, liste=[]):  # liste partagÃ©e !\n    liste.append(element)\n    return liste\nâœ”ï¸ Correct :\ndef ajouter(element, liste=None):\n    if liste is None: liste = []\n    liste.append(element)\n    return liste\n\n\n0.10.5 ğŸ§ª Mini-exercice â€” Fonctions sur des posts\n\n0.10.5.1 ğŸ“Œ Dataset simulÃ©\nposts = [\n  {\"user\": \"alice\", \"text\": \"  Hello World  \"},\n  {\"user\": \"bob\", \"text\": \"Data Engineer ici\"},\n  {\"user\": \"alice\", \"text\": \"Python est top \"}\n]\n\n\n0.10.5.2 ğŸ¯ Instructions\nCrÃ©er 3 fonctions :\n\nnettoyer_texte(text: str) -&gt; str\nNettoie le texte (supprime espaces, convertit en minuscules)\nlongueur_post(post: dict) -&gt; int\nRetourne la longueur du texte nettoyÃ© dâ€™un post\nstats_posts(posts: list[dict]) -&gt; tuple[float, int, int]\nRetour attendu : (moyenne, maximum, minimum) des longueurs de texte\n\n# Ã€ toi de jouer ğŸ˜Š\n\n# TODO\n\n\nğŸ’¡ Correction (cliquer pour afficher)\n\ndef nettoyer_texte(text: str) -&gt; str:\n    return text.strip().lower()\n\ndef longueur_post(post: dict) -&gt; int:\n    return len(nettoyer_texte(post[\"text\"]))\n\ndef stats_posts(posts: list[dict]) -&gt; tuple[float, int, int]:\n    longueurs = [longueur_post(p) for p in posts]\n    return (sum(longueurs)/len(longueurs), max(longueurs), min(longueurs))\n\nprint(stats_posts(posts))\nRÃ©sultat attendu : (15.333333333333334, 19, 11)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#exemple-simple-modÃ©liser-un-utilisateur",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#exemple-simple-modÃ©liser-un-utilisateur",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.1 5.1 Exemple simple : ModÃ©liser un utilisateur ğŸ‘¤",
    "text": "1.1 5.1 Exemple simple : ModÃ©liser un utilisateur ğŸ‘¤\nclass Utilisateur:\n    def __init__(self, identifiant: int, nom: str, ville: str) -&gt; None:\n        self.identifiant = identifiant\n        self.nom = nom\n        self.ville = ville\n\n    def presentation(self) -&gt; str:\n        return f\"Je m'appelle {self.nom} et j'habite Ã  {self.ville}.\"\nu = Utilisateur(1, \"Alice\", \"Abidjan\")\nprint(u.presentation())",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#ajouter-une-mÃ©thode-utile",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#ajouter-une-mÃ©thode-utile",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.2 5.2 Ajouter une mÃ©thode utile ğŸ™ï¸",
    "text": "1.2 5.2 Ajouter une mÃ©thode utile ğŸ™ï¸\nclass Utilisateur:\n    def __init__(self, identifiant: int, nom: str, ville: str) -&gt; None:\n        self.identifiant = identifiant\n        self.nom = nom\n        self.ville = ville\n\n    def presentation(self) -&gt; str:\n        return f\"Je m'appelle {self.nom} et j'habite Ã  {self.ville}.\"\n\n    def changer_ville(self, nouvelle_ville: str) -&gt; None:\n        self.ville = nouvelle_ville",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#encapsulation-attributs-protÃ©gÃ©sprivÃ©s",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#encapsulation-attributs-protÃ©gÃ©sprivÃ©s",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.3 5.3 Encapsulation : attributs protÃ©gÃ©s/privÃ©s ğŸ”’",
    "text": "1.3 5.3 Encapsulation : attributs protÃ©gÃ©s/privÃ©s ğŸ”’\nclass Compte:\n    def __init__(self, solde: float):\n        self._solde = solde        # usage interne\n        self.__secret = \"XYZ123\"   # privÃ© via name mangling",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#reprÃ©sentation-textuelle-str",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#reprÃ©sentation-textuelle-str",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.4 5.4 ReprÃ©sentation textuelle (str) ğŸ“",
    "text": "1.4 5.4 ReprÃ©sentation textuelle (str) ğŸ“\nclass Utilisateur:\n    def __init__(self, identifiant, nom, ville):\n        self.identifiant = identifiant\n        self.nom = nom\n        self.ville = ville\n\n    def __str__(self) -&gt; str:\n        return f\"[{self.identifiant}] {self.nom} ({self.ville})\"",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#composition-dobjets-objet-dans-un-objet",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#composition-dobjets-objet-dans-un-objet",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.5 5.5 Composition dâ€™objets (objet dans un objet) ğŸ§±",
    "text": "1.5 5.5 Composition dâ€™objets (objet dans un objet) ğŸ§±\nclass Adresse:\n    def __init__(self, rue: str, ville: str, pays: str) -&gt; None:\n        self.rue = rue\n        self.ville = ville\n        self.pays = pays\n\n    def __str__(self) -&gt; str:\n        return f\"{self.rue}, {self.ville} ({self.pays})\"\n\nclass Utilisateur:\n    def __init__(self, identifiant: int, nom: str, adresse: Adresse) -&gt; None:\n        self.identifiant = identifiant\n        self.nom = nom\n        self.adresse = adresse\n\n    def presentation(self) -&gt; str:\n        return f\"Je m'appelle {self.nom} et j'habite Ã  {self.adresse}.\"",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-utiliser-des-classes-en-data-engineering",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-utiliser-des-classes-en-data-engineering",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.6 5.6 Pourquoi utiliser des classes en Data Engineering ? âš™ï¸",
    "text": "1.6 5.6 Pourquoi utiliser des classes en Data Engineering ? âš™ï¸\nclass Transaction:\n    def __init__(self, id, montant, devise, timestamp):\n        self.id = id\n        self.montant = montant\n        self.devise = devise\n        self.timestamp = timestamp\n\nclass Transaction:\n    def __init__(self, id, montant, devise):\n        self.id = id\n        self.montant = montant\n        self.devise = devise\n\n    def montant_fcfa(self):\n        taux = {\"EUR\": 655, \"USD\": 600}\n        return self.montant * taux.get(self.devise, 1)\n\nclass ExtracteurCSV:\n    def __init__(self, chemin):\n        self.chemin = chemin\n\n    def extract(self):\n        with open(self.chemin) as f:\n            return f.readlines()\n\nevent = EventHubRecord(payload)\nevent.clean()\nevent.validate()\nevent.to_parquet()",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.7 5.7 Erreurs frÃ©quentes âš ï¸",
    "text": "1.7 5.7 Erreurs frÃ©quentes âš ï¸\n\nOublier self dans les mÃ©thodes.\nAccÃ©der Ã  un attribut avant de lâ€™avoir crÃ©Ã©.\nUtiliser une valeur mutable dans __init__ (list, dict).\nConfondre composition et hÃ©ritage.\nFaire une classe Â« God Object Â» avec trop de responsabilitÃ©s.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#gestion-derreurs-indispensable-en-data-engineering",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#gestion-derreurs-indispensable-en-data-engineering",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.8 6. Gestion dâ€™erreurs ğŸ›‘ â€” (Indispensable en Data Engineering)",
    "text": "1.8 6. Gestion dâ€™erreurs ğŸ›‘ â€” (Indispensable en Data Engineering)\nEn Data Engineering, les erreurs sont inÃ©vitables :\n- fichiers manquants\n- API indisponible\n- JSON mal formÃ©\n- division par zÃ©ro\n- connexion BD Ã©chouÃ©e\n- typage incorrect\nğŸ‘‰ La bonne pratique consiste Ã  capturer, expliquer, puis continuer proprement.\nCâ€™est le rÃ´le de try / except.\n\n\n1.8.1 ğŸ¯ Exemple simple â€” division sÃ©curisÃ©e\ndef division(a: float, b: float) -&gt; float | None:\n    try:\n        return a / b\n    except ZeroDivisionError:\n        print(\"âŒ Erreur : division par zÃ©ro.\")\n        return None\nprint(division(10, 2))  # OK\nprint(division(10, 0))  # Erreur gÃ©rÃ©e\n\n\n\n1.8.2 ğŸ§° Exemple plus rÃ©aliste â€” lecture de fichier\ndef lire_csv(chemin: str) -&gt; list | None:\n    try:\n        with open(chemin, \"r\") as f:\n            return f.readlines()\n    except FileNotFoundError:\n        print(f\"âŒ Fichier introuvable : {chemin}\")\n        return None\n\n\n\n1.8.3 ğŸ’¡ else et finally\nOn peut amÃ©liorer la lisibilitÃ© avec else et finally :\ntry:\n    result = 10 / 2\nexcept ZeroDivisionError:\n    print(\"Erreur\")\nelse:\n    print(\"Aucune erreur, rÃ©sultat =\", result)\nfinally:\n    print(\"Bloc exÃ©cutÃ© dans tous les cas\")\n\n\n\n1.8.4 ğŸ—ï¸ Exemple Data Engineering : appel API sÃ©curisÃ©\nimport requests\n\ndef fetch_json(url: str) -&gt; dict | None:\n    try:\n        response = requests.get(url, timeout=3)\n        response.raise_for_status()   # GÃ©nÃ¨re une erreur HTTP si code â‰  200\n        return response.json()\n    except requests.exceptions.HTTPError as e:\n        print(\"âŒ Erreur HTTP :\", e)\n    except requests.exceptions.Timeout:\n        print(\"â±ï¸ Timeout : serveur trop lent\")\n    except ValueError:\n        print(\"âŒ JSON mal formÃ©\")\n    except Exception as e:\n        print(\"âš ï¸ Erreur inconnue :\", e)\n    return None\n\n\n\n1.8.5 âš ï¸ Erreurs frÃ©quentes Ã  Ã©viter\n\n\n\n\n\n\n\nâŒ Mauvaise pratique\nâœ… Bonne pratique\n\n\n\n\nexcept: (attrape tout)\nSpÃ©cifier lâ€™erreur : except ValueError:\n\n\nCacher lâ€™erreur sans message\nFournir un contexte ğŸ—ƒï¸\n\n\nRetourner nâ€™importe quoi\nRetour cohÃ©rent (None ou valeur par dÃ©faut)\n\n\nMettre trop de logique dans try\nLimiter au strict nÃ©cessaire\n\n\nIgnorer les erreurs silencieusement\nLogguer ou notifier\n\n\n\n\n\n\n1.8.6 ğŸš€ Conseil pro (trÃ¨s utile en Data Engineering)\nUtiliser raise pour propager lâ€™erreur si elle doit Ãªtre traitÃ©e ailleurs :\ndef parse_json(data: str) -&gt; dict:\n    try:\n        return json.loads(data)\n    except json.JSONDecodeError as e:\n        raise ValueError(f\"JSON invalide : {e}\")\n\n\n\n1.8.7 ğŸ“Œ Ã€ retenir\n\nToujours attraper le type exact dâ€™erreur.\n\nToujours expliquer lâ€™erreur (message clair).\n\nToujours garder un comportement cohÃ©rent (retour None ou valeur dÃ©faut).\n\nLes erreurs silencieuses sont pires que les erreurs visibles.\n\nLes pipelines cassent souvent â€” gÃ©rer les erreurs = Ãªtre un vrai Data Engineer.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#modules-et-imports-structurer-son-code-comme-un-data-engineer",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#modules-et-imports-structurer-son-code-comme-un-data-engineer",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.9 7. Modules et Imports ğŸ“¦ â€” Structurer son code comme un Data Engineer",
    "text": "1.9 7. Modules et Imports ğŸ“¦ â€” Structurer son code comme un Data Engineer\nEn Python :\n\nUn module = un fichier .py\nUn package = un dossier contenant plusieurs modules + un fichier __init__.py\n\nğŸ‘‰ Cela permet dâ€™organiser un projet data en blocs logiques :\ningestion, nettoyage, transformation, validation, etc.\n\n\n1.9.1 ğŸ—‚ï¸ Exemple de structure de projet (propre & professionnelle)\nproject/\nâ”œâ”€â”€ utils/               â† Package (outils rÃ©utilisables)\nâ”‚   â”œâ”€â”€ __init__.py      â† Indique que `utils` est un package\nâ”‚   â””â”€â”€ math_utils.py     â† Module\nâ”œâ”€â”€ processors/           â† Package pour le traitement\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â””â”€â”€ text_cleaner.py   â† Module\nâ””â”€â”€ main.py               â† Point dâ€™entrÃ©e du projet\n\n\n\n1.9.2 ğŸ“Œ Contenu du module : utils/math_utils.py\ndef somme(a, b):\n    return a + b\n\n\n\n1.9.3 ğŸ“Œ Contenu dâ€™un autre module : processors/text_cleaner.py\ndef nettoyer_texte(text: str) -&gt; str:\n    return text.strip().lower()\n\n\n\n1.9.4 ğŸ“Œ Importer dans main.py\nfrom utils.math_utils import somme\nfrom processors.text_cleaner import nettoyer_texte\n\nprint(somme(2, 3))\nprint(nettoyer_texte(\"  Hello WORLD  \"))",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#import-absolu-vs-import-relatif",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#import-absolu-vs-import-relatif",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.10 ğŸ” ğŸ’¡ Import absolu vs import relatif",
    "text": "1.10 ğŸ” ğŸ’¡ Import absolu vs import relatif\n\n1.10.1 âœ”ï¸ Import absolu (recommandÃ©)\nfrom utils.math_utils import somme\nâ¡ï¸ Le plus lisible, idÃ©al pour projets pro / Data Engineering.\n\n\n1.10.2 âœ”ï¸ Import relatif (utile dans les packages)\nfrom .math_utils import somme\nâ¡ï¸ Courant dans les gros projets et dans les packages pip.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-cest-important-en-data-engineering",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-cest-important-en-data-engineering",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.11 ğŸ§  Pourquoi câ€™est important en Data Engineering ?",
    "text": "1.11 ğŸ§  Pourquoi câ€™est important en Data Engineering ?\n\nCrÃ©er des modules = rendre ton code rÃ©utilisable (API, pipelines, notebooks)\nStructurer ton projet = Ã©viter le â€œscript spaghettiâ€\nFaciliter les tests unitaires\nFaciliter la maintenance dâ€™un pipeline data\nRÃ©duire les erreurs de duplication de logique",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-solutions",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-solutions",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.12 âš ï¸ Erreurs frÃ©quentes & solutions",
    "text": "1.12 âš ï¸ Erreurs frÃ©quentes & solutions\n\n\n\n\n\n\n\n\nâŒ ProblÃ¨me\nğŸ’¡ Cause\nâœ… Solution\n\n\n\n\nModuleNotFoundError\nexÃ©cuter Python depuis le mauvais dossier\nToujours lancer Python depuis la racine du projet\n\n\nImport relatif impossible\nabsence du fichier __init__.py\nAjouter __init__.py dans le dossier\n\n\nModules dupliquÃ©s\nfichiers ayant le mÃªme nom dans deux dossiers\nRenommer ou structurer les packages\n\n\nimport *\nimports imprÃ©cis\nToujours importer explicitement\n\n\n\n\n\n1.12.1 âœ”ï¸ Astuce pro : vÃ©rifier ton PYTHONPATH\nimport sys\nprint(sys.path)\nCela indique oÃ¹ Python cherche les modules.\n\n\n\n1.12.2 â­ Rappel essentiel\n\nImporter = RÃ©utiliser.\nStructurer = Devenir un vrai Data Engineer.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#manipulation-de-fichiers-compÃ©tence-essentielle-du-data-engineer",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#manipulation-de-fichiers-compÃ©tence-essentielle-du-data-engineer",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.13 8. Manipulation de fichiers ğŸ“ â€” CompÃ©tence essentielle du Data Engineer",
    "text": "1.13 8. Manipulation de fichiers ğŸ“ â€” CompÃ©tence essentielle du Data Engineer\nDans un pipeline Data, on manipule en permanence des fichiers : - fichiers texte (logs, outputs) - fichiers CSV (exports mÃ©tier, ingestion) - fichiers JSON (APIs, NoSQL, Ã©vÃ©nements Kafka) - dossiers qui contiennent les donnÃ©es\nPython fournit des outils natifs trÃ¨s puissants pour cela :\n\npathlib.Path â†’ gÃ©rer les chemins et dossiers\n\nopen() â†’ lire/Ã©crire des fichiers texte\n\njson â†’ sÃ©rialiser/dÃ©sÃ©rialiser des donnÃ©es JSON\n\n\n\n1.13.1 ğŸ—‚ï¸ Initialisation du dossier data/\nfrom pathlib import Path\nimport json\n\n# CrÃ©ation du dossier de travail\nDATA_DIR = Path(\"data\")\nDATA_DIR.mkdir(exist_ok=True)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#manipulation-dun-fichier-texte-logs-outputs",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#manipulation-dun-fichier-texte-logs-outputs",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.14 8.1 ğŸ“„ Manipulation dâ€™un fichier texte (logs, outputsâ€¦)",
    "text": "1.14 8.1 ğŸ“„ Manipulation dâ€™un fichier texte (logs, outputsâ€¦)\ntexte_path = DATA_DIR / \"exemple.txt\"\n\n# Ã‰criture\nwith open(texte_path, \"w\", encoding=\"utf-8\") as f:\n    f.write(\"Bonjour Data Engineer\\n\")\n\n# Lecture\nwith open(texte_path, \"r\", encoding=\"utf-8\") as f:\n    contenu = f.read()\n\nprint(\"Contenu du fichier :\", contenu)\nğŸ” Bonnes pratiques : - Toujours utiliser encoding=\"utf-8\"\n- Toujours utiliser with ... (fermeture automatique du fichier)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#manipulation-dun-fichier-json",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#manipulation-dun-fichier-json",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.15 8.2 ğŸ§© Manipulation dâ€™un fichier JSON",
    "text": "1.15 8.2 ğŸ§© Manipulation dâ€™un fichier JSON\nFormat le plus utilisÃ© dans : - APIs REST - MongoDB - Events Kafka / Kinesis - Configurations de job\njson_path = DATA_DIR / \"utilisateur.json\"\nutilisateur = {\"nom\": \"Alice\", \"age\": 30}\n\n# Ã‰criture JSON\nwith open(json_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(utilisateur, f, ensure_ascii=False, indent=2)\n\n# Lecture JSON\nwith open(json_path, \"r\", encoding=\"utf-8\") as f:\n    utilisateur_charge = json.load(f)\n\nprint(\"Utilisateur chargÃ© :\", utilisateur_charge)\nğŸ’¡ ensure_ascii=False permet dâ€™Ã©crire proprement les accents.\nğŸ’¡ indent=2 rend le JSON lisible (log, debug, auditsâ€¦).",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#optionnel-manipulation-dun-csv-avec-pandas",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#optionnel-manipulation-dun-csv-avec-pandas",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.16 8.3 ğŸ“Š (Optionnel) Manipulation dâ€™un CSV avec Pandas",
    "text": "1.16 8.3 ğŸ“Š (Optionnel) Manipulation dâ€™un CSV avec Pandas\nSouvent utilisÃ© en ingestion de donnÃ©es.\nimport pandas as pd\n\ncsv_path = DATA_DIR / \"exemple.csv\"\n\ndf = pd.DataFrame({\n    \"nom\": [\"Alice\", \"Bob\"],\n    \"age\": [30, 25]\n})\n\ndf.to_csv(csv_path, index=False)\n\ndf_loaded = pd.read_csv(csv_path)\nprint(df_loaded)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-comment-les-Ã©viter",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-comment-les-Ã©viter",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.17 âš ï¸ Erreurs frÃ©quentes & comment les Ã©viter",
    "text": "1.17 âš ï¸ Erreurs frÃ©quentes & comment les Ã©viter\n\n\n\n\n\n\n\n\nâŒ ProblÃ¨me\nğŸ’¡ Cause\nâœ… Solution\n\n\n\n\nFileNotFoundError\nMauvais chemin\nToujours utiliser Path() et vÃ©rifier path.exists()\n\n\nAccents cassÃ©s (Ã©, Ã â€¦)\nMauvais encoding\nToujours encoding=\"utf-8\"\n\n\nFichier non fermÃ©\nopen() sans contexte\nToujours utiliser with open(...)\n\n\nJSON mal formÃ©\nÃ©crit Ã  la main\nToujours utiliser json.dump / json.load\n\n\nChemins relatifs non fiables\nmauvais dossier dâ€™exÃ©cution\nUtiliser Path(__file__).resolve().parent dans un projet rÃ©el",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#points-clÃ©s-Ã -retenir-1",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#points-clÃ©s-Ã -retenir-1",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.18 ğŸ“ Points clÃ©s Ã  retenir",
    "text": "1.18 ğŸ“ Points clÃ©s Ã  retenir\n\npathlib.Path simplifie la gestion des chemins.\n\nwith open(...) est obligatoire pour Ã©viter les fuites de fichier.\n\nJSON = format standard du Data Engineering (MongoDB, API, logsâ€¦).\n\nToujours contrÃ´ler lâ€™encoding lors de la lecture/Ã©criture.\n\nLe dossier data/ centralise vos fichiers dans un projet propre.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#packages-et-pip-gÃ©rer-les-dÃ©pendances-comme-un-data-engineer",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#packages-et-pip-gÃ©rer-les-dÃ©pendances-comme-un-data-engineer",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.19 9. Packages et pip ğŸ“¦ â€” GÃ©rer les dÃ©pendances comme un Data Engineer",
    "text": "1.19 9. Packages et pip ğŸ“¦ â€” GÃ©rer les dÃ©pendances comme un Data Engineer\nPython devient puissant grÃ¢ce Ã  ses packages externes :\nPandas, Requests, SQLAlchemy, PyMongo, Polars, FastAPI, etc.\nPour installer ces packages, on utilise pip, le gestionnaire officiel de Python.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#installer-un-package-avec-pip",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#installer-un-package-avec-pip",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.20 ğŸ”§ Installer un package avec pip",
    "text": "1.20 ğŸ”§ Installer un package avec pip\nExemple : installer requests pour faire des appels HTTP (API REST).\npython -m pip install requests\nğŸ‘‰ Pourquoi python -m pip et pas juste pip install ?\nParce que cela garantit quâ€™on utilise le pip liÃ© Ã  la bonne version de Python, surtout si plusieurs versions sont installÃ©es.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#utilisation-dans-un-script",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#utilisation-dans-un-script",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.21 ğŸ“Œ Utilisation dans un script",
    "text": "1.21 ğŸ“Œ Utilisation dans un script\nimport requests\n\nresponse = requests.get(\"https://api.github.com\")\nprint(response.status_code)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#installer-plusieurs-packages-requirements.txt",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#installer-plusieurs-packages-requirements.txt",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.22 ğŸ“ Installer plusieurs packages â€” requirements.txt",
    "text": "1.22 ğŸ“ Installer plusieurs packages â€” requirements.txt\nDans un vrai projet Data Engineering, on liste les dÃ©pendances dans un fichier :\nrequests\npandas\nsqlalchemy\npymongo\nPuis on installe tout dâ€™un coup :\npython -m pip install -r requirements.txt",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#mettre-Ã -jour-un-package",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#mettre-Ã -jour-un-package",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.23 â™»ï¸ Mettre Ã  jour un package",
    "text": "1.23 â™»ï¸ Mettre Ã  jour un package\npython -m pip install --upgrade requests",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#dÃ©sinstaller-un-package",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#dÃ©sinstaller-un-package",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.24 ğŸ§¹ DÃ©sinstaller un package",
    "text": "1.24 ğŸ§¹ DÃ©sinstaller un package\npython -m pip uninstall requests",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#oÃ¹-sont-installÃ©s-les-packages",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#oÃ¹-sont-installÃ©s-les-packages",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.25 ğŸ“¦ OÃ¹ sont installÃ©s les packages ?",
    "text": "1.25 ğŸ“¦ OÃ¹ sont installÃ©s les packages ?\npython -m pip show requests\nDonne : version, emplacement, dÃ©pendances, etc.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-bonnes-pratiques",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-bonnes-pratiques",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.26 âš ï¸ Erreurs frÃ©quentes & bonnes pratiques",
    "text": "1.26 âš ï¸ Erreurs frÃ©quentes & bonnes pratiques\n\n\n\n\n\n\n\n\nâŒ ProblÃ¨me\nğŸ’¡ Cause\nâœ… Solution\n\n\n\n\npip: command not found\nPython mal installÃ©\nUtiliser python -m pip\n\n\nInstaller dans le mauvais Python\nPlusieurs versions installÃ©es\nToujours python -m pip install\n\n\nVersion incompatible\nConflit de dÃ©pendances\nSpÃ©cifier une version : requests==2.31.0\n\n\nInstaller globalement\nRisque de casser le systÃ¨me\nUtiliser un venv (python -m venv .venv)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#astuce-pro-figer-les-versions-pour-la-production",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#astuce-pro-figer-les-versions-pour-la-production",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.27 â­ Astuce Pro : figer les versions pour la production",
    "text": "1.27 â­ Astuce Pro : figer les versions pour la production\npython -m pip freeze &gt; requirements.txt\nâ¡ï¸ Cela capture exactement les versions utilisÃ©es dans ton environnement.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#logging-traÃ§abilitÃ©-indispensable-en-data-engineering",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#logging-traÃ§abilitÃ©-indispensable-en-data-engineering",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.28 10. Logging ğŸ§¾ â€” TraÃ§abilitÃ© indispensable en Data Engineering",
    "text": "1.28 10. Logging ğŸ§¾ â€” TraÃ§abilitÃ© indispensable en Data Engineering\nDans un vrai pipeline Data (ingestion, nettoyage, transformationâ€¦), on doit suivre ce quâ€™il se passe :\n\nFichier introuvable ?\nAPI trop lente ?\nFormat JSON invalide ?\nDonnÃ©es anormales ?\nETL en retard ?\n\nâ¡ï¸ print() ne suffit pas, car il ne permet ni filtrage, ni niveaux, ni logs dans un fichier.\nâ¡ï¸ Le module logging est le standard utilisÃ© en entreprise.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-utiliser-logging",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#pourquoi-utiliser-logging",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.29 ğŸ” 10.1 Pourquoi utiliser logging ?",
    "text": "1.29 ğŸ” 10.1 Pourquoi utiliser logging ?\n\n\n\n\n\n\n\nAvantage\nDescription\n\n\n\n\nğŸšï¸ Niveaux de log\nDEBUG, INFO, WARNING, ERROR, CRITICAL\n\n\nğŸ¯ Filtrage des messages\nOn peut afficher seulement WARNING+\n\n\nğŸ’¾ Logs dans un fichier\nIndispensable en production\n\n\nğŸ§© Standard Python\nCompatible Airflow, FastAPI, ETL, microservices\n\n\nğŸ§µ Thread-safe\nFonctionne mÃªme avec du multithreading",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#configuration-minimale-recommandÃ©e",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#configuration-minimale-recommandÃ©e",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.30 ğŸ”§ Configuration minimale recommandÃ©e",
    "text": "1.30 ğŸ”§ Configuration minimale recommandÃ©e\nimport logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n)\nExplications : - level=INFO â†’ DEBUG est ignorÃ© - %(asctime)s â†’ timestamp (important dans les pipelines) - %(levelname)s â†’ niveau (INFO, ERRORâ€¦) - %(message)s â†’ contenu du message",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#exemple-dutilisation",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#exemple-dutilisation",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.31 ğŸ§ª Exemple dâ€™utilisation",
    "text": "1.31 ğŸ§ª Exemple dâ€™utilisation\nlogging.debug(\"Message DEBUG (non affichÃ© en mode INFO)\")\nlogging.info(\"DÃ©marrage du mini-script\")\nlogging.warning(\"Attention : donnÃ©es manquantes\")\nlogging.error(\"Erreur : Ã©chec de connexion API\")\nlogging.critical(\"CRITIQUE : le pipeline doit s'arrÃªter !\")",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#Ã©crire-les-logs-dans-un-fichier-cas-rÃ©el-data-engineering",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#Ã©crire-les-logs-dans-un-fichier-cas-rÃ©el-data-engineering",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.32 ğŸ“ 10.2 Ã‰crire les logs dans un fichier (cas rÃ©el Data Engineering)",
    "text": "1.32 ğŸ“ 10.2 Ã‰crire les logs dans un fichier (cas rÃ©el Data Engineering)\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n    filename=\"pipeline.log\",\n    filemode=\"a\",  # append au lieu de rÃ©Ã©crire\n)\nâ¡ï¸ TrÃ¨s utilisÃ© dans : - scripts Airflow - traitements batch - pipelines de production",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#exemple-typique-dans-une-fonction",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#exemple-typique-dans-une-fonction",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.33 ğŸ§° 10.3 Exemple typique dans une fonction",
    "text": "1.33 ğŸ§° 10.3 Exemple typique dans une fonction\ndef charger_json(chemin: str) -&gt; dict | None:\n    logging.info(f\"Chargement du fichier : {chemin}\")\n    try:\n        with open(chemin, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except FileNotFoundError:\n        logging.error(f\"Fichier introuvable : {chemin}\")\n    except json.JSONDecodeError:\n        logging.error(\"JSON invalide\")\n    return None",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-comment-les-Ã©viter-1",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#erreurs-frÃ©quentes-comment-les-Ã©viter-1",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.34 âš ï¸ Erreurs frÃ©quentes & comment les Ã©viter",
    "text": "1.34 âš ï¸ Erreurs frÃ©quentes & comment les Ã©viter\n\n\n\n\n\n\n\n\nâŒ Mauvaise pratique\nğŸ’¡ Pourquoi\nâœ… Bonne pratique\n\n\n\n\nUtiliser print() partout\nimpossible Ã  filtrer/logguer\nUtiliser logging.info()\n\n\nAppeler logging.basicConfig() plusieurs fois\nne fonctionne que la 1Ã¨re fois\nConfigurer un seul logger global\n\n\nLogger des donnÃ©es sensibles\nfuite de secrets/mots de passe\nFiltrer/masquer les champs sensibles\n\n\nLogs trop verbeux\nralentissent les pipelines\nUtiliser DEBUG seulement en dev\n\n\nLogs insuffisants\ndifficile de diagnostiquer\nLogger les erreurs + contexte",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#astuce-pro-logger-dans-la-console-et-dans-un-fichier",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#astuce-pro-logger-dans-la-console-et-dans-un-fichier",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.35 â­ Astuce pro : Logger dans la console et dans un fichier",
    "text": "1.35 â­ Astuce pro : Logger dans la console et dans un fichier\nlogger = logging.getLogger(\"pipeline\")\nlogger.setLevel(logging.INFO)\n\n# Handler console\nconsole = logging.StreamHandler()\nconsole.setLevel(logging.INFO)\n\n# Handler fichier\nfile = logging.FileHandler(\"pipeline.log\")\nfile.setLevel(logging.INFO)\n\n# Format\nfmt = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\nconsole.setFormatter(fmt)\nfile.setFormatter(fmt)\n\n# Ajouter handlers\nlogger.addHandler(console)\nlogger.addHandler(file)\n\nlogger.info(\"Pipeline dÃ©marrÃ©\")",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#Ã -retenir-1",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#Ã -retenir-1",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.36 ğŸ“ Ã€ retenir",
    "text": "1.36 ğŸ“ Ã€ retenir\n\nlogging = indispensable en Data Engineering\n\nToujours configurer : niveau + format\n\nUtiliser un fichier log en production\n\nJamais de print() dans un vrai pipeline\n\nBien choisir le niveau (INFO, WARNING, ERRORâ€¦)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#exercices-pratiques",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#exercices-pratiques",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.37 11. Exercices pratiques ğŸ§ª",
    "text": "1.37 11. Exercices pratiques ğŸ§ª\nEssaie de rÃ©soudre ces exercices avant dâ€™afficher les corrections.\n\n1.37.1 Exercice 1 â€“ Validation dâ€™Ã¢ge\nÃ‰crire une fonction est_majeur(age: int) -&gt; bool qui : - retourne True si age est supÃ©rieur ou Ã©gal Ã  18 ; - sinon retourne False.\n# Ã€ toi de jouer\ndef est_majeur(age: int) -&gt; bool:\n    # TODO: complÃ©ter\n    pass\n\nprint(est_majeur(15))  # attendu: False\nprint(est_majeur(18))  # attendu: True\n\n\nAfficher une solution possible\n\ndef est_majeur(age: int) -&gt; bool:\n    return age &gt;= 18\n\nprint(est_majeur(15))  # False\nprint(est_majeur(18))  # True\n\n\n\n1.37.2 Exercice 2 â€“ Compter les posts par utilisateur\nOn dispose dâ€™une liste de dictionnaires reprÃ©sentant des posts :\nposts = [\n    {\"user\": \"alice\", \"text\": \"Hello\"},\n    {\"user\": \"bob\", \"text\": \"Salut\"},\n    {\"user\": \"alice\", \"text\": \"Rebonjour\"},\n]\nÃ‰crire une fonction compter_posts_par_utilisateur(posts) qui retourne :\n{\"alice\": 2, \"bob\": 1}\n# Ã€ toi de jouer\nposts = [\n    {\"user\": \"alice\", \"text\": \"Hello\"},\n    {\"user\": \"bob\", \"text\": \"Salut\"},\n    {\"user\": \"alice\", \"text\": \"Rebonjour\"},\n]\n\ndef compter_posts_par_utilisateur(posts: list[dict]) -&gt; dict:\n    # TODO: complÃ©ter\n    result = {}\n    return result\n\nprint(compter_posts_par_utilisateur(posts))\n\n\nAfficher une solution possible\n\ndef compter_posts_par_utilisateur(posts: list[dict]) -&gt; dict:\n    result = {}\n    for p in posts:\n        user = p[\"user\"]\n        if user not in result:\n            result[user] = 0\n        result[user] += 1\n    return result\n\nprint(compter_posts_par_utilisateur(posts))  # {'alice': 2, 'bob': 1}\n\n\n\n1.37.3 Exercice 3 â€“ Classe Post\nCrÃ©er une classe Post avec : - attributs : auteur (str), texte (str) ; - mÃ©thode longueur() qui retourne la longueur du texte.\n# Ã€ toi de jouer\nclass Post:\n    def __init__(self, auteur: str, texte: str) -&gt; None:\n        # TODO: stocker les attributs\n        pass\n\n    def longueur(self) -&gt; int:\n        # TODO: retourner la longueur du texte\n        return 0\n\np = Post(\"alice\", \"Bonjour tout le monde\")\nprint(p.longueur())  # attendu: longueur de la phrase\n\n\nAfficher une solution possible\n\nclass Post:\n    def __init__(self, auteur: str, texte: str) -&gt; None:\n        self.auteur = auteur\n        self.texte = texte\n\n    def longueur(self) -&gt; int:\n        return len(self.texte)\n\np = Post(\"alice\", \"Bonjour tout le monde\")\nprint(p.longueur())",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#quiz-final",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#quiz-final",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.38 12. Quiz final ğŸ¯",
    "text": "1.38 12. Quiz final ğŸ¯\nTeste tes connaissances ! RÃ©ponds mentalement puis vÃ©rifie les rÃ©ponses.\n\n\n1.38.1 â“ Q1. Quel type correspond Ã  une chaÃ®ne de caractÃ¨res ?\n\nstr\n\ntext\n\nchar\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : a â€” str est le type pour les chaÃ®nes de caractÃ¨res.\n\n\n\n\n1.38.2 â“ Q2. Quelle structure est la plus adaptÃ©e pour reprÃ©senter un objet JSON ?\n\nlist\n\ndict\n\ntuple\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” dict avec des paires clÃ©/valeur, comme JSON.\n\n\n\n\n1.38.3 â“ Q3. Laquelle de ces boucles risque le plus de devenir infinie ?\n\nfor\n\nwhile\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” while continue tant que la condition est vraie.\n\n\n\n\n1.38.4 â“ Q4. Quel mot-clÃ© permet de gÃ©rer une erreur ?\n\nerror\n\nexcept\n\ncatch\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” try/except pour gÃ©rer les exceptions.\n\n\n\n\n1.38.5 â“ Q5. Quel module est utilisÃ© pour le logging ?\n\nlogs\n\nlogging\n\nlogger\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” import logging\n\n\n\n\n1.38.6 â“ Q6. Comment crÃ©er un environnement virtuel avec venv ?\n\npython -m venv mon_env\n\npip create venv mon_env\n\npython --venv mon_env\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : a â€” python -m venv nom_environnement\n\n\n\n\n1.38.7 â“ Q7. Quel fichier liste les dÃ©pendances dâ€™un projet Python ?\n\npackages.txt\n\nrequirements.txt\n\ndependencies.json\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” requirements.txt avec pip freeze",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.39 ğŸ“š Ressources pour aller plus loin",
    "text": "1.39 ğŸ“š Ressources pour aller plus loin\n\n1.39.1 ğŸ“– Documentation officielle\n\nPython.org Documentation â€” RÃ©fÃ©rence complÃ¨te\nPython Tutorial â€” Tutoriel officiel\n\n\n\n1.39.2 ğŸ“ Cours et tutoriels\n\nReal Python â€” Tutoriels de qualitÃ©\nPython for Data Engineering (DataCamp) â€” Cours interactifs\nAutomate the Boring Stuff â€” Livre gratuit\n\n\n\n1.39.3 ğŸ› ï¸ Outils recommandÃ©s\n\nPyPI â€” Repository de packages Python\nRuff â€” Linter ultra-rapide\nBlack â€” Formateur de code\nmypy â€” VÃ©rification des types\n\n\n\n1.39.4 ğŸ“Š Packages Data Engineering essentiels\n\n\n\nPackage\nUsage\n\n\n\n\npandas\nManipulation de donnÃ©es tabulaires\n\n\nnumpy\nCalcul numÃ©rique\n\n\nrequests\nAppels API HTTP\n\n\nsqlalchemy\nORM et connexions bases de donnÃ©es\n\n\npydantic\nValidation de donnÃ©es\n\n\npytest\nTests unitaires\n\n\nclick\nCLI (Command Line Interface)",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/04_python_basics_for_data_engineers.html#prochaine-Ã©tape",
    "href": "notebooks/beginner/04_python_basics_for_data_engineers.html#prochaine-Ã©tape",
    "title": "ğŸ“˜ Python â€“ Bases pour Data Engineers",
    "section": "1.40 â¡ï¸ Prochaine Ã©tape",
    "text": "1.40 â¡ï¸ Prochaine Ã©tape\nMaintenant que tu maÃ®trises les bases de Python, passons au traitement de donnÃ©es !\nğŸ‘‰ Module suivant : 05_python_data_processing_for_data_engineers.ipynb â€” Pandas, Matplotlib, Seaborn et ETL\n\nğŸ‰ FÃ©licitations ! Tu as terminÃ© le module Python Basics pour Data Engineers.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ“˜ Python â€“ Bases pour Data Engineers"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html",
    "href": "notebooks/beginner/01_intro_data_engineering.html",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "",
    "text": "Bienvenue dans cette premiÃ¨re leÃ§on du parcours Data Engineering â€” From Zero to Hero.\nDans ce notebook, nous allons dÃ©couvrir : - Ce quâ€™est le Data Engineering - Les diffÃ©rences entre Data Engineer, Data Scientist et Data Analyst - Lâ€™architecture dâ€™un systÃ¨me de donnÃ©es moderne - ETL vs ELT â€” Quelle est la diffÃ©rence ? - Les types de pipelines (batch vs streaming) - Fondations des pipelines de donnÃ©es - Panorama des outils du Data Engineer - Soft Skills & Mindset du Data Engineer - Quiz de fin de module",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#prÃ©requis",
    "href": "notebooks/beginner/01_intro_data_engineering.html#prÃ©requis",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "1 ğŸ“‹ PrÃ©requis",
    "text": "1 ğŸ“‹ PrÃ©requis\nAvant de commencer ce parcours, il est recommandÃ© dâ€™avoir :\n\n\n\n\n\n\n\nNiveau\nCompÃ©tence\n\n\n\n\nâœ… Basique\nSavoir utiliser un ordinateur et naviguer dans des fichiers\n\n\nâœ… Basique\nConnaÃ®tre les concepts de base dâ€™internet (API, serveurs, clients)\n\n\nğŸŸ¡ Optionnel\nAvoir dÃ©jÃ  Ã©crit quelques lignes de code (Python, JavaScript, etc.)\n\n\nğŸŸ¡ Optionnel\nConnaÃ®tre les bases de SQL (SELECT, WHERE, JOIN)\n\n\n\n\nğŸ’¡ Pas de panique ! Ce parcours est conÃ§u pour les dÃ©butants. Nous couvrirons tout ce dont tu as besoin.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#cest-quoi-le-data-engineering",
    "href": "notebooks/beginner/01_intro_data_engineering.html#cest-quoi-le-data-engineering",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "2 ğŸ“Œ 1. Câ€™est quoi le Data Engineering ?",
    "text": "2 ğŸ“Œ 1. Câ€™est quoi le Data Engineering ?\nLe Data Engineering (ou ingÃ©nierie des donnÃ©es) est une discipline qui consiste Ã  concevoir, construire, maintenir et optimiser les systÃ¨mes de traitement de donnÃ©es.\nLe Data Engineer, spÃ©cialiste en gestion des donnÃ©es, conÃ§oit et maintient lâ€™infrastructure data (bases de donnÃ©es, entrepÃ´ts de donnÃ©es, lacs de donnÃ©es) et dÃ©veloppe des pipelines automatisÃ©s qui extraient, transforment et chargent les donnÃ©es dans des systÃ¨mes adaptÃ©s.\nCâ€™est le socle technique qui garantit la qualitÃ©, la disponibilitÃ© et la sÃ©curitÃ© des donnÃ©es utilisÃ©es par les Data Analysts et Data Scientists pour gÃ©nÃ©rer des insights et orienter les stratÃ©gies dâ€™entreprise.\n\n2.1 ğŸ¢ Exemples concrets en entreprise\n\n\n\n\n\n\n\nEntreprise\nCas dâ€™usage Data Engineering\n\n\n\n\nNetflix\nPipeline qui collecte les donnÃ©es de visionnage de millions dâ€™utilisateurs pour alimenter le systÃ¨me de recommandation\n\n\nUber\nTraitement en temps rÃ©el des donnÃ©es GPS de milliers de chauffeurs pour optimiser les trajets et les prix\n\n\nSpotify\nAgrÃ©gation des donnÃ©es dâ€™Ã©coute pour gÃ©nÃ©rer les playlists â€œDiscover Weeklyâ€ personnalisÃ©es\n\n\nAirbnb\nPipeline de donnÃ©es pour analyser les prix du marchÃ© et suggÃ©rer des tarifs aux hÃ´tes\n\n\nE-commerce\nSynchronisation des stocks entre le site web, lâ€™ERP et les entrepÃ´ts en temps rÃ©el",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#diffÃ©rences-entre-mÃ©tiers",
    "href": "notebooks/beginner/01_intro_data_engineering.html#diffÃ©rences-entre-mÃ©tiers",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "3 ğŸ‘¨ğŸ½â€ğŸ’» 2. DiffÃ©rences entre mÃ©tiers",
    "text": "3 ğŸ‘¨ğŸ½â€ğŸ’» 2. DiffÃ©rences entre mÃ©tiers\n\n\n\n\n\n\n\n\n\nMÃ©tier\nRÃ´le Principal\nFocus\nOutils ClÃ©s\n\n\n\n\nğŸ”§ Data Engineer\nConstruire et maintenir lâ€™infrastructure de donnÃ©es\nInfrastructure & Pipelines\nApache Airflow, Apache Spark, Kafka, Snowflake, dbt, Python, SQL, Prefect, Docker, Kubernetes\n\n\nğŸ”¬ Data Scientist\nExtraire des insights et crÃ©er des modÃ¨les prÃ©dictifs\nModÃ©lisation & ML\nPython, R, scikit-learn, TensorFlow, PyTorch, Jupyter, MLflow, Pandas, XGBoost\n\n\nğŸ“ˆ Data Analyst\nTransformer les donnÃ©es en insights actionnables\nBusiness Intelligence\nSQL, Excel, Power BI, Tableau, Looker, Google Analytics, Python (basique)\n\n\n\n\n3.1 ğŸ”„ Comment ces rÃ´les collaborent ?\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Data Engineer  â”‚ â”€â”€â–¶ â”‚  Data Scientist â”‚ â”€â”€â–¶ â”‚  Data Analyst   â”‚\nâ”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚\nâ”‚ â€¢ Collecte      â”‚     â”‚ â€¢ ModÃ©lisation  â”‚     â”‚ â€¢ Visualisation â”‚\nâ”‚ â€¢ Pipelines     â”‚     â”‚ â€¢ PrÃ©dictions   â”‚     â”‚ â€¢ Reporting     â”‚\nâ”‚ â€¢ Infrastructureâ”‚     â”‚ â€¢ ML/AI         â”‚     â”‚ â€¢ Insights      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n        â”‚                                               â”‚\n        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Feedback & Besoins â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#architecture-typique-dun-pipeline-de-donnÃ©es-moderne",
    "href": "notebooks/beginner/01_intro_data_engineering.html#architecture-typique-dun-pipeline-de-donnÃ©es-moderne",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "4 ğŸ—ï¸ 3. Architecture typique dâ€™un pipeline de donnÃ©es moderne",
    "text": "4 ğŸ—ï¸ 3. Architecture typique dâ€™un pipeline de donnÃ©es moderne\nUn pipeline de donnÃ©es moderne suit gÃ©nÃ©ralement ce flux :\nflowchart LR\n    subgraph Sources[\"ğŸ“¥ Sources\"]\n        A1[API REST]\n        A2[Bases de donnÃ©es]\n        A3[Fichiers CSV/JSON]\n        A4[Ã‰vÃ©nements/Logs]\n    end\n    \n    subgraph Ingestion[\"ğŸ”„ Ingestion\"]\n        B1[ETL / ELT]\n        B2[Streaming]\n    end\n    \n    subgraph Storage[\"ğŸ’¾ Stockage\"]\n        C1[Data Lake]\n        C2[Data Warehouse]\n    end\n    \n    subgraph Transform[\"âš™ï¸ Transformation\"]\n        D1[Nettoyage]\n        D2[AgrÃ©gation]\n        D3[Enrichissement]\n    end\n    \n    subgraph Exposition[\"ğŸ“Š Exposition\"]\n        E1[Dashboards BI]\n        E2[ModÃ¨les ML]\n        E3[APIs]\n    end\n    \n    Sources --&gt; Ingestion --&gt; Storage --&gt; Transform --&gt; Exposition\nReprÃ©sentation simplifiÃ©e :\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ğŸ“¥ SOURCES      â”‚  API, CSV, Bases de donnÃ©es, Logs, IoT\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ğŸ”„ INGESTION    â”‚  ETL / ELT (Airbyte, Fivetran, Scripts)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ğŸ’¾ STOCKAGE     â”‚  Data Lake (S3) / Data Warehouse (Snowflake, BigQuery)\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  âš™ï¸ TRANSFORMATIONâ”‚  dbt, Spark, SQL, Pandas\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n         â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ğŸ“Š EXPOSITION   â”‚  Dashboards (Tableau, Power BI), ML, APIs\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n4.1 ğŸ” ETL vs ELT â€” Quelle est la diffÃ©rence ?\n\n\n\n\n\n\n\n\nCritÃ¨re\nETL (Extract â†’ Transform â†’ Load)\nELT (Extract â†’ Load â†’ Transform)\n\n\n\n\nğŸ”„ Ordre\nExtraction â†’ Transformation â†’ Chargement\nExtraction â†’ Chargement â†’ Transformation\n\n\nğŸ“ Lieu de la transformation\nEn dehors du stockage (dans un script ou un outil)\nDirectement dans le data warehouse\n\n\nâœ… Avantages\nPlus de contrÃ´le sur la transformation\nPlus rapide sur des gros volumes\n\n\nâš ï¸ InconvÃ©nients\nPeut surcharger les outils intermÃ©diaires\nBesoin dâ€™un entrepÃ´t puissant (coÃ»ts)\n\n\nğŸ› ï¸ Outils typiques\nInformatica, Talend, scripts Python\ndbt, Snowflake, BigQuery\n\n\nğŸ“… Cas dâ€™usage\nDonnÃ©es sensibles nÃ©cessitant un prÃ©-traitement\nAnalytics modernes sur le cloud",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#pipelines-batch-vs-streaming",
    "href": "notebooks/beginner/01_intro_data_engineering.html#pipelines-batch-vs-streaming",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "5 ğŸ•˜ 4. Pipelines batch vs streaming",
    "text": "5 ğŸ•˜ 4. Pipelines batch vs streaming\n\n\n\n\n\n\n\n\n\nMode\nDÃ©finition\nLatence\nExemples\n\n\n\n\nBatch\nTraitement pÃ©riodique (toutes les heures, tous les joursâ€¦)\nMinutes Ã  heures\nRapport quotidien, import CSV, agrÃ©gations nocturnes\n\n\nStreaming\nTraitement en temps rÃ©el, Ã©vÃ©nement par Ã©vÃ©nement\nMillisecondes Ã  secondes\nLogs serveurs, capteurs IoT, transactions bancaires, dÃ©tection de fraude\n\n\n\n\n5.1 ğŸ¤” Comment choisir ?\n\n\n\n\n\n\n\nQuestion\nSi oui â†’\n\n\n\n\nLes donnÃ©es doivent-elles Ãªtre traitÃ©es immÃ©diatement ?\nStreaming\n\n\nLe volume est-il trÃ¨s Ã©levÃ© mais la latence peu critique ?\nBatch\n\n\nAvez-vous besoin de dÃ©tecter des anomalies en temps rÃ©el ?\nStreaming\n\n\nSâ€™agit-il de rapports quotidiens/hebdomadaires ?\nBatch\n\n\n\n\n\n5.2 ğŸ§± Fondations des pipelines de donnÃ©es\nTout pipeline de donnÃ©es repose sur plusieurs piliers fondamentaux :\n\n\n\n\n\n\n\n\nğŸ”¢ Pilier\nğŸ’¡ Description\nğŸ“š Module associÃ©\n\n\n\n\n1. Data Collecting\nComment collecter les donnÃ©es brutes (fichiers, API, capteursâ€¦)\nPython, APIs\n\n\n2. Data Ingestion\nComment les intÃ©grer dans un systÃ¨me (DB, data lakeâ€¦)\nETL, Airbyte\n\n\n3. Data Storage\nComment et oÃ¹ les stocker (SQL, NoSQL, S3â€¦)\nDatabases, Cloud\n\n\n4. Data Processing\nComment les transformer, nettoyer, agrÃ©ger\nPython, Spark, dbt\n\n\n5. Data Modeling\nComment organiser les donnÃ©es pour lâ€™analyse\nSQL, dbt\n\n\n6. Data Quality & Governance\nComment garantir la fiabilitÃ© et la traÃ§abilitÃ©\nGreat Expectations\n\n\n7. Data Orchestration\nComment automatiser les tÃ¢ches et gÃ©rer les dÃ©pendances\nAirflow, Prefect\n\n\n8. ScalabilitÃ© & Performance\nComment faire face Ã  de gros volumes ou Ã  la charge\nSpark, Kubernetes\n\n\n9. SÃ©curitÃ© des donnÃ©es\nChiffrement, contrÃ´le dâ€™accÃ¨s, audit\nIAM, Vault\n\n\n10. DevOps pour la Data\nConteneurisation, CI/CD, monitoring\nDocker, GitHub Actions\n\n\n\n\nğŸ“˜ Ces concepts seront abordÃ©s progressivement dans le parcours.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#panorama-des-outils-du-data-engineer",
    "href": "notebooks/beginner/01_intro_data_engineering.html#panorama-des-outils-du-data-engineer",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "6 ğŸ§° 5. Panorama des outils du Data Engineer",
    "text": "6 ğŸ§° 5. Panorama des outils du Data Engineer\n\n\n\n\n\n\n\n\nDomaine\nOutils populaires\nNiveau\n\n\n\n\nğŸ“¥ Collecte\nPython, API REST, Scrapy, Kafka\nDÃ©butant â†’ IntermÃ©diaire\n\n\nğŸ”„ Ingestion\nAirbyte, Fivetran, Python scripts\nDÃ©butant\n\n\nğŸ’¾ Stockage\nPostgreSQL, Snowflake, S3, Delta Lake\nDÃ©butant â†’ AvancÃ©\n\n\nâš™ï¸ Traitement (Batch)\nPandas, Spark, dbt, SQL\nDÃ©butant â†’ AvancÃ©\n\n\nâš¡ Traitement (Streaming)\nKafka, Spark Streaming, Flink\nIntermÃ©diaire â†’ AvancÃ©\n\n\nğŸ¼ Orchestration\nApache Airflow, Prefect, Dagster\nIntermÃ©diaire\n\n\nğŸ³ DevOps & CI/CD\nDocker, GitHub Actions, Terraform\nIntermÃ©diaire\n\n\nğŸ“Š Monitoring\nGrafana, Prometheus, ELK Stack\nIntermÃ©diaire\n\n\n\n\n6.1 ğŸ—ºï¸ Stack moderne typique (2024)\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                    STACK DATA MODERNE                       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Orchestration    â”‚  Airflow / Prefect / Dagster            â”‚\nâ”‚  Transformation   â”‚  dbt / Spark / Python                   â”‚\nâ”‚  Warehouse        â”‚  Snowflake / BigQuery / Redshift        â”‚\nâ”‚  Ingestion        â”‚  Airbyte / Fivetran / Stitch            â”‚\nâ”‚  Sources          â”‚  APIs / Databases / SaaS / Files        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#soft-skills-mindset-du-data-engineer",
    "href": "notebooks/beginner/01_intro_data_engineering.html#soft-skills-mindset-du-data-engineer",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "7 ğŸ§  6. Soft Skills & Mindset du Data Engineer",
    "text": "7 ğŸ§  6. Soft Skills & Mindset du Data Engineer\nLe mÃ©tier de Data Engineer nâ€™est pas uniquement technique. Pour rÃ©ussir dans ce domaine, il faut aussi dÃ©velopper des compÃ©tences humaines et professionnelles essentielles :\n\n\n\n\n\n\n\n\nCompÃ©tence\nDescription\nPourquoi câ€™est important\n\n\n\n\nğŸ“ Documenter\nÃ‰crire une documentation claire pour son code et ses pipelines\nFacilite la maintenance et lâ€™onboarding des nouveaux membres\n\n\nğŸ¤ Collaborer\nTravailler avec les Ã©quipes Data Science, BI, Produit, DevOps\nLes donnÃ©es traversent toute lâ€™organisation\n\n\nğŸ¯ ÃŠtre rigoureux\nGarantir la qualitÃ©, la fiabilitÃ© et la traÃ§abilitÃ© des donnÃ©es\nUne erreur de donnÃ©es peut avoir des consÃ©quences business majeures\n\n\nğŸ•µğŸ½â€â™‚ï¸ Investiguer\nSavoir dÃ©bugger des anomalies, logs ou Ã©checs de pipeline\nLes pipelines cassent, il faut savoir pourquoi rapidement\n\n\nğŸ“š Apprendre en continu\nSe tenir Ã  jour sur les nouveaux outils et pratiques\nLe domaine Ã©volue trÃ¨s rapidement\n\n\nğŸ’¬ Communiquer\nExpliquer des concepts techniques Ã  des non-techniques\nAlignement avec les Ã©quipes mÃ©tier",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#quiz-de-fin-de-module",
    "href": "notebooks/beginner/01_intro_data_engineering.html#quiz-de-fin-de-module",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "8 ğŸ§ª Quiz de fin de module",
    "text": "8 ğŸ§ª Quiz de fin de module\nRÃ©ponds aux questions suivantes pour valider tes acquis ğŸ‘‡ğŸ½\n\n\n8.1 â“ Q1. Quel est le rÃ´le principal dâ€™un Data Engineer ?\n\nCrÃ©er des modÃ¨les prÃ©dictifs\n\nVisualiser les donnÃ©es dans Power BI\n\nConcevoir et maintenir des pipelines de donnÃ©es\n\nFaire des analyses statistiques dans Excel\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” Le Data Engineer conÃ§oit et maintient des pipelines de donnÃ©es.\n\n\n\n\n8.2 â“ Q2. Dans un pipeline ETL, que signifie le â€œTâ€ ?\n\nTransfer\n\nTrigger\n\nTransform\n\nTransport\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” â€œTâ€ signifie Transform, câ€™est lâ€™Ã©tape de transformation des donnÃ©es.\n\n\n\n\n8.3 â“ Q3. Quelle est la principale diffÃ©rence entre ETL et ELT ?\n\nELT ne fait pas de transformation\n\nELT transforme les donnÃ©es aprÃ¨s les avoir chargÃ©es\n\nETL est utilisÃ© uniquement pour les fichiers CSV\n\nELT est un outil comme Apache Airflow\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” ELT charge dâ€™abord les donnÃ©es, puis les transforme dans le data warehouse.\n\n\n\n\n8.4 â“ Q4. Lequel de ces outils est utilisÃ© pour orchestrer des pipelines ?\n\nApache Kafka\n\nApache Airflow\n\nTableau\n\nPostgreSQL\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” Apache Airflow est un outil dâ€™orchestration de pipelines.\n\n\n\n\n8.5 â“ Q5. Le traitement batch consiste Ã  :\n\nTraiter les donnÃ©es en continu\n\nTraiter les donnÃ©es en petits lots Ã  la volÃ©e\n\nTraiter les donnÃ©es par groupe, Ã  intervalle rÃ©gulier\n\nTraiter uniquement les donnÃ©es texte\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” Le batch consiste Ã  traiter les donnÃ©es par lots Ã  intervalles dÃ©finis.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#bonus-quiz-nouveaux-paradigmes-etlt-reverse-etl",
    "href": "notebooks/beginner/01_intro_data_engineering.html#bonus-quiz-nouveaux-paradigmes-etlt-reverse-etl",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "9 ğŸ§  Bonus Quiz â€” Nouveaux paradigmes : ETLt & Reverse ETL",
    "text": "9 ğŸ§  Bonus Quiz â€” Nouveaux paradigmes : ETLt & Reverse ETL\n\n\n9.1 â“ Q6. Que signifie ETLt ?\n\nUne erreur dans la chaÃ®ne ETL\n\nUne combinaison hybride entre ETL et ELT\n\nUne technique de transfert via email\n\nUne transformation uniquement aprÃ¨s chargement\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” ETLt correspond Ã  : Extract â†’ Transform (1) â†’ Load â†’ Transform (2).\nCâ€™est une approche hybride oÃ¹ une partie des transformations est faite avant le chargement, et une autre aprÃ¨s.\n\n\n\n\n9.2 â“ Q7. Le Reverse ETL est utilisÃ© pour :\n\nRecharger les donnÃ©es sources depuis le warehouse\n\nSupprimer les donnÃ©es invalides dans un lac de donnÃ©es\n\nPousser les donnÃ©es du data warehouse vers les outils mÃ©tiers\n\nTransformer les donnÃ©es en reverse-engineering\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” Reverse ETL consiste Ã  extraire les donnÃ©es dâ€™un data warehouse (ex. BigQuery) pour les charger dans des outils mÃ©tiers comme Salesforce, Notion, Slack, etc.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#ressources-pour-aller-plus-loin",
    "href": "notebooks/beginner/01_intro_data_engineering.html#ressources-pour-aller-plus-loin",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "10 ğŸ“š Ressources pour aller plus loin",
    "text": "10 ğŸ“š Ressources pour aller plus loin\n\n10.1 ğŸ“– Lectures recommandÃ©es\n\nFundamentals of Data Engineering â€” Joe Reis & Matt Housley\nThe Data Warehouse Toolkit â€” Ralph Kimball\nDesigning Data-Intensive Applications â€” Martin Kleppmann\n\n\n\n10.2 ğŸŒ Sites & Blogs\n\nData Engineering Weekly â€” Newsletter hebdomadaire\nSeattle Data Guy â€” ChaÃ®ne YouTube\nStart Data Engineering â€” Tutoriels pratiques\n\n\n\n10.3 ğŸ“ Certifications\n\nGoogle Cloud Professional Data Engineer\nAWS Certified Data Engineer\nDatabricks Certified Data Engineer\n\n\n\n10.4 ğŸ› ï¸ Outils Ã  explorer\n\ndbt â€” Transformation de donnÃ©es\nAirbyte â€” Ingestion de donnÃ©es (open source)\nApache Airflow â€” Orchestration",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/01_intro_data_engineering.html#prochaine-Ã©tape",
    "href": "notebooks/beginner/01_intro_data_engineering.html#prochaine-Ã©tape",
    "title": "ğŸ§  Introduction au Data Engineering",
    "section": "11 â¡ï¸ Prochaine Ã©tape",
    "text": "11 â¡ï¸ Prochaine Ã©tape\nMaintenant que tu as une vue dâ€™ensemble du Data Engineering, passons Ã  la pratique !\nğŸ‘‰ Module suivant : 02_bash_for_data_engineers.ipynb â€” MaÃ®triser la ligne de commande\n\nğŸ‰ FÃ©licitations ! Tu as terminÃ© le premier module du parcours Data Engineering.",
    "crumbs": [
      "DÃ©butant",
      "ğŸ§  Introduction au Data Engineering"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bootcamp Data Engineering â€“ From Zero to Hero",
    "section": "",
    "text": "Deviens un Data Engineer opÃ©rationnel, Ã©tape par Ã©tape.",
    "crumbs": [
      "Bootcamp Data Engineering â€“ From Zero to Hero"
    ]
  },
  {
    "objectID": "index.html#niveau-dÃ©butant",
    "href": "index.html#niveau-dÃ©butant",
    "title": "1 Bootcamp Data Engineering",
    "section": "",
    "text": "Apprenez les fondations du Data Engineering : - Python - Bash - Git - SQL - Bases de donnÃ©es - PySpark - Orchestration (Airflow) - NoSQL (MongoDB, Elasticsearch)",
    "crumbs": [
      "Bootcamp Data Engineering"
    ]
  },
  {
    "objectID": "index.html#niveau-intermÃ©diaire",
    "href": "index.html#niveau-intermÃ©diaire",
    "title": "1 Bootcamp Data Engineering",
    "section": "",
    "text": "Approfondissez vos compÃ©tences : - Data Lakes & Lakehouse - Docker & Kubernetes - Kafka Streaming - Spark avancÃ© + Scala - Hadoop ecosystem - Polars, DuckDB & Arrow - Data Governance & Lineage - Data Contracts & API - Performance & FinOps - Modern Data Stack (DBT, Airbyte)",
    "crumbs": [
      "Bootcamp Data Engineering"
    ]
  },
  {
    "objectID": "index.html#niveau-avancÃ©",
    "href": "index.html#niveau-avancÃ©",
    "title": "1 Bootcamp Data Engineering",
    "section": "",
    "text": "Niveau expert / architecte : - SystÃ¨mes distribuÃ©s - Flink & streaming avancÃ© - Lakehouse internals (Delta/Iceberg/Hudi) - Feature Store temps rÃ©el & Serving ML - MLOps (MLflow, Kubeflow) - SRE appliquÃ© Ã  la Data - SÃ©curitÃ© avancÃ©e - Plateforme Data dâ€™entreprise - Projet final architecture complÃ¨te",
    "crumbs": [
      "Bootcamp Data Engineering"
    ]
  },
  {
    "objectID": "index.html#objectif-du-bootcamp",
    "href": "index.html#objectif-du-bootcamp",
    "title": "1 Bootcamp Data Engineering",
    "section": "",
    "text": "Ã€ la fin de ce programme, vous serez capable de : - Construire des pipelines batch & streaming - GÃ©rer une architecture Data Lakehouse moderne - DÃ©ployer des pipelines cloud robustes - ImplÃ©menter du MLOps Ã  lâ€™Ã©chelle - Concevoir une plateforme Data complÃ¨te - Travailler en tant que Data Engineer intermÃ©diaire, senior ou architecte\n\nğŸ‘‰ Utilisez la barre de navigation pour commencer votre parcours.\nBonne formation ğŸš€",
    "crumbs": [
      "Bootcamp Data Engineering"
    ]
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "",
    "text": "Ce module couvre le traitement de donnÃ©es avancÃ© avec Python : Pandas, visualisation, APIs, et pipelines ETL."
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#prÃ©requis",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#prÃ©requis",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "0.1 ğŸ“‹ PrÃ©requis",
    "text": "0.1 ğŸ“‹ PrÃ©requis\n\n\n\n\n\n\n\nNiveau\nCompÃ©tence\n\n\n\n\nâœ… Requis\nAvoir suivi le module 04_python_basics_for_data_engineers\n\n\nâœ… Requis\nMaÃ®triser les bases de Python (variables, fonctions, boucles)\n\n\nâœ… Requis\nSavoir utiliser pip et les environnements virtuels"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#objectifs-du-module",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#objectifs-du-module",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "0.2 ğŸ¯ Objectifs du module",
    "text": "0.2 ğŸ¯ Objectifs du module\nÃ€ la fin de ce notebook, tu seras capable de : - âœ… Manipuler des donnÃ©es avec Pandas (DataFrames, nettoyage, agrÃ©gations) - âœ… Visualiser des donnÃ©es avec Matplotlib - âœ… CrÃ©er des graphiques statistiques avec Seaborn - âœ… Traiter du texte et utiliser les regex - âœ… Consommer des APIs REST - âœ… Valider la qualitÃ© des donnÃ©es - âœ… Construire un pipeline ETL complet - âœ… GÃ©rer les configurations et secrets"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#installation-des-dÃ©pendances",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#installation-des-dÃ©pendances",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "0.3 ğŸ“¦ Installation des dÃ©pendances",
    "text": "0.3 ğŸ“¦ Installation des dÃ©pendances\nAvant de commencer, assurons-nous dâ€™avoir toutes les librairies nÃ©cessaires.\n\n\nCode\n# Installation des packages (Ã  exÃ©cuter une seule fois)\n!pip install pandas numpy requests python-dotenv pytest pandera pyarrow openpyxl matplotlib seaborn\n\n\n\n\nCode\n# Imports de base\nimport pandas as pd\nimport numpy as np\nimport json\nimport requests\nfrom datetime import datetime\nimport time\nimport logging\nimport re\nfrom pathlib import Path\n\n# Configuration de l'affichage\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', 100)\npd.set_option('display.width', None)\n\nprint(\"âœ… Imports rÃ©ussis !\")\nprint(f\"Version Pandas : {pd.__version__}\")\nprint(f\"Version NumPy : {np.__version__}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#crÃ©er-et-lire-des-donnÃ©es",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#crÃ©er-et-lire-des-donnÃ©es",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.1 1.1 CrÃ©er et lire des donnÃ©es",
    "text": "1.1 1.1 CrÃ©er et lire des donnÃ©es\n\n\nCode\n# CrÃ©er un DataFrame simple\ndata = {\n    'nom': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n    'age': [25, 30, 35, None, 28],\n    'ville': ['Paris', 'Lyon', 'Paris', 'Marseille', 'Lyon'],\n    'salaire': [45000, 55000, 60000, 50000, None]\n}\n\ndf = pd.DataFrame(data)\nprint(\"ğŸ“Š DataFrame crÃ©Ã© :\")\nprint(df)\n\n\n\n\nCode\n# Sauvegarder en CSV\ndf.to_csv('exemple_employes.csv', index=False)\nprint(\"âœ… Fichier CSV sauvegardÃ©\")\n\n# Lire depuis CSV\ndf_from_csv = pd.read_csv('exemple_employes.csv')\nprint(\"\\nğŸ“‚ Lecture depuis CSV :\")\nprint(df_from_csv.head())"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exploration-des-donnÃ©es",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exploration-des-donnÃ©es",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.2 1.2 Exploration des donnÃ©es",
    "text": "1.2 1.2 Exploration des donnÃ©es\n\n\nCode\n# Informations gÃ©nÃ©rales\nprint(\"ğŸ“‹ Informations du DataFrame :\")\nprint(df.info())\nprint(\"\\n\" + \"=\"*50)\n\n# Statistiques descriptives\nprint(\"\\nğŸ“Š Statistiques descriptives :\")\nprint(df.describe())\n\n# PremiÃ¨res lignes\nprint(\"\\nğŸ” PremiÃ¨res lignes :\")\nprint(df.head(3))\n\n# DerniÃ¨res lignes\nprint(\"\\nğŸ”š DerniÃ¨res lignes :\")\nprint(df.tail(2))"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#nettoyage-des-donnÃ©es",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#nettoyage-des-donnÃ©es",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.3 1.3 Nettoyage des donnÃ©es",
    "text": "1.3 1.3 Nettoyage des donnÃ©es\n\n\nCode\n# DÃ©tecter les valeurs manquantes\nprint(\"â“ Valeurs manquantes par colonne :\")\nprint(df.isnull().sum())\nprint(f\"\\nTotal de valeurs manquantes : {df.isnull().sum().sum()}\")\n\n# Visualiser les lignes avec des valeurs manquantes\nprint(\"\\nğŸ” Lignes avec des NaN :\")\nprint(df[df.isnull().any(axis=1)])\n\n\n\n\nCode\n# StratÃ©gies de gestion des valeurs manquantes\n\n# 1. Supprimer les lignes avec des NaN\ndf_drop = df.dropna()\nprint(\"ğŸ—‘ï¸ AprÃ¨s suppression des lignes avec NaN :\")\nprint(df_drop)\n\n# 2. Remplir avec une valeur par dÃ©faut\ndf_fill = df.fillna({\n    'age': df['age'].median(),\n    'salaire': df['salaire'].mean()\n})\nprint(\"\\nâœ¨ AprÃ¨s remplissage des NaN :\")\nprint(df_fill)\n\n# 3. Forward fill (propager la valeur prÃ©cÃ©dente)\ndf_ffill = df.fillna(method='ffill')\nprint(\"\\nâ¡ï¸ AprÃ¨s forward fill :\")\nprint(df_ffill)\n\n\n\n\nCode\n# Supprimer les doublons\ndf_with_duplicates = pd.DataFrame({\n    'id': [1, 2, 3, 2, 4],\n    'nom': ['Alice', 'Bob', 'Charlie', 'Bob', 'David']\n})\n\nprint(\"Avant suppression des doublons :\")\nprint(df_with_duplicates)\n\ndf_no_duplicates = df_with_duplicates.drop_duplicates()\nprint(\"\\nAprÃ¨s suppression :\")\nprint(df_no_duplicates)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#sÃ©lection-et-filtrage",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#sÃ©lection-et-filtrage",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.4 1.4 SÃ©lection et filtrage",
    "text": "1.4 1.4 SÃ©lection et filtrage\n\n\nCode\n# Utilisons le DataFrame nettoyÃ©\ndf_clean = df_fill.copy()\n\n# SÃ©lectionner une colonne\nprint(\"ğŸ“Œ Colonne 'nom' :\")\nprint(df_clean['nom'])\n\n# SÃ©lectionner plusieurs colonnes\nprint(\"\\nğŸ“Œ Colonnes 'nom' et 'ville' :\")\nprint(df_clean[['nom', 'ville']])\n\n# Filtrer les lignes\nprint(\"\\nğŸ” EmployÃ©s de Paris :\")\nprint(df_clean[df_clean['ville'] == 'Paris'])\n\n# Filtres multiples\nprint(\"\\nğŸ” EmployÃ©s de Paris avec salaire &gt; 50000 :\")\nprint(df_clean[(df_clean['ville'] == 'Paris') & (df_clean['salaire'] &gt; 50000)])\n\n\n\n\nCode\n# Indexation avancÃ©e avec loc et iloc\n\n# loc : par label/nom\nprint(\"ğŸ“ loc[0, 'nom'] :\")\nprint(df_clean.loc[0, 'nom'])\n\n# iloc : par position numÃ©rique\nprint(\"\\nğŸ“ iloc[0, 0] (premiÃ¨re ligne, premiÃ¨re colonne) :\")\nprint(df_clean.iloc[0, 0])\n\n# SÃ©lection de plages\nprint(\"\\nğŸ“ loc[0:2, ['nom', 'age']] :\")\nprint(df_clean.loc[0:2, ['nom', 'age']])"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#groupby-et-agrÃ©gations",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#groupby-et-agrÃ©gations",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.5 1.5 GroupBy et agrÃ©gations",
    "text": "1.5 1.5 GroupBy et agrÃ©gations\n\n\nCode\n# Grouper par ville et calculer des statistiques\nprint(\"ğŸ“Š Statistiques par ville :\")\ngrouped = df_clean.groupby('ville').agg({\n    'nom': 'count',\n    'age': ['mean', 'min', 'max'],\n    'salaire': ['mean', 'sum']\n})\nprint(grouped)\n\n# Renommer les colonnes pour plus de clartÃ©\nprint(\"\\nğŸ“Š Salaire moyen par ville :\")\nsalaire_moyen = df_clean.groupby('ville')['salaire'].mean().round(2)\nprint(salaire_moyen)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#apply-vs-vectorisation",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#apply-vs-vectorisation",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.6 1.6 Apply vs Vectorisation",
    "text": "1.6 1.6 Apply vs Vectorisation\n\n\nCode\n# CrÃ©er une colonne calculÃ©e\n\n# MÃ©thode 1 : Apply (plus lent mais flexible)\ndef categoriser_age(age):\n    if age &lt; 30:\n        return 'Junior'\n    elif age &lt; 40:\n        return 'Senior'\n    else:\n        return 'Expert'\n\ndf_clean['categorie_apply'] = df_clean['age'].apply(categoriser_age)\n\n# MÃ©thode 2 : Vectorisation (plus rapide)\ndf_clean['categorie_vect'] = pd.cut(\n    df_clean['age'],\n    bins=[0, 30, 40, 100],\n    labels=['Junior', 'Senior', 'Expert']\n)\n\nprint(\"ğŸ”§ Colonnes calculÃ©es :\")\nprint(df_clean[['nom', 'age', 'categorie_apply', 'categorie_vect']])\n\n\n\n\nCode\n# Comparaison de performance (sur un grand dataset)\nimport time\n\n# CrÃ©er un grand DataFrame\nbig_df = pd.DataFrame({\n    'valeur': np.random.randint(1, 100, 100000)\n})\n\n# MÃ©thode Apply\nstart = time.time()\nbig_df['double_apply'] = big_df['valeur'].apply(lambda x: x * 2)\ntime_apply = time.time() - start\n\n# MÃ©thode VectorisÃ©e\nstart = time.time()\nbig_df['double_vect'] = big_df['valeur'] * 2\ntime_vect = time.time() - start\n\nprint(f\"â±ï¸ Temps Apply : {time_apply:.4f}s\")\nprint(f\"â±ï¸ Temps Vectorisation : {time_vect:.4f}s\")\nprint(f\"ğŸš€ Vectorisation est {time_apply/time_vect:.1f}x plus rapide !\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-de-la-mÃ©moire",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-de-la-mÃ©moire",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.7 1.7 Gestion de la mÃ©moire",
    "text": "1.7 1.7 Gestion de la mÃ©moire\n\n\nCode\n# VÃ©rifier l'utilisation mÃ©moire\nprint(\"ğŸ’¾ Utilisation mÃ©moire par colonne :\")\nprint(df_clean.memory_usage(deep=True))\nprint(f\"\\nTotal : {df_clean.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n\n\n\n\nCode\n# Optimiser les types de donnÃ©es\ndf_optimized = df_clean.copy()\n\n# Avant optimisation\nprint(\"Avant optimisation :\")\nprint(df_optimized.dtypes)\nprint(f\"MÃ©moire : {df_optimized.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n\n# Convertir en types plus efficaces\ndf_optimized['age'] = df_optimized['age'].astype('int8')\ndf_optimized['salaire'] = df_optimized['salaire'].astype('int32')\ndf_optimized['ville'] = df_optimized['ville'].astype('category')\n\nprint(\"\\nAprÃ¨s optimisation :\")\nprint(df_optimized.dtypes)\nprint(f\"MÃ©moire : {df_optimized.memory_usage(deep=True).sum() / 1024:.2f} KB\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#manipulation-de-dates",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#manipulation-de-dates",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.8 1.8 Manipulation de dates",
    "text": "1.8 1.8 Manipulation de dates\n\n\nCode\n# CrÃ©er un DataFrame avec des dates\ndf_dates = pd.DataFrame({\n    'date_str': ['2024-01-15', '2024-02-20', '2024-03-10', '2024-04-05'],\n    'montant': [1000, 1500, 1200, 1800]\n})\n\n# Convertir en datetime\ndf_dates['date'] = pd.to_datetime(df_dates['date_str'])\n\n# Extraire des composantes\ndf_dates['annee'] = df_dates['date'].dt.year\ndf_dates['mois'] = df_dates['date'].dt.month\ndf_dates['jour'] = df_dates['date'].dt.day\ndf_dates['nom_mois'] = df_dates['date'].dt.month_name()\ndf_dates['jour_semaine'] = df_dates['date'].dt.day_name()\n\nprint(\"ğŸ“… DataFrame avec dates extraites :\")\nprint(df_dates)\n\n\n\n\nCode\n# Calculs avec les dates\ndf_dates['jours_depuis_debut'] = (df_dates['date'] - df_dates['date'].min()).dt.days\n\n# Ajouter/soustraire des pÃ©riodes\ndf_dates['date_plus_30j'] = df_dates['date'] + pd.Timedelta(days=30)\ndf_dates['date_moins_1mois'] = df_dates['date'] - pd.DateOffset(months=1)\n\nprint(\"ğŸ“… Calculs de dates :\")\nprint(df_dates[['date', 'jours_depuis_debut', 'date_plus_30j', 'date_moins_1mois']])"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#export-de-donnÃ©es",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#export-de-donnÃ©es",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.9 1.9 Export de donnÃ©es",
    "text": "1.9 1.9 Export de donnÃ©es\n\n\nCode\n# Export CSV\ndf_clean.to_csv('employes_clean.csv', index=False)\nprint(\"âœ… Export CSV rÃ©ussi\")\n\n# Export JSON\ndf_clean.to_json('employes_clean.json', orient='records', indent=2)\nprint(\"âœ… Export JSON rÃ©ussi\")\n\n# Export Parquet (format columnar, trÃ¨s efficace)\ndf_clean.to_parquet('employes_clean.parquet', index=False)\nprint(\"âœ… Export Parquet rÃ©ussi\")\n\n# Export Excel\ndf_clean.to_excel('employes_clean.xlsx', index=False, sheet_name='EmployÃ©s')\nprint(\"âœ… Export Excel rÃ©ussi\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-1-pandas",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-1-pandas",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "1.10 ğŸ¯ Exercice Pratique 1 : Pandas",
    "text": "1.10 ğŸ¯ Exercice Pratique 1 : Pandas\nObjectif : Analyser un fichier de ventes\n\nCrÃ©er un DataFrame avec des donnÃ©es de ventes (produit, quantitÃ©, prix, date)\nCalculer le chiffre dâ€™affaires total\nTrouver le produit le plus vendu\nCalculer les ventes mensuelles\nExporter le rÃ©sultat en CSV\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# Votre code ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-linÃ©aires-line-plots",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-linÃ©aires-line-plots",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.1 ğŸ“Š Graphiques linÃ©aires (Line Plots)",
    "text": "2.1 ğŸ“Š Graphiques linÃ©aires (Line Plots)\n\n\nCode\n# DonnÃ©es pour un graphique linÃ©aire\nx = np.linspace(0, 10, 100)\ny1 = np.sin(x)\ny2 = np.cos(x)\n\n# CrÃ©ation du graphique\nplt.figure(figsize=(12, 6))\nplt.plot(x, y1, label='Sin(x)', color='blue', linewidth=2)\nplt.plot(x, y2, label='Cos(x)', color='red', linestyle='--', linewidth=2)\n\n# Personnalisation\nplt.title('Fonctions trigonomÃ©triques', fontsize=16, fontweight='bold')\nplt.xlabel('x', fontsize=12)\nplt.ylabel('y', fontsize=12)\nplt.legend(loc='upper right')\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-Ã -barres-bar-plots",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-Ã -barres-bar-plots",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.2 ğŸ“Š Graphiques Ã  barres (Bar Plots)",
    "text": "2.2 ğŸ“Š Graphiques Ã  barres (Bar Plots)\n\n\nCode\n# DonnÃ©es de ventes par mois\nmois = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Juin']\nventes_2023 = [1200, 1500, 1800, 1600, 2000, 2200]\nventes_2024 = [1400, 1700, 1900, 1800, 2300, 2500]\n\nx = np.arange(len(mois))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Barres groupÃ©es\nbars1 = ax.bar(x - width/2, ventes_2023, width, label='2023', color='steelblue')\nbars2 = ax.bar(x + width/2, ventes_2024, width, label='2024', color='coral')\n\n# Personnalisation\nax.set_title('Comparaison des ventes 2023 vs 2024', fontsize=16, fontweight='bold')\nax.set_xlabel('Mois', fontsize=12)\nax.set_ylabel('Ventes (â‚¬)', fontsize=12)\nax.set_xticks(x)\nax.set_xticklabels(mois)\nax.legend()\n\n# Ajouter les valeurs sur les barres\nfor bar in bars1:\n    height = bar.get_height()\n    ax.annotate(f'{height}', xy=(bar.get_x() + bar.get_width()/2, height),\n                xytext=(0, 3), textcoords='offset points', ha='center', fontsize=9)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#nuages-de-points-scatter-plots",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#nuages-de-points-scatter-plots",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.3 ğŸ“Š Nuages de points (Scatter Plots)",
    "text": "2.3 ğŸ“Š Nuages de points (Scatter Plots)\n\n\nCode\n# DonnÃ©es alÃ©atoires avec corrÃ©lation\nnp.random.seed(42)\nx = np.random.randn(100)\ny = 2 * x + np.random.randn(100) * 0.5\ncolors = np.random.rand(100)\nsizes = np.random.rand(100) * 200\n\n# Scatter plot avec couleurs et tailles variables\nplt.figure(figsize=(10, 8))\nscatter = plt.scatter(x, y, c=colors, s=sizes, alpha=0.6, cmap='viridis')\n\n# Ajouter une ligne de tendance\nz = np.polyfit(x, y, 1)\np = np.poly1d(z)\nplt.plot(x, p(x), 'r--', linewidth=2, label=f'Tendance: y = {z[0]:.2f}x + {z[1]:.2f}')\n\nplt.colorbar(scatter, label='Valeur')\nplt.title('Nuage de points avec ligne de tendance', fontsize=16, fontweight='bold')\nplt.xlabel('Variable X')\nplt.ylabel('Variable Y')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#histogrammes",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#histogrammes",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.4 ğŸ“Š Histogrammes",
    "text": "2.4 ğŸ“Š Histogrammes\n\n\nCode\n# DonnÃ©es de distribution\nnp.random.seed(42)\ndata_normal = np.random.normal(loc=50, scale=10, size=1000)\ndata_skewed = np.random.exponential(scale=10, size=1000)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Histogramme distribution normale\naxes[0].hist(data_normal, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\naxes[0].axvline(data_normal.mean(), color='red', linestyle='--', label=f'Moyenne: {data_normal.mean():.1f}')\naxes[0].set_title('Distribution Normale', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Valeur')\naxes[0].set_ylabel('FrÃ©quence')\naxes[0].legend()\n\n# Histogramme distribution exponentielle\naxes[1].hist(data_skewed, bins=30, color='coral', edgecolor='black', alpha=0.7)\naxes[1].axvline(data_skewed.mean(), color='red', linestyle='--', label=f'Moyenne: {data_skewed.mean():.1f}')\naxes[1].set_title('Distribution Exponentielle', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Valeur')\naxes[1].set_ylabel('FrÃ©quence')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-circulaires-pie-charts",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-circulaires-pie-charts",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.5 ğŸ“Š Graphiques circulaires (Pie Charts)",
    "text": "2.5 ğŸ“Š Graphiques circulaires (Pie Charts)\n\n\nCode\n# DonnÃ©es de rÃ©partition\ncategories = ['Produit A', 'Produit B', 'Produit C', 'Produit D', 'Autres']\nparts = [35, 25, 20, 15, 5]\ncolors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#ff99cc']\nexplode = (0.05, 0, 0, 0, 0)  # Mettre en Ã©vidence le premier segment\n\nplt.figure(figsize=(10, 8))\nwedges, texts, autotexts = plt.pie(parts, labels=categories, colors=colors, explode=explode,\n                                    autopct='%1.1f%%', startangle=90, shadow=True)\n\n# AmÃ©liorer l'apparence du texte\nfor autotext in autotexts:\n    autotext.set_fontsize(11)\n    autotext.set_fontweight('bold')\n\nplt.title('RÃ©partition des ventes par produit', fontsize=16, fontweight='bold')\nplt.axis('equal')  # Assure que le cercle est bien rond\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#sous-graphiques-subplots",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#sous-graphiques-subplots",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.6 ğŸ“Š Sous-graphiques (Subplots)",
    "text": "2.6 ğŸ“Š Sous-graphiques (Subplots)\n\n\nCode\n# CrÃ©er une grille de sous-graphiques\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# DonnÃ©es\nx = np.linspace(0, 10, 50)\n\n# Graphique 1: Ligne\naxes[0, 0].plot(x, np.sin(x), 'b-', linewidth=2)\naxes[0, 0].set_title('Graphique linÃ©aire')\naxes[0, 0].set_xlabel('X')\naxes[0, 0].set_ylabel('Sin(X)')\naxes[0, 0].grid(True, alpha=0.3)\n\n# Graphique 2: Barres\ncategories = ['A', 'B', 'C', 'D']\nvalues = [23, 45, 56, 78]\naxes[0, 1].bar(categories, values, color=['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4'])\naxes[0, 1].set_title('Graphique Ã  barres')\n\n# Graphique 3: Scatter\nx_scatter = np.random.rand(50)\ny_scatter = np.random.rand(50)\naxes[1, 0].scatter(x_scatter, y_scatter, c='purple', alpha=0.6, s=100)\naxes[1, 0].set_title('Nuage de points')\n\n# Graphique 4: Histogramme\ndata = np.random.randn(1000)\naxes[1, 1].hist(data, bins=30, color='orange', edgecolor='black', alpha=0.7)\naxes[1, 1].set_title('Histogramme')\n\nplt.suptitle('Tableau de bord - Vue d\\'ensemble', fontsize=16, fontweight='bold', y=1.02)\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#sauvegarder-des-graphiques",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#sauvegarder-des-graphiques",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.7 ğŸ’¾ Sauvegarder des graphiques",
    "text": "2.7 ğŸ’¾ Sauvegarder des graphiques\n\n\nCode\n# CrÃ©er un graphique Ã  sauvegarder\nfig, ax = plt.subplots(figsize=(10, 6))\nx = np.linspace(0, 10, 100)\nax.plot(x, np.sin(x), 'b-', linewidth=2, label='Sin(x)')\nax.set_title('Graphique Ã  exporter', fontsize=14)\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Sauvegarder dans diffÃ©rents formats\nfig.savefig('graphique.png', dpi=300, bbox_inches='tight')\nfig.savefig('graphique.pdf', bbox_inches='tight')\nfig.savefig('graphique.svg', bbox_inches='tight')\n\nprint(\"âœ… Graphiques sauvegardÃ©s en PNG, PDF et SVG\")\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-matplotlib",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-matplotlib",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "2.8 ğŸ¯ Exercice Pratique : Matplotlib",
    "text": "2.8 ğŸ¯ Exercice Pratique : Matplotlib\nObjectif : CrÃ©er un tableau de bord de visualisation\n\nCrÃ©er un DataFrame avec des donnÃ©es de ventes (produit, mois, ventes, profit)\nCrÃ©er 4 sous-graphiques montrant :\n\nÃ‰volution des ventes mensuelles (ligne)\nVentes par produit (barres)\nRelation ventes/profit (scatter)\nDistribution des profits (histogramme)\n\nPersonnaliser les couleurs et ajouter des titres\nSauvegarder le rÃ©sultat en PNG\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# Votre code ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#charger-des-jeux-de-donnÃ©es-intÃ©grÃ©s",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#charger-des-jeux-de-donnÃ©es-intÃ©grÃ©s",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.1 ğŸ“¦ Charger des jeux de donnÃ©es intÃ©grÃ©s",
    "text": "3.1 ğŸ“¦ Charger des jeux de donnÃ©es intÃ©grÃ©s\n\n\nCode\n# Seaborn propose des jeux de donnÃ©es pour s'entraÃ®ner\ntips = sns.load_dataset('tips')\nprint(\"ğŸ“Š Dataset 'tips' :\")\nprint(tips.head())\nprint(f\"\\nDimensions : {tips.shape}\")\nprint(f\"\\nColonnes : {list(tips.columns)}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisation-des-distributions",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisation-des-distributions",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.2 ğŸ“Š Visualisation des distributions",
    "text": "3.2 ğŸ“Š Visualisation des distributions\n\n\nCode\n# Histogramme avec KDE (Kernel Density Estimation)\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Histogramme simple\nsns.histplot(data=tips, x='total_bill', kde=True, ax=axes[0], color='steelblue')\naxes[0].set_title('Distribution du montant total', fontsize=14, fontweight='bold')\n\n# Histogramme avec hue (groupement)\nsns.histplot(data=tips, x='total_bill', hue='time', kde=True, ax=axes[1])\naxes[1].set_title('Distribution par moment de la journÃ©e', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# KDE plot (densitÃ© de probabilitÃ©)\nplt.figure(figsize=(10, 6))\nsns.kdeplot(data=tips, x='total_bill', hue='day', fill=True, alpha=0.5)\nplt.title('DensitÃ© du montant total par jour', fontsize=14, fontweight='bold')\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisation-des-donnÃ©es-catÃ©gorielles",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisation-des-donnÃ©es-catÃ©gorielles",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.3 ğŸ“Š Visualisation des donnÃ©es catÃ©gorielles",
    "text": "3.3 ğŸ“Š Visualisation des donnÃ©es catÃ©gorielles\n\n\nCode\n# Box plot - Distribution par catÃ©gorie\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Box plot simple\nsns.boxplot(data=tips, x='day', y='total_bill', ax=axes[0], palette='Set2')\naxes[0].set_title('Montant total par jour', fontsize=14, fontweight='bold')\n\n# Box plot avec hue\nsns.boxplot(data=tips, x='day', y='total_bill', hue='sex', ax=axes[1], palette='Set1')\naxes[1].set_title('Montant total par jour et sexe', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# Violin plot - Combine box plot et KDE\nplt.figure(figsize=(12, 6))\nsns.violinplot(data=tips, x='day', y='total_bill', hue='sex', split=True, palette='muted')\nplt.title('Distribution du montant par jour et sexe (Violin Plot)', fontsize=14, fontweight='bold')\nplt.show()\n\n\n\n\nCode\n# Bar plot avec estimation statistique\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Bar plot avec intervalle de confiance\nsns.barplot(data=tips, x='day', y='total_bill', ax=axes[0], palette='Blues_d', errorbar='ci')\naxes[0].set_title('Montant moyen par jour (avec IC 95%)', fontsize=14, fontweight='bold')\n\n# Count plot (compte les occurrences)\nsns.countplot(data=tips, x='day', hue='time', ax=axes[1], palette='Set2')\naxes[1].set_title('Nombre de repas par jour', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisation-des-relations-entre-variables",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisation-des-relations-entre-variables",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.4 ğŸ“Š Visualisation des relations entre variables",
    "text": "3.4 ğŸ“Š Visualisation des relations entre variables\n\n\nCode\n# Scatter plot avec rÃ©gression\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Scatter plot simple avec rÃ©gression\nsns.regplot(data=tips, x='total_bill', y='tip', ax=axes[0], color='coral')\naxes[0].set_title('Relation montant/pourboire avec rÃ©gression', fontsize=14, fontweight='bold')\n\n# Scatter plot avec hue et style\nsns.scatterplot(data=tips, x='total_bill', y='tip', hue='time', style='sex', \n                size='size', sizes=(50, 200), ax=axes[1], palette='Set1')\naxes[1].set_title('Relation multidimensionnelle', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# lmplot - RÃ©gression avec facettes\ng = sns.lmplot(data=tips, x='total_bill', y='tip', hue='smoker', col='time', \n               height=5, aspect=1.2, palette='Set1')\ng.fig.suptitle('RÃ©gression par moment et statut fumeur', y=1.02, fontsize=14, fontweight='bold')\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#heatmaps-et-matrices-de-corrÃ©lation",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#heatmaps-et-matrices-de-corrÃ©lation",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.5 ğŸ“Š Heatmaps et matrices de corrÃ©lation",
    "text": "3.5 ğŸ“Š Heatmaps et matrices de corrÃ©lation\n\n\nCode\n# Matrice de corrÃ©lation\n# SÃ©lectionner uniquement les colonnes numÃ©riques\nnumeric_cols = tips.select_dtypes(include=[np.number])\ncorrelation_matrix = numeric_cols.corr()\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n            fmt='.2f', linewidths=0.5, square=True)\nplt.title('Matrice de corrÃ©lation', fontsize=16, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# Heatmap de donnÃ©es pivotÃ©es\npivot_data = tips.pivot_table(values='tip', index='day', columns='time', aggfunc='mean')\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='YlOrRd', linewidths=0.5)\nplt.title('Pourboire moyen par jour et moment', fontsize=14, fontweight='bold')\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#pair-plots-visualisation-multivariÃ©e",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#pair-plots-visualisation-multivariÃ©e",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.6 ğŸ“Š Pair plots (visualisation multivariÃ©e)",
    "text": "3.6 ğŸ“Š Pair plots (visualisation multivariÃ©e)\n\n\nCode\n# Pair plot - Toutes les combinaisons de variables\ng = sns.pairplot(tips, hue='time', palette='Set1', diag_kind='kde', \n                 plot_kws={'alpha': 0.6}, height=2.5)\ng.fig.suptitle('Pair Plot - Dataset Tips', y=1.02, fontsize=14, fontweight='bold')\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#facetgrid---graphiques-multi-facettes",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#facetgrid---graphiques-multi-facettes",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.7 ğŸ“Š FacetGrid - Graphiques multi-facettes",
    "text": "3.7 ğŸ“Š FacetGrid - Graphiques multi-facettes\n\n\nCode\n# CrÃ©er une grille de facettes\ng = sns.FacetGrid(tips, col='time', row='smoker', height=4, aspect=1.2)\ng.map_dataframe(sns.histplot, x='total_bill', kde=True)\ng.add_legend()\ng.fig.suptitle('Distribution du montant par temps et statut fumeur', y=1.02, \n               fontsize=14, fontweight='bold')\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#joint-plots---distributions-jointes",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#joint-plots---distributions-jointes",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.8 ğŸ“Š Joint plots - Distributions jointes",
    "text": "3.8 ğŸ“Š Joint plots - Distributions jointes\n\n\nCode\n# Joint plot avec distributions marginales\ng = sns.jointplot(data=tips, x='total_bill', y='tip', kind='reg', \n                  height=8, ratio=4, color='coral')\ng.fig.suptitle('Distribution jointe montant/pourboire', y=1.02, fontsize=14, fontweight='bold')\nplt.show()\n\n\n\n\nCode\n# Joint plot avec hexbin (pour grandes quantitÃ©s de donnÃ©es)\ng = sns.jointplot(data=tips, x='total_bill', y='tip', kind='hex', \n                  height=8, ratio=4, cmap='Blues')\ng.fig.suptitle('Distribution jointe (Hexbin)', y=1.02, fontsize=14, fontweight='bold')\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#personnalisation-des-styles",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#personnalisation-des-styles",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.9 ğŸ¨ Personnalisation des styles",
    "text": "3.9 ğŸ¨ Personnalisation des styles\n\n\nCode\n# Explorer diffÃ©rents styles\nstyles = ['white', 'dark', 'whitegrid', 'darkgrid', 'ticks']\n\nfig, axes = plt.subplots(1, 5, figsize=(20, 4))\n\nfor ax, style in zip(axes, styles):\n    with sns.axes_style(style):\n        sns.histplot(tips['total_bill'], ax=ax, color='steelblue')\n        ax.set_title(f\"Style: {style}\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# Palettes de couleurs\npalettes = ['deep', 'muted', 'bright', 'pastel', 'dark', 'colorblind']\n\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.flatten()\n\nfor ax, palette in zip(axes, palettes):\n    sns.barplot(data=tips, x='day', y='total_bill', palette=palette, ax=ax)\n    ax.set_title(f\"Palette: {palette}\", fontsize=12)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exemple-tableau-de-bord-complet",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exemple-tableau-de-bord-complet",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.10 ğŸ“Š Exemple : Tableau de bord complet",
    "text": "3.10 ğŸ“Š Exemple : Tableau de bord complet\n\n\nCode\n# CrÃ©er un tableau de bord d'analyse complet\nsns.set_theme(style='whitegrid')\n\nfig = plt.figure(figsize=(16, 12))\n\n# CrÃ©er une grille personnalisÃ©e\ngs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n\n# 1. Distribution des montants\nax1 = fig.add_subplot(gs[0, 0])\nsns.histplot(data=tips, x='total_bill', kde=True, ax=ax1, color='steelblue')\nax1.set_title('Distribution des montants', fontweight='bold')\n\n# 2. Distribution des pourboires\nax2 = fig.add_subplot(gs[0, 1])\nsns.histplot(data=tips, x='tip', kde=True, ax=ax2, color='coral')\nax2.set_title('Distribution des pourboires', fontweight='bold')\n\n# 3. Relation montant/pourboire\nax3 = fig.add_subplot(gs[0, 2])\nsns.regplot(data=tips, x='total_bill', y='tip', ax=ax3, color='purple', scatter_kws={'alpha':0.5})\nax3.set_title('Montant vs Pourboire', fontweight='bold')\n\n# 4. Boxplot par jour\nax4 = fig.add_subplot(gs[1, 0])\nsns.boxplot(data=tips, x='day', y='total_bill', ax=ax4, palette='Set2')\nax4.set_title('Montants par jour', fontweight='bold')\n\n# 5. Violin plot par temps\nax5 = fig.add_subplot(gs[1, 1])\nsns.violinplot(data=tips, x='time', y='total_bill', hue='sex', split=True, ax=ax5, palette='muted')\nax5.set_title('Distribution par temps et sexe', fontweight='bold')\n\n# 6. Count plot\nax6 = fig.add_subplot(gs[1, 2])\nsns.countplot(data=tips, x='day', hue='time', ax=ax6, palette='Set1')\nax6.set_title('Nombre de repas', fontweight='bold')\n\n# 7. Heatmap de corrÃ©lation (grande)\nax7 = fig.add_subplot(gs[2, :])\npivot = tips.pivot_table(values='tip', index='day', columns='size', aggfunc='mean')\nsns.heatmap(pivot, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax7, linewidths=0.5)\nax7.set_title('Pourboire moyen par jour et taille de groupe', fontweight='bold')\n\nplt.suptitle('ğŸ“Š Tableau de bord - Analyse des pourboires', fontsize=18, fontweight='bold', y=1.01)\nplt.tight_layout()\nplt.savefig('dashboard_seaborn.png', dpi=300, bbox_inches='tight')\nprint(\"âœ… Dashboard sauvegardÃ© en PNG\")\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-seaborn",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-seaborn",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "3.11 ğŸ¯ Exercice Pratique : Seaborn",
    "text": "3.11 ğŸ¯ Exercice Pratique : Seaborn\nObjectif : Analyser le dataset â€˜titanicâ€™ de Seaborn\n\nCharger le dataset avec sns.load_dataset('titanic')\nCrÃ©er un tableau de bord avec :\n\nDistribution des Ã¢ges par classe (violin plot)\nTaux de survie par sexe et classe (bar plot)\nMatrice de corrÃ©lation des variables numÃ©riques (heatmap)\nRelation Ã¢ge/tarif avec survie en couleur (scatter plot)\n\nUtiliser FacetGrid pour analyser les survivants par sexe et classe\nSauvegarder votre tableau de bord\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# Charger le dataset\ntitanic = sns.load_dataset('titanic')\nprint(titanic.head())\nprint(f\"\\nDimensions : {titanic.shape}\")\n\n# Votre code de visualisation ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-de-base-avec-matplotlib",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#graphiques-de-base-avec-matplotlib",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "4.1 ğŸ“Š Graphiques de base avec Matplotlib",
    "text": "4.1 ğŸ“Š Graphiques de base avec Matplotlib\n\n\nCode\n# DonnÃ©es pour les graphiques\nmois = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Juin']\nventes = [1200, 1500, 1800, 1600, 2000, 2200]\n\n# CrÃ©er une figure avec 2x2 sous-graphiques\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Graphique linÃ©aire\naxes[0, 0].plot(mois, ventes, marker='o', linewidth=2, color='steelblue')\naxes[0, 0].set_title('ğŸ“ˆ Ã‰volution des ventes', fontweight='bold')\naxes[0, 0].set_xlabel('Mois')\naxes[0, 0].set_ylabel('Ventes (â‚¬)')\naxes[0, 0].grid(True, alpha=0.3)\n\n# 2. Graphique Ã  barres\ncolors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4', '#ffeaa7', '#dfe6e9']\naxes[0, 1].bar(mois, ventes, color=colors, edgecolor='black')\naxes[0, 1].set_title('ğŸ“Š Ventes par mois', fontweight='bold')\naxes[0, 1].set_xlabel('Mois')\naxes[0, 1].set_ylabel('Ventes (â‚¬)')\n\n# 3. Graphique circulaire\naxes[1, 0].pie(ventes, labels=mois, autopct='%1.1f%%', colors=colors)\naxes[1, 0].set_title('ğŸ¥§ RÃ©partition des ventes', fontweight='bold')\n\n# 4. Nuage de points\nnp.random.seed(42)\nx = np.random.randn(50)\ny = 2 * x + np.random.randn(50) * 0.5\naxes[1, 1].scatter(x, y, c='coral', alpha=0.7, s=100)\naxes[1, 1].set_title('ğŸ“ Nuage de points', fontweight='bold')\naxes[1, 1].set_xlabel('Variable X')\naxes[1, 1].set_ylabel('Variable Y')\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('graphiques_matplotlib.png', dpi=150)\nprint(\"âœ… Graphique sauvegardÃ© en PNG\")\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#histogrammes-et-distributions",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#histogrammes-et-distributions",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "4.2 ğŸ“Š Histogrammes et distributions",
    "text": "4.2 ğŸ“Š Histogrammes et distributions\n\n\nCode\n# GÃ©nÃ©rer des donnÃ©es de distribution\nnp.random.seed(42)\ndata_normal = np.random.normal(loc=50, scale=10, size=1000)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Histogramme simple\naxes[0].hist(data_normal, bins=30, color='steelblue', edgecolor='black', alpha=0.7)\naxes[0].axvline(data_normal.mean(), color='red', linestyle='--', label=f'Moyenne: {data_normal.mean():.1f}')\naxes[0].set_title('Distribution des donnÃ©es', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Valeur')\naxes[0].set_ylabel('FrÃ©quence')\naxes[0].legend()\n\n# Box plot\ndata_multi = [np.random.normal(50, 10, 100), np.random.normal(60, 15, 100), np.random.normal(45, 8, 100)]\nbp = axes[1].boxplot(data_multi, labels=['Groupe A', 'Groupe B', 'Groupe C'], patch_artist=True)\ncolors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\nfor patch, color in zip(bp['boxes'], colors):\n    patch.set_facecolor(color)\naxes[1].set_title('Comparaison des groupes', fontsize=14, fontweight='bold')\naxes[1].set_ylabel('Valeur')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisations-avec-seaborn",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#visualisations-avec-seaborn",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "5.1 ğŸ“Š Visualisations avec Seaborn",
    "text": "5.1 ğŸ“Š Visualisations avec Seaborn\n\n\nCode\n# CrÃ©er un tableau de bord avec Seaborn\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Distribution avec KDE\nsns.histplot(data=tips, x='total_bill', kde=True, ax=axes[0, 0], color='steelblue')\naxes[0, 0].set_title('Distribution du montant', fontweight='bold')\n\n# 2. Box plot par catÃ©gorie\nsns.boxplot(data=tips, x='day', y='total_bill', palette='Set2', ax=axes[0, 1])\naxes[0, 1].set_title('Montant par jour', fontweight='bold')\n\n# 3. Scatter plot avec rÃ©gression\nsns.regplot(data=tips, x='total_bill', y='tip', ax=axes[1, 0], color='coral')\naxes[1, 0].set_title('Relation montant/pourboire', fontweight='bold')\n\n# 4. Count plot\nsns.countplot(data=tips, x='day', hue='time', palette='Set1', ax=axes[1, 1])\naxes[1, 1].set_title('Nombre de repas par jour', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nCode\n# Heatmap de corrÃ©lation\nplt.figure(figsize=(8, 6))\nnumeric_cols = tips.select_dtypes(include=[np.number])\ncorrelation = numeric_cols.corr()\n\nsns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n            fmt='.2f', linewidths=0.5, square=True)\nplt.title('Matrice de corrÃ©lation', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-visualisation",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-visualisation",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "5.2 ğŸ¯ Exercice : Visualisation",
    "text": "5.2 ğŸ¯ Exercice : Visualisation\nCrÃ©er un tableau de bord de visualisation avec les donnÃ©es df_clean (employÃ©s) : 1. Distribution des salaires (histogramme) 2. Salaire moyen par ville (bar plot) 3. Relation Ã¢ge/salaire (scatter plot) 4. RÃ©partition par ville (pie chart)\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# CrÃ©ez votre tableau de bord ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#nettoyage-de-base",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#nettoyage-de-base",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "6.1 2.1 Nettoyage de base",
    "text": "6.1 2.1 Nettoyage de base\n\n\nCode\n# DonnÃ©es textuelles brutes\ntextes = pd.DataFrame({\n    'texte': [\n        '  BONJOUR   ',\n        'Salut tout le monde!',\n        'Python_est_gÃ©nial',\n        'Data-Engineering-2024'\n    ]\n})\n\n# Nettoyage basique\ntextes['clean'] = textes['texte'].str.strip()  # Supprimer espaces\ntextes['lower'] = textes['texte'].str.lower()  # Minuscules\ntextes['upper'] = textes['texte'].str.upper()  # Majuscules\ntextes['replace'] = textes['texte'].str.replace('_', ' ')  # Remplacer\n\nprint(\"ğŸ§¹ Nettoyage de texte :\")\nprint(textes)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#mÃ©thodes-pandas-string-.str-accessor",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#mÃ©thodes-pandas-string-.str-accessor",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "6.2 2.2 MÃ©thodes Pandas string (.str accessor)",
    "text": "6.2 2.2 MÃ©thodes Pandas string (.str accessor)\n\n\nCode\n# DonnÃ©es d'exemple\ndf_text = pd.DataFrame({\n    'email': ['alice@example.com', 'bob@test.org', 'charlie@mail.fr'],\n    'nom_complet': ['Jean Dupont', 'Marie Martin', 'Pierre Durand'],\n    'telephone': ['0612345678', '06-98-76-54-32', '06 11 22 33 44']\n})\n\n# VÃ©rifier si contient\ndf_text['email_gmail'] = df_text['email'].str.contains('gmail')\n\n# Commencer/finir par\ndf_text['email_com'] = df_text['email'].str.endswith('.com')\n\n# Extraire le domaine\ndf_text['domaine'] = df_text['email'].str.split('@').str[1]\n\n# SÃ©parer nom et prÃ©nom\ndf_text[['prenom', 'nom']] = df_text['nom_complet'].str.split(' ', expand=True)\n\n# Longueur\ndf_text['longueur_nom'] = df_text['nom_complet'].str.len()\n\nprint(\"ğŸ”¤ MÃ©thodes string :\")\nprint(df_text)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#expressions-rÃ©guliÃ¨res-regex",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#expressions-rÃ©guliÃ¨res-regex",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "6.3 2.3 Expressions rÃ©guliÃ¨res (Regex)",
    "text": "6.3 2.3 Expressions rÃ©guliÃ¨res (Regex)\n\n\nCode\nimport re\n\n# Exemples de regex courantes\ntexte_test = \"\"\"\nContact: alice@example.com ou bob@test.org\nTÃ©lÃ©phones: 06.12.34.56.78, 01-23-45-67-89\nURL: https://www.example.com\nPrix: 29.99â‚¬, 15.50â‚¬, 100â‚¬\n\"\"\"\n\n# Extraire les emails\nemails = re.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', texte_test)\nprint(\"ğŸ“§ Emails trouvÃ©s :\")\nprint(emails)\n\n# Extraire les tÃ©lÃ©phones\ntelephones = re.findall(r'\\d{2}[-.\\s]?\\d{2}[-.\\s]?\\d{2}[-.\\s]?\\d{2}[-.\\s]?\\d{2}', texte_test)\nprint(\"\\nğŸ“ TÃ©lÃ©phones trouvÃ©s :\")\nprint(telephones)\n\n# Extraire les URLs\nurls = re.findall(r'https?://[^\\s]+', texte_test)\nprint(\"\\nğŸ”— URLs trouvÃ©es :\")\nprint(urls)\n\n# Extraire les prix\nprix = re.findall(r'\\d+\\.?\\d*â‚¬', texte_test)\nprint(\"\\nğŸ’° Prix trouvÃ©s :\")\nprint(prix)\n\n\n\n\nCode\n# Validation avec regex\ndef valider_email(email):\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n\n# Test\nemails_test = ['alice@example.com', 'bob@invalid', 'charlie.fr', 'david@test.org']\nfor email in emails_test:\n    valide = \"âœ…\" if valider_email(email) else \"âŒ\"\n    print(f\"{valide} {email}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#cas-dusage-rÃ©els-parsing-de-logs",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#cas-dusage-rÃ©els-parsing-de-logs",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "6.4 2.4 Cas dâ€™usage rÃ©els : Parsing de logs",
    "text": "6.4 2.4 Cas dâ€™usage rÃ©els : Parsing de logs\n\n\nCode\n# Exemple de logs Apache/Nginx\nlogs = \"\"\"\n192.168.1.1 - - [01/Dec/2024:10:15:30 +0000] \"GET /api/users HTTP/1.1\" 200 1234\n192.168.1.2 - - [01/Dec/2024:10:16:45 +0000] \"POST /api/login HTTP/1.1\" 401 567\n192.168.1.3 - - [01/Dec/2024:10:17:20 +0000] \"GET /api/products HTTP/1.1\" 200 8901\n\"\"\"\n\n# Pattern pour parser les logs\npattern = r'(\\S+) - - \\[([^\\]]+)\\] \"(\\S+) (\\S+) (\\S+)\" (\\d+) (\\d+)'\n\n# Extraire les informations\nmatches = re.findall(pattern, logs)\n\n# CrÃ©er un DataFrame\ndf_logs = pd.DataFrame(matches, columns=[\n    'ip', 'timestamp', 'methode', 'endpoint', 'protocole', 'status', 'bytes'\n])\n\n# Convertir les types\ndf_logs['status'] = df_logs['status'].astype(int)\ndf_logs['bytes'] = df_logs['bytes'].astype(int)\n\nprint(\"ğŸ“‹ Logs parsÃ©s :\")\nprint(df_logs)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-de-lencodage",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-de-lencodage",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "6.5 2.5 Gestion de lâ€™encodage",
    "text": "6.5 2.5 Gestion de lâ€™encodage\n\n\nCode\n# CrÃ©er un fichier avec encodage spÃ©cifique\ntexte_accentue = \"Voici du texte avec des accents : Ã©Ã Ã¹Ã´ Ã§Ã±\"\n\n# Sauvegarder en UTF-8\nwith open('test_utf8.txt', 'w', encoding='utf-8') as f:\n    f.write(texte_accentue)\n\n# Sauvegarder en Latin-1\nwith open('test_latin1.txt', 'w', encoding='latin-1') as f:\n    f.write(texte_accentue)\n\n# Lire avec le bon encodage\nprint(\"âœ… Lecture UTF-8 :\")\nwith open('test_utf8.txt', 'r', encoding='utf-8') as f:\n    print(f.read())\n\nprint(\"\\nâœ… Lecture Latin-1 :\")\nwith open('test_latin1.txt', 'r', encoding='latin-1') as f:\n    print(f.read())\n\n\n\n\nCode\n# DÃ©tecter l'encodage automatiquement\n!pip install chardet\n\nimport chardet\n\n# DÃ©tecter l'encodage d'un fichier\nwith open('test_utf8.txt', 'rb') as f:\n    result = chardet.detect(f.read())\n    print(f\"Encodage dÃ©tectÃ© : {result['encoding']} (confiance: {result['confidence']*100:.1f}%)\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-2-texte-et-regex",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-2-texte-et-regex",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "6.6 ğŸ¯ Exercice Pratique 2 : Texte et Regex",
    "text": "6.6 ğŸ¯ Exercice Pratique 2 : Texte et Regex\nObjectif : Nettoyer et valider des donnÃ©es clients\n\nCrÃ©er un DataFrame avec nom, email, tÃ©lÃ©phone\nNettoyer les noms (trim, capitaliser)\nValider les emails avec regex\nNormaliser les numÃ©ros de tÃ©lÃ©phone (format uniforme)\nExporter les donnÃ©es valides uniquement\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# Votre code ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#manipulation-de-json",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#manipulation-de-json",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.1 3.1 Manipulation de JSON",
    "text": "7.1 3.1 Manipulation de JSON\n\n\nCode\nimport json\n\n# CrÃ©er un dictionnaire Python\ndata = {\n    \"nom\": \"Alice\",\n    \"age\": 30,\n    \"competences\": [\"Python\", \"SQL\", \"Pandas\"],\n    \"actif\": True\n}\n\n# Convertir en JSON\njson_str = json.dumps(data, indent=2)\nprint(\"ğŸ“„ JSON formatÃ© :\")\nprint(json_str)\n\n# Reconvertir en dictionnaire\ndata_reloaded = json.loads(json_str)\nprint(\"\\nğŸ”„ RechargÃ© :\")\nprint(data_reloaded)\n\n\n\n\nCode\n# Sauvegarder et lire des fichiers JSON\n\n# Sauvegarder\nwith open('data.json', 'w', encoding='utf-8') as f:\n    json.dump(data, f, indent=2, ensure_ascii=False)\nprint(\"âœ… JSON sauvegardÃ©\")\n\n# Lire\nwith open('data.json', 'r', encoding='utf-8') as f:\n    data_loaded = json.load(f)\nprint(\"\\nğŸ“‚ JSON chargÃ© :\")\nprint(data_loaded)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#appels-api-avec-requests",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#appels-api-avec-requests",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.2 3.2 Appels API avec requests",
    "text": "7.2 3.2 Appels API avec requests\n\n\nCode\nimport requests\n\n# API publique gratuite : JSONPlaceholder\nurl = \"https://jsonplaceholder.typicode.com/users\"\n\n# GET Request\nresponse = requests.get(url)\n\n# VÃ©rifier le statut\nprint(f\"Status code: {response.status_code}\")\n\nif response.status_code == 200:\n    users = response.json()\n    print(f\"\\nâœ… {len(users)} utilisateurs rÃ©cupÃ©rÃ©s\")\n    print(\"\\nPremier utilisateur :\")\n    print(json.dumps(users[0], indent=2))\nelse:\n    print(\"âŒ Erreur lors de la requÃªte\")\n\n\n\n\nCode\n# Convertir en DataFrame\ndf_users = pd.json_normalize(users)\nprint(\"ğŸ‘¥ DataFrame des utilisateurs :\")\nprint(df_users.head())\nprint(f\"\\nColonnes : {df_users.columns.tolist()}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-des-erreurs-http",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-des-erreurs-http",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.3 3.3 Gestion des erreurs HTTP",
    "text": "7.3 3.3 Gestion des erreurs HTTP\n\n\nCode\ndef fetch_data_safe(url):\n    \"\"\"RÃ©cupÃ¨re des donnÃ©es avec gestion d'erreurs\"\"\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()  # LÃ¨ve une exception si statut &gt;= 400\n        return response.json()\n    except requests.exceptions.Timeout:\n        print(\"â±ï¸ Timeout : le serveur met trop de temps Ã  rÃ©pondre\")\n        return None\n    except requests.exceptions.HTTPError as e:\n        print(f\"âŒ Erreur HTTP : {e}\")\n        return None\n    except requests.exceptions.RequestException as e:\n        print(f\"âŒ Erreur de connexion : {e}\")\n        return None\n\n# Test avec une URL valide\ndata = fetch_data_safe(\"https://jsonplaceholder.typicode.com/users/1\")\nif data:\n    print(\"âœ… DonnÃ©es rÃ©cupÃ©rÃ©es :\")\n    print(json.dumps(data, indent=2))\n\n# Test avec une URL invalide\ndata = fetch_data_safe(\"https://jsonplaceholder.typicode.com/invalid\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#authentification-api",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#authentification-api",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.4 3.4 Authentification API",
    "text": "7.4 3.4 Authentification API\n\n\nCode\n# Exemple 1 : API Key dans les headers\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY_HERE\",\n    \"Content-Type\": \"application/json\"\n}\n\n# response = requests.get(url, headers=headers)\n\n# Exemple 2 : API Key dans les paramÃ¨tres\nparams = {\n    \"api_key\": \"YOUR_API_KEY_HERE\",\n    \"format\": \"json\"\n}\n\n# response = requests.get(url, params=params)\n\n# Exemple 3 : Basic Auth\nfrom requests.auth import HTTPBasicAuth\n\n# response = requests.get(url, auth=HTTPBasicAuth('username', 'password'))\n\nprint(\"ğŸ’¡ Les exemples ci-dessus montrent diffÃ©rentes mÃ©thodes d'authentification\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#pagination-dapis",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#pagination-dapis",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.5 3.5 Pagination dâ€™APIs",
    "text": "7.5 3.5 Pagination dâ€™APIs\n\n\nCode\ndef fetch_all_pages(base_url, max_pages=5):\n    \"\"\"RÃ©cupÃ¨re toutes les pages d'une API paginÃ©e\"\"\"\n    all_data = []\n    \n    for page in range(1, max_pages + 1):\n        url = f\"{base_url}?_page={page}&_limit=10\"\n        print(f\"ğŸ“„ RÃ©cupÃ©ration page {page}...\")\n        \n        response = requests.get(url)\n        if response.status_code == 200:\n            data = response.json()\n            if not data:  # Plus de donnÃ©es\n                break\n            all_data.extend(data)\n        else:\n            print(f\"âŒ Erreur page {page}\")\n            break\n    \n    return all_data\n\n# Test avec JSONPlaceholder\nposts = fetch_all_pages(\"https://jsonplaceholder.typicode.com/posts\", max_pages=3)\nprint(f\"\\nâœ… Total rÃ©cupÃ©rÃ© : {len(posts)} posts\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#rate-limiting-et-retry-logic",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#rate-limiting-et-retry-logic",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.6 3.6 Rate Limiting et Retry Logic",
    "text": "7.6 3.6 Rate Limiting et Retry Logic\n\n\nCode\nimport time\nfrom datetime import datetime\n\ndef fetch_with_retry(url, max_retries=3, delay=2):\n    \"\"\"RÃ©cupÃ¨re des donnÃ©es avec retry et backoff exponentiel\"\"\"\n    for attempt in range(max_retries):\n        try:\n            print(f\"ğŸ”„ Tentative {attempt + 1}/{max_retries}\")\n            response = requests.get(url, timeout=10)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            print(f\"âŒ Erreur : {e}\")\n            if attempt &lt; max_retries - 1:\n                wait_time = delay * (2 ** attempt)  # Backoff exponentiel\n                print(f\"â³ Attente de {wait_time}s avant nouvelle tentative...\")\n                time.sleep(wait_time)\n            else:\n                print(\"âŒ Ã‰chec aprÃ¨s toutes les tentatives\")\n                return None\n\n# Test\ndata = fetch_with_retry(\"https://jsonplaceholder.typicode.com/users/1\")\nif data:\n    print(\"\\nâœ… SuccÃ¨s !\")\n\n\n\n\nCode\n# Rate limiting simple\ndef fetch_with_rate_limit(urls, requests_per_second=2):\n    \"\"\"RÃ©cupÃ¨re plusieurs URLs en respectant un rate limit\"\"\"\n    delay = 1.0 / requests_per_second\n    results = []\n    \n    for url in urls:\n        start = time.time()\n        print(f\"â¬ RÃ©cupÃ©ration : {url}\")\n        \n        response = requests.get(url)\n        if response.status_code == 200:\n            results.append(response.json())\n        \n        elapsed = time.time() - start\n        sleep_time = max(0, delay - elapsed)\n        if sleep_time &gt; 0:\n            time.sleep(sleep_time)\n    \n    return results\n\n# Test\nurls = [\n    \"https://jsonplaceholder.typicode.com/users/1\",\n    \"https://jsonplaceholder.typicode.com/users/2\",\n    \"https://jsonplaceholder.typicode.com/users/3\"\n]\n\nstart_time = time.time()\nresults = fetch_with_rate_limit(urls, requests_per_second=1)\ntotal_time = time.time() - start_time\n\nprint(f\"\\nâœ… {len(results)} URLs rÃ©cupÃ©rÃ©es en {total_time:.2f}s\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#json-imbriquÃ©-complexe",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#json-imbriquÃ©-complexe",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.7 3.7 JSON imbriquÃ© complexe",
    "text": "7.7 3.7 JSON imbriquÃ© complexe\n\n\nCode\n# JSON complexe imbriquÃ©\ncomplex_json = {\n    \"id\": 1,\n    \"nom\": \"Entreprise A\",\n    \"employes\": [\n        {\n            \"id\": 101,\n            \"nom\": \"Alice\",\n            \"competences\": [\"Python\", \"SQL\"],\n            \"adresse\": {\"ville\": \"Paris\", \"code_postal\": \"75001\"}\n        },\n        {\n            \"id\": 102,\n            \"nom\": \"Bob\",\n            \"competences\": [\"Java\", \"Docker\"],\n            \"adresse\": {\"ville\": \"Lyon\", \"code_postal\": \"69001\"}\n        }\n    ]\n}\n\n# Normaliser avec json_normalize\ndf_complex = pd.json_normalize(\n    complex_json,\n    record_path='employes',\n    meta=['nom'],\n    meta_prefix='entreprise_'\n)\n\nprint(\"ğŸ”„ JSON normalisÃ© :\")\nprint(df_complex)"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-3-apis",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-3-apis",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "7.8 ğŸ¯ Exercice Pratique 3 : APIs",
    "text": "7.8 ğŸ¯ Exercice Pratique 3 : APIs\nObjectif : RÃ©cupÃ©rer et analyser des donnÃ©es dâ€™une API publique\n\nUtiliser lâ€™API JSONPlaceholder pour rÃ©cupÃ©rer les posts\nConvertir en DataFrame\nCompter le nombre de posts par utilisateur\nRÃ©cupÃ©rer les dÃ©tails des 5 utilisateurs les plus actifs\nExporter le rÃ©sultat en JSON\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# Votre code ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#vÃ©rifications-basiques",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#vÃ©rifications-basiques",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "8.1 4.1 VÃ©rifications basiques",
    "text": "8.1 4.1 VÃ©rifications basiques\n\n\nCode\n# CrÃ©er des donnÃ©es de test\ntest_data = pd.DataFrame({\n    'user_id': [1, 2, 3, 2, 5],\n    'email': ['alice@test.com', 'bob@test', None, 'bob@test', 'eve@test.com'],\n    'age': [25, 150, -5, 30, 28],\n    'salaire': [45000, 55000, 60000, 55000, None]\n})\n\nprint(\"ğŸ“Š DonnÃ©es de test :\")\nprint(test_data)\n\n# VÃ©rifications\nprint(\"\\nğŸ” VÃ©rifications :\")\nprint(f\"Colonnes manquantes : {set(['user_id', 'email', 'age', 'salaire']) - set(test_data.columns)}\")\nprint(f\"Valeurs nulles : {test_data.isnull().sum().sum()}\")\nprint(f\"Doublons : {test_data.duplicated().sum()}\")\nprint(f\"Types : \\n{test_data.dtypes}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#classe-de-validation-complÃ¨te",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#classe-de-validation-complÃ¨te",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "8.2 4.2 Classe de validation complÃ¨te",
    "text": "8.2 4.2 Classe de validation complÃ¨te\n\n\nCode\nclass DataValidator:\n    \"\"\"Validateur simple pour DataFrames\"\"\"\n    \n    def __init__(self, df):\n        self.df = df\n        self.errors = []\n    \n    def check_columns(self, required_columns):\n        \"\"\"VÃ©rifie prÃ©sence des colonnes requises\"\"\"\n        missing = set(required_columns) - set(self.df.columns)\n        if missing:\n            self.errors.append(f\"Colonnes manquantes: {missing}\")\n            return False\n        return True\n    \n    def check_nulls(self, max_null_pct=10):\n        \"\"\"VÃ©rifie le pourcentage de valeurs nulles\"\"\"\n        null_pct = (self.df.isnull().sum() / len(self.df)) * 100\n        violations = null_pct[null_pct &gt; max_null_pct]\n        if not violations.empty:\n            self.errors.append(f\"Trop de nulls: {violations.to_dict()}\")\n            return False\n        return True\n    \n    def check_range(self, column, min_val, max_val):\n        \"\"\"VÃ©rifie que les valeurs sont dans une plage\"\"\"\n        if column in self.df.columns:\n            violations = self.df[(self.df[column] &lt; min_val) | (self.df[column] &gt; max_val)]\n            if len(violations) &gt; 0:\n                self.errors.append(f\"{column}: {len(violations)} valeurs hors plage [{min_val}, {max_val}]\")\n                return False\n        return True\n    \n    def check_duplicates(self, subset=None):\n        \"\"\"VÃ©rifie les doublons\"\"\"\n        duplicates = self.df.duplicated(subset=subset).sum()\n        if duplicates &gt; 0:\n            self.errors.append(f\"{duplicates} doublons trouvÃ©s\")\n            return False\n        return True\n    \n    def check_types(self, column, expected_type):\n        \"\"\"VÃ©rifie le type d'une colonne\"\"\"\n        if column in self.df.columns:\n            if self.df[column].dtype != expected_type:\n                self.errors.append(f\"{column}: type attendu {expected_type}, obtenu {self.df[column].dtype}\")\n                return False\n        return True\n    \n    def validate(self):\n        \"\"\"Retourne True si valide, False sinon\"\"\"\n        return len(self.errors) == 0\n    \n    def report(self):\n        \"\"\"GÃ©nÃ¨re un rapport de validation\"\"\"\n        return {\n            'is_valid': self.validate(),\n            'total_errors': len(self.errors),\n            'errors': self.errors\n        }\n\n# Utilisation\nvalidator = DataValidator(test_data)\nvalidator.check_columns(['user_id', 'email', 'age'])\nvalidator.check_nulls(max_null_pct=15)\nvalidator.check_range('age', 0, 120)\nvalidator.check_duplicates(subset=['user_id', 'email'])\n\nreport = validator.report()\nprint(\"\\nğŸ“‹ Rapport de validation:\")\nprint(json.dumps(report, indent=2))"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#validation-avec-schÃ©ma",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#validation-avec-schÃ©ma",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "8.3 4.3 Validation avec schÃ©ma",
    "text": "8.3 4.3 Validation avec schÃ©ma\n\n\nCode\n# DÃ©finir un schÃ©ma de validation\nschema = {\n    'user_id': {'type': 'int64', 'nullable': False, 'unique': True},\n    'email': {'type': 'object', 'nullable': False, 'pattern': r'.+@.+\\..+'},\n    'age': {'type': 'int64', 'nullable': False, 'min': 0, 'max': 120},\n    'salaire': {'type': 'int64', 'nullable': True, 'min': 0}\n}\n\ndef validate_schema(df, schema):\n    \"\"\"Valide un DataFrame contre un schÃ©ma\"\"\"\n    errors = []\n    \n    for column, rules in schema.items():\n        # VÃ©rifier si la colonne existe\n        if column not in df.columns:\n            errors.append(f\"Colonne manquante: {column}\")\n            continue\n        \n        # VÃ©rifier les nulls\n        if not rules.get('nullable', True) and df[column].isnull().any():\n            errors.append(f\"{column}: contient des valeurs nulles\")\n        \n        # VÃ©rifier l'unicitÃ©\n        if rules.get('unique', False) and df[column].duplicated().any():\n            errors.append(f\"{column}: contient des doublons\")\n        \n        # VÃ©rifier la plage\n        if 'min' in rules:\n            violations = df[df[column] &lt; rules['min']]\n            if len(violations) &gt; 0:\n                errors.append(f\"{column}: {len(violations)} valeurs &lt; {rules['min']}\")\n        \n        if 'max' in rules:\n            violations = df[df[column] &gt; rules['max']]\n            if len(violations) &gt; 0:\n                errors.append(f\"{column}: {len(violations)} valeurs &gt; {rules['max']}\")\n        \n        # VÃ©rifier le pattern (pour les strings)\n        if 'pattern' in rules:\n            pattern = rules['pattern']\n            invalid = df[column].dropna()[~df[column].dropna().str.match(pattern)]\n            if len(invalid) &gt; 0:\n                errors.append(f\"{column}: {len(invalid)} valeurs ne matchent pas le pattern\")\n    \n    return {\n        'is_valid': len(errors) == 0,\n        'errors': errors\n    }\n\n# Test\nresult = validate_schema(test_data, schema)\nprint(\"\\nğŸ“‹ Validation avec schÃ©ma :\")\nprint(json.dumps(result, indent=2))"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-4-validation",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-pratique-4-validation",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "8.4 ğŸ¯ Exercice Pratique 4 : Validation",
    "text": "8.4 ğŸ¯ Exercice Pratique 4 : Validation\nObjectif : CrÃ©er un validateur pour des transactions\n\nCrÃ©er un DataFrame de transactions (id, date, montant, type)\nDÃ©finir un schÃ©ma de validation\nValider que toutes les transactions ont un montant positif\nVÃ©rifier quâ€™il nâ€™y a pas de doublons dâ€™ID\nGÃ©nÃ©rer un rapport de qualitÃ©\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# Votre code ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#architecture-du-pipeline",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#architecture-du-pipeline",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.1 5.1 Architecture du pipeline",
    "text": "9.1 5.1 Architecture du pipeline\n\n\nCode\n# CrÃ©er la structure de dossiers\nfrom pathlib import Path\n\ndirs = ['data/raw', 'data/processed', 'data/output', 'logs']\nfor dir_path in dirs:\n    Path(dir_path).mkdir(parents=True, exist_ok=True)\n\nprint(\"âœ… Structure de dossiers crÃ©Ã©e\")\nprint(\"\\nğŸ“ Structure :\")\nprint(\"\"\"\nproject/\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/\nâ”‚   â”œâ”€â”€ processed/\nâ”‚   â””â”€â”€ output/\nâ””â”€â”€ logs/\n\"\"\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#configuration-et-logging",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#configuration-et-logging",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.2 5.2 Configuration et Logging",
    "text": "9.2 5.2 Configuration et Logging\n\n\nCode\nimport logging\nfrom datetime import datetime\n\n# Configuration du logging\nlog_file = f\"logs/pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler(log_file),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger('ETL_Pipeline')\nlogger.info(\"ğŸš€ Pipeline dÃ©marrÃ©\")\n\n\n\n\nCode\n# Configuration centralisÃ©e\nclass Config:\n    \"\"\"Configuration du pipeline\"\"\"\n    # Chemins\n    RAW_DATA_DIR = 'data/raw'\n    PROCESSED_DATA_DIR = 'data/processed'\n    OUTPUT_DIR = 'data/output'\n    \n    # API\n    API_URL = 'https://jsonplaceholder.typicode.com'\n    API_TIMEOUT = 10\n    API_MAX_RETRIES = 3\n    \n    # Validation\n    MAX_NULL_PCT = 10\n    \n    # Export\n    EXPORT_FORMATS = ['csv', 'parquet', 'json']\n\nconfig = Config()\nlogger.info(\"âš™ï¸ Configuration chargÃ©e\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-1-extract",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-1-extract",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.3 5.3 Ã‰tape 1 : Extract",
    "text": "9.3 5.3 Ã‰tape 1 : Extract\n\n\nCode\ndef extract_from_api(url, max_retries=3):\n    \"\"\"Extrait des donnÃ©es depuis une API\"\"\"\n    logger.info(f\"ğŸ“¥ Extraction depuis {url}\")\n    \n    for attempt in range(max_retries):\n        try:\n            response = requests.get(url, timeout=config.API_TIMEOUT)\n            response.raise_for_status()\n            data = response.json()\n            logger.info(f\"âœ… {len(data)} enregistrements extraits\")\n            return data\n        except Exception as e:\n            logger.warning(f\"âš ï¸ Tentative {attempt + 1}/{max_retries} Ã©chouÃ©e: {e}\")\n            if attempt == max_retries - 1:\n                logger.error(\"âŒ Extraction Ã©chouÃ©e\")\n                raise\n            time.sleep(2 ** attempt)\n\n# Test extraction\nusers_data = extract_from_api(f\"{config.API_URL}/users\")\ndf_raw = pd.DataFrame(users_data)\n\n# Sauvegarder les donnÃ©es brutes\nraw_file = f\"{config.RAW_DATA_DIR}/users_raw_{datetime.now().strftime('%Y%m%d')}.csv\"\ndf_raw.to_csv(raw_file, index=False)\nlogger.info(f\"ğŸ’¾ DonnÃ©es brutes sauvegardÃ©es: {raw_file}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-2-transform",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-2-transform",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.4 5.4 Ã‰tape 2 : Transform",
    "text": "9.4 5.4 Ã‰tape 2 : Transform\n\n\nCode\ndef transform_data(df):\n    \"\"\"Transforme et nettoie les donnÃ©es\"\"\"\n    logger.info(\"ğŸ”„ DÃ©but de la transformation\")\n    \n    df_transformed = df.copy()\n    \n    # 1. Normaliser les colonnes imbriquÃ©es\n    if 'address' in df.columns:\n        address_df = pd.json_normalize(df['address'])\n        address_df.columns = ['address_' + col for col in address_df.columns]\n        df_transformed = pd.concat([df_transformed.drop('address', axis=1), address_df], axis=1)\n        logger.info(\"âœ… Colonnes adresse normalisÃ©es\")\n    \n    # 2. Nettoyer les noms de colonnes\n    df_transformed.columns = df_transformed.columns.str.lower().str.replace('.', '_')\n    logger.info(\"âœ… Noms de colonnes nettoyÃ©s\")\n    \n    # 3. GÃ©rer les valeurs manquantes\n    null_counts = df_transformed.isnull().sum()\n    if null_counts.sum() &gt; 0:\n        logger.warning(f\"âš ï¸ {null_counts.sum()} valeurs manquantes dÃ©tectÃ©es\")\n        df_transformed = df_transformed.dropna()\n        logger.info(\"âœ… Valeurs manquantes supprimÃ©es\")\n    \n    # 4. CrÃ©er des colonnes dÃ©rivÃ©es\n    if 'name' in df_transformed.columns:\n        df_transformed['name_length'] = df_transformed['name'].str.len()\n        logger.info(\"âœ… Colonne dÃ©rivÃ©e 'name_length' crÃ©Ã©e\")\n    \n    # 5. Ajouter metadata\n    df_transformed['processed_at'] = datetime.now().isoformat()\n    \n    logger.info(f\"âœ… Transformation terminÃ©e: {len(df_transformed)} lignes\")\n    return df_transformed\n\n# Test transformation\ndf_transformed = transform_data(df_raw)\nprint(\"\\nğŸ“Š DonnÃ©es transformÃ©es :\")\nprint(df_transformed.head())\nprint(f\"\\nColonnes: {df_transformed.columns.tolist()}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-3-validate",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-3-validate",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.5 5.5 Ã‰tape 3 : Validate",
    "text": "9.5 5.5 Ã‰tape 3 : Validate\n\n\nCode\ndef validate_data(df):\n    \"\"\"Valide la qualitÃ© des donnÃ©es\"\"\"\n    logger.info(\"ğŸ” DÃ©but de la validation\")\n    \n    validator = DataValidator(df)\n    \n    # DÃ©finir les rÃ¨gles de validation\n    required_columns = ['id', 'name', 'email']\n    validator.check_columns(required_columns)\n    validator.check_nulls(max_null_pct=config.MAX_NULL_PCT)\n    validator.check_duplicates(subset=['id'])\n    \n    # GÃ©nÃ©rer le rapport\n    report = validator.report()\n    \n    if report['is_valid']:\n        logger.info(\"âœ… Validation rÃ©ussie\")\n    else:\n        logger.error(f\"âŒ Validation Ã©chouÃ©e: {report['total_errors']} erreurs\")\n        for error in report['errors']:\n            logger.error(f\"  - {error}\")\n    \n    return report\n\n# Test validation\nvalidation_report = validate_data(df_transformed)\nprint(\"\\nğŸ“‹ Rapport de validation :\")\nprint(json.dumps(validation_report, indent=2))"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-4-load",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#Ã©tape-4-load",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.6 5.6 Ã‰tape 4 : Load",
    "text": "9.6 5.6 Ã‰tape 4 : Load\n\n\nCode\ndef load_data(df, base_filename):\n    \"\"\"Exporte les donnÃ©es dans plusieurs formats\"\"\"\n    logger.info(\"ğŸ’¾ DÃ©but de l'export\")\n    \n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    files_created = []\n    \n    for format_type in config.EXPORT_FORMATS:\n        filename = f\"{config.OUTPUT_DIR}/{base_filename}_{timestamp}.{format_type}\"\n        \n        try:\n            if format_type == 'csv':\n                df.to_csv(filename, index=False)\n            elif format_type == 'parquet':\n                df.to_parquet(filename, index=False)\n            elif format_type == 'json':\n                df.to_json(filename, orient='records', indent=2)\n            \n            file_size = Path(filename).stat().st_size / 1024  # KB\n            logger.info(f\"âœ… Export {format_type.upper()}: {filename} ({file_size:.2f} KB)\")\n            files_created.append(filename)\n        except Exception as e:\n            logger.error(f\"âŒ Erreur export {format_type}: {e}\")\n    \n    return files_created\n\n# Test export\nexported_files = load_data(df_transformed, 'users_processed')\nprint(\"\\nğŸ“¦ Fichiers exportÃ©s :\")\nfor file in exported_files:\n    print(f\"  - {file}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#pipeline-complet",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#pipeline-complet",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.7 5.7 Pipeline complet",
    "text": "9.7 5.7 Pipeline complet\n\n\nCode\ndef run_pipeline():\n    \"\"\"ExÃ©cute le pipeline complet\"\"\"\n    start_time = time.time()\n    logger.info(\"=\"*50)\n    logger.info(\"ğŸš€ DÃ‰MARRAGE DU PIPELINE\")\n    logger.info(\"=\"*50)\n    \n    try:\n        # EXTRACT\n        logger.info(\"\\nğŸ“¥ PHASE 1: EXTRACTION\")\n        data = extract_from_api(f\"{config.API_URL}/users\")\n        df = pd.DataFrame(data)\n        logger.info(f\"Lignes extraites: {len(df)}\")\n        \n        # TRANSFORM\n        logger.info(\"\\nğŸ”„ PHASE 2: TRANSFORMATION\")\n        df_clean = transform_data(df)\n        logger.info(f\"Lignes aprÃ¨s transformation: {len(df_clean)}\")\n        \n        # VALIDATE\n        logger.info(\"\\nğŸ” PHASE 3: VALIDATION\")\n        validation = validate_data(df_clean)\n        \n        if not validation['is_valid']:\n            logger.error(\"âŒ Validation Ã©chouÃ©e, arrÃªt du pipeline\")\n            return False\n        \n        # LOAD\n        logger.info(\"\\nğŸ’¾ PHASE 4: EXPORT\")\n        files = load_data(df_clean, 'users_final')\n        \n        # STATISTIQUES\n        duration = time.time() - start_time\n        logger.info(\"\\n\" + \"=\"*50)\n        logger.info(\"ğŸ“Š STATISTIQUES DU PIPELINE\")\n        logger.info(\"=\"*50)\n        logger.info(f\"DurÃ©e totale: {duration:.2f}s\")\n        logger.info(f\"Lignes traitÃ©es: {len(df_clean)}\")\n        logger.info(f\"Fichiers crÃ©Ã©s: {len(files)}\")\n        logger.info(f\"Taux de rÃ©ussite: 100%\")\n        logger.info(\"=\"*50)\n        logger.info(\"âœ… PIPELINE TERMINÃ‰ AVEC SUCCÃˆS\")\n        logger.info(\"=\"*50)\n        \n        return True\n        \n    except Exception as e:\n        logger.error(f\"âŒ ERREUR FATALE: {e}\")\n        logger.exception(\"Stack trace:\")\n        return False\n\n# ExÃ©cuter le pipeline\nsuccess = run_pipeline()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-final-pipeline-complet",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#exercice-final-pipeline-complet",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "9.8 ğŸ¯ Exercice Final : Pipeline Complet",
    "text": "9.8 ğŸ¯ Exercice Final : Pipeline Complet\nObjectif : CrÃ©er votre propre pipeline ETL\n\nExtraire des donnÃ©es de posts depuis JSONPlaceholder\nEnrichir avec les donnÃ©es utilisateurs\nCalculer des statistiques (posts par utilisateur, mots par post, etc.)\nValider la qualitÃ©\nExporter dans tous les formats\nAjouter un logging complet\n\n\n\nCode\n# Ã€ VOUS DE JOUER ! ğŸ®\n# CrÃ©ez votre pipeline complet ici"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-des-configurations",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#gestion-des-configurations",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "10.1 6ï¸âƒ£ Gestion des configurations",
    "text": "10.1 6ï¸âƒ£ Gestion des configurations\n\n\nCode\n# Installer python-dotenv\n!pip install python-dotenv\n\n# CrÃ©er un fichier .env (Ã  ne JAMAIS commiter)\nenv_content = \"\"\"\nAPI_KEY=votre_cle_api_secrete\nDATABASE_URL=postgresql://user:password@localhost:5432/db\nENVIRONMENT=development\n\"\"\"\n\nwith open('.env', 'w') as f:\n    f.write(env_content)\n\nprint(\"âœ… Fichier .env crÃ©Ã©\")\nprint(\"âš ï¸ N'oubliez pas d'ajouter .env Ã  votre .gitignore !\")\n\n\n\n\nCode\nfrom dotenv import load_dotenv\nimport os\n\n# Charger les variables d'environnement\nload_dotenv()\n\n# AccÃ©der aux variables\napi_key = os.getenv('API_KEY')\ndb_url = os.getenv('DATABASE_URL')\nenv = os.getenv('ENVIRONMENT')\n\nprint(f\"ğŸ”‘ API Key: {api_key[:10]}...\")\nprint(f\"ğŸ—„ï¸ Database URL: {db_url[:30]}...\")\nprint(f\"ğŸŒ Environment: {env}\")"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#tests-unitaires-basiques",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#tests-unitaires-basiques",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "10.2 7ï¸âƒ£ Tests unitaires basiques",
    "text": "10.2 7ï¸âƒ£ Tests unitaires basiques\n\n\nCode\n# Exemple de fonction Ã  tester\ndef calculer_age_moyen(df, colonne='age'):\n    \"\"\"Calcule l'Ã¢ge moyen d'un DataFrame\"\"\"\n    if colonne not in df.columns:\n        raise ValueError(f\"Colonne '{colonne}' introuvable\")\n    return df[colonne].mean()\n\n# Tests\ndef test_calculer_age_moyen():\n    # Test avec donnÃ©es valides\n    df_test = pd.DataFrame({'age': [20, 30, 40]})\n    assert calculer_age_moyen(df_test) == 30, \"Test 1 Ã©chouÃ©\"\n    print(\"âœ… Test 1: donnÃ©es valides\")\n    \n    # Test avec colonne manquante\n    try:\n        calculer_age_moyen(pd.DataFrame({'nom': ['Alice']}), 'age')\n        print(\"âŒ Test 2 Ã©chouÃ©: devrait lever une exception\")\n    except ValueError:\n        print(\"âœ… Test 2: exception levÃ©e correctement\")\n    \n    # Test avec valeurs nulles\n    df_null = pd.DataFrame({'age': [20, None, 40]})\n    result = calculer_age_moyen(df_null)\n    assert result == 30, \"Test 3 Ã©chouÃ©\"\n    print(\"âœ… Test 3: gestion des nulls\")\n    \n    print(\"\\nğŸ‰ Tous les tests passent !\")\n\n# ExÃ©cuter les tests\ntest_calculer_age_moyen()"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#ce-que-tu-as-appris",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#ce-que-tu-as-appris",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "11.1 Ce que tu as appris âœ…",
    "text": "11.1 Ce que tu as appris âœ…\n\n\n\n\n\n\n\nSection\nCompÃ©tences acquises\n\n\n\n\nPandas\nManipulation de donnÃ©es, nettoyage, agrÃ©gations, merges\n\n\nMatplotlib\nGraphiques de base, personnalisation, export\n\n\nSeaborn\nVisualisations statistiques, heatmaps, pair plots\n\n\nTexte & Regex\nNettoyage, parsing de logs, expressions rÃ©guliÃ¨res\n\n\nAPIs\nAppels REST, pagination, retry logic\n\n\nValidation\nSchÃ©mas, checks de qualitÃ©\n\n\nPipeline ETL\nArchitecture complÃ¨te Extract-Transform-Load\n\n\nBonnes pratiques\nLogging, configuration, tests"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "11.2 ğŸ“š Ressources pour aller plus loin",
    "text": "11.2 ğŸ“š Ressources pour aller plus loin\n\n11.2.1 Documentation officielle\n\nPandas Documentation\nMatplotlib Documentation\nSeaborn Documentation\nRequests Documentation\n\n\n\n11.2.2 Tutoriels et cours\n\nReal Python - Pandas\nKaggle Learn\nDataCamp\n\n\n\n11.2.3 Outils avancÃ©s Ã  explorer\n\nPolars â€” Alternative plus rapide Ã  Pandas\nGreat Expectations â€” Validation de donnÃ©es avancÃ©e\nPandera â€” SchÃ©mas de validation pour DataFrames"
  },
  {
    "objectID": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#prochaine-Ã©tape",
    "href": "notebooks/beginner/05_python_data_processing_for_data_engineers.html#prochaine-Ã©tape",
    "title": "ğŸ“Š Python for Data Processing - Complete Guide",
    "section": "11.3 â¡ï¸ Prochaine Ã©tape",
    "text": "11.3 â¡ï¸ Prochaine Ã©tape\nMaintenant que tu maÃ®trises le traitement de donnÃ©es, passons aux bases de donnÃ©es !\nğŸ‘‰ Module suivant : 06_intro_databases.ipynb â€” Introduction aux bases de donnÃ©es\n\nğŸ‰ FÃ©licitations ! Tu as terminÃ© le module Python Data Processing pour Data Engineers."
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html",
    "href": "notebooks/beginner/03_git_for_data_engineers.html",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "",
    "text": "Objectif : Comprendre Git, GitHub et GitLab, savoir versionner ses scripts, notebooks et configurations."
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#prÃ©requis",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#prÃ©requis",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.1 ğŸ“‹ PrÃ©requis",
    "text": "0.1 ğŸ“‹ PrÃ©requis\n\n\n\nNiveau\nCompÃ©tence\n\n\n\n\nâœ… Requis\nAvoir suivi le module 02_bash_for_data_engineers\n\n\nâœ… Requis\nSavoir utiliser un terminal\n\n\nğŸŸ¡ Optionnel\nAvoir un compte GitHub ou GitLab"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#objectifs-du-module",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#objectifs-du-module",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.2 ğŸ¯ Objectifs du module",
    "text": "0.2 ğŸ¯ Objectifs du module\nÃ€ la fin de ce module, tu seras capable de : - Comprendre les concepts de versioning - Initialiser et configurer un dÃ©pÃ´t Git - MaÃ®triser le workflow : add â†’ commit â†’ push - Travailler avec les branches - Collaborer efficacement avec une Ã©quipe - Utiliser .gitignore pour protÃ©ger les donnÃ©es sensibles"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#pourquoi-git-est-essentiel-pour-un-data-engineer",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#pourquoi-git-est-essentiel-pour-un-data-engineer",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.3 ğŸ§° Pourquoi Git est essentiel pour un Data Engineer ?",
    "text": "0.3 ğŸ§° Pourquoi Git est essentiel pour un Data Engineer ?\n\n\n\n\n\n\n\nCas dâ€™usage\nExemple concret\n\n\n\n\nVersionner les pipelines\nSuivre lâ€™Ã©volution de tes scripts ETL\n\n\nCollaborer en Ã©quipe\nTravailler Ã  plusieurs sur le mÃªme projet data\n\n\nRevenir en arriÃ¨re\nRestaurer une version qui fonctionnait aprÃ¨s un bug\n\n\nCode review\nValider les modifications avant mise en production\n\n\nCI/CD\nDÃ©clencher automatiquement des tests et dÃ©ploiements\n\n\nDocumentation\nHistorique complet de qui a fait quoi et pourquoi\n\n\n\n\nğŸ’¡ En bref : Git est le systÃ¨me nerveux de tout projet data moderne. Sans Git, pas de collaboration efficace ni de traÃ§abilitÃ©."
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#dÃ©finitions-git-github-et-gitlab",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#dÃ©finitions-git-github-et-gitlab",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.4 1ï¸âƒ£ DÃ©finitions : Git, GitHub et GitLab",
    "text": "0.4 1ï¸âƒ£ DÃ©finitions : Git, GitHub et GitLab\n\n0.4.1 ğŸ§© Quâ€™est-ce que Git ?\nGit est un logiciel de gestion de versions distribuÃ©. Il permet de : - Suivre lâ€™Ã©volution de vos fichiers au fil du temps - CrÃ©er des points de restauration (commits) - Travailler en parallÃ¨le sur diffÃ©rentes fonctionnalitÃ©s (branches) - Fusionner le travail de plusieurs personnes\nğŸ“ Ton projet\n    â”‚\n    â”œâ”€â”€ ğŸ“„ pipeline.py      â† VersionnÃ© par Git\n    â”œâ”€â”€ ğŸ“„ config.yaml      â† VersionnÃ© par Git  \n    â”œâ”€â”€ ğŸ“ .git/            â† Dossier cachÃ© contenant l'historique\n    â””â”€â”€ ğŸ“ data/            â† âš ï¸ Ã€ NE PAS versionner !\n\n\n0.4.2 â˜ï¸ Quâ€™est-ce que GitHub ?\nGitHub est une plateforme cloud (propriÃ©tÃ© de Microsoft) qui hÃ©berge vos dÃ©pÃ´ts Git. - Interface web moderne - TrÃ¨s populaire pour lâ€™open source - GitHub Actions pour la CI/CD\n\n\n0.4.3 ğŸ—ï¸ Quâ€™est-ce que GitLab ?\nGitLab est une alternative open source Ã  GitHub : - Peut Ãªtre auto-hÃ©bergÃ© (on-premise) - CI/CD intÃ©grÃ© trÃ¨s puissant - Souvent utilisÃ© en entreprise"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#github-vs-gitlab-comparatif",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#github-vs-gitlab-comparatif",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.5 2ï¸âƒ£ GitHub vs GitLab â€” Comparatif",
    "text": "0.5 2ï¸âƒ£ GitHub vs GitLab â€” Comparatif\n\n\n\n\n\n\n\n\nFonctionnalitÃ©\nGitHub\nGitLab\n\n\n\n\nğŸ  HÃ©bergement\nCloud (Microsoft)\nCloud ou auto-hÃ©bergÃ©\n\n\nâš™ï¸ CI/CD\nGitHub Actions\nGitLab CI/CD (intÃ©grÃ©)\n\n\nğŸ‘¥ CommunautÃ©\nTrÃ¨s vaste (open source)\nOrientÃ© entreprise\n\n\nğŸ¨ Interface\nModerne, simple\nComplÃ¨te, personnalisable\n\n\nğŸ’° Prix\nGratuit + plans payants\nGratuit + plans payants\n\n\nğŸ”’ SÃ©curitÃ©\nDÃ©pend du plan\nPeut Ãªtre auto-hÃ©bergÃ©\n\n\nğŸ“Š Usage recommandÃ©\nProjets publics, open source\nProjets internes, entreprise\n\n\n\n\nğŸ’¡ Pour ce cours, tu peux utiliser lâ€™un ou lâ€™autre. Les commandes Git sont identiques !"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#installation-et-configuration-de-git",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#installation-et-configuration-de-git",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.6 3ï¸âƒ£ Installation et configuration de Git",
    "text": "0.6 3ï¸âƒ£ Installation et configuration de Git\n\n0.6.1 ğŸ§° Installation\n\n\n\nSystÃ¨me\nCommande\n\n\n\n\nğŸªŸ Windows\nTÃ©lÃ©charger depuis git-scm.com\n\n\nğŸ macOS\nbrew install git\n\n\nğŸ§ Linux (Debian/Ubuntu)\nsudo apt install git\n\n\nğŸ§ Linux (Fedora)\nsudo dnf install git\n\n\n\n\n\nCode\n%%bash\n# VÃ©rifier la version installÃ©e\ngit --version\n\n# Configuration obligatoire (identitÃ©)\ngit config --global user.name \"Ton Nom\"\ngit config --global user.email \"ton.email@exemple.com\"\n\n# Configuration recommandÃ©e\ngit config --global init.defaultBranch main    # Branche par dÃ©faut\ngit config --global core.editor \"code --wait\"  # Ã‰diteur (VS Code)\ngit config --global pull.rebase false          # Merge par dÃ©faut lors du pull\n\n# VÃ©rifier la configuration\ngit config --list"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#comprendre-le-workflow-git",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#comprendre-le-workflow-git",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.7 4ï¸âƒ£ Comprendre le workflow Git",
    "text": "0.7 4ï¸âƒ£ Comprendre le workflow Git\n\n0.7.1 ğŸ“Š Les 4 zones de Git\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    git add     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Working Dir    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚  Staging Area   â”‚\nâ”‚  (tes fichiers) â”‚                â”‚  (index)        â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                            â”‚ git commit\n                                            â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    git push    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  Remote         â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  Local Repo     â”‚\nâ”‚  (GitHub/GitLab)â”‚                â”‚  (.git)         â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n\n0.7.2 ğŸ”„ Cycle de vie dâ€™un fichier\n\n\n\nÃ‰tat\nDescription\nCommande pour passer Ã  lâ€™Ã©tat suivant\n\n\n\n\nUntracked\nNouveau fichier, non suivi\ngit add &lt;fichier&gt;\n\n\nStaged\nPrÃªt Ã  Ãªtre commitÃ©\ngit commit -m \"message\"\n\n\nCommitted\nEnregistrÃ© localement\ngit push\n\n\nPushed\nEnvoyÃ© sur le serveur distant\nâœ… TerminÃ©"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#clients-git-alternatives-aux-commandes",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#clients-git-alternatives-aux-commandes",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.8 ğŸ–¥ï¸ Clients Git (alternatives aux commandes)",
    "text": "0.8 ğŸ–¥ï¸ Clients Git (alternatives aux commandes)\nTu nâ€™es pas obligÃ© dâ€™utiliser le terminal ! Il existe des interfaces graphiques (GUI) pour Git qui facilitent la visualisation et certaines opÃ©rations.\n\n0.8.1 ğŸ“± Clients populaires\n\n\n\nClient\nPlateforme\nPoints forts\nPrix\n\n\n\n\nGitHub Desktop\nWindows, Mac\nSimple, parfait pour dÃ©buter, intÃ©gration GitHub\nGratuit\n\n\nGitKraken\nWindows, Mac, Linux\nInterface visuelle puissante, graphe des branches\nGratuit (public)\n\n\nSourcetree\nWindows, Mac\nComplet, supporte Git et Mercurial\nGratuit\n\n\nVS Code\nTous\nGit intÃ©grÃ© + extension GitLens\nGratuit\n\n\nPyCharm / IntelliJ\nTous\nGit intÃ©grÃ© dans lâ€™IDE\nGratuit / Payant\n\n\n\n\n\n0.8.2 ğŸ¤” Terminal vs GUI : quand utiliser quoi ?\n\n\n\n\n\n\n\nSituation\nRecommandation\n\n\n\n\nVisualiser lâ€™historique et les branches\nğŸ–¥ï¸ GUI â€” Plus clair visuellement\n\n\nRÃ©soudre des conflits de merge\nğŸ–¥ï¸ GUI â€” Comparaison cÃ´te Ã  cÃ´te\n\n\nOpÃ©rations quotidiennes (add, commit, push)\nâŒ¨ï¸ Terminal ou ğŸ–¥ï¸ GUI â€” Au choix\n\n\nScripts et automatisation (CI/CD)\nâŒ¨ï¸ Terminal â€” Obligatoire\n\n\nServeurs distants (SSH)\nâŒ¨ï¸ Terminal â€” Pas de GUI disponible\n\n\nApprendre Git en profondeur\nâŒ¨ï¸ Terminal â€” Comprendre ce qui se passe\n\n\n\n\nğŸ’¡ Conseil : Apprends dâ€™abord les commandes pour comprendre Git, puis utilise un client GUI pour gagner en productivitÃ© au quotidien."
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#utilisation-de-git-pas-Ã -pas",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#utilisation-de-git-pas-Ã -pas",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.9 5ï¸âƒ£ Utilisation de Git pas Ã  pas",
    "text": "0.9 5ï¸âƒ£ Utilisation de Git pas Ã  pas\n\n0.9.1 Ã‰tape 1 : CrÃ©er un projet et initialiser Git\n\n\nCode\n%%bash\n# CrÃ©er un dossier de projet\nmkdir mon_projet_data\ncd mon_projet_data\n\n# Initialiser Git (crÃ©e le dossier .git)\ngit init\n\n# VÃ©rifier le statut\ngit status\n\n\n\n\n0.9.2 Ã‰tape 2 : Ajouter des fichiers et commiter\n\n\nCode\n%%bash\ncd mon_projet_data\n\n# CrÃ©er un fichier Python\necho \"print('Hello Data Engineering!')\" &gt; main.py\n\n# Voir le statut (fichier untracked)\ngit status\n\n# Ajouter le fichier Ã  la staging area\ngit add main.py\n\n# Voir le statut (fichier staged)\ngit status\n\n# Commiter avec un message descriptif\ngit commit -m \"feat: ajouter script principal\"\n\n# Voir l'historique\ngit log --oneline\n\n\n\n\n0.9.3 ğŸ“ Conventions de commits (Conventional Commits)\nUtilise des prÃ©fixes standardisÃ©s pour des messages clairs :\n\n\n\n\n\n\n\n\nPrÃ©fixe\nUsage\nExemple\n\n\n\n\nfeat:\nNouvelle fonctionnalitÃ©\nfeat: ajouter extraction API\n\n\nfix:\nCorrection de bug\nfix: corriger parsing dates\n\n\ndocs:\nDocumentation\ndocs: mettre Ã  jour README\n\n\nrefactor:\nRefactoring (sans changer le comportement)\nrefactor: simplifier fonction ETL\n\n\ntest:\nAjout/modification de tests\ntest: ajouter tests unitaires\n\n\nchore:\nMaintenance, config\nchore: mettre Ã  jour dÃ©pendances\n\n\n\nExemple de bon message :\nfeat: ajouter pipeline d'extraction des donnÃ©es clients\n\n- Connexion Ã  l'API CRM\n- Transformation des donnÃ©es JSON\n- Export en format Parquet"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#le-fichier-.gitignore-essentiel-pour-data-engineers",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#le-fichier-.gitignore-essentiel-pour-data-engineers",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.10 6ï¸âƒ£ Le fichier .gitignore â€” ESSENTIEL pour Data Engineers",
    "text": "0.10 6ï¸âƒ£ Le fichier .gitignore â€” ESSENTIEL pour Data Engineers\nLe .gitignore indique Ã  Git quels fichiers NE PAS versionner.\n\n0.10.1 âš ï¸ Ne JAMAIS versionner :\n\nğŸ“Š Fichiers de donnÃ©es (CSV, Parquet, JSON volumineux)\nğŸ”‘ Secrets et credentials (mots de passe, clÃ©s API)\nğŸ“¦ DÃ©pendances (node_modules, venv)\nğŸ—‘ï¸ Fichiers temporaires (cache, logs)\n\n\n\nCode\n%%bash\ncd mon_projet_data\n\n# CrÃ©er un .gitignore pour projet Data Engineering\ncat &lt;&lt; 'EOF' &gt; .gitignore\n# ==== DONNÃ‰ES ====\n*.csv\n*.parquet\n*.json\n*.xlsx\ndata/\nraw/\nprocessed/\n\n# ==== SECRETS ====\n.env\n*.pem\n*.key\ncredentials.json\nsecrets.yaml\n\n# ==== PYTHON ====\n__pycache__/\n*.py[cod]\nvenv/\n.venv/\n*.egg-info/\n.pytest_cache/\n\n# ==== JUPYTER ====\n.ipynb_checkpoints/\n*.ipynb_checkpoints\n\n# ==== IDE ====\n.idea/\n.vscode/\n*.swp\n\n# ==== LOGS ====\n*.log\nlogs/\n\n# ==== OS ====\n.DS_Store\nThumbs.db\nEOF\n\necho \"âœ… .gitignore crÃ©Ã©\"\ncat .gitignore\n\n\n\n\n0.10.2 ğŸ’¡ Astuces .gitignore\n# Ignorer un dossier\ndata/\n\n# Ignorer tous les .csv sauf un\n*.csv\n!schema.csv\n\n# Ignorer les fichiers dans tous les sous-dossiers\n**/*.log\n\n# VÃ©rifier ce qui est ignorÃ©\ngit status --ignored\n\nğŸ”— GÃ©nÃ©rateur de .gitignore : gitignore.io"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#lier-Ã -un-dÃ©pÃ´t-distant-githubgitlab",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#lier-Ã -un-dÃ©pÃ´t-distant-githubgitlab",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.11 7ï¸âƒ£ Lier Ã  un dÃ©pÃ´t distant (GitHub/GitLab)",
    "text": "0.11 7ï¸âƒ£ Lier Ã  un dÃ©pÃ´t distant (GitHub/GitLab)\n\n0.11.1 Ã‰tape 1 : CrÃ©er un dÃ©pÃ´t sur GitHub/GitLab\n\nVa sur github.com ou gitlab.com\nClique sur â€œNew repositoryâ€ / â€œNew projectâ€\nDonne un nom (ex: mon_projet_data)\nNe coche PAS â€œInitialize with READMEâ€ (on a dÃ©jÃ  un repo local)\nCopie lâ€™URL HTTPS\n\n\n\n0.11.2 Ã‰tape 2 : Connecter le dÃ©pÃ´t local\n\n\nCode\n%%bash\ncd mon_projet_data\n\n# Ajouter le dÃ©pÃ´t distant (remplace par ton URL)\ngit remote add origin https://github.com/ton-username/mon_projet_data.git\n\n# VÃ©rifier les remotes\ngit remote -v\n\n# S'assurer d'Ãªtre sur la branche main\ngit branch -M main\n\n# Pousser le code (premiÃ¨re fois : -u pour lier la branche)\ngit push -u origin main\n\n\n\n\n0.11.3 ğŸ“¥ Cloner un projet existant\n# Cloner un dÃ©pÃ´t\ngit clone https://github.com/username/projet.git\n\n# Cloner dans un dossier spÃ©cifique\ngit clone https://github.com/username/projet.git mon_dossier\n\n\n0.11.4 ğŸ”„ Synchroniser avec le distant\n# RÃ©cupÃ©rer les modifications (fetch + merge)\ngit pull\n\n# Voir les modifications distantes sans les appliquer\ngit fetch\ngit log origin/main --oneline"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#travailler-avec-les-branches",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#travailler-avec-les-branches",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.12 8ï¸âƒ£ Travailler avec les branches",
    "text": "0.12 8ï¸âƒ£ Travailler avec les branches\nLes branches permettent de travailler sur des fonctionnalitÃ©s en parallÃ¨le sans affecter le code principal.\nmain         â—â”€â”€â”€â—â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â—  (code stable)\n                  â”‚               â†‘\nfeature/etl       â””â”€â”€â”€â—â”€â”€â”€â—â”€â”€â”€â—â”€â”€â”€â”˜     (nouvelle fonctionnalitÃ©)\n\n\nCode\n%%bash\ncd mon_projet_data\n\n# Voir les branches existantes\ngit branch\n\n# CrÃ©er une nouvelle branche\ngit branch feature/add-etl\n\n# Basculer sur la branche\ngit switch feature/add-etl\n\n# OU crÃ©er + basculer en une commande\ngit switch -c feature/add-validation\n\n# Faire des modifications\necho \"def validate(df): pass\" &gt; validation.py\ngit add validation.py\ngit commit -m \"feat: ajouter module de validation\"\n\n# Revenir sur main\ngit switch main\n\n# Fusionner la branche\ngit merge feature/add-validation\n\n# Supprimer la branche fusionnÃ©e\ngit branch -d feature/add-validation\n\n\n\n0.12.1 ğŸŒ¿ Workflow de branches recommandÃ© pour Data Engineers\nmain (production)\n  â”‚\n  â”œâ”€â”€ develop (intÃ©gration)\n  â”‚     â”‚\n  â”‚     â”œâ”€â”€ feature/etl-clients\n  â”‚     â”œâ”€â”€ feature/dashboard-ventes  \n  â”‚     â””â”€â”€ fix/bug-parsing-dates\n  â”‚\n  â””â”€â”€ hotfix/critical-fix (urgences)\n\n\n\nBranche\nUsage\n\n\n\n\nmain\nCode en production, toujours stable\n\n\ndevelop\nIntÃ©gration des features avant release\n\n\nfeature/*\nNouvelles fonctionnalitÃ©s\n\n\nfix/*\nCorrections de bugs\n\n\nhotfix/*\nCorrections urgentes en production"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#rÃ©soudre-les-conflits-de-merge",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#rÃ©soudre-les-conflits-de-merge",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.13 9ï¸âƒ£ RÃ©soudre les conflits de merge",
    "text": "0.13 9ï¸âƒ£ RÃ©soudre les conflits de merge\nUn conflit survient quand deux personnes modifient la mÃªme ligne.\n\n0.13.1 ğŸ” Ã€ quoi ressemble un conflit ?\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\ndef process_data(df):\n    return df.dropna()\n=======\ndef process_data(dataframe):\n    return dataframe.fillna(0)\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature/autre-branche\n\n\n0.13.2 âœ… Comment rÃ©soudre ?\n\nOuvrir le fichier et choisir la bonne version\nSupprimer les marqueurs (&lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, &gt;&gt;&gt;&gt;&gt;&gt;&gt;)\nTester que le code fonctionne\nCommiter la rÃ©solution\n\n# AprÃ¨s avoir Ã©ditÃ© le fichier\ngit add fichier_resolu.py\ngit commit -m \"fix: rÃ©soudre conflit sur process_data\"\n\nğŸ’¡ Astuce : Utilise un outil visuel comme VS Code pour rÃ©soudre les conflits plus facilement."
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#commandes-utiles-avancÃ©es",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#commandes-utiles-avancÃ©es",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.14 ğŸ”§ Commandes utiles avancÃ©es",
    "text": "0.14 ğŸ”§ Commandes utiles avancÃ©es\n\n0.14.1 ğŸ“¦ git stash â€” Mettre de cÃ´tÃ© temporairement\n# Sauvegarder les modifications en cours\ngit stash\n\n# Voir les stash\ngit stash list\n\n# RÃ©cupÃ©rer le dernier stash\ngit stash pop\n\n# RÃ©cupÃ©rer un stash spÃ©cifique\ngit stash apply stash@{0}\n\n\n0.14.2 â†©ï¸ï¸ Annuler des changements\n# Annuler les modifications d'un fichier (non commitÃ©)\ngit checkout -- fichier.py\n\n# Retirer un fichier de la staging area\ngit reset HEAD fichier.py\n\n# Annuler le dernier commit (garde les fichiers)\ngit reset --soft HEAD~1\n\n# Annuler le dernier commit (supprime les fichiers)\ngit reset --hard HEAD~1  # âš ï¸ DANGEREUX\n\n# CrÃ©er un commit qui annule un commit prÃ©cÃ©dent\ngit revert &lt;commit-hash&gt;\n\n\n0.14.3 ğŸ” Inspecter lâ€™historique\n# Historique compact\ngit log --oneline\n\n# Historique graphique\ngit log --oneline --graph --all\n\n# Voir les modifications d'un commit\ngit show &lt;commit-hash&gt;\n\n# Voir qui a modifiÃ© chaque ligne\ngit blame fichier.py\n\n# Chercher un commit par message\ngit log --grep=\"ETL\""
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#cheatsheet-commandes-essentielles",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#cheatsheet-commandes-essentielles",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.15 ğŸ“‹ Cheatsheet â€” Commandes essentielles",
    "text": "0.15 ğŸ“‹ Cheatsheet â€” Commandes essentielles\n\n\n\n\n\n\n\n\nCatÃ©gorie\nCommande\nDescription\n\n\n\n\nSetup\ngit init\nInitialiser un dÃ©pÃ´t\n\n\n\ngit clone &lt;url&gt;\nCloner un dÃ©pÃ´t distant\n\n\n\ngit config --global user.name\nConfigurer son nom\n\n\nBasique\ngit status\nVoir lâ€™Ã©tat des fichiers\n\n\n\ngit add &lt;fichier&gt;\nAjouter Ã  la staging area\n\n\n\ngit add .\nAjouter tous les fichiers\n\n\n\ngit commit -m \"msg\"\nEnregistrer les modifications\n\n\nHistorique\ngit log --oneline\nVoir lâ€™historique compact\n\n\n\ngit diff\nVoir les modifications\n\n\n\ngit blame &lt;fichier&gt;\nVoir qui a modifiÃ© quoi\n\n\nBranches\ngit branch\nLister les branches\n\n\n\ngit switch -c &lt;nom&gt;\nCrÃ©er et basculer\n\n\n\ngit merge &lt;branche&gt;\nFusionner une branche\n\n\n\ngit branch -d &lt;nom&gt;\nSupprimer une branche\n\n\nRemote\ngit remote add origin &lt;url&gt;\nAjouter un dÃ©pÃ´t distant\n\n\n\ngit push\nEnvoyer sur le serveur\n\n\n\ngit pull\nRÃ©cupÃ©rer du serveur\n\n\n\ngit fetch\nVÃ©rifier les changements\n\n\nAnnuler\ngit stash\nMettre de cÃ´tÃ©\n\n\n\ngit reset --soft HEAD~1\nAnnuler dernier commit\n\n\n\ngit revert &lt;hash&gt;\nCrÃ©er un commit dâ€™annulation\n\n\n\nğŸ“¥ TÃ©lÃ©charger le Git Cheatsheet officiel (PDF)"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#quiz-de-fin-de-module",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#quiz-de-fin-de-module",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.16 ğŸ§ª Quiz de fin de module",
    "text": "0.16 ğŸ§ª Quiz de fin de module\n\n\n0.16.1 â“ Q1. Git est un outil de :\n\nDesign graphique\n\nGestion de versions\n\nStockage cloud\n\nDÃ©ploiement automatique\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” Git est un systÃ¨me de gestion de versions distribuÃ©.\n\n\n\n\n0.16.2 â“ Q2. Quelle commande initialise un dÃ©pÃ´t Git ?\n\ngit start\n\ngit init\n\ngit create\n\ngit new\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” git init crÃ©e un nouveau dÃ©pÃ´t Git.\n\n\n\n\n0.16.3 â“ Q3. Quelle est la diffÃ©rence entre git commit et git push ?\n\ncommit enregistre localement, push envoie au serveur distant\n\ncommit supprime des fichiers\n\npush crÃ©e un dÃ©pÃ´t local\n\nAucune diffÃ©rence\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : a â€” commit sauvegarde localement, push synchronise avec le serveur.\n\n\n\n\n0.16.4 â“ Q4. Que faut-il mettre dans le .gitignore pour un projet Data ?\n\nLes fichiers Python\n\nLes fichiers de donnÃ©es (CSV, Parquet) et les secrets\n\nLe README\n\nTous les fichiers\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” Ne jamais versionner les donnÃ©es volumineuses ni les credentials !\n\n\n\n\n0.16.5 â“ Q5. Quelle commande crÃ©e une nouvelle branche et bascule dessus ?\n\ngit branch new\n\ngit create-branch nom\n\ngit switch -c nom\n\ngit branch -m nom\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” git switch -c nom crÃ©e et bascule sur la branche.\n\n\n\n\n0.16.6 â“ Q6. Comment annuler le dernier commit tout en gardant les fichiers ?\n\ngit delete commit\n\ngit reset --hard HEAD~1\n\ngit reset --soft HEAD~1\n\ngit undo\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” --soft garde les fichiers, --hard les supprime."
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#exercice-pratique",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#exercice-pratique",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "0.17 ğŸ’» Exercice pratique",
    "text": "0.17 ğŸ’» Exercice pratique\n\n0.17.1 ğŸ¯ Objectif\nCrÃ©er un projet Data Engineering versionnÃ© et le pousser sur GitHub/GitLab.\n\n\n0.17.2 ğŸ“ Instructions\n\nCrÃ©er un dossier projet_etl\nInitialiser Git\nCrÃ©er un .gitignore appropriÃ©\nCrÃ©er un fichier etl.py avec un script simple\nCrÃ©er un fichier README.md\nFaire un premier commit\nCrÃ©er une branche feature/add-config\nAjouter un fichier config.yaml sur cette branche\nMerger dans main\nCrÃ©er un dÃ©pÃ´t sur GitHub et pousser le code\n\n\n\n0.17.3 âœ… Solution\n\n\nğŸ“¥ Afficher la solution complÃ¨te\n\n# 1. CrÃ©er le dossier\nmkdir projet_etl && cd projet_etl\n\n# 2. Initialiser Git\ngit init\n\n# 3. CrÃ©er le .gitignore\ncat &lt;&lt; 'EOF' &gt; .gitignore\n# DonnÃ©es\n*.csv\n*.parquet\ndata/\n\n# Secrets\n.env\ncredentials.json\n\n# Python\n__pycache__/\nvenv/\nEOF\n\n# 4. CrÃ©er le script ETL\ncat &lt;&lt; 'EOF' &gt; etl.py\n#!/usr/bin/env python3\n\"\"\"Simple ETL Pipeline\"\"\"\n\ndef extract():\n    print(\"ğŸ“¥ Extracting data...\")\n    return {\"data\": [1, 2, 3]}\n\ndef transform(data):\n    print(\"ğŸ”„ Transforming data...\")\n    return {\"data\": [x * 2 for x in data[\"data\"]]}\n\ndef load(data):\n    print(\"ğŸ’¾ Loading data...\")\n    print(f\"Result: {data}\")\n\nif __name__ == \"__main__\":\n    raw = extract()\n    transformed = transform(raw)\n    load(transformed)\n    print(\"âœ… ETL completed!\")\nEOF\n\n# 5. CrÃ©er le README\ncat &lt;&lt; 'EOF' &gt; README.md\n# Projet ETL\n\nUn pipeline ETL simple pour apprendre Git.\n\n## Usage\n\n```bash\npython etl.py\nEOF"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#ressources-pour-aller-plus-loin",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "5.1 ğŸ“š Ressources pour aller plus loin",
    "text": "5.1 ğŸ“š Ressources pour aller plus loin\n\n5.1.1 ğŸ® Apprendre en pratiquant\n\nLearn Git Branching â€” Tutoriel interactif visuel\nOh My Git! â€” Jeu pour apprendre Git\nGit Katas â€” Exercices pratiques\n\n\n\n5.1.2 ğŸ“– Documentation\n\nPro Git Book â€” Livre gratuit (en franÃ§ais)\nGitHub Docs\nGitLab Docs\n\n\n\n5.1.3 ğŸ› ï¸ Outils\n\nGitHub Desktop â€” Interface graphique\nGitKraken â€” Client Git visuel\nConventional Commits â€” Standard de messages"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#conclusion",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#conclusion",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "5.2 âœ… Conclusion",
    "text": "5.2 âœ… Conclusion\nTu sais maintenant : - âœ… Ce quâ€™est Git, GitHub et GitLab - âœ… Comment initialiser et configurer un projet - âœ… Le workflow : add â†’ commit â†’ push - âœ… Travailler avec les branches - âœ… Utiliser .gitignore pour protÃ©ger les donnÃ©es sensibles - âœ… RÃ©soudre les conflits de merge - âœ… Les commandes avancÃ©es (stash, reset, revert)"
  },
  {
    "objectID": "notebooks/beginner/03_git_for_data_engineers.html#prochaine-Ã©tape",
    "href": "notebooks/beginner/03_git_for_data_engineers.html#prochaine-Ã©tape",
    "title": "ğŸ“˜ Git pour Data Engineers",
    "section": "5.3 â¡ï¸ Prochaine Ã©tape",
    "text": "5.3 â¡ï¸ Prochaine Ã©tape\nMaintenant que tu sais versionner ton code, passons aux bases de donnÃ©es !\nğŸ‘‰ Module suivant : 04_python_basics_for_data_engineers.ipynb â€” Les fondamentaux de Python\n\nğŸ‰ FÃ©licitations ! Tu as terminÃ© le module Git pour Data Engineers."
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html",
    "href": "notebooks/beginner/06_intro_databases.html",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "",
    "text": "Ce module prÃ©sente les fondamentaux des bases de donnÃ©es : types, concepts clÃ©s, et critÃ¨res de choix."
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#prÃ©requis",
    "href": "notebooks/beginner/06_intro_databases.html#prÃ©requis",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "1 ğŸ“‹ PrÃ©requis",
    "text": "1 ğŸ“‹ PrÃ©requis\n\n\n\n\n\n\n\nNiveau\nCompÃ©tence\n\n\n\n\nâœ… Requis\nAvoir suivi le module 05_python_data_processing\n\n\nâœ… Requis\nComprendre les structures de donnÃ©es (listes, dictionnaires)\n\n\nğŸŸ¡ Optionnel\nNotions de JSON"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#objectifs-du-module",
    "href": "notebooks/beginner/06_intro_databases.html#objectifs-du-module",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "2 ğŸ¯ Objectifs du module",
    "text": "2 ğŸ¯ Objectifs du module\nÃ€ la fin de ce notebook, tu seras capable de : - âœ… Comprendre ce quâ€™est une base de donnÃ©es et son rÃ´le - âœ… DiffÃ©rencier les bases SQL (relationnelles) et NoSQL - âœ… ConnaÃ®tre les diffÃ©rents types de bases NoSQL - âœ… Comprendre les concepts ACID, BASE et le thÃ©orÃ¨me CAP - âœ… Choisir le bon type de base selon le cas dâ€™usage - âœ… ConnaÃ®tre les solutions cloud et les connecteurs Python"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#dÃ©finition-simple",
    "href": "notebooks/beginner/06_intro_databases.html#dÃ©finition-simple",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "3 ğŸ¯ DÃ©finition Simple",
    "text": "3 ğŸ¯ DÃ©finition Simple\nUne base de donnÃ©es est un systÃ¨me organisÃ© qui permet de :\n\nğŸ’¾ STOCKER des informations de faÃ§on permanente\n\nğŸ” RECHERCHER rapidement nâ€™importe quelle donnÃ©e\n\nâœï¸ MODIFIER et mettre Ã  jour les informations\n\nğŸ”’ SÃ‰CURISER lâ€™accÃ¨s aux donnÃ©es sensibles\n\nğŸ”— RELIER diffÃ©rentes informations entre elles"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#en-une-phrase",
    "href": "notebooks/beginner/06_intro_databases.html#en-une-phrase",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "4 ğŸŒŸ En Une Phrase",
    "text": "4 ğŸŒŸ En Une Phrase\n\nâ€œUne base de donnÃ©es, câ€™est comme un classeur numÃ©rique gÃ©ant, ultra-organisÃ© et intelligent, capable de retrouver nâ€™importe quelle information en une fraction de seconde, mÃªme parmi des milliards de donnÃ©es.â€"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#vue-densemble-des-bases-de-donnÃ©es",
    "href": "notebooks/beginner/06_intro_databases.html#vue-densemble-des-bases-de-donnÃ©es",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "5 ğŸ—ºï¸ Vue dâ€™ensemble des bases de donnÃ©es",
    "text": "5 ğŸ—ºï¸ Vue dâ€™ensemble des bases de donnÃ©es\n                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n                        â”‚       BASES DE DONNÃ‰ES              â”‚\n                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                                       â”‚\n              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n              â”‚                        â”‚                        â”‚\n              â–¼                        â–¼                        â–¼\n    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n    â”‚   RELATIONNELLE â”‚     â”‚     NoSQL       â”‚     â”‚   SPÃ‰CIALISÃ‰ES  â”‚\n    â”‚      (SQL)      â”‚     â”‚                 â”‚     â”‚                 â”‚\n    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n             â”‚                       â”‚                       â”‚\n             â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚\n             â”‚              â”‚        â”‚        â”‚              â”‚\n             â–¼              â–¼        â–¼        â–¼              â–¼\n      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n      â”‚PostgreSQL â”‚  â”‚Document â”‚â”‚ClÃ©-Val â”‚â”‚Graphe â”‚  â”‚Time-Series â”‚\n      â”‚  MySQL    â”‚  â”‚MongoDB  â”‚â”‚ Redis  â”‚â”‚ Neo4j â”‚  â”‚ InfluxDB   â”‚\n      â”‚  Oracle   â”‚  â”‚Couchbaseâ”‚â”‚DynamoDBâ”‚â”‚       â”‚  â”‚TimescaleDB â”‚\n      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#types-de-bases-de-donnÃ©es",
    "href": "notebooks/beginner/06_intro_databases.html#types-de-bases-de-donnÃ©es",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "6 ğŸ§© Types de bases de donnÃ©es",
    "text": "6 ğŸ§© Types de bases de donnÃ©es\nIl existe 2 grandes familles de bases de donnÃ©es :\n\n\n6.1 1. ğŸ“Š Bases de donnÃ©es relationnelles (SQL)\n\n\n\n\n\n\n\n\nType\nExemples\nDescription\n\n\n\n\nRelationnelle (SQL)\nPostgreSQL, MySQL, Oracle, SQLite\nDonnÃ©es organisÃ©es en tables avec schÃ©ma strict (colonnes, types, relations). RequÃªtes SQL. ACID garanti.\n\n\n\n\n\n\n6.2 2. ğŸ“¦ Bases de donnÃ©es non relationnelles (NoSQL)\n\n\n\n\n\n\n\n\nSous-type NoSQL\nExemples\nDescription\n\n\n\n\nDocumentaire\nMongoDB, Couchbase\nStockage de documents (souvent JSON), structure flexible\n\n\nClÃ©-Valeur\nRedis, DynamoDB\nStockage ultra-rapide de paires clÃ©/valeur\n\n\nColonnes\nCassandra, Bigtable\nStockage orientÃ© colonne, idÃ©al pour volumes massifs et analytics\n\n\nGraphes\nNeo4j, ArangoDB\nModÃ©lise des relations complexes entre entitÃ©s (nÅ“uds/arÃªtes)\n\n\nTime-series\nInfluxDB, TimescaleDB\nSpÃ©cialisÃ©es pour des donnÃ©es temporelles (IoT, monitoring, logs)\n\n\n\n\n\nğŸ’¡ Le choix entre SQL et NoSQL dÃ©pend toujours du cas dâ€™usage, du volume de donnÃ©es, de la structure et de la scalabilitÃ© requise."
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#bases-de-donnÃ©es-relationnelles-sql-1",
    "href": "notebooks/beginner/06_intro_databases.html#bases-de-donnÃ©es-relationnelles-sql-1",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "7 ğŸ§± Bases de donnÃ©es relationnelles (SQL)",
    "text": "7 ğŸ§± Bases de donnÃ©es relationnelles (SQL)\nLes bases relationnelles reprÃ©sentent la forme classique, structurÃ©e et la plus utilisÃ©e dans les systÃ¨mes dâ€™information.\n\n\n7.1 ğŸ“ Structure logique\nUne base relationnelle est composÃ©e de plusieurs tables organisÃ©es en lignes et colonnes. On y retrouve :\n\n\n\n\n\n\n\nÃ‰lÃ©ment\nDescription\n\n\n\n\nğŸ—‚ï¸ Base\nConteneur global (comme un classeur)\n\n\nğŸ“‹ Table\nEnsemble de donnÃ©es organisÃ©es en lignes/colonnes\n\n\nğŸ§± Colonne\nUn champ (ex : nom, date, email)\n\n\nğŸ§ Ligne (enregistrement)\nUne donnÃ©e individuelle (ex : un client)\n\n\nğŸ”‘ ClÃ© primaire (PK)\nIdentifiant unique dâ€™une ligne\n\n\nğŸ”— ClÃ© Ã©trangÃ¨re (FK)\nRÃ©fÃ©rence vers une autre table (relation)\n\n\n\n\n\n\n7.2 ğŸ“Š Exemple simple : Table clients\n\n\n\nid (PK)\nnom\nemail\n\n\n\n\n1\nAlice\nalice@mail.com\n\n\n2\nBob\nbob@mail.com\n\n\n\n\n\n\n7.3 ğŸ”— Exemple de relation entre tables\nTable commandes (chaque commande est liÃ©e Ã  un client via client_id)\n\n\n\nid (PK)\nclient_id (FK)\nproduit\nmontant\n\n\n\n\n1\n1\nClavier\n50 â‚¬\n\n\n2\n2\nSouris\n25 â‚¬\n\n\n\n\nğŸ¯ Ici, client_id fait rÃ©fÃ©rence Ã  clients.id â†’ câ€™est une clÃ© Ã©trangÃ¨re.\n\n\n\n\n7.4 âœ… Avantages des bases relationnelles\n\nğŸ”„ RequÃªtes complexes avec jointures\nğŸ” Recherche ultra prÃ©cise (filtres, agrÃ©gatsâ€¦)\nğŸ” FiabilitÃ© grÃ¢ce aux propriÃ©tÃ©s ACID\nğŸ“Š TrÃ¨s utilisÃ©es en BI, CRM, e-commerce, RH, financeâ€¦\n\n\n\n\n7.5 ğŸ” ACID : 4 garanties pour la fiabilitÃ© des transactions\nLes bases SQL appliquent le modÃ¨le ACID pour sÃ©curiser toutes les opÃ©rations :\n\n\n\n\n\n\n\n\nLettre\nPropriÃ©tÃ©\nDescription\n\n\n\n\nA\nAtomicitÃ©\nTout ou rien : une transaction est indivisible\n\n\nC\nCohÃ©rence\nLâ€™Ã©tat de la base reste toujours valide\n\n\nI\nIsolation\nLes transactions simultanÃ©es ne se gÃªnent pas\n\n\nD\nDurabilitÃ©\nUne fois validÃ©e, une transaction est permanente mÃªme en cas de crash\n\n\n\n\nğŸ’¡ Exemple : lors dâ€™un virement bancaire, le dÃ©bit ET le crÃ©dit doivent rÃ©ussir. Sinon, rien ne change.\n\n\nğŸ“Œ Bases relationnelles courantes :\nPostgreSQL, MySQL, Oracle, SQL Server, SQLite\nğŸ“¦ Cas dâ€™usage frÃ©quents :\nERP, CRM, finance, gestion RH, e-commerce, data warehouse"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#bases-de-donnÃ©es-nosql",
    "href": "notebooks/beginner/06_intro_databases.html#bases-de-donnÃ©es-nosql",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "8 ğŸ“¦ Bases de donnÃ©es NoSQL",
    "text": "8 ğŸ“¦ Bases de donnÃ©es NoSQL\nContrairement aux bases relationnelles, les bases NoSQL sont conÃ§ues pour plus de flexibilitÃ©, scalabilitÃ© et performance, souvent au dÃ©triment du schÃ©ma strict.\n\n\n8.1 ğŸ”„ Pourquoi â€œNoSQLâ€ ?\n\nâ€œNoSQLâ€ signifie Not Only SQL (pas seulement SQL)\nCes bases nâ€™utilisent pas forcÃ©ment de tables ou de schÃ©mas fixes\nTrÃ¨s utilisÃ©es pour des donnÃ©es non structurÃ©es ou semi-structurÃ©es\nSont souvent hautement distribuÃ©es et scalables horizontalement\nSâ€™accommodent bien de la haute disponibilitÃ© et la tolÃ©rance aux pannes\nNe garantissent pas toujours les propriÃ©tÃ©s ACID, mais souvent BASE\n\n\n\n\n8.2 ğŸ§© Principaux types de NoSQL\n\n\n\n\n\n\n\n\n\nType\nExemples\nDescription\nCas dâ€™usage\n\n\n\n\nDocument\nMongoDB, Couchbase\nDonnÃ©es stockÃ©es sous forme de documents (JSON, BSON)\nApps web, APIs REST, CMS\n\n\nClÃ©-Valeur\nRedis, DynamoDB\nAccÃ¨s rapide par clÃ© unique Ã  une valeur\nCache, sessions utilisateurs\n\n\nColonnes\nCassandra, Bigtable, HBase\nDonnÃ©es stockÃ©es par colonnes (plutÃ´t que lignes)\nBig Data, analyses temps rÃ©el\n\n\nGraphes\nNeo4j, ArangoDB\nStockage orientÃ© relation (nÅ“uds et arÃªtes)\nRÃ©seaux sociaux, moteurs de recommandation\n\n\nTime-Series\nInfluxDB, TimescaleDB\nOptimisÃ©es pour les sÃ©ries temporelles horodatÃ©es\nIoT, monitoring, logs serveur\n\n\n\n\n\n\n8.3 ğŸ” CaractÃ©ristiques gÃ©nÃ©rales des bases NoSQL\n\n\n\n\n\n\n\nCaractÃ©ristique\nDÃ©tail\n\n\n\n\nğŸ“„ Flexible\nSchÃ©ma souple, donnÃ©es hÃ©tÃ©rogÃ¨nes possibles\n\n\nğŸŒ DistribuÃ©e\nRÃ©partition naturelle sur plusieurs nÅ“uds ou datacenters\n\n\nâš¡ Haute performance\nOptimisÃ©e pour lectures/Ã©critures massives\n\n\nğŸ“ˆ Scalable horizontalement\nAjout facile de serveurs sans changer lâ€™architecture\n\n\nğŸ” Ã‰ventuellement cohÃ©rente (BASE)\nPas toujours ACID, mais plus adaptÃ©e Ã  la disponibilitÃ©\n\n\nğŸ”Œ SpÃ©cialisÃ©e\nChaque type rÃ©pond Ã  un besoin prÃ©cis (graphe, temps rÃ©el, etc.)\n\n\n\n\nğŸ’¡ BASE = Basically Available, Soft state, Eventually consistent\n\n\n\n\n8.4 ğŸ“š Exemple (MongoDB â€” type Document)\n{\n  \"nom\": \"Alice\",\n  \"email\": \"alice@mail.com\",\n  \"commandes\": [\n    { \"produit\": \"Clavier\", \"montant\": 50 },\n    { \"produit\": \"Souris\", \"montant\": 25 }\n  ]\n}\n\n## âš–ï¸ Comparaison : Bases relationnelles vs NoSQL\n\n| CritÃ¨re                     | Bases Relationnelles (SQL)                                 | Bases NoSQL                                           |\n|-----------------------------|-------------------------------------------------------------|--------------------------------------------------------|\n| ğŸ§± Structure                | Tables rigides (lignes & colonnes, schÃ©ma fixe)             | SchÃ©ma flexible (documents, paires clÃ©/valeur, etc.)   |\n| ğŸ§  ModÃ¨le de donnÃ©es        | Relationnel (jointures, normalisation)                      | Non relationnel (document, graphe, colonnes, etc.)     |\n| ğŸ› ï¸ Langage                 | SQL (standardisÃ©)                                           | Propre Ã  chaque moteur (Mongo Query, Cypher, CQLâ€¦)     |\n| ğŸ” CohÃ©rence               | Forte (ACID)                                                | Faible ou Ã©ventuelle (BASE)                            |\n| ğŸ“ Contraintes              | Types, clÃ©s primaires/Ã©trangÃ¨res, contraintes dâ€™unicitÃ©     | Peu ou pas de contraintes                              |\n| âš™ï¸ ScalabilitÃ©             | Verticale (gros serveur)                                   | Horizontale (ajout de nÅ“uds)                           |\n| âš¡ Performance              | OptimisÃ©e pour les jointures et les relations complexes     | OptimisÃ©e pour la vitesse et la haute disponibilitÃ©    |\n| ğŸ“ˆ Volume de donnÃ©es        | AdaptÃ© aux donnÃ©es structurÃ©es                              | AdaptÃ© aux gros volumes non structurÃ©s ou distribuÃ©s    |\n| ğŸ”„ FlexibilitÃ©              | Moindre (changement de schÃ©ma difficile)                    | TrÃ¨s flexible (Ã©volution facile du modÃ¨le)             |\n| ğŸ§© Cas dâ€™usage typique     | ERP, finance, CRM, entrepÃ´t de donnÃ©es                      | Apps temps rÃ©el, IoT, rÃ©seaux sociaux, analytics       |\n| ğŸŒ Exemples                 | PostgreSQL, MySQL, Oracle, SQL Server                       | MongoDB, Cassandra, Redis, Neo4j, InfluxDB             |\n\n---\n\n&gt; ğŸ§  **En pratique :** beaucoup dâ€™architectures modernes utilisent les **deux types** en fonction des besoins :\n&gt; - SQL pour les donnÃ©es structurÃ©es et critiques\n&gt; - NoSQL pour les donnÃ©es massives, Ã©volutives ou semi-structurÃ©es\n\n## ğŸ§ª Le modÃ¨le BASE â€“ La logique NoSQL\n\nAlors qu'**ACID** est la norme des bases relationnelles pour garantir la **fiabilitÃ© stricte**, les bases **NoSQL** reposent sur un modÃ¨le plus souple appelÃ© **BASE**.\n\n---\n\n### ğŸ’¡ BASE = Basically Available, Soft state, Eventually consistent\n\n| Terme                    | Signification                  | Explication |\n|--------------------------|--------------------------------|-------------|\n| **Basically Available**  | Toujours disponible            | Le systÃ¨me rÃ©pond toujours, mÃªme en cas de panne partielle |\n| **Soft State**           | Ã‰tat temporairement instable   | Lâ€™Ã©tat peut Ã©voluer mÃªme sans nouvelle requÃªte explicite (par ex. : rÃ©plication en cours) |\n| **Eventually Consistent**| CohÃ©rence Ã  terme              | Toutes les copies de donnÃ©es finissent par devenir cohÃ©rentes, mais pas immÃ©diatement |\n\n---\n\n## âš–ï¸ BASE privilÃ©gie : DisponibilitÃ© + ScalabilitÃ©\n\nContrairement Ã  ACID qui privilÃ©gie la **cohÃ©rence immÃ©diate**, BASE assume un compromis :\n\n| PrioritÃ© BASE / NoSQL         | Pourquoi ? |\n|-------------------------------|------------|\n| âœ… **DisponibilitÃ©**           | Fournir une rÃ©ponse mÃªme en cas de dÃ©faillance rÃ©seau |\n| âœ… **ScalabilitÃ© horizontale** | GÃ©rer des volumes Ã©normes de donnÃ©es en rÃ©partissant la charge |\n| âš ï¸ **CohÃ©rence immÃ©diate ?**   | Pas garantie â€“ on accepte une cohÃ©rence **Ã  terme** (*eventually consistent*) |\n\n&gt; ğŸ§  BASE est utilisÃ© par des gÃ©ants comme **Amazon**, **Netflix**, **Facebook**, qui gÃ¨rent des milliards dâ€™opÃ©rations et prÃ©fÃ¨rent la **performance** Ã  la cohÃ©rence stricte.\n\n---\n\n## ğŸŒ Pourquoi BASE ? â†’ Car les systÃ¨mes sont distribuÃ©s !\n\nUn **systÃ¨me distribuÃ©** est un ensemble de machines (nÅ“uds) connectÃ©es en rÃ©seau qui travaillent ensemble. Ce modÃ¨le permet :\n\n- ğŸ“ˆ ScalabilitÃ©\n- ğŸ›¡ï¸ RÃ©silience aux pannes\n- âš¡ RÃ©duction de la latence\n\nMais cela complique la cohÃ©rence ! Dâ€™oÃ¹ la naissance du thÃ©orÃ¨me CAP ğŸ‘‡\n\n---\n\n## ğŸ“š ThÃ©orÃ¨me CAP â€“ Le fondement du modÃ¨le BASE\n\nLe **thÃ©orÃ¨me CAP** (Eric Brewer, 2000) affirme quâ€™un systÃ¨me **distribuÃ©** ne peut garantir simultanÃ©ment **les trois propriÃ©tÃ©s suivantes** :\n\n| Lettre | PropriÃ©tÃ©                    | Description |\n|--------|------------------------------|-------------|\n| **C**  | Consistency (CohÃ©rence)      | Tous les nÅ“uds voient les mÃªmes donnÃ©es au mÃªme moment |\n| **A**  | Availability (DisponibilitÃ©) | Chaque requÃªte reÃ§oit une rÃ©ponse, mÃªme en cas de panne |\n| **P**  | Partition tolerance          | Le systÃ¨me continue Ã  fonctionner malgrÃ© une perte de communication entre nÅ“uds |\n\n---\n\n### ğŸ’¥ CAP implique un choix : 2 sur 3 maximum\n\nEn cas de panne rÃ©seau, tu dois **sacrifier soit la cohÃ©rence, soit la disponibilitÃ©**.\n\n| SystÃ¨me            | Garantit CAP | Exemple                        |\n|--------------------|--------------|--------------------------------|\n| **SQL classique**  | CA            | Oracle, MySQL (single instance) |\n| **NoSQL scalable** | AP            | Cassandra, Couchbase           |\n| **NoSQL cohÃ©rent** | CP            | MongoDB, HBase                 |\n\n---\n\n## ğŸ“¦ BASE = AP selon CAP\n\nLe modÃ¨le BASE **priorise** :\n\n- âœ… **A** : DisponibilitÃ©\n- âœ… **P** : TolÃ©rance aux partitions\n- âŒ **C** : Pas de cohÃ©rence stricte\n\n---\n\n## ğŸ§® Tableau rÃ©capitulatif : ACID vs BASE vs CAP\n\n| ModÃ¨le          | Objectif                | CohÃ©rence     | DisponibilitÃ© | TolÃ©rance aux partitions | ScalabilitÃ©        |\n|-----------------|-------------------------|---------------|----------------|----------------------------|---------------------|\n| **ACID (SQL)**  | IntÃ©gritÃ© stricte       | âœ… ImmÃ©diate  | âš ï¸ Variable     | âŒ Non                     | âŒ LimitÃ© (verticale) |\n| **BASE (NoSQL)**| Performance Ã  grande Ã©chelle | â— Ã‰ventuelle | âœ… Forte        | âœ… Forte                   | âœ… Excellente (horizontale) |\n| **CAP (principe)** | Choix forcÃ©           | 2 sur 3       | 2 sur 3        | 2 sur 3                    | â€“                   |\n\n---\n\n### ğŸ§  Ã€ retenir\n\n- **ACID** = Tout doit Ãªtre cohÃ©rent, mÃªme si câ€™est lent\n- **BASE** = Le systÃ¨me reste rapide et dispo, quitte Ã  Ãªtre incohÃ©rent temporairement\n- **CAP** = Tu choisis ce que tu sacrifies : cohÃ©rence, disponibilitÃ©, ou tolÃ©rance aux pannes\n\n## ğŸ¤” Comment choisir sa base de donnÃ©es ?\n\n### ğŸ“Š Arbre de dÃ©cision simplifiÃ©\nTes donnÃ©es ont-elles une structure fixe et des relations ? â”‚ â”œâ”€â”€ OUI â†’ As-tu besoin de transactions ACID ? â”‚ â”‚ â”‚ â”œâ”€â”€ OUI â†’ ğŸ—„ï¸ SQL (PostgreSQL, MySQL) â”‚ â”‚ â”‚ â””â”€â”€ NON â†’ Volume &gt; 1TB et scalabilitÃ© horizontale ? â”‚ â”‚ â”‚ â”œâ”€â”€ OUI â†’ ğŸ“Š Colonnes (Cassandra) â”‚ â””â”€â”€ NON â†’ ğŸ—„ï¸ SQL reste un bon choix â”‚ â””â”€â”€ NON â†’ Quel type de donnÃ©es ? â”‚ â”œâ”€â”€ Documents JSON flexibles â†’ ğŸ“„ MongoDB â”œâ”€â”€ Cache / Sessions â†’ âš¡ Redis â”œâ”€â”€ Relations complexes â†’ ğŸ”— Neo4j â””â”€â”€ MÃ©triques temporelles â†’ ğŸ“ˆ InfluxDB\n\n### ğŸ¯ Guide rapide par cas d'usage\n\n| Cas d'usage | Base recommandÃ©e | Pourquoi |\n|-------------|------------------|----------|\n| **E-commerce** | PostgreSQL | Transactions, relations produits/commandes |\n| **Application mobile** | MongoDB | SchÃ©ma flexible, JSON natif |\n| **Cache / Sessions** | Redis | Ultra-rapide, en mÃ©moire |\n| **RÃ©seau social** | Neo4j | Relations amis, recommandations |\n| **IoT / Monitoring** | InfluxDB | OptimisÃ© pour les sÃ©ries temporelles |\n| **Big Data analytics** | Cassandra | ScalabilitÃ© horizontale massive |\n| **Data Warehouse** | PostgreSQL / Snowflake | RequÃªtes analytiques complexes |\n| **Logs / Search** | Elasticsearch | Recherche full-text, agrÃ©gations |\n\n---\n\n## â˜ï¸ Bases de donnÃ©es Cloud (Managed Services)\n\nLes cloud providers proposent des bases de donnÃ©es **managÃ©es** : pas de serveur Ã  gÃ©rer, backups automatiques, scalabilitÃ© simplifiÃ©e.\n\n### ğŸ¢ Services par provider\n\n| Type | AWS | GCP | Azure |\n|------|-----|-----|-------|\n| **SQL** | RDS, Aurora | Cloud SQL | Azure SQL |\n| **Document** | DocumentDB | Firestore | Cosmos DB |\n| **ClÃ©-Valeur** | ElastiCache, DynamoDB | Memorystore | Cache for Redis |\n| **Data Warehouse** | Redshift | BigQuery | Synapse |\n| **Time-Series** | Timestream | â€“ | Time Series Insights |\n\n### âœ… Avantages du Cloud\n\n| Avantage | Description |\n|----------|-------------|\n| ğŸ”§ **ZÃ©ro maintenance** | Mises Ã  jour, patches gÃ©rÃ©s automatiquement |\n| ğŸ’¾ **Backups automatiques** | Snapshots rÃ©guliers, point-in-time recovery |\n| ğŸ“ˆ **ScalabilitÃ©** | Augmenter les ressources en quelques clics |\n| ğŸŒ **Haute disponibilitÃ©** | RÃ©plication multi-zones |\n| ğŸ’° **Pay-as-you-go** | Payer uniquement ce qu'on consomme |\n\n### âš ï¸ Points d'attention\n\n- ğŸ’¸ **CoÃ»ts** : Peut devenir cher Ã  grande Ã©chelle\n- ğŸ”’ **Vendor lock-in** : Migration difficile entre providers\n- ğŸŒ **Latence** : DÃ©pend de la rÃ©gion choisie\n\n---\n\n## ğŸ Connexion Python aux bases de donnÃ©es\n\nEn tant que Data Engineer, tu utiliseras Python pour interagir avec les bases. Voici les principaux connecteurs :\n\n### ğŸ“¦ Connecteurs par type de base\n\n| Type | Package Python | Installation | Usage |\n|------|----------------|--------------|-------|\n| **PostgreSQL** | `psycopg2` | `pip install psycopg2-binary` | Connexion native |\n| **MySQL** | `mysql-connector` | `pip install mysql-connector-python` | Connexion native |\n| **SQLite** | `sqlite3` | Inclus dans Python | Bases locales |\n| **MongoDB** | `pymongo` | `pip install pymongo` | Documents JSON |\n| **Redis** | `redis` | `pip install redis` | Cache |\n| **Elasticsearch** | `elasticsearch` | `pip install elasticsearch` | Search |\n\n### ğŸ”§ SQLAlchemy â€” L'ORM universel\n\n**SQLAlchemy** est un ORM (Object-Relational Mapper) qui permet d'interagir avec **n'importe quelle base SQL** de faÃ§on unifiÃ©e.\n\n```python\n# Installation\n# pip install sqlalchemy\n\nfrom sqlalchemy import create_engine\n\n# Connexion Ã  diffÃ©rentes bases avec la mÃªme syntaxe\nengine_pg = create_engine('postgresql://user:pass@localhost/db')\nengine_mysql = create_engine('mysql://user:pass@localhost/db')\nengine_sqlite = create_engine('sqlite:///local.db')\n\nğŸ’¡ Conseil : Utilise SQLAlchemy pour les projets professionnels. Il facilite les migrations entre bases."
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#quiz-de-fin-de-module",
    "href": "notebooks/beginner/06_intro_databases.html#quiz-de-fin-de-module",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "9 ğŸ§ª Quiz de fin de module",
    "text": "9 ğŸ§ª Quiz de fin de module\n\n\n9.1 â“ Q1. Que signifie â€œACIDâ€ ?\n\nAutomatisation, CohÃ©rence, Indexation, DurabilitÃ©\n\nAtomicitÃ©, CohÃ©rence, Isolation, DurabilitÃ©\n\nArchitecture, Chargement, IntÃ©gration, DisponibilitÃ©\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” ACID garantit la fiabilitÃ© des transactions.\n\n\n\n\n9.2 â“ Q2. Quelle base de donnÃ©es est orientÃ©e â€œdocumentsâ€ ?\n\nMySQL\n\nMongoDB\n\nRedis\n\nNeo4j\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” MongoDB stocke des documents JSON/BSON.\n\n\n\n\n9.3 â“ Q3. Quel type de base est le plus adaptÃ© Ã  une application e-commerce structurÃ©e ?\n\nRelationnelle (SQL)\n\nGraphe\n\nTime Series\n\nClÃ©-Valeur\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : a â€” Les relations produits/commandes/clients sont parfaites pour SQL.\n\n\n\n\n9.4 â“ Q4. Que signifie BASE ?\n\nBackup Always Secured Engine\n\nBasically Available, Soft state, Eventually consistent\n\nBinary API Storage Engine\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” BASE privilÃ©gie la disponibilitÃ© Ã  la cohÃ©rence immÃ©diate.\n\n\n\n\n9.5 â“ Q5. Selon le thÃ©orÃ¨me CAP, combien de propriÃ©tÃ©s peut-on garantir simultanÃ©ment ?\n\n1\n\n2\n\n3\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” On peut garantir 2 propriÃ©tÃ©s sur 3 (C, A, P).\n\n\n\n\n9.6 â“ Q6. Quelle base utiliser pour du cache ultra-rapide ?\n\nPostgreSQL\n\nMongoDB\n\nRedis\n\nCassandra\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : c â€” Redis est une base clÃ©-valeur en mÃ©moire, parfaite pour le cache.\n\n\n\n\n9.7 â“ Q7. Quel ORM Python permet de se connecter Ã  plusieurs types de bases SQL ?\n\npymongo\n\nSQLAlchemy\n\npsycopg2\n\nredis-py\n\n\n\nğŸ’¡ Voir la rÃ©ponse\n\nâœ… RÃ©ponse : b â€” SQLAlchemy est un ORM universel pour les bases SQL."
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#ressources-pour-aller-plus-loin",
    "href": "notebooks/beginner/06_intro_databases.html#ressources-pour-aller-plus-loin",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "10 ğŸ“š Ressources pour aller plus loin",
    "text": "10 ğŸ“š Ressources pour aller plus loin\n\n10.1 ğŸ“– Documentation officielle\n\nPostgreSQL Documentation\nMongoDB Manual\nRedis Documentation\nSQLAlchemy Tutorial\n\n\n\n10.2 ğŸ“ Cours et tutoriels\n\nDatabase Design Course (freeCodeCamp)\nSQL vs NoSQL Explained\nCAP Theorem Visualized\n\n\n\n10.3 ğŸ› ï¸ Outils utiles\n\nDB-Engines Ranking â€” Classement des bases de donnÃ©es\nDBDiagram.io â€” CrÃ©er des schÃ©mas de base\nSQL Fiddle â€” Tester du SQL en ligne"
  },
  {
    "objectID": "notebooks/beginner/06_intro_databases.html#prochaine-Ã©tape",
    "href": "notebooks/beginner/06_intro_databases.html#prochaine-Ã©tape",
    "title": "ğŸ§  Introduction aux bases de donnÃ©es pour Data Engineers",
    "section": "11 â¡ï¸ Prochaine Ã©tape",
    "text": "11 â¡ï¸ Prochaine Ã©tape\nMaintenant que tu comprends les concepts des bases de donnÃ©es, passons Ã  la pratique avec SQL !\nğŸ‘‰ Module suivant : 07_sql_for_data_engineers.ipynb â€” RequÃªtes SQL pour Data Engineers\n\nğŸ‰ FÃ©licitations ! Tu as terminÃ© le module Introduction aux bases de donnÃ©es."
  },
  {
    "objectID": "index.html#pourquoi-ce-bootcamp",
    "href": "index.html#pourquoi-ce-bootcamp",
    "title": "Bootcamp Data Engineering â€“ From Zero to Hero",
    "section": "1.1 ğŸ¯ Pourquoi ce Bootcamp ?",
    "text": "1.1 ğŸ¯ Pourquoi ce Bootcamp ?\nBienvenue dans le Bootcamp Data Engineering â€“ From Zero to Hero, un programme structurÃ© pensÃ© pour :\n\napprendre les bases solides du Data Engineering,\n\nmaÃ®triser les outils modernes utilisÃ©s par les Data Engineers professionnels,\n\ncomprendre les architectures data dâ€™entreprise,\n\npratiquer avec des notebooks interactifs et des projets concrets,\n\nprogresser du niveau DÃ©butant â†’ IntermÃ©diaire â†’ AvancÃ©.",
    "crumbs": [
      "Bootcamp Data Engineering â€“ From Zero to Hero"
    ]
  },
  {
    "objectID": "index.html#structure-du-programme",
    "href": "index.html#structure-du-programme",
    "title": "Bootcamp Data Engineering â€“ From Zero to Hero",
    "section": "1.2 ğŸ“˜ Structure du programme",
    "text": "1.2 ğŸ“˜ Structure du programme\n\n1.2.1 ğŸŸ¦ DÃ©butant\n\nPython pour les Data Engineers\n\nBash, Git, Bases de donnÃ©es\n\nSQL, Pandas, PySpark\n\nArchitecture de bases & premiers pipelines\n\n\n\n1.2.2 ğŸŸ© IntermÃ©diaire\n\nSpark avancÃ©, Scala\n\nKafka & streaming\n\nDocker, Kubernetes\n\nData Lakes, Lakehouse, Polars, DuckDB\n\nData Quality, Governance, CI/CD\n\n\n\n1.2.3 ğŸŸ¥ AvancÃ©\n\nDistributed Systems\n\nAdvanced Streaming (Flink/Spark)\n\nLakehouse Internals\n\nMLOps, MLflow, Kubeflow\n\nSRE/Observability pour la Data\n\nFinOps et architectures cloud Ã  grande Ã©chelle",
    "crumbs": [
      "Bootcamp Data Engineering â€“ From Zero to Hero"
    ]
  },
  {
    "objectID": "index.html#ready-to-start",
    "href": "index.html#ready-to-start",
    "title": "Bootcamp Data Engineering â€“ From Zero to Hero",
    "section": "1.3 ğŸš€ Ready to Start?",
    "text": "1.3 ğŸš€ Ready to Start?\nğŸ‘‰ Navigue dans le menu Ã  gauche pour commencer ton parcours.\nğŸ‘‰ Tu peux contribuer ou proposer des amÃ©liorations via GitHub.\nBonne montÃ©e en compÃ©tence ! ğŸ’ª",
    "crumbs": [
      "Bootcamp Data Engineering â€“ From Zero to Hero"
    ]
  }
]